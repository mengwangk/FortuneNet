{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "04_02_automated_machine_learning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengwangk/dl-projects/blob/master/04_09_auto_ml_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4hyoPGdjpqa_"
      },
      "source": [
        "# Automated ML - Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLxr2k_ue8yq",
        "colab": {}
      },
      "source": [
        "COLAB = True\n",
        "\n",
        "DATASET_NAME = '4D.zip'\n",
        "\n",
        "FEATURE_DATASET_PREFIX = 'feature_matrix_d2_v3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wwYshXtLt7b7",
        "colab": {}
      },
      "source": [
        "#!pip install -U imblearn\n",
        "#!pip install -U xgboost\n",
        "# !pip install -U featuretools\n",
        "\n",
        "# https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28\n",
        "# https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
        "# https://machinelearningmastery.com/imbalanced-classification-model-to-detect-oil-spills/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oy5ww2zRfFGG",
        "outputId": "4de30d4c-ca2a-4119-ac8f-a7cd7f1e2b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "if COLAB:\n",
        "  !rm -rf dl-projects\n",
        "  !git clone https://github.com/mengwangk/dl-projects"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dl-projects'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/64)\u001b[K\rremote: Counting objects:   3% (2/64)\u001b[K\rremote: Counting objects:   4% (3/64)\u001b[K\rremote: Counting objects:   6% (4/64)\u001b[K\rremote: Counting objects:   7% (5/64)\u001b[K\rremote: Counting objects:   9% (6/64)\u001b[K\rremote: Counting objects:  10% (7/64)\u001b[K\rremote: Counting objects:  12% (8/64)\u001b[K\rremote: Counting objects:  14% (9/64)\u001b[K\rremote: Counting objects:  15% (10/64)\u001b[K\rremote: Counting objects:  17% (11/64)\u001b[K\rremote: Counting objects:  18% (12/64)\u001b[K\rremote: Counting objects:  20% (13/64)\u001b[K\rremote: Counting objects:  21% (14/64)\u001b[K\rremote: Counting objects:  23% (15/64)\u001b[K\rremote: Counting objects:  25% (16/64)\u001b[K\rremote: Counting objects:  26% (17/64)\u001b[K\rremote: Counting objects:  28% (18/64)\u001b[K\rremote: Counting objects:  29% (19/64)\u001b[K\rremote: Counting objects:  31% (20/64)\u001b[K\rremote: Counting objects:  32% (21/64)\u001b[K\rremote: Counting objects:  34% (22/64)\u001b[K\rremote: Counting objects:  35% (23/64)\u001b[K\rremote: Counting objects:  37% (24/64)\u001b[K\rremote: Counting objects:  39% (25/64)\u001b[K\rremote: Counting objects:  40% (26/64)\u001b[K\rremote: Counting objects:  42% (27/64)\u001b[K\rremote: Counting objects:  43% (28/64)\u001b[K\rremote: Counting objects:  45% (29/64)\u001b[K\rremote: Counting objects:  46% (30/64)\u001b[K\rremote: Counting objects:  48% (31/64)\u001b[K\rremote: Counting objects:  50% (32/64)\u001b[K\rremote: Counting objects:  51% (33/64)\u001b[K\rremote: Counting objects:  53% (34/64)\u001b[K\rremote: Counting objects:  54% (35/64)\u001b[K\rremote: Counting objects:  56% (36/64)\u001b[K\rremote: Counting objects:  57% (37/64)\u001b[K\rremote: Counting objects:  59% (38/64)\u001b[K\rremote: Counting objects:  60% (39/64)\u001b[K\rremote: Counting objects:  62% (40/64)\u001b[K\rremote: Counting objects:  64% (41/64)\u001b[K\rremote: Counting objects:  65% (42/64)\u001b[K\rremote: Counting objects:  67% (43/64)\u001b[K\rremote: Counting objects:  68% (44/64)\u001b[K\rremote: Counting objects:  70% (45/64)\u001b[K\rremote: Counting objects:  71% (46/64)\u001b[K\rremote: Counting objects:  73% (47/64)\u001b[K\rremote: Counting objects:  75% (48/64)\u001b[K\rremote: Counting objects:  76% (49/64)\u001b[K\rremote: Counting objects:  78% (50/64)\u001b[K\rremote: Counting objects:  79% (51/64)\u001b[K\rremote: Counting objects:  81% (52/64)\u001b[K\rremote: Counting objects:  82% (53/64)\u001b[K\rremote: Counting objects:  84% (54/64)\u001b[K\rremote: Counting objects:  85% (55/64)\u001b[K\rremote: Counting objects:  87% (56/64)\u001b[K\rremote: Counting objects:  89% (57/64)\u001b[K\rremote: Counting objects:  90% (58/64)\u001b[K\rremote: Counting objects:  92% (59/64)\u001b[K\rremote: Counting objects:  93% (60/64)\u001b[K\rremote: Counting objects:  95% (61/64)\u001b[K\rremote: Counting objects:  96% (62/64)\u001b[K\rremote: Counting objects:  98% (63/64)\u001b[K\rremote: Counting objects: 100% (64/64)\u001b[K\rremote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 1866 (delta 39), reused 7 (delta 3), pack-reused 1802\u001b[K\n",
            "Receiving objects: 100% (1866/1866), 76.79 MiB | 12.77 MiB/s, done.\n",
            "Resolving deltas: 100% (1150/1150), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G2xin10SfozR",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  !cp dl-projects/utils* .\n",
        "  !cp dl-projects/preprocess* .\n",
        "  !cp dl-projects/plot* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fC2-l3JBpqbE",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "# %reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TP7V_IzepqbK",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "import matplotlib\n",
        "import sys\n",
        "import gc\n",
        "\n",
        "from scipy import stats\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import featuretools as ft\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, make_scorer, recall_score, roc_curve, mean_squared_error, accuracy_score, average_precision_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedShuffleSplit, RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from imblearn.under_sampling import (RandomUnderSampler, \n",
        "                                     ClusterCentroids,\n",
        "                                     TomekLinks,\n",
        "                                     NeighbourhoodCleaningRule,\n",
        "                                     AllKNN,\n",
        "                                     NearMiss,\n",
        "                                     OneSidedSelection,\n",
        "                                     EditedNearestNeighbours)\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN\n",
        "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
        "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
        "from imblearn.over_sampling import SMOTE, SMOTENC, ADASYN \n",
        "import pylab as pl\n",
        "import xgboost as xgb\n",
        "from collections import Counter\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "\n",
        "# from skopt import BayesSearchCV\n",
        "# from skopt.space import Real, Categorical, Integer\n",
        "# from scikitplot.plotters import plot_precision_recall_curve\n",
        "\n",
        "from utils import feature_selection, plot_feature_importances\n",
        "from preprocess import *\n",
        "from plot import plot_correlation_matrix, plot_labeled_scatter\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "# The Answer to the Ultimate Question of Life, the Universe, and Everything.\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3bFT5CoxpqbP",
        "outputId": "7be9f1f0-0756-49c0-a09d-2173f7e2705a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%aimport"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modules to reload:\n",
            "all-except-skipped\n",
            "\n",
            "Modules to skip:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3E16jPVPpqbV"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U421BuhtfYS7",
        "outputId": "a79f7a2e-8ce9-40bb-8caf-8cf45e4d18c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  GDRIVE_DATASET_FOLDER = Path('gdrive/My Drive/datasets/')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9IgnETKkpqbX",
        "outputId": "6f2ce1ed-1fda-4020-f833-d87abd65d8c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "if COLAB:\n",
        "  DATASET_PATH = GDRIVE_DATASET_FOLDER\n",
        "  ORIGIN_DATASET_PATH = Path('dl-projects/datasets')\n",
        "else:\n",
        "  DATASET_PATH = Path(\"../datasets\")\n",
        "  ORIGIN_DATASET_PATH = Path('datasets')\n",
        "\n",
        "DATASET = DATASET_PATH/f\"{FEATURE_DATASET_PREFIX}.ft\"\n",
        "ORIGIN_DATASET = ORIGIN_DATASET_PATH/DATASET_NAME\n",
        "\n",
        "if COLAB:\n",
        "  !ls -l gdrive/\"My Drive\"/datasets/ --block-size=M\n",
        "  !ls -l dl-projects/datasets --block-size=M"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4710M\n",
            "-rw------- 1 root root 2454M Jan 12 01:24 feature_matrix_d2_v2.ft\n",
            "-rw------- 1 root root 1585M Jan 12 23:39 feature_matrix_d2_v3.ft\n",
            "-rw------- 1 root root   17M Feb 21 13:07 feature_matrix_snapshot.ft\n",
            "-rw------- 1 root root   17M Feb 21 13:07 feature_matrix_snapshot_origin.pkl\n",
            "-rw------- 1 root root    5M Jan 30 04:33 orig_X_test.ft\n",
            "-rw------- 1 root root  415M Jan 30 04:33 orig_X_train.ft\n",
            "-rw------- 1 root root    1M Jan 30 04:33 orig_y_test.ft\n",
            "-rw------- 1 root root    7M Jan 30 04:33 orig_y_train.ft\n",
            "-rw------- 1 root root    3M Feb 26 14:03 test_X_test.ft\n",
            "-rw------- 1 root root  204M Feb 26 14:03 test_X_train.ft\n",
            "-rw------- 1 root root    1M Feb 26 14:03 test_y_test.ft\n",
            "-rw------- 1 root root    7M Feb 26 14:03 test_y_train.ft\n",
            "total 25M\n",
            "-rw-r--r-- 1 root root  1M Feb 29 06:34 4D.zip\n",
            "-rw-r--r-- 1 root root 25M Feb 29 06:34 labels.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urQTD6DQNutw",
        "colab": {}
      },
      "source": [
        "# Read the data\n",
        "data = pd.read_feather(DATASET)\n",
        "origin_data = format_tabular(ORIGIN_DATASET)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vOYlp-8Br61r"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kHiN1VVlG9Kh"
      },
      "source": [
        "### View data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JnQXyVqng5Cm",
        "colab": {}
      },
      "source": [
        "# Feature matrix\n",
        "feature_matrix = data.drop(columns=['NumberId', 'month', 'year'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apMYVNz9HK9e",
        "outputId": "83d52272-0f88-4e2d-ab01-5a6cee50ce7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Sort data\n",
        "feature_matrix.sort_values(by=['time', 'MAX(Results.LuckyNo)'], inplace=True)\n",
        "feature_matrix.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 959893 entries, 7020 to 956511\n",
            "Columns: 214 entries, time to LAST(Results.PrizeType)_Prize\n",
            "dtypes: datetime64[ns](1), float64(155), int64(56), uint8(2)\n",
            "memory usage: 1.5 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CZKTbWRFJNUq",
        "outputId": "6192eb02-1f9b-48d1-939e-668e5ae23756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print('Distribution')\n",
        "print(feature_matrix['Label'].value_counts())\n",
        "print()\n",
        "print('Positive: ' + str(feature_matrix['Label'].value_counts()[0]) + ' which is ', round(feature_matrix['Label'].value_counts()[0]/len(feature_matrix) * 100,2), '% of the dataset')\n",
        "print('Negative: ' + str(feature_matrix['Label'].value_counts()[1]) + ' which is ', round(feature_matrix['Label'].value_counts()[1]/len(feature_matrix) * 100,2), '% of the dataset')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution\n",
            "0    927839\n",
            "1     32054\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Positive: 927839 which is  96.66 % of the dataset\n",
            "Negative: 32054 which is  3.34 % of the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plplpAQ6JrKb",
        "outputId": "5b743547-ede7-443c-a046-8e81db473e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "feature_matrix.isna().sum().sort_values(ascending=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))               7636\n",
              "CUM_MEAN(TREND(Results.LuckyNo, DrawDate))                7636\n",
              "TREND(Results.TIME_SINCE_PREVIOUS(DrawDate), DrawDate)    7636\n",
              "TREND(Results.CUM_MEAN(TotalStrike), DrawDate)            7636\n",
              "TREND(Results.CUM_SUM(LuckyNo), DrawDate)                 7636\n",
              "                                                          ... \n",
              "CUM_SUM(MIN(Results.DrawNo))                                 0\n",
              "NUM_UNIQUE(Results.DAY(DrawDate))                            0\n",
              "NUM_UNIQUE(Results.MONTH(DrawDate))                          0\n",
              "SUM(Results.PERCENTILE(LuckyNo))                             0\n",
              "time                                                         0\n",
              "Length: 214, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF_zCRksL1Ls"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1aLGsXSOa9K",
        "colab": {}
      },
      "source": [
        "# Fill all NaN with 0\n",
        "feature_matrix = feature_matrix.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5A8LZ805MqjP",
        "outputId": "560cb9b9-c00e-4162-e7ce-25d0f1666d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feature_matrix.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(959893, 214)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rPFOkiGjhuKj",
        "outputId": "1ac2c870-3414-4e55-afee-c00729b149e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "feature_matrix_selection = feature_selection(feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label']))\n",
        "# feature_matrix_selection = feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape:  (959893, 211)\n",
            "0 missing columns with threshold: 90.\n",
            "41 zero variance columns.\n",
            "109 collinear columns removed with threshold: 0.95.\n",
            "Total columns removed:  150\n",
            "Shape after feature selection: (959893, 61).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vT2K0WeJhugH",
        "outputId": "db7dedbb-280e-4ba3-f0b6-d9253a56db38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "feature_matrix_selection.shape, feature_matrix_selection.columns"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((959893, 61),\n",
              " Index(['STD(Results.DrawNo)', 'MAX(Results.DrawNo)', 'MAX(Results.LuckyNo)',\n",
              "        'MIN(Results.DrawNo)', 'MEAN(Results.DrawNo)', 'SKEW(Results.DrawNo)',\n",
              "        'AVG_TIME_BETWEEN(Results.DrawDate)', 'COUNT(Results)',\n",
              "        'SUM(Results.DrawNo)', 'SUM(Results.LuckyNo)',\n",
              "        'TREND(Results.DrawNo, DrawDate)', 'MONTH(first_Results_time)',\n",
              "        'DAY(first_Results_time)', 'TIME_SINCE(first_Results_time)',\n",
              "        'TIME_SINCE_PREVIOUS(first_Results_time)',\n",
              "        'STD(Results.PERCENTILE(DrawNo))',\n",
              "        'STD(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'STD(Results.CUM_SUM(DrawNo))', 'STD(Results.CUM_MEAN(LuckyNo))',\n",
              "        'MAX(Results.PERCENTILE(DrawNo))',\n",
              "        'MAX(Results.PERCENTILE(TotalStrike))',\n",
              "        'MAX(Results.CUM_MEAN(LuckyNo))',\n",
              "        'MIN(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'MIN(Results.CUM_MEAN(LuckyNo))', 'MODE(Results.MONTH(DrawDate))',\n",
              "        'MODE(Results.DAY(DrawDate))', 'MEAN(Results.TIME_SINCE(DrawDate))',\n",
              "        'MEAN(Results.PERCENTILE(DrawNo))',\n",
              "        'MEAN(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'MEAN(Results.CUM_MEAN(LuckyNo))',\n",
              "        'SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'SKEW(Results.CUM_SUM(DrawNo))', 'SKEW(Results.CUM_MEAN(LuckyNo))',\n",
              "        'LAST(Results.DAY(DrawDate))',\n",
              "        'LAST(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'LAST(Results.MONTH(DrawDate))', 'LAST(Results.CUM_MEAN(LuckyNo))',\n",
              "        'SUM(Results.TIME_SINCE(DrawDate))',\n",
              "        'SUM(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'TREND(Results.CUM_MEAN(LuckyNo), DrawDate)',\n",
              "        'TREND(Results.PERCENTILE(LuckyNo), DrawDate)',\n",
              "        'TREND(Results.PERCENTILE(DrawNo), DrawDate)',\n",
              "        'TREND(Results.PERCENTILE(TotalStrike), DrawDate)',\n",
              "        'TREND(Results.TIME_SINCE_PREVIOUS(DrawDate), DrawDate)',\n",
              "        'TREND(Results.CUM_SUM(DrawNo), DrawDate)',\n",
              "        'NUM_UNIQUE(Results.MONTH(DrawDate))',\n",
              "        'NUM_UNIQUE(Results.DAY(DrawDate))', 'CUM_SUM(MIN(Results.DrawNo))',\n",
              "        'CUM_SUM(SKEW(Results.DrawNo))',\n",
              "        'CUM_MEAN(AVG_TIME_BETWEEN(Results.DrawDate))',\n",
              "        'CUM_MEAN(SUM(Results.LuckyNo))', 'CUM_MEAN(SKEW(Results.DrawNo))',\n",
              "        'PERCENTILE(STD(Results.LuckyNo))', 'PERCENTILE(LAST(Results.DrawNo))',\n",
              "        'PERCENTILE(MAX(Results.TotalStrike))',\n",
              "        'PERCENTILE(AVG_TIME_BETWEEN(Results.DrawDate))',\n",
              "        'PERCENTILE(COUNT(Results))', 'PERCENTILE(STD(Results.DrawNo))',\n",
              "        'PERCENTILE(SKEW(Results.DrawNo))', 'PERCENTILE(SUM(Results.DrawNo))',\n",
              "        'PERCENTILE(TREND(Results.DrawNo, DrawDate))'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZUhYrWFiRod",
        "colab": {}
      },
      "source": [
        "feature_matrix_selection['time'] = feature_matrix['time']\n",
        "feature_matrix_selection['TotalStrike'] = feature_matrix['TotalStrike']\n",
        "feature_matrix_selection['Label'] = feature_matrix['Label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hugygOqSiR6K"
      },
      "source": [
        "### Feature Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "loagcqTEKOkO",
        "outputId": "4e8eace1-be09-41f3-d69e-9380c4b29b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "feature_matrix.isnull().sum().sort_values(ascending=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LAST(Results.PrizeType)_Prize                  0\n",
              "SKEW(Results.TIME_SINCE(DrawDate))             0\n",
              "MEAN(Results.CUM_MEAN(TotalStrike))            0\n",
              "MEAN(Results.CUM_MEAN(LuckyNo))                0\n",
              "MEAN(Results.CUM_SUM(DrawNo))                  0\n",
              "                                              ..\n",
              "CUM_SUM(COUNT(Results))                        0\n",
              "CUM_SUM(MAX(Results.DrawNo))                   0\n",
              "CUM_SUM(MEAN(Results.LuckyNo))                 0\n",
              "CUM_SUM(AVG_TIME_BETWEEN(Results.DrawDate))    0\n",
              "time                                           0\n",
              "Length: 214, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u7Ha8Zlkhuoe",
        "colab": {}
      },
      "source": [
        "# Check with feature selection\n",
        "corrs = feature_matrix_selection.corr().sort_values('Label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EWRODfAdPk6j",
        "outputId": "3f3c3def-085f-41b6-8413-0d456f6419bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "corrs['Label'].head(60)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CUM_MEAN(SUM(Results.LuckyNo))                           -0.003288\n",
              "TIME_SINCE(first_Results_time)                           -0.002944\n",
              "STD(Results.DrawNo)                                      -0.002877\n",
              "STD(Results.CUM_SUM(DrawNo))                             -0.002778\n",
              "MAX(Results.LuckyNo)                                     -0.002680\n",
              "SUM(Results.LuckyNo)                                     -0.002426\n",
              "MAX(Results.DrawNo)                                      -0.002377\n",
              "MIN(Results.CUM_MEAN(LuckyNo))                           -0.002333\n",
              "CUM_MEAN(AVG_TIME_BETWEEN(Results.DrawDate))             -0.002238\n",
              "MEAN(Results.TIME_SINCE(DrawDate))                       -0.002056\n",
              "STD(Results.PERCENTILE(DrawNo))                          -0.001937\n",
              "PERCENTILE(STD(Results.LuckyNo))                         -0.001931\n",
              "PERCENTILE(STD(Results.DrawNo))                          -0.001814\n",
              "CUM_SUM(SKEW(Results.DrawNo))                            -0.001741\n",
              "SUM(Results.TIME_SINCE(DrawDate))                        -0.001492\n",
              "MEAN(Results.CUM_MEAN(LuckyNo))                          -0.001477\n",
              "AVG_TIME_BETWEEN(Results.DrawDate)                       -0.001429\n",
              "PERCENTILE(SKEW(Results.DrawNo))                         -0.001354\n",
              "SKEW(Results.CUM_MEAN(LuckyNo))                          -0.001339\n",
              "SKEW(Results.CUM_SUM(DrawNo))                            -0.001294\n",
              "SKEW(Results.DrawNo)                                     -0.001030\n",
              "MAX(Results.PERCENTILE(DrawNo))                          -0.001006\n",
              "LAST(Results.DAY(DrawDate))                              -0.001000\n",
              "TREND(Results.CUM_SUM(DrawNo), DrawDate)                 -0.000958\n",
              "PERCENTILE(AVG_TIME_BETWEEN(Results.DrawDate))           -0.000921\n",
              "NUM_UNIQUE(Results.DAY(DrawDate))                        -0.000833\n",
              "MODE(Results.MONTH(DrawDate))                            -0.000827\n",
              "DAY(first_Results_time)                                  -0.000677\n",
              "TREND(Results.DrawNo, DrawDate)                          -0.000630\n",
              "SUM(Results.DrawNo)                                      -0.000541\n",
              "COUNT(Results)                                           -0.000535\n",
              "CUM_MEAN(SKEW(Results.DrawNo))                           -0.000398\n",
              "LAST(Results.MONTH(DrawDate))                            -0.000351\n",
              "NUM_UNIQUE(Results.MONTH(DrawDate))                      -0.000248\n",
              "SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))              -0.000226\n",
              "MEAN(Results.DrawNo)                                     -0.000160\n",
              "TREND(Results.PERCENTILE(TotalStrike), DrawDate)         -0.000156\n",
              "PERCENTILE(COUNT(Results))                               -0.000139\n",
              "LAST(Results.TIME_SINCE_PREVIOUS(DrawDate))              -0.000131\n",
              "PERCENTILE(LAST(Results.DrawNo))                         -0.000094\n",
              "TREND(Results.TIME_SINCE_PREVIOUS(DrawDate), DrawDate)    0.000169\n",
              "STD(Results.TIME_SINCE_PREVIOUS(DrawDate))                0.000213\n",
              "MEAN(Results.TIME_SINCE_PREVIOUS(DrawDate))               0.000345\n",
              "SUM(Results.TIME_SINCE_PREVIOUS(DrawDate))                0.000442\n",
              "MODE(Results.DAY(DrawDate))                               0.000471\n",
              "PERCENTILE(SUM(Results.DrawNo))                           0.000610\n",
              "TREND(Results.PERCENTILE(LuckyNo), DrawDate)              0.000687\n",
              "MONTH(first_Results_time)                                 0.000858\n",
              "PERCENTILE(TREND(Results.DrawNo, DrawDate))               0.000912\n",
              "MIN(Results.TIME_SINCE_PREVIOUS(DrawDate))                0.000984\n",
              "TIME_SINCE_PREVIOUS(first_Results_time)                   0.000987\n",
              "LAST(Results.CUM_MEAN(LuckyNo))                           0.000988\n",
              "MAX(Results.CUM_MEAN(LuckyNo))                            0.001007\n",
              "MEAN(Results.PERCENTILE(DrawNo))                          0.001149\n",
              "TREND(Results.CUM_MEAN(LuckyNo), DrawDate)                0.001493\n",
              "TREND(Results.PERCENTILE(DrawNo), DrawDate)               0.001528\n",
              "PERCENTILE(MAX(Results.TotalStrike))                      0.001564\n",
              "MIN(Results.DrawNo)                                       0.001718\n",
              "CUM_SUM(MIN(Results.DrawNo))                              0.001852\n",
              "MAX(Results.PERCENTILE(TotalStrike))                      0.002320\n",
              "Name: Label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "waeD1ED_kqDB"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9yrJyIVLh5So",
        "colab": {}
      },
      "source": [
        "def recall_optim(y_true, y_pred):\n",
        "    \"\"\"Make a scoring function that improves specificity while identifying all strikes\n",
        "    \"\"\"\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    # Recall will be worth a greater value than specificity\n",
        "    rec = recall_score(y_true, y_pred) * 0.8 \n",
        "    spe = conf_matrix[0,0]/conf_matrix[0,:].sum() * 0.2 \n",
        "    \n",
        "    # Imperfect recalls will lose a penalty\n",
        "    # This means the best results will have perfect recalls and compete for specificity\n",
        "    if rec < 0.8:\n",
        "        rec -= 0.2\n",
        "    return rec + spe \n",
        "\n",
        "\n",
        "# Make a scoring callable from recall_score\n",
        "recall = make_scorer(recall_score)\n",
        "\n",
        "# Create a scoring callable based on the scoring function\n",
        "optimize = make_scorer(recall_optim)\n",
        "\n",
        "# Geometric mean scorer\n",
        "geo_mean_scorer = make_scorer(geometric_mean_score)\n",
        "\n",
        "# DataFrame to store classifier performance\n",
        "performance = pd.DataFrame(columns=['Train_Recall','Test_Recall','Test_Specificity', 'Optimize'])\n",
        "\n",
        "def to_labels(pos_probs, threshold):\n",
        "    \"\"\"Apply threshold to positive probabilities to create labels.\n",
        "    \"\"\"\n",
        "    return (pos_probs >= threshold).astype('int')\n",
        " \n",
        "\n",
        "def score_optimization(dt, feature_matrix, clf, params, X_train, y_train, X_test, y_test, skip_grid_search_cv=False, optimized_scorer=False):\n",
        "    \"\"\"Find the optimized classifier.\n",
        "    \"\"\"\n",
        "    if not skip_grid_search_cv:\n",
        "      print(\"\\nFinding the optimized classifier...\")\n",
        "\n",
        "      # Load GridSearchCV\n",
        "      # search = GridSearchCV(\n",
        "      search = RandomizedSearchCV(\n",
        "            estimator=clf,\n",
        "            #param_grid=params,\n",
        "            param_distributions=params,\n",
        "            n_jobs=4,\n",
        "            scoring=optimize  # Use custom scorer\n",
        "      )\n",
        "\n",
        "      # Train search object\n",
        "      search.fit(X_train, y_train)\n",
        "\n",
        "      # Heading\n",
        "      print('\\n','-'*40,'\\n',clf.__class__.__name__,'\\n','-'*40)\n",
        "\n",
        "      # Extract best estimator\n",
        "      best = search.best_estimator_\n",
        "      print('Best parameters: \\n\\n',search.best_params_,'\\n')\n",
        "    \n",
        "    else:\n",
        "      print(\"\\nUse the passed in classifier...\\n\")\n",
        "      best = clf\n",
        "\n",
        "    # Cross-validate on the train data\n",
        "    if not skip_grid_search_cv: \n",
        "      print(\"TRAIN GROUP\")\n",
        "      #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
        "      cv = 3\n",
        "      if not optimized_scorer:\n",
        "        print('\\nUse default scorer')\n",
        "        train_cv = cross_val_score(\n",
        "                                  n_jobs=4,\n",
        "                                  X=X_train, \n",
        "                                  y=y_train, \n",
        "                                  estimator=best, \n",
        "                                  scoring=recall,\n",
        "                                  cv=cv)\n",
        "      else:\n",
        "        print('\\nUse optimized scorer')\n",
        "        train_cv = cross_val_score(\n",
        "                                  n_jobs=4,\n",
        "                                  X=X_train, \n",
        "                                  y=y_train, \n",
        "                                  estimator=best, \n",
        "                                  #scoring=optimize,\n",
        "                                  scoring='roc_auc',\n",
        "                                  #scoring=geo_mean_scorer,\n",
        "                                  cv=cv)\n",
        "\n",
        "      print(\"\\nCross-validation recall scores:\",train_cv)\n",
        "      print(\"Mean recall score:\",train_cv.mean())\n",
        "      print('Mean G-Mean: %.3f (%.3f)' % (np.mean(train_cv), np.std(train_cv)))\n",
        "    else:\n",
        "      train_cv = np.zeros(3)\n",
        "\n",
        "    # Now predict on the test group\n",
        "    print(\"\\nTEST GROUP\")\n",
        "    y_pred = best.fit(X_train, y_train).predict(X_test)\n",
        "    # y_pred = best.fit(X_train, y_train,\n",
        "    #                   eval_set=[(X_test, y_test)],\n",
        "    #                   eval_metric='auc',\n",
        "    #                   early_stopping_rounds=10,\n",
        "    #                   verbose=True\n",
        "    #                   ).predict(X_test)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    probas = best.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # define thresholds\n",
        "    thresholds = np.arange(0, 1, 0.001)\n",
        "\n",
        "    # evaluate each threshold\n",
        "    scores = [f1_score(y_test, to_labels(probas, t)) for t in thresholds]\n",
        "\n",
        "    # get best threshold\n",
        "    ix = np.argmax(scores)\n",
        "    print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))\n",
        "\n",
        "    # print recall\n",
        "    print(\"\\nRecall:\",recall_score(y_test,y_pred))\n",
        "\n",
        "    # Get imbalanced classification report\n",
        "    print(classification_report_imbalanced(y_test, y_pred))\n",
        "\n",
        "    # Print confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test,y_pred)\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
        "    plt.show()\n",
        "\n",
        "    # Store results\n",
        "    performance.loc[clf.__class__.__name__+'_optimize',:] = [\n",
        "        train_cv.mean(),\n",
        "        recall_score(y_test,y_pred),\n",
        "        conf_matrix[0,0]/conf_matrix[0,:].sum(),\n",
        "        recall_optim(y_test,y_pred)\n",
        "    ]\n",
        "    # Look at the parameters for the top best scores\n",
        "    if not skip_grid_search_cv:\n",
        "      display(pd.DataFrame(search.cv_results_).iloc[:,4:].sort_values(by='rank_test_score').head())\n",
        "    display(performance)\n",
        "\n",
        "    # Additionl info\n",
        "    print('\\n\\nAdditional Info')\n",
        "    print('='*40)\n",
        "    positive = np.where((y_pred==1))\n",
        "    print(f'Total predicted to be positive: {len(positive[0])} \\n')\n",
        "\n",
        "    pred = np.where((y_pred==1))\n",
        "    all_preds = pred[0]\n",
        "\n",
        "    # Total predicted matches\n",
        "    print('First 23 matches')\n",
        "    print(23, all_preds[0:23])\n",
        "    print(f'\\n{probas[all_preds[0:23]]}\\n') \n",
        "\n",
        "    print(\"\\nTop 23 Probable Matches\")\n",
        "    #print('probas', probas)\n",
        "    topN = np.argpartition(probas, -23)[-23:]\n",
        "    print(f'\\n{topN}\\n')          # Top N most high probability numbers\n",
        "    print(f'\\n{probas[topN]}\\n')  # Top N probability\n",
        "\n",
        "    # Check for 2 to 3 digits range \n",
        "    print('\\n2 To 3 Digits\\n')\n",
        "    idx_range = np.where((all_preds < 1000) & (all_preds >= 10))\n",
        "    #print(idx_range)\n",
        "    range_numbers = all_preds[idx_range]\n",
        "    print(len(range_numbers), range_numbers)\n",
        "    print(f'\\n{probas[range_numbers]}\\n') \n",
        "\n",
        "\n",
        "    # 2 to 3 Digits > Average Probas\n",
        "    print('\\n2 To 3 Digits Average Proba\\n')\n",
        "    avg_proba = np.average(probas[range_numbers])\n",
        "    print(f'Average proba {avg_proba}\\n')\n",
        "    idx_avg_proba = np.where(probas > avg_proba) \n",
        "    print(len(idx_avg_proba[0]), idx_avg_proba[0])\n",
        "\n",
        "    # 2 to 3 Digits > All Average Probas\n",
        "    print('\\n\\nAll Average Proba\\n')\n",
        "    all_avg_proba = np.average(probas[all_preds])\n",
        "    print(f'All average probas {all_avg_proba}\\n')\n",
        "    idx_all_avg_proba = np.where(probas > all_avg_proba) \n",
        "    print(len(idx_all_avg_proba[0]), idx_all_avg_proba[0])\n",
        "\n",
        "\n",
        "    # All predicted matches\n",
        "    print('\\n\\nAll Predictions\\n')\n",
        "    print(len(all_preds), all_preds)\n",
        "    print()\n",
        "    print(len(probas[all_preds]), probas[all_preds])\n",
        "    \n",
        "    #print('Debug')\n",
        "    #print(pred)\n",
        "    \n",
        "    if len(positive[0]) > 0:\n",
        "    \n",
        "      # Matching draws\n",
        "      print('\\nMatched draws')\n",
        "      md = np.where((y_pred==1) & (y_test==1))\n",
        "      print(f\"Count: {len(md[0])}, Index: {md}\")\n",
        "      month_data = feature_matrix.loc[feature_matrix['time'] == dt]\n",
        "      numbers = month_data.iloc[md[0]][['MAX(Results.LuckyNo)']]\n",
        "\n",
        "      print('\\n\\nTop 23 Possibility')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(topN))].head(23))  \n",
        "      \n",
        "      print('\\n\\nFirst 23 Numbers')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(pred[0][0:23]))].head(23))    \n",
        "             \n",
        "\n",
        "      print('\\n\\n2 To 3 Digits Numbers')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(range_numbers))].head(23))    \n",
        "     \n",
        "\n",
        "      print('\\n\\nAll matched')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(numbers['MAX(Results.LuckyNo)']))].head(100))    \n",
        "                                                  \n",
        "    else:\n",
        "      print('No luck this month')  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VrL8gYwjc-hd",
        "colab": {}
      },
      "source": [
        "def remove_outliers(balanced, threshold=0.001, remove=True):\n",
        "    \"\"\"Removing Outliers from high-correlation features.\n",
        "    \"\"\"\n",
        "\n",
        "    if not remove:\n",
        "      return balanced\n",
        "\n",
        "    bal_corr = balanced.corr()\n",
        "    no_outliers=pd.DataFrame(balanced.copy())\n",
        "\n",
        "    cols = bal_corr.Label.index[:-1]\n",
        "\n",
        "    # For each feature correlated with Class...\n",
        "    for col in cols:\n",
        "        # If absolute correlation value is more than X percent...\n",
        "        correlation = bal_corr.loc['Label',col]\n",
        "\n",
        "        if np.absolute(correlation) > threshold:\n",
        "          # Separate the classes of the high-correlation column\n",
        "          nonstrikes = no_outliers.loc[no_outliers.Label==0,col]\n",
        "          strikes = no_outliers.loc[no_outliers.Label==1,col]\n",
        "\n",
        "          # Identify the 25th and 75th quartiles\n",
        "          all_values = no_outliers.loc[:,col]\n",
        "          q25, q75 = np.percentile(all_values, 25), np.percentile(all_values, 75)\n",
        "          # Get the inter quartile range\n",
        "          iqr = q75 - q25\n",
        "          # Smaller cutoffs will remove more outliers\n",
        "          cutoff = iqr * 7\n",
        "          # Set the bounds of the desired portion to keep\n",
        "          lower, upper = q25 - cutoff, q75 + cutoff\n",
        "          \n",
        "          # If positively correlated...\n",
        "          # Drop nonstrikes above upper bound, and strikes below lower bound\n",
        "          if correlation > 0: \n",
        "              no_outliers.drop(index=nonstrikes[nonstrikes>upper].index,inplace=True)\n",
        "              no_outliers.drop(index=strikes[strikes<lower].index,inplace=True)\n",
        "          \n",
        "          # If negatively correlated...\n",
        "          # Drop non strikes below lower bound, and strikes above upper bound\n",
        "          elif correlation < 0: \n",
        "              no_outliers.drop(index=nonstrikes[nonstrikes<lower].index,inplace=True)\n",
        "              no_outliers.drop(index=strikes[strikes>upper].index,inplace=True)\n",
        "        \n",
        "    print('\\nData shape before removing outliers:', balanced.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in previous data:')\n",
        "    print(balanced.Label.value_counts())\n",
        "    print('-'*40)\n",
        "    print('-'*40)\n",
        "    print('\\nData shape after removing outliers:', no_outliers.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
        "    print(no_outliers.Label.value_counts())\n",
        "\n",
        "    # no_outliers.iloc[:,:-1].boxplot(rot=90,figsize=(16,4))\n",
        "    # plt.title('Distributions with Less Outliers', fontsize=17)\n",
        "    # plt.show()\n",
        "    \n",
        "    no_outliers.reset_index(drop=True, inplace=True)\n",
        "    return no_outliers\n",
        "\n",
        "\n",
        "def filter_features(no_outliers, threshold=0.001):\n",
        "    \"\"\"Feature selection.\n",
        "    \"\"\"\n",
        "    feat_sel = pd.DataFrame(no_outliers.copy())\n",
        "\n",
        "    # Make a dataframe with the label-correlations before removing outliers\n",
        "    # corr_change = pd.DataFrame()\n",
        "    # corr_change['correlation']= bal_corr.Label\n",
        "    # corr_change['origin']= 'w/outliers'\n",
        "\n",
        "    # Make a dataframe with label-correlations after removing outliers \n",
        "    # corr_other = pd.DataFrame()\n",
        "    # corr_other['correlation']= feat_sel.corr().Label\n",
        "    # corr_other['origin']= 'no_outliers'\n",
        "\n",
        "    # Join them\n",
        "    # corr_change = corr_change.append(corr_other)\n",
        "\n",
        "    # plt.figure(figsize=(14,6))\n",
        "    # plt.xticks(rotation=90)\n",
        "\n",
        "    # Plot them\n",
        "    # sns.set_style('darkgrid')\n",
        "    # plt.title('Label correlation per feature. With vs without outliers', fontsize=17)\n",
        "    # sns.barplot(data=corr_change,x=corr_change.index,y='correlation',hue='origin')\n",
        "    # plt.show()\n",
        "\n",
        "    # Feature Selection based on correlation with label\n",
        "\n",
        "    print('\\nData shape before feature selection:', feat_sel.shape)\n",
        "    print('\\nCounts of strikes vs non-strikes before feature selection:')\n",
        "    print(feat_sel.Label.value_counts())\n",
        "    print('-'*40)\n",
        "\n",
        "    # Correlation matrix after removing outliers\n",
        "    new_corr = feat_sel.corr()\n",
        "\n",
        "    for col in new_corr.Label.index[:-1]:\n",
        "        # Pick desired cutoff for dropping features. In absolute-value terms.\n",
        "        if np.absolute(new_corr.loc['Label',col]) < threshold:\n",
        "            # Drop the feature if correlation is below cutoff\n",
        "            feat_sel.drop(columns=col,inplace=True)\n",
        "\n",
        "    print('-'*40)\n",
        "    print('\\nData shape after feature selection:', feat_sel.shape)\n",
        "    print('\\nCounts of strikes vs non-strikes in new data:')\n",
        "    print(feat_sel.Label.value_counts())\n",
        "\n",
        "    return feat_sel\n",
        "\n",
        "    # feat_sel.iloc[:,:-1].boxplot(rot=90,figsize=(16,4))\n",
        "    # plt.title('Distribution of Features Selected', fontsize=17)\n",
        "    # plt.show()\n",
        "\n",
        "def under_sampler(data, sample_size=20000, sampling=False):\n",
        "    # Undersample model for efficiency and balance classes.\n",
        "\n",
        "    X_train = data.drop('Label',1)\n",
        "    y_train = data.Label\n",
        "\n",
        "    if not sampling:\n",
        "      return X_train, y_train\n",
        "\n",
        "    # After feature-selection, X_test needs to include only the same features as X_train\n",
        "    # cols = X_train.columns\n",
        "    # X_test = X_test[cols]\n",
        "\n",
        "    # Undersample and balance classes\n",
        "    X_train, y_train = RandomUnderSampler(sampling_strategy={1:sample_size,0:sample_size}).fit_resample(X_train,y_train)\n",
        "\n",
        "    print('\\nX_train shape after reduction:', X_train.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in y_train:')\n",
        "    print(np.unique(y_train, return_counts=True))\n",
        "\n",
        "    return X_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pl5ZoepSNPf4",
        "colab": {}
      },
      "source": [
        "def gen_train_test_set(dt, feature_matrix, file_prefix='data'): \n",
        "    \n",
        "    # Subset labels\n",
        "    test_labels = feature_matrix.loc[feature_matrix['time'] == dt, 'Label']\n",
        "    train_labels = feature_matrix.loc[feature_matrix['time'] < dt, 'Label']\n",
        "\n",
        "    # Features\n",
        "    X_train = feature_matrix[feature_matrix['time'] < dt].drop(columns = ['NumberId', 'time', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    X_test = feature_matrix[feature_matrix['time'] == dt].drop(columns = ['NumberId', 'time', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    feature_names = list(X_train.columns)\n",
        "    \n",
        "    # Labels\n",
        "    y_train = np.array(train_labels).reshape((-1, ))\n",
        "    y_test = np.array(test_labels).reshape((-1, ))\n",
        "    \n",
        "    print('Training on {} observations.'.format(len(X_train)))\n",
        "    print('Testing on {} observations.\\n'.format(len(X_test)))\n",
        "\n",
        "    # Join the train data\n",
        "    train = X_train.join(train_labels)\n",
        "\n",
        "    print('Data shape before balancing:', train.shape)\n",
        "    print('\\nCounts of strikes vs non-strikes in previous data:')\n",
        "    print(train.Label.value_counts())\n",
        "    print('-'*40)\n",
        "\n",
        "    # sklearn pipeline\n",
        "    pipeline = make_pipeline(\n",
        "        SimpleImputer(strategy = 'constant', fill_value=0),\n",
        "        StandardScaler())\n",
        "    \n",
        "    X_train = pipeline.fit_transform(X_train)\n",
        "    X_test = pipeline.transform(X_test)\n",
        "\n",
        "    # imblearn pipeline\n",
        "    imb_pipeline = make_pipeline_imb(\n",
        "          # NearMiss(version=3, n_neighbors_ver3=3, n_jobs=4)\n",
        "          # SMOTE(sampling_strategy='minority',random_state=42, n_jobs=4)\n",
        "          # ADASYN(sampling_strategy='minority',random_state=42, n_jobs=4)\n",
        "          # OneSidedSelection(n_neighbors=1, n_seeds_S=200, random_state=42, n_jobs=4)\n",
        "          SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='majority'))\n",
        "    )\n",
        "     \n",
        "    # Balance the data\n",
        "    to_balanced = False\n",
        "    if to_balanced:\n",
        "      print('\\nBalancing data')\n",
        "      X_bal, y_bal = imb_pipeline.fit_resample(X_train, y_train)\n",
        "      X_bal = pd.DataFrame(X_bal,columns=feature_names)\n",
        "      y_bal = pd.DataFrame(y_bal,columns=['Label'])\n",
        "    else:\n",
        "      print('\\nNO balancing')\n",
        "      X_bal = pd.DataFrame(X_train,columns=feature_names)\n",
        "      y_bal = pd.DataFrame(y_train,columns=['Label'])\n",
        "\n",
        "    balanced = X_bal.join(y_bal)\n",
        "\n",
        "    # print('-'*40)\n",
        "    print('Data shape after balancing:',balanced.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
        "    print(balanced.Label.value_counts())\n",
        "\n",
        "    # Remove high correlation outliers\n",
        "    no_outliers = remove_outliers(balanced, remove=False)\n",
        "   \n",
        "    # Remove features with low correlation\n",
        "    remove_features = True\n",
        "    if remove_features:\n",
        "      print('\\nFiltering features')\n",
        "      features_selected = filter_features(no_outliers)\n",
        "    else:\n",
        "      print('\\nNO filtering')\n",
        "      features_selected = no_outliers \n",
        "\n",
        "    columns_selected = features_selected.drop('Label',1).columns\n",
        "\n",
        "    # Under sampling\n",
        "    X_train, y_train = under_sampler(features_selected, sampling=False) \n",
        "    X_train = pd.DataFrame(X_train,columns=columns_selected)\n",
        "    y_train = pd.DataFrame(y_train,columns=['Label'])\n",
        "\n",
        "    # For X_test, now only use the selected features\n",
        "    X_test = pd.DataFrame(X_test,columns=feature_names)\n",
        "    X_test = X_test[columns_selected]\n",
        "    y_test = pd.DataFrame(y_test,columns=['Label'])\n",
        "\n",
        "    #print(X_train.describe())\n",
        "    #return\n",
        "\n",
        "    # Save data\n",
        "    # print(X_train.head(10))\n",
        "    # print(y_train.head(10)) \n",
        "\n",
        "    # print(X_test.head(10))\n",
        "    # print(y_test.head(10)) \n",
        "    X_train.to_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
        "    y_train.to_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
        "   \n",
        "    X_test.to_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
        "    y_test.to_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
        "\n",
        "    gc.collect()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PcKlL67TP9UM",
        "colab": {}
      },
      "source": [
        "def model(dt, feature_matrix, file_prefix='data', csv=False):\n",
        "    \"\"\"Predict for a particular month.\n",
        "\n",
        "    - https://www.kaggle.com/miguelniblock/optimizing-imbalanced-classification-100-recall\n",
        "    - https://www.kaggle.com/saxinou/imbalanced-data-xgboost-tunning\n",
        "    - https://www.kaggle.com/andreanuzzo/balance-the-imbalanced-rf-and-xgboost-with-smote\n",
        "    - https://github.com/mengwangk/FraudDetection/blob/master/05_Sampling_techniques_for_extremely_imbalanced_data.ipynb\n",
        "    - https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
        "    - https://github.com/coding-maniacs/over-under-sampling/blob/master/src/main.py\n",
        "    - https://github.com/scikit-learn-contrib/imbalanced-learn/issues/552#issuecomment-466348310\n",
        "    - https://stackoverflow.com/questions/52499788/smotetomek-how-to-set-ratio-as-dictionary-for-fixed-balance\n",
        "    - https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.OneSidedSelection.html#imblearn.under_sampling.OneSidedSelection\n",
        "    - https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\n",
        "    - https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n",
        "    - https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
        "    - https://stats.stackexchange.com/questions/243207/what-is-the-proper-usage-of-scale-pos-weight-in-xgboost-for-imbalanced-datasets\n",
        "    - https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py\n",
        "    - https://machinelearningmastery.com/cost-sensitive-logistic-regression/\n",
        "    \n",
        "    - https://datascience.stackexchange.com/questions/28285/what-is-the-best-way-to-deal-with-imbalanced-data-for-xgboost/28292\n",
        "    - https://machinelearningmastery.com/xgboost-for-imbalanced-classification/\n",
        "    - https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # Read data\n",
        "    if not csv:\n",
        "      X_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
        "      y_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
        "    \n",
        "      X_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
        "      y_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
        "    else:\n",
        "      X_train = pd.read_csv(DATASET_PATH/f\"{file_prefix}_X_train.csv\", header=0, sep=',', quotechar='\"')\n",
        "      y_train = pd.read_csv(DATASET_PATH/f\"{file_prefix}_y_train.csv\", header=0, sep=',', quotechar='\"')\n",
        "    \n",
        "      X_test = pd.read_csv(DATASET_PATH/f\"{file_prefix}_X_test.csv\", header=0, sep=',', quotechar='\"')\n",
        "      y_test = pd.read_csv(DATASET_PATH/f\"{file_prefix}_y_test.csv\", header=0, sep=',', quotechar='\"')\n",
        "\n",
        "    # Reshape\n",
        "    y_train = np.array(y_train).reshape((-1, ))\n",
        "    y_test = np.array(y_test).reshape((-1, ))\n",
        "    \n",
        "    print('Data shape')\n",
        "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "    # print(X_train.describe())\n",
        "    # return\n",
        "\n",
        "    # Calculate hit ratio for xgboost classifier\n",
        "    print(\"\\nCalculating scale pos weight\")\n",
        "    counter = Counter(y_train)\n",
        "    print(Counter(y_train))\n",
        "    scale_pos_weight = float(counter[0] / counter[1])\n",
        "    print(f\"\\nscale_pos_weight - {scale_pos_weight}\\n\")\n",
        "    \n",
        "     # Modeling\n",
        "#     clf = xgb.XGBClassifier(\n",
        "#               n_jobs=4, \n",
        "#               random_state=42,\n",
        "#               #learning_rate=0.1,\n",
        "#               #n_estimators=500,\n",
        "#               #max_depth=6, \n",
        "#               #min_child_weight=3, \n",
        "#               #gamma=0,\n",
        "#               #subsample=0.8,\n",
        "#               #colsample_bytree=0.8,\n",
        "#               objective='binary:logistic', \n",
        "#               scale_pos_weight=scale_pos_weight,\n",
        "#               ##eval_metric=\"auc\",\n",
        "#               ##max_delta_step=1,\n",
        "#               seed=27)\n",
        "#     clf = xgb.XGBClassifier(n_jobs=4, \n",
        "#                             random_state=42,\n",
        "#                             objective='binary:logistic', \n",
        "#                             #scale_pos_weight=28)\n",
        "#                             scale_pos_weight=scale_pos_weight)\n",
        "    \n",
        "    clf = xgb.XGBClassifier(\n",
        "                    n_jobs=4, \n",
        "                    random_state=42,\n",
        "                    objective='binary:logistic',\n",
        "                    subsample=0.55, \n",
        "                    n_estimators=300,\n",
        "                    #n_estimators=400,\n",
        "                    min_child_weight=1,\n",
        "                    #max_depth=3, \n",
        "                    max_depth=5, \n",
        "                    learning_rate=0.007,\n",
        "                    gamma=0.1, \n",
        "                    colsample_bytree=0.95,\n",
        "                    tree_method='hist',\n",
        "                    booster='dart',\n",
        "                    scale_pos_weight=scale_pos_weight\n",
        "                    )\n",
        "\n",
        "    clf_params = clf.get_params()\n",
        "    print(clf_params)\n",
        "\n",
        "    # Set parameters\n",
        "    #clf_params['max_depth'] = 10\n",
        "    #clf.set_params(clf_params)\n",
        "\n",
        "    # Parameters to compare\n",
        "    weights = [i for i in range(1,36,1)]\n",
        "    weights.append(scale_pos_weight)\n",
        "    learn_params = {\n",
        "        'n_estimators': [100, 300, 500, 800, 1000], \n",
        "        'max_depth': range(3,10,2),\n",
        "        'min_child_weight': range(1,6,2),\n",
        "        #'gamma':[i/10.0 for i in range(0,5)],\n",
        "        'subsample':[i/100.0 for i in range(55,70,5)],\n",
        "        'colsample_bytree':[i/100.0 for i in range(85,100,5)],\n",
        "        #'learning_rate':[i/1000.0 for i in range(5,20,2)],\n",
        "        'scale_pos_weight': weights\n",
        "    }\n",
        "    print(f'Parameter distribution: {learn_params}')\n",
        "    \n",
        "    # Test and validate\n",
        "    score_optimization(dt,\n",
        "                       feature_matrix,\n",
        "                       clf, \n",
        "                       learn_params,  \n",
        "                       X_train, \n",
        "                       y_train, \n",
        "                       X_test, \n",
        "                       y_test, \n",
        "                       skip_grid_search_cv=True,\n",
        "                       optimized_scorer=True)\n",
        "\n",
        "    gc.collect()\n",
        "    \n",
        "    # clf.fit(X_train, y_train)\n",
        "    # y_pred = clf.predict(X_test)\n",
        "\n",
        "    # # ROC score\n",
        "    # auc = roc_auc_score(y_test, y_pred)\n",
        "    # print(\"ROC score: \", auc)\n",
        "\n",
        "    # # Print confusion matrix\n",
        "    # conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    # sns.heatmap(conf_matrix, annot=True,fmt='d', cmap=plt.cm.copper)\n",
        "    # plt.show()\n",
        "\n",
        "    # Parameters to compare\n",
        "    # params = {\n",
        "    #     'criterion':['entropy','gini'],\n",
        "    #     'class_weight':[{1:1,0:0.3},{1:1,0:0.4},{1:1,0:0.5},{1:1,0:0.6},{1:1,0:7}]\n",
        "    # }\n",
        "\n",
        "    # Implement the classifier\n",
        "    # clf = RandomForestClassifier(\n",
        "    #     n_estimators=100,\n",
        "    #     max_features=None,\n",
        "    #     n_jobs=4,\n",
        "    # )\n",
        "\n",
        "    # # Test and validate\n",
        "    # score_optimization(clf, params, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m9UobqUWMI9b",
        "jupyter": {
          "source_hidden": true
        },
        "outputId": "a77f42e5-f8b4-425e-d195-f0646922a65f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Predict for a particular month\n",
        "\n",
        "# %time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection)\n",
        "\n",
        "#%time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='test')\n",
        "%time model(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='orig')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data shape\n",
            "(889893, 61) (889893,) (10000, 61) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 860060, 1: 29833})\n",
            "\n",
            "scale_pos_weight - 28.829148929038315\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.829148929038315, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.829148929038315]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.471, F-Score=0.06675\n",
            "\n",
            "Recall: 0.017857142857142856\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.99      0.02      0.98      0.13      0.02      9664\n",
            "          1       0.04      0.02      0.99      0.03      0.13      0.02       336\n",
            "\n",
            "avg / total       0.94      0.95      0.05      0.94      0.13      0.02     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0178571</td>\n",
              "      <td>0.986445</td>\n",
              "      <td>0.0115746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity   Optimize\n",
              "XGBClassifier_optimize            0   0.0178571         0.986445  0.0115746"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 137 \n",
            "\n",
            "First 23 matches\n",
            "23 [ 44  52  72 219 230 271 298 336 399 479 487 507 510 511 537 557 558 567\n",
            " 586 592 604 692 732]\n",
            "\n",
            "[0.5024763  0.50242084 0.50625664 0.5015767  0.5025692  0.50463367\n",
            " 0.50390583 0.50059813 0.50186515 0.5033057  0.50088143 0.501753\n",
            " 0.5024148  0.50209004 0.5003103  0.50467205 0.50327104 0.50571525\n",
            " 0.50011367 0.5103051  0.50017303 0.50126743 0.5012014 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[4928  950  567 8701 7166 1047 7227 7455  905 9258 2532  895 1271  803\n",
            " 3105 4796  823 5921 8938   72  592 3497  974]\n",
            "\n",
            "\n",
            "[0.5046966  0.50554454 0.50571525 0.5060377  0.5057846  0.51537687\n",
            " 0.51552385 0.51151985 0.5120834  0.5058914  0.5057698  0.5071819\n",
            " 0.5137448  0.50490165 0.5140703  0.505184   0.5134327  0.5075024\n",
            " 0.51210064 0.50625664 0.5103051  0.5054198  0.5050841 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "34 [ 44  52  72 219 230 271 298 336 399 479 487 507 510 511 537 557 558 567\n",
            " 586 592 604 692 732 803 816 823 886 895 897 903 905 928 950 974]\n",
            "\n",
            "[0.5024763  0.50242084 0.50625664 0.5015767  0.5025692  0.50463367\n",
            " 0.50390583 0.50059813 0.50186515 0.5033057  0.50088143 0.501753\n",
            " 0.5024148  0.50209004 0.5003103  0.50467205 0.50327104 0.50571525\n",
            " 0.50011367 0.5103051  0.50017303 0.50126743 0.5012014  0.50490165\n",
            " 0.5019867  0.5134327  0.50071096 0.5071819  0.50005734 0.5007446\n",
            " 0.5120834  0.5011069  0.50554454 0.5050841 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5034298300743103\n",
            "\n",
            "41 [  72  271  298  557  567  592  803  823  895  905  950  974 1043 1047\n",
            " 1230 1271 1671 1836 2107 2532 3029 3105 3497 4267 4562 4796 4928 5311\n",
            " 5355 5842 5921 6019 7166 7196 7227 7455 7532 8476 8701 8938 9258]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5030230283737183\n",
            "\n",
            "50 [  72  271  298  479  557  558  567  592  803  823  895  905  950  974\n",
            " 1043 1047 1115 1230 1271 1671 1836 2107 2532 2633 2672 3029 3105 3497\n",
            " 4060 4267 4562 4796 4928 5311 5355 5842 5921 6019 6326 6772 7106 7166\n",
            " 7196 7227 7455 7532 8476 8701 8938 9258]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "137 [  44   52   72  219  230  271  298  336  399  479  487  507  510  511\n",
            "  537  557  558  567  586  592  604  692  732  803  816  823  886  895\n",
            "  897  903  905  928  950  974 1009 1018 1043 1047 1050 1115 1142 1164\n",
            " 1230 1271 1414 1478 1519 1647 1649 1671 1684 1686 1699 1723 1758 1776\n",
            " 1807 1818 1822 1836 1984 1989 2107 2185 2198 2326 2327 2461 2466 2479\n",
            " 2532 2550 2633 2672 2792 2983 3029 3105 3138 3400 3411 3497 3809 3948\n",
            " 4015 4016 4036 4055 4060 4267 4562 4609 4613 4725 4796 4851 4876 4928\n",
            " 5191 5311 5355 5378 5725 5820 5842 5921 5949 6019 6114 6257 6326 6391\n",
            " 6507 6761 6772 7106 7166 7173 7181 7196 7227 7294 7455 7532 7983 8051\n",
            " 8078 8082 8186 8476 8701 8938 8988 9028 9074 9237 9258]\n",
            "\n",
            "137 [0.5024763  0.50242084 0.50625664 0.5015767  0.5025692  0.50463367\n",
            " 0.50390583 0.50059813 0.50186515 0.5033057  0.50088143 0.501753\n",
            " 0.5024148  0.50209004 0.5003103  0.50467205 0.50327104 0.50571525\n",
            " 0.50011367 0.5103051  0.50017303 0.50126743 0.5012014  0.50490165\n",
            " 0.5019867  0.5134327  0.50071096 0.5071819  0.50005734 0.5007446\n",
            " 0.5120834  0.5011069  0.50554454 0.5050841  0.502397   0.50213015\n",
            " 0.50437164 0.51537687 0.5017277  0.50311846 0.50120497 0.5003078\n",
            " 0.504138   0.5137448  0.5009746  0.5024164  0.50093085 0.5014079\n",
            " 0.5006458  0.5041424  0.5022935  0.5027255  0.50127256 0.502941\n",
            " 0.50021344 0.500428   0.50078803 0.5016057  0.50004125 0.5044788\n",
            " 0.5013216  0.5023268  0.50393355 0.501695   0.5000374  0.50214475\n",
            " 0.5014921  0.5011416  0.5021017  0.50146115 0.5057698  0.5023065\n",
            " 0.5031197  0.5033327  0.5011518  0.500587   0.50345004 0.5140703\n",
            " 0.50031483 0.5008276  0.5006245  0.5054198  0.50118977 0.50058424\n",
            " 0.50044155 0.5016405  0.50105536 0.50042784 0.50321263 0.50352675\n",
            " 0.503768   0.5019083  0.5024436  0.5002009  0.505184   0.5019985\n",
            " 0.5002933  0.5046966  0.5010395  0.5042255  0.50375026 0.5020132\n",
            " 0.5003512  0.50028974 0.5039994  0.5075024  0.50205696 0.503613\n",
            " 0.5017017  0.5013793  0.5033554  0.5005537  0.5017096  0.50251263\n",
            " 0.5033991  0.5031912  0.5057846  0.5008871  0.5015924  0.5038235\n",
            " 0.51552385 0.50029147 0.51151985 0.5040446  0.5007425  0.5005518\n",
            " 0.501147   0.5015     0.5025246  0.50354046 0.5060377  0.51210064\n",
            " 0.50281024 0.50217324 0.5005013  0.50088716 0.5058914 ]\n",
            "\n",
            "Matched draws\n",
            "Count: 6, Index: (array([  44,  511,  558, 4613, 6257, 8988]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "104571  495419 2019-06-01  SpecialNo1      511\n",
            "104599  495519 2019-06-02  SpecialNo5      558\n",
            "104789  496419 2019-06-22  2ndPrizeNo       44\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "104571  495419 2019-06-01  SpecialNo1      511\n",
            "104599  495519 2019-06-02  SpecialNo5      558\n",
            "104789  496419 2019-06-22  2ndPrizeNo       44\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "104571  495419 2019-06-01      SpecialNo1      511\n",
            "104599  495519 2019-06-02      SpecialNo5      558\n",
            "104789  496419 2019-06-22      2ndPrizeNo       44\n",
            "104798  496419 2019-06-22  ConsolationNo7     8988\n",
            "104803  496419 2019-06-22      SpecialNo2     6257\n",
            "104898  496819 2019-06-30      SpecialNo5     4613\n",
            "CPU times: user 3min 19s, sys: 490 ms, total: 3min 20s\n",
            "Wall time: 54.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ns3Puh7Gnxl5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3378efd-541e-4645-ae4d-38f9be901c95"
      },
      "source": [
        "%time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='test')\n",
        "%time model(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='test')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 889893 observations.\n",
            "Testing on 10000 observations.\n",
            "\n",
            "Data shape before balancing: (889893, 62)\n",
            "\n",
            "Counts of strikes vs non-strikes in previous data:\n",
            "0    860060\n",
            "1     29833\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "\n",
            "NO balancing\n",
            "Data shape after balancing: (889893, 62)\n",
            "\n",
            "Counts of strikes VS non-strikes in new data:\n",
            "0    860060\n",
            "1     29833\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Filtering features\n",
            "\n",
            "Data shape before feature selection: (889893, 62)\n",
            "\n",
            "Counts of strikes vs non-strikes before feature selection:\n",
            "0    860060\n",
            "1     29833\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "\n",
            "Data shape after feature selection: (889893, 31)\n",
            "\n",
            "Counts of strikes vs non-strikes in new data:\n",
            "0    860060\n",
            "1     29833\n",
            "Name: Label, dtype: int64\n",
            "CPU times: user 11.2 s, sys: 108 ms, total: 11.3 s\n",
            "Wall time: 18.4 s\n",
            "Data shape\n",
            "(889893, 30) (889893,) (10000, 30) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 860060, 1: 29833})\n",
            "\n",
            "scale_pos_weight - 28.829148929038315\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.829148929038315, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.829148929038315]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.489, F-Score=0.06839\n",
            "\n",
            "Recall: 0.017857142857142856\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.99      0.02      0.98      0.13      0.02      9664\n",
            "          1       0.05      0.02      0.99      0.03      0.13      0.02       336\n",
            "\n",
            "avg / total       0.94      0.96      0.05      0.95      0.13      0.02     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0178571</td>\n",
              "      <td>0.987997</td>\n",
              "      <td>0.0118851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity   Optimize\n",
              "XGBClassifier_optimize            0   0.0178571         0.987997  0.0118851"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 122 \n",
            "\n",
            "First 23 matches\n",
            "23 [  6  22  42  44  52 152 163 193 197 201 219 226 253 259 279 283 291 298\n",
            " 322 352 380 392 498]\n",
            "\n",
            "[0.50080395 0.50334287 0.5052871  0.5025526  0.50145906 0.50012857\n",
            " 0.5027822  0.5054151  0.5028476  0.5026786  0.5015116  0.50095034\n",
            " 0.50019866 0.50203264 0.5010221  0.5063149  0.5008269  0.5005599\n",
            " 0.5006754  0.50294393 0.5028974  0.5049916  0.5015267 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[1597  594 2958   42 5301 1531 4060 2479 5311 4609 2107 1949 3105 1047\n",
            "  392 1271 1207 1553  283 1702 3576  193 7181]\n",
            "\n",
            "\n",
            "[0.50449854 0.5045001  0.5048205  0.5052871  0.5084969  0.5076182\n",
            " 0.505373   0.5093117  0.51060724 0.5060254  0.50597495 0.51323\n",
            " 0.5053036  0.5102036  0.5049916  0.5059752  0.5057163  0.5076201\n",
            " 0.5063149  0.5054221  0.5052292  0.5054151  0.5069316 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "43 [ 22  42  44  52 152 163 193 197 201 219 226 253 259 279 283 291 298 322\n",
            " 352 380 392 498 507 540 546 559 567 581 594 604 628 722 731 732 789 838\n",
            " 851 886 895 903 909 923 954]\n",
            "\n",
            "[0.50334287 0.5052871  0.5025526  0.50145906 0.50012857 0.5027822\n",
            " 0.5054151  0.5028476  0.5026786  0.5015116  0.50095034 0.50019866\n",
            " 0.50203264 0.5010221  0.5063149  0.5008269  0.5005599  0.5006754\n",
            " 0.50294393 0.5028974  0.5049916  0.5015267  0.5013166  0.5020532\n",
            " 0.50370383 0.50309426 0.5022585  0.50337917 0.5045001  0.50328803\n",
            " 0.50089115 0.5034196  0.5002502  0.50171685 0.50292975 0.5009198\n",
            " 0.5014762  0.50134075 0.5023796  0.5017521  0.5037188  0.5043214\n",
            " 0.50034714]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5023722052574158\n",
            "\n",
            "51 [  22   42   44  163  193  197  201  283  352  380  392  546  559  581\n",
            "  594  604  722  789  895  909  923 1047 1115 1207 1217 1271 1531 1553\n",
            " 1597 1702 1949 2107 2479 2936 2958 3034 3105 3576 3968 4060 4479 4609\n",
            " 4663 5261 5301 5311 5442 5615 7181 7303 8051]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5026209950447083\n",
            "\n",
            "46 [  22   42  163  193  197  201  283  352  380  392  546  559  581  594\n",
            "  604  722  789  909  923 1047 1115 1207 1217 1271 1531 1553 1597 1702\n",
            " 1949 2107 2479 2936 2958 3034 3105 3576 3968 4060 4479 4609 4663 5261\n",
            " 5301 5311 5442 7181]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "122 [   6   22   42   44   52  152  163  193  197  201  219  226  253  259\n",
            "  279  283  291  298  322  352  380  392  498  507  540  546  559  567\n",
            "  581  594  604  628  722  731  732  789  838  851  886  895  903  909\n",
            "  923  954 1043 1047 1093 1115 1198 1207 1217 1271 1300 1410 1474 1478\n",
            " 1531 1553 1554 1555 1597 1651 1702 1710 1723 1914 1949 1950 1952 2107\n",
            " 2117 2122 2278 2326 2342 2479 2571 2603 2692 2749 2786 2872 2936 2958\n",
            " 3003 3034 3090 3091 3105 3113 3211 3319 3387 3576 3664 3968 4060 4166\n",
            " 4465 4479 4609 4663 5067 5261 5301 5311 5442 5501 5506 5615 6941 6962\n",
            " 7081 7106 7181 7249 7294 7303 7320 7733 8051 8556]\n",
            "\n",
            "122 [0.50080395 0.50334287 0.5052871  0.5025526  0.50145906 0.50012857\n",
            " 0.5027822  0.5054151  0.5028476  0.5026786  0.5015116  0.50095034\n",
            " 0.50019866 0.50203264 0.5010221  0.5063149  0.5008269  0.5005599\n",
            " 0.5006754  0.50294393 0.5028974  0.5049916  0.5015267  0.5013166\n",
            " 0.5020532  0.50370383 0.50309426 0.5022585  0.50337917 0.5045001\n",
            " 0.50328803 0.50089115 0.5034196  0.5002502  0.50171685 0.50292975\n",
            " 0.5009198  0.5014762  0.50134075 0.5023796  0.5017521  0.5037188\n",
            " 0.5043214  0.50034714 0.5005333  0.5102036  0.50046784 0.5040719\n",
            " 0.5020989  0.5057163  0.50438243 0.5059752  0.5012187  0.5012836\n",
            " 0.500315   0.5009685  0.5076182  0.5076201  0.502139   0.50100327\n",
            " 0.50449854 0.50159764 0.5054221  0.50016147 0.5002294  0.5021322\n",
            " 0.51323    0.5021135  0.50099105 0.50597495 0.50086206 0.5016362\n",
            " 0.5005217  0.50098836 0.5017434  0.5093117  0.50067973 0.5017201\n",
            " 0.5001491  0.5002624  0.5002722  0.5015337  0.5035061  0.5048205\n",
            " 0.50027496 0.50405777 0.50054413 0.5023407  0.5053036  0.50125796\n",
            " 0.5001046  0.50137544 0.5014853  0.5052292  0.50007194 0.50298065\n",
            " 0.505373   0.50038207 0.5020544  0.50398517 0.5060254  0.50401807\n",
            " 0.500279   0.5027589  0.5084969  0.51060724 0.50369537 0.50126696\n",
            " 0.5013827  0.5024305  0.50138736 0.50011235 0.5012832  0.5013445\n",
            " 0.5069316  0.50047696 0.50177133 0.502416   0.50012463 0.50062895\n",
            " 0.50254613 0.5001779 ]\n",
            "\n",
            "Matched draws\n",
            "Count: 6, Index: (array([   6,   22,   44,  628, 4663, 5501]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "104635  495719 2019-06-08  ConsolationNo5        6\n",
            "104789  496419 2019-06-22      2ndPrizeNo       44\n",
            "104802  496419 2019-06-22     SpecialNo10       22\n",
            "104856  496619 2019-06-26      SpecialNo9        6\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate    PrizeType  LuckyNo\n",
            "104789  496419 2019-06-22   2ndPrizeNo       44\n",
            "104802  496419 2019-06-22  SpecialNo10       22\n",
            "104900  496819 2019-06-30   SpecialNo7      628\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "104635  495719 2019-06-08  ConsolationNo5        6\n",
            "104789  496419 2019-06-22      2ndPrizeNo       44\n",
            "104802  496419 2019-06-22     SpecialNo10       22\n",
            "104807  496419 2019-06-22      SpecialNo6     4663\n",
            "104856  496619 2019-06-26      SpecialNo9        6\n",
            "104899  496819 2019-06-30      SpecialNo6     5501\n",
            "104900  496819 2019-06-30      SpecialNo7      628\n",
            "CPU times: user 29min 33s, sys: 1.12 s, total: 29min 34s\n",
            "Wall time: 7min 30s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE6Xbz-IyvLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "30e5c047-c7a6-4ef1-c6ce-4076326101ba"
      },
      "source": [
        "%time gen_train_test_set(pd.datetime(2019,7,1), feature_matrix_selection, file_prefix='test')\n",
        "%time model(pd.datetime(2019,7,1), feature_matrix_selection, file_prefix='test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 899893 observations.\n",
            "Testing on 10000 observations.\n",
            "\n",
            "Data shape before balancing: (899893, 62)\n",
            "\n",
            "Counts of strikes vs non-strikes in previous data:\n",
            "0    869724\n",
            "1     30169\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "\n",
            "NO balancing\n",
            "Data shape after balancing: (899893, 62)\n",
            "\n",
            "Counts of strikes VS non-strikes in new data:\n",
            "0    869724\n",
            "1     30169\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Filtering features\n",
            "\n",
            "Data shape before feature selection: (899893, 62)\n",
            "\n",
            "Counts of strikes vs non-strikes before feature selection:\n",
            "0    869724\n",
            "1     30169\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "\n",
            "Data shape after feature selection: (899893, 32)\n",
            "\n",
            "Counts of strikes vs non-strikes in new data:\n",
            "0    869724\n",
            "1     30169\n",
            "Name: Label, dtype: int64\n",
            "CPU times: user 11.3 s, sys: 129 ms, total: 11.4 s\n",
            "Wall time: 11.5 s\n",
            "Data shape\n",
            "(899893, 31) (899893,) (10000, 31) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 869724, 1: 30169})\n",
            "\n",
            "scale_pos_weight - 28.828400013258644\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 5, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.828400013258644, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.828400013258644]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qktZbi7OGqP3",
        "colab": {}
      },
      "source": [
        "# NO Feature_selection\n",
        "# n_estimators = 300\n",
        "# NO remove outliers\n",
        "# filter features\n",
        "#start_mt = pd.datetime(2019,6,1)\n",
        "#how_many_mt = 7 \n",
        "#for i in range(how_many_mt):\n",
        "#  month_to_predict = start_mt + relativedelta(months=i)\n",
        "#  print(f\"\\n{month_to_predict}\\n-------------------\\n\")\n",
        "#  %time gen_train_test_set(month_to_predict, feature_matrix_selection, file_prefix='test')\n",
        "#  %time model(month_to_predict, feature_matrix_selection, file_prefix='test')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8tcqn4yIl21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}