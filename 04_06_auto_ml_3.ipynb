{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "04_02_automated_machine_learning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengwangk/dl-projects/blob/master/04_06_auto_ml_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4hyoPGdjpqa_"
      },
      "source": [
        "# Automated ML - Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLxr2k_ue8yq",
        "colab": {}
      },
      "source": [
        "COLAB = True\n",
        "\n",
        "DATASET_NAME = '4D.zip'\n",
        "\n",
        "FEATURE_DATASET_PREFIX = 'feature_matrix_d2_v3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oy5ww2zRfFGG",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  !pip install -U imblearn\n",
        "  !rm -rf dl-projects\n",
        "  !git clone https://github.com/mengwangk/dl-projects"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G2xin10SfozR",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  !cp dl-projects/utils* .\n",
        "  !cp dl-projects/preprocess* .\n",
        "  !cp dl-projects/plot* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fC2-l3JBpqbE",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "# %reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TP7V_IzepqbK",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "import matplotlib\n",
        "import sys\n",
        "\n",
        "from scipy import stats\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "import featuretools as ft\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, roc_curve, mean_squared_error, accuracy_score, average_precision_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.decomposition import PCA\n",
        "import pylab as pl\n",
        "from collections import Counter\n",
        "\n",
        "# from skopt import BayesSearchCV\n",
        "# from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# from scikitplot.plotters import plot_precision_recall_curve\n",
        "\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "from utils import *\n",
        "from preprocess import *\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "# The Answer to the Ultimate Question of Life, the Universe, and Everything.\n",
        "np.random.seed(42)\n",
        "\n",
        "from utils import feature_selection, plot_feature_importances\n",
        "from plot import plot_correlation_matrix, plot_labelled_scatter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3bFT5CoxpqbP",
        "colab": {}
      },
      "source": [
        "%aimport"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3E16jPVPpqbV"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U421BuhtfYS7",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  GDRIVE_DATASET_FOLDER = Path('gdrive/My Drive/datasets/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9IgnETKkpqbX",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  DATASET_PATH = GDRIVE_DATASET_FOLDER\n",
        "  ORIGIN_DATASET_PATH = Path('dl-projects/datasets')\n",
        "else:\n",
        "  DATASET_PATH = Path(\"datasets\")\n",
        "  ORIGIN_DATASET_PATH = Path('datasets')\n",
        "\n",
        "DATASET = DATASET_PATH/f\"{FEATURE_DATASET_PREFIX}.ft\"\n",
        "ORIGIN_DATASET = ORIGIN_DATASET_PATH/DATASET_NAME\n",
        "\n",
        "if COLAB:\n",
        "  !ls -l gdrive/\"My Drive\"/datasets/ --block-size=M\n",
        "  !ls -l dl-projects/datasets --block-size=M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urQTD6DQNutw",
        "colab": {}
      },
      "source": [
        "data = pd.read_feather(DATASET)\n",
        "origin_data = format_tabular(ORIGIN_DATASET)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4BjrERxV8WuT",
        "colab": {}
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vOYlp-8Br61r"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kHiN1VVlG9Kh"
      },
      "source": [
        "### View data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JnQXyVqng5Cm",
        "colab": {}
      },
      "source": [
        "# Feature matrix\n",
        "feature_matrix = data.drop(columns=['NumberId', 'month', 'year'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apMYVNz9HK9e",
        "colab": {}
      },
      "source": [
        "# Sort data\n",
        "feature_matrix.sort_values(by=['time', 'MAX(Results.LuckyNo)'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CZKTbWRFJNUq",
        "colab": {}
      },
      "source": [
        "print('Positive: ' + str(feature_matrix['Label'].value_counts()[0]) + ' which is ', round(feature_matrix['Label'].value_counts()[0]/len(feature_matrix) * 100,2), '% of the dataset')\n",
        "print('Negative: ' + str(feature_matrix['Label'].value_counts()[1]) + ' which is ', round(feature_matrix['Label'].value_counts()[1]/len(feature_matrix) * 100,2), '% of the dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E8ZoClJ9JmFY",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "sns.countplot('Label', data=feature_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plplpAQ6JrKb",
        "colab": {}
      },
      "source": [
        "feature_matrix.isna().sum().sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1612o1VKnof",
        "colab": {}
      },
      "source": [
        "feature_matrix[feature_matrix.isnull().any(axis=1)].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fdayfSLPLN_k"
      },
      "source": [
        "### Data Cleansing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9LcvGa8eLiEX",
        "colab": {}
      },
      "source": [
        "## Fill all NaN with 0\n",
        "feature_matrix = feature_matrix.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7KMHiiNyLv_a",
        "colab": {}
      },
      "source": [
        "feature_matrix.isna().sum().sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mzHx8OYQLx0C",
        "colab": {}
      },
      "source": [
        "feature_matrix[feature_matrix.isnull().any(axis=1)].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF_zCRksL1Ls"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_uA8YPbHlleB",
        "colab": {}
      },
      "source": [
        "# Feature scaling first??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5A8LZ805MqjP",
        "colab": {}
      },
      "source": [
        "print(feature_matrix.shape)\n",
        "feature_matrix.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rPFOkiGjhuKj",
        "colab": {}
      },
      "source": [
        "feature_matrix_selection = feature_selection(feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vT2K0WeJhugH",
        "colab": {}
      },
      "source": [
        "feature_matrix_selection.shape, feature_matrix_selection.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZUhYrWFiRod",
        "colab": {}
      },
      "source": [
        "feature_matrix_selection['time'] = feature_matrix['time']\n",
        "feature_matrix_selection['TotalStrike'] = feature_matrix['TotalStrike']\n",
        "feature_matrix_selection['Label'] = feature_matrix['Label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hugygOqSiR6K"
      },
      "source": [
        "### Feature Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JwecxRqfjtaH",
        "colab": {}
      },
      "source": [
        "# Check without feature selection\n",
        "# corrs = feature_matrix.corr().sort_values('Label')\n",
        "# corrs['Label'].tail(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u7Ha8Zlkhuoe",
        "colab": {}
      },
      "source": [
        "# Check with feature selection\n",
        "corrs = feature_matrix_selection.corr().sort_values('Label')\n",
        "corrs['Label'].tail(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b5MHgSCaQCh1"
      },
      "source": [
        "### Balancing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pMtgp-f-Uzee",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import (RandomUnderSampler, \n",
        "                                     ClusterCentroids,\n",
        "                                     TomekLinks,\n",
        "                                     NeighbourhoodCleaningRule,\n",
        "                                     AllKNN,\n",
        "                                     NearMiss)\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = Pipeline([('imputer', SimpleImputer(strategy = 'constant', fill_value=0)), ('scaler', StandardScaler())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG6IuU2KQVQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def under_sampling_test(feature_data, cut_off_date, ratio=0.8):\n",
        "  y = feature_data.loc[feature_data['time'] < cut_off_date, 'Label']\n",
        "  X = feature_data[feature_data['time'] < cut_off_date].drop(columns = ['Label', 'TotalStrike','time','date'], errors='ignore')\n",
        "  total_count = y.value_counts()\n",
        "  neg_count = y.value_counts()[0]\n",
        "  pos_count = y.value_counts()[1]\n",
        "  target_neg_count = int(pos_count / (1-ratio))\n",
        "  target_ratio = {0: target_neg_count, 1:  pos_count}\n",
        "  print(X.shape, y.shape, target_ratio)\n",
        "  # print('Before sampling {}'.format(Counter(y)))\n",
        "  sampler = RandomUnderSampler(sampling_strategy=target_ratio, random_state=42)\n",
        "  X_bal, y_bal = sampler.fit_sample(X, y)\n",
        "  print('Undersampling {}'.format(Counter(y_bal)))\n",
        "  return X_bal, y_bal\n",
        "\n",
        "# https://stackoverflow.com/questions/52499788/smotetomek-how-to-set-ratio-as-dictionary-for-fixed-balance\n",
        "def balancing_pipeline_test(feature_data, cut_off_date, ratio=0.8):\n",
        "  y = feature_data.loc[feature_data['time'] < cut_off_date, 'Label']\n",
        "  X = feature_data[feature_data['time'] < cut_off_date].drop(columns = ['Label', 'TotalStrike','time','date'], errors='ignore')\n",
        "  \n",
        "  total_count = y.value_counts()\n",
        "  neg_count = y.value_counts()[0]\n",
        "  pos_count = y.value_counts()[1]\n",
        "  target_neg_count = int(pos_count / (1-ratio))\n",
        "  target_ratio = {0: target_neg_count, 1:  pos_count}\n",
        "\n",
        "  print('Before sampling {}'.format(Counter(y)))\n",
        "  #sampler = NearMiss(sampling_strategy={0: target_neg_count}, n_jobs=4)\n",
        "  sampler = SMOTETomek(sampling_strategy='auto')\n",
        "  X = pipeline.fit_transform(X)\n",
        "  X_bal, y_bal = sampler.fit_sample(X, y)\n",
        "  print('Over and undersampling {}'.format(Counter(y_bal)))\n",
        "  return X_bal, y_bal\n",
        "\n",
        "%time X_res, y_res = balancing_pipeline_test(feature_matrix_selection, pd.datetime(2019,6,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyZSWpKCSeL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_this(X_rs,y_rs,method):\n",
        "  # Use principal component to condense the 10 features to 2 features\n",
        "  pca = PCA(n_components=2).fit(X_rs)\n",
        "  pca_2d = pca.transform(X_rs)\n",
        "  # Assign colors\n",
        "  for i in range(0, pca_2d.shape[0]):\n",
        "    if y_rs[i] == 0:\n",
        "      c1 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='r', marker='o')\n",
        "    elif y_rs[i] == 1:\n",
        "      c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='g', marker='*')  \n",
        "  pl.legend([c1, c2], ['Class 1', 'Class 2'])\n",
        "  pl.title(method)\n",
        "  pl.axis([-4, 5, -4, 4])  # x axis (-4,5), y axis (-4,4)\n",
        "  pl.show()\n",
        "\n",
        "# Plot \n",
        "plot_this(X_res, y_res, 'SMOTETomek')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K2G3__hQZ6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def under_sampling(X, y, ratio=0.9):\n",
        "  total_count = y.value_counts()\n",
        "  neg_count = y.value_counts()[0]\n",
        "  pos_count = y.value_counts()[1]\n",
        "\n",
        "  target_neg_count = int(pos_count / (1-ratio))\n",
        "  target_ratio = {0: target_neg_count, 1:  pos_count}\n",
        "  #print(X.shape, y.shape, target_ratio)\n",
        "  print('Before sampling {}'.format(Counter(y)))\n",
        "  sampler = RandomUnderSampler(random_state=42, sampling_strategy=target_ratio)\n",
        "  X_bal, y_bal = sampler.fit_sample(X, y)\n",
        "  print('Undersampling {}'.format(Counter(y_bal)))\n",
        "  return X_bal, y_bal\n",
        "\n",
        "def over_under_sampling(X, y):\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "waeD1ED_kqDB"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Gq0iPZ1C8ka",
        "colab": {}
      },
      "source": [
        "def predict(dt, feature_matrix, sampling = False, return_probs = False): \n",
        "   \n",
        "    feature_matrix['date'] = feature_matrix['time']\n",
        "\n",
        "    # Subset labels\n",
        "    test_labels = feature_matrix.loc[feature_matrix['date'] == dt, 'Label']\n",
        "    train_labels = feature_matrix.loc[feature_matrix['date'] < dt, 'Label']\n",
        "\n",
        "    print(f\"Size of test labels {len(test_labels)}\")\n",
        "    print(f\"Size of train labels {len(train_labels)}\")\n",
        "    \n",
        "    # Features\n",
        "    X_train = feature_matrix[feature_matrix['date'] < dt].drop(columns = ['NumberId', 'time',\n",
        "                                                                                     'date', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    X_test = feature_matrix[feature_matrix['date'] == dt].drop(columns = ['NumberId', 'time',\n",
        "                                                                                     'date', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    print(f\"Size of X train {len(X_train)}\")\n",
        "    print(f\"Size of X test  {len(X_test)}\")\n",
        "   \n",
        "    feature_names = list(X_train.columns)\n",
        "    \n",
        "   \n",
        "    # Impute and scale features\n",
        "    pipeline = Pipeline([('imputer', SimpleImputer(strategy = 'constant', fill_value=0)), ('scaler', StandardScaler())])\n",
        "\n",
        "    # Fit and transform training data\n",
        "    X_train = pipeline.fit_transform(X_train)\n",
        "    X_test = pipeline.transform(X_test)\n",
        "\n",
        "    # Balance the data\n",
        "    if sampling:\n",
        "      X_train, train_labels = under_sampling(X_train, train_labels)\n",
        "   \n",
        "    # Labels\n",
        "    y_train = np.array(train_labels).reshape((-1, ))\n",
        "    y_test = np.array(test_labels).reshape((-1, ))\n",
        "    \n",
        "    print('Training on {} observations.'.format(len(X_train)))\n",
        "    print('Testing on {} observations.\\n'.format(len(X_test)))\n",
        "    \n",
        "    # https://xgboost.readthedocs.io/en/latest/parameter.html\n",
        "    # https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html\n",
        "    # https://stats.stackexchange.com/questions/224512/reduce-false-positives-with-xgboost\n",
        "\n",
        "    if type(train_labels) == np.ndarray:\n",
        "      hit_ratio = float( len(np.where(train_labels == 0)[0]) / len(np.where(train_labels == 1)[0]) ) \n",
        "    else:\n",
        "      hit_ratio = float(train_labels.value_counts()[0]/train_labels.value_counts()[1]) \n",
        "    print(f\"Hit ratio - {hit_ratio}\\n\")\n",
        "\n",
        "     # Create the classifier\n",
        "    model = xgb.XGBClassifier(n_jobs=-1, \n",
        "                             random_state = 42,\n",
        "                             n_estimators=100, \n",
        "                             max_depth=3,\n",
        "                             objective='binary:logistic',\n",
        "                             min_child_weight=1,\n",
        "                             scale_pos_weight=hit_ratio \n",
        "                             )\n",
        "\n",
        "    # Train \n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions\n",
        "    predictions = model.predict(X_test)\n",
        "    probs = model.predict_proba(X_test)[:, 1]\n",
        "    # Total positive\n",
        "    positive = np.where((predictions==1))\n",
        "    print(f'Total predicted to be positive: {len(positive[0])} \\n')\n",
        "  \n",
        "    # Calculate metrics\n",
        "    rpt = classification_report(y_test, predictions)\n",
        "    cm = confusion_matrix(y_test, predictions)\n",
        "    print('Classification report')\n",
        "    print(rpt)\n",
        "    print(f'Confusion matrix:\\n {cm}\\n')\n",
        "\n",
        "    # Total predicted matches\n",
        "    print('Predicted matches')\n",
        "    pred = np.where((predictions==1))\n",
        "    print(len(pred[0]), pred[0][0:23])\n",
        "    topN = np.argpartition(probs, -23)[-23:]\n",
        "    print(f'\\n{topN}\\n')  # Top N most high probability numbers\n",
        "  \n",
        "    if len(positive[0]) > 0:\n",
        "    \n",
        "      # Matching draws\n",
        "      print('Matched draws')\n",
        "      md = np.where((predictions==1) & (y_test==1))\n",
        "      print(f\"Count: {len(md[0])}, Index: {md}\")\n",
        "      month_data = feature_matrix.loc[feature_matrix['date'] == dt]\n",
        "      numbers = month_data.iloc[md[0]][['MAX(Results.LuckyNo)']]\n",
        "\n",
        "      print('\\n\\nTop 23 Possibility')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(topN))].head(23))  \n",
        "      \n",
        "      print('\\n\\nFirst 23 Numbers')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(pred[0][0:23]))].head(23))    \n",
        "             \n",
        "\n",
        "      print('\\n\\nAll matched')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(numbers['MAX(Results.LuckyNo)']))].head(100))    \n",
        "                                                  \n",
        "    else:\n",
        "      print('No luck this month')                 \n",
        "\n",
        "    # Feature importances\n",
        "    fi = pd.DataFrame({'feature': feature_names, 'importance': model.feature_importances_})\n",
        "    \n",
        "    if return_probs:\n",
        "        return fi, probs\n",
        "    \n",
        "    return fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EFAFoPBEoWFi",
        "colab": {}
      },
      "source": [
        "%time june_2019 = predict(pd.datetime(2019,6,1), feature_matrix_selection)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rV0niLRnfmsj",
        "colab": {}
      },
      "source": [
        "#normalized_fi = plot_feature_importances(june_2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7itdGGHwprH",
        "colab": {}
      },
      "source": [
        "# Loop through from June to Dec\n",
        "# start_mt = pd.datetime(2019,6,1)\n",
        "# how_many_mt = 7\n",
        "# for i in range(how_many_mt):\n",
        "#   month_to_predict = start_mt + relativedelta(months=i)\n",
        "#   print(f\"\\n{month_to_predict}\\n-------------------\\n\")\n",
        "#   %time predict(month_to_predict, feature_matrix_selection)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q91OSb9M3xfj",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}