{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "04_02_automated_machine_learning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengwangk/dl-projects/blob/master/04_06_auto_ml_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4hyoPGdjpqa_"
      },
      "source": [
        "# Automated ML - Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLxr2k_ue8yq",
        "colab": {}
      },
      "source": [
        "COLAB = True\n",
        "\n",
        "DATASET_NAME = '4D.zip'\n",
        "\n",
        "FEATURE_DATASET_PREFIX = 'feature_matrix_d2_v3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oy5ww2zRfFGG",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  !pip install -U imblearn\n",
        "  !rm -rf dl-projects\n",
        "  !git clone https://github.com/mengwangk/dl-projects"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G2xin10SfozR",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  !cp dl-projects/utils* .\n",
        "  !cp dl-projects/preprocess* .\n",
        "  !cp dl-projects/plot* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fC2-l3JBpqbE",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "# %reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TP7V_IzepqbK",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "import matplotlib\n",
        "import sys\n",
        "\n",
        "from scipy import stats\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "import featuretools as ft\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, make_scorer, recall_score, roc_curve, mean_squared_error, accuracy_score, average_precision_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedShuffleSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import pylab as pl\n",
        "from collections import Counter\n",
        "\n",
        "# from skopt import BayesSearchCV\n",
        "# from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# from scikitplot.plotters import plot_precision_recall_curve\n",
        "\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "from utils import *\n",
        "from preprocess import *\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "# The Answer to the Ultimate Question of Life, the Universe, and Everything.\n",
        "np.random.seed(42)\n",
        "\n",
        "from utils import feature_selection, plot_feature_importances\n",
        "from plot import plot_correlation_matrix, plot_labeled_scatter\n",
        "\n",
        "\n",
        "from imblearn.under_sampling import (RandomUnderSampler, \n",
        "                                     ClusterCentroids,\n",
        "                                     TomekLinks,\n",
        "                                     NeighbourhoodCleaningRule,\n",
        "                                     AllKNN,\n",
        "                                     NearMiss,\n",
        "                                     OneSidedSelection)\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "from imblearn.over_sampling import SMOTE, SMOTENC, ADASYN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3bFT5CoxpqbP",
        "colab": {}
      },
      "source": [
        "%aimport"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3E16jPVPpqbV"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U421BuhtfYS7",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  GDRIVE_DATASET_FOLDER = Path('gdrive/My Drive/datasets/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9IgnETKkpqbX",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  DATASET_PATH = GDRIVE_DATASET_FOLDER\n",
        "  ORIGIN_DATASET_PATH = Path('dl-projects/datasets')\n",
        "else:\n",
        "  DATASET_PATH = Path(\"datasets\")\n",
        "  ORIGIN_DATASET_PATH = Path('datasets')\n",
        "\n",
        "DATASET = DATASET_PATH/f\"{FEATURE_DATASET_PREFIX}.ft\"\n",
        "ORIGIN_DATASET = ORIGIN_DATASET_PATH/DATASET_NAME\n",
        "\n",
        "if COLAB:\n",
        "  !ls -l gdrive/\"My Drive\"/datasets/ --block-size=M\n",
        "  !ls -l dl-projects/datasets --block-size=M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urQTD6DQNutw",
        "colab": {}
      },
      "source": [
        "data = pd.read_feather(DATASET)\n",
        "origin_data = format_tabular(ORIGIN_DATASET)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vOYlp-8Br61r"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kHiN1VVlG9Kh"
      },
      "source": [
        "### View data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JnQXyVqng5Cm",
        "colab": {}
      },
      "source": [
        "# Feature matrix\n",
        "feature_matrix = data.drop(columns=['NumberId', 'month', 'year'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apMYVNz9HK9e",
        "colab": {}
      },
      "source": [
        "# Sort data\n",
        "feature_matrix.sort_values(by=['time', 'MAX(Results.LuckyNo)'], inplace=True)\n",
        "feature_matrix.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CZKTbWRFJNUq",
        "colab": {}
      },
      "source": [
        "print('Distrbution')\n",
        "print(feature_matrix['Label'].value_counts())\n",
        "print()\n",
        "print('Positive: ' + str(feature_matrix['Label'].value_counts()[0]) + ' which is ', round(feature_matrix['Label'].value_counts()[0]/len(feature_matrix) * 100,2), '% of the dataset')\n",
        "print('Negative: ' + str(feature_matrix['Label'].value_counts()[1]) + ' which is ', round(feature_matrix['Label'].value_counts()[1]/len(feature_matrix) * 100,2), '% of the dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E8ZoClJ9JmFY",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "sns.countplot('Label', data=feature_matrix)\n",
        "plt.title(\"Strike Count\", fontsize=18)\n",
        "plt.xlabel(\"Strike?\", fontsize=15)\n",
        "plt.ylabel(\"Count\", fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plplpAQ6JrKb",
        "colab": {}
      },
      "source": [
        "feature_matrix.isna().sum().sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1612o1VKnof",
        "colab": {}
      },
      "source": [
        "feature_matrix[feature_matrix.isnull().any(axis=1)].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fdayfSLPLN_k"
      },
      "source": [
        "### Data Cleansing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9LcvGa8eLiEX",
        "colab": {}
      },
      "source": [
        "## Fill all NaN with 0\n",
        "feature_matrix = feature_matrix.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7KMHiiNyLv_a",
        "colab": {}
      },
      "source": [
        "feature_matrix.isna().sum().sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mzHx8OYQLx0C",
        "colab": {}
      },
      "source": [
        "feature_matrix[feature_matrix.isnull().any(axis=1)].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vjMbf9bZ9Z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Distribution\n",
        "\n",
        "# plt.figure(figsize=(16,4))\n",
        "# feature_matrix.iloc[:,:-1].boxplot()\n",
        "# plt.title('(Raw) Distribution of Features', fontsize=17)\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(figsize=(16,4))\n",
        "# np.log(feature_matrix.drop(columns=['time']).iloc[:,:-1]).boxplot() # Remove time column\n",
        "# plt.title('(Log) Distribution of Features', fontsize=17)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF_zCRksL1Ls"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_uA8YPbHlleB",
        "colab": {}
      },
      "source": [
        "# Feature scaling first??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5A8LZ805MqjP",
        "colab": {}
      },
      "source": [
        "print(feature_matrix.shape)\n",
        "feature_matrix.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rPFOkiGjhuKj",
        "colab": {}
      },
      "source": [
        "feature_matrix_selection = feature_selection(feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vT2K0WeJhugH",
        "colab": {}
      },
      "source": [
        "feature_matrix_selection.shape, feature_matrix_selection.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZUhYrWFiRod",
        "colab": {}
      },
      "source": [
        "feature_matrix_selection['time'] = feature_matrix['time']\n",
        "feature_matrix_selection['TotalStrike'] = feature_matrix['TotalStrike']\n",
        "feature_matrix_selection['Label'] = feature_matrix['Label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hugygOqSiR6K"
      },
      "source": [
        "### Feature Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JwecxRqfjtaH",
        "colab": {}
      },
      "source": [
        "# Check without feature selection\n",
        "# corrs = feature_matrix.corr().sort_values('Label')\n",
        "# corrs['Label'].tail(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u7Ha8Zlkhuoe",
        "colab": {}
      },
      "source": [
        "# Check with feature selection\n",
        "corrs = feature_matrix_selection.corr().sort_values('Label')\n",
        "corrs['Label'].tail(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELHhrnmfR6zd",
        "colab_type": "text"
      },
      "source": [
        "### Feature Distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0wZ1SBcR7FC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(24,10))\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(wspace=1)\n",
        "plt.subplot(311)\n",
        "ax = feature_matrix_selection.iloc[:,:20].boxplot()\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=30)\n",
        "plt.title('(Raw) Distribution of Features', fontsize=17)\n",
        "\n",
        "plt.subplot(312)\n",
        "ax = feature_matrix_selection.iloc[:,20:40].boxplot()\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=30)\n",
        "\n",
        "plt.subplot(313)\n",
        "ax = feature_matrix_selection.iloc[:,40:-1].boxplot()\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=30)\n",
        "\n",
        "fig.subplots_adjust(hspace=10)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCPCFed8Sy8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16,4))\n",
        "np.log(feature_matrix_selection.drop(columns=['time']).iloc[:,:-1]).boxplot() # Remove time column\n",
        "plt.title('(Log) Distribution of Features', fontsize=17)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-DdmYLBbL-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(11,6))\n",
        "sns.distplot(feature_matrix_selection['LAST(Results.CUM_MEAN(LuckyNo))'],kde=False)\n",
        "plt.title('Distribution of Time', fontsize=17)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "waeD1ED_kqDB"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8-5gozXcsGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Baseline - https://www.kaggle.com/miguelniblock/optimizing-imbalanced-classification-100-recall\n",
        "def predict_baseline(dt, feature_matrix): \n",
        "    \n",
        "    feature_matrix['date'] = feature_matrix['time']\n",
        "\n",
        "    # Subset labels\n",
        "    test_labels = feature_matrix.loc[feature_matrix['date'] == dt, 'Label']\n",
        "    train_labels = feature_matrix.loc[feature_matrix['date'] < dt, 'Label']\n",
        "\n",
        "    # Features\n",
        "    X_train = feature_matrix[feature_matrix['date'] < dt].drop(columns = ['NumberId', 'time',\n",
        "                                                                                     'date', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    X_test = feature_matrix[feature_matrix['date'] == dt].drop(columns = ['NumberId', 'time',\n",
        "                                                                                     'date', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    feature_names = list(X_train.columns)\n",
        "    \n",
        "    if type(train_labels) == np.ndarray:\n",
        "      hit_ratio = float( len(np.where(train_labels == 0)[0]) / len(np.where(train_labels == 1)[0]) ) \n",
        "    else:\n",
        "      hit_ratio = float(train_labels.value_counts()[0]/train_labels.value_counts()[1]) \n",
        "    \n",
        "    print(f\"Hit ratio before balancing - {hit_ratio}\\n\")\n",
        "\n",
        "    # Labels\n",
        "    y_train = np.array(train_labels).reshape((-1, ))\n",
        "    y_test = np.array(test_labels).reshape((-1, ))\n",
        "    \n",
        "    print('Training on {} observations.'.format(len(X_train)))\n",
        "    print('Testing on {} observations.\\n'.format(len(X_test)))\n",
        "  \n",
        "    pipeline = make_pipeline_imb(\n",
        "                                SimpleImputer(strategy = 'constant', fill_value=0),\n",
        "                                StandardScaler()\n",
        "                                )\n",
        "    \n",
        "   \n",
        "    X_train = pipeline.fit_transform(X_train)\n",
        "    X_test = pipeline.transform(X_test)\n",
        "\n",
        "    # Create the classifier\n",
        "    clf = xgb.XGBClassifier(\n",
        "                             n_jobs=4, \n",
        "                             random_state = 42,\n",
        "                            #  n_estimators=300, \n",
        "                            #  max_depth=5,\n",
        "                            n_estimators=100, \n",
        "                            max_depth=3,\n",
        "                            # n_estimators=1000, \n",
        "                            #  max_depth=5,\n",
        "                            #  gamma=0,\n",
        "                            #  subsample=0.8,\n",
        "                            #  colsample_bytree=0.8,\n",
        "                            #  learning_rate=0.1,\n",
        "                             objective='binary:logistic',\n",
        "                             min_child_weight=1,\n",
        "                             scale_pos_weight=hit_ratio \n",
        "                             )\n",
        "    \n",
        "    # Make a scoring callable from recall_score\n",
        "    recall = make_scorer(recall_score)\n",
        "\n",
        "    train_cv = cross_val_score(X=X_train,y=y_train, scoring=recall, estimator=clf,cv=3)\n",
        "    print(\"TRAIN GROUP\")\n",
        "    print(\"\\nCross-validation recall scores:\",train_cv)\n",
        "    print(\"Mean recall score:\",train_cv.mean())\n",
        "\n",
        "    # Now predict on the test group\n",
        "    print(\"\\nTEST GROUP\")\n",
        "    y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "    print(\"\\nRecall:\",recall_score(y_test,y_pred))\n",
        "\n",
        "    # Classification report\n",
        "    print('\\nClassification report:\\n')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test,y_pred)\n",
        "    sns.heatmap(conf_matrix, annot=True,fmt='d', cmap=plt.cm.copper)\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4JTQraJd5L5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict_baseline(pd.datetime(2019,6,1), feature_matrix_selection)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE4Hm5Y-eCiP",
        "colab_type": "text"
      },
      "source": [
        "### Balancing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yrJyIVLh5So",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a scoring function that improves specificity while identifying all frauds\n",
        "def recall_optim(y_true, y_pred):\n",
        "    \n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    # Recall will be worth a greater value than specificity\n",
        "    rec = recall_score(y_true, y_pred) * 0.8 \n",
        "    spe = conf_matrix[0,0]/conf_matrix[0,:].sum() * 0.2 \n",
        "    \n",
        "    # Imperfect recalls will lose a penalty\n",
        "    # This means the best results will have perfect recalls and compete for specificity\n",
        "    if rec < 0.8:\n",
        "        rec -= 0.2\n",
        "    return rec + spe \n",
        "    \n",
        "# Create a scoring callable based on the scoring function\n",
        "optimize = make_scorer(recall_optim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCW6VZwueGPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_imbalanced(dt, feature_matrix): \n",
        "    \n",
        "    feature_matrix['date'] = feature_matrix['time']\n",
        "\n",
        "    # Subset labels\n",
        "    test_labels = feature_matrix.loc[feature_matrix['date'] == dt, 'Label']\n",
        "    train_labels = feature_matrix.loc[feature_matrix['date'] < dt, 'Label']\n",
        "\n",
        "    # Features\n",
        "    X_train = feature_matrix[feature_matrix['date'] < dt].drop(columns = ['NumberId', 'time',\n",
        "                                                                                     'date', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    X_test = feature_matrix[feature_matrix['date'] == dt].drop(columns = ['NumberId', 'time',\n",
        "                                                                                     'date', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    feature_names = list(X_train.columns)\n",
        "    \n",
        "    if type(train_labels) == np.ndarray:\n",
        "      hit_ratio = float( len(np.where(train_labels == 0)[0]) / len(np.where(train_labels == 1)[0]) ) \n",
        "    else:\n",
        "      hit_ratio = float(train_labels.value_counts()[0]/train_labels.value_counts()[1]) \n",
        "    \n",
        "    print(f\"Hit ratio before balancing - {hit_ratio}\\n\")\n",
        "\n",
        "    # Labels\n",
        "    y_train = np.array(train_labels).reshape((-1, ))\n",
        "    y_test = np.array(test_labels).reshape((-1, ))\n",
        "    \n",
        "    print('Training on {} observations.'.format(len(X_train)))\n",
        "    print('Testing on {} observations.\\n'.format(len(X_test)))\n",
        "  \n",
        "    # Join the train data\n",
        "    train = X_train.join(train_labels)\n",
        "\n",
        "    print('Data shape before balancing:',train.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in previous data:')\n",
        "    print(train.Label.value_counts())\n",
        "    print('-'*40)\n",
        "\n",
        "    # Balancing the test data\n",
        "    pipeline = make_pipeline_imb(\n",
        "                                SimpleImputer(strategy = 'constant', fill_value=0),\n",
        "                                StandardScaler(),\n",
        "                                SMOTE(sampling_strategy='minority',random_state=42, n_jobs=4)\n",
        "                                #OneSidedSelection(n_neighbors=1, n_seeds_S=200, random_state=42, n_jobs=4)\n",
        "                                )\n",
        "    X_bal, y_bal = pipeline.fit_resample(X_train, y_train)\n",
        "    X_bal = pd.DataFrame(X_bal,columns=X_train.columns)\n",
        "    y_bal = pd.DataFrame(y_bal,columns=['Label'])\n",
        "    balanced = X_bal.join(y_bal)\n",
        "\n",
        "    print('-'*40)\n",
        "    print('Data shape after balancing:',balanced.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
        "    print(balanced.Label.value_counts())\n",
        "\n",
        "    print('Distribution of the Classes in the subsample dataset')\n",
        "    print(balanced.Label.value_counts()/len(train))\n",
        "\n",
        "    sns.countplot('Label', data=balanced)\n",
        "    plt.title('Label Distribution', fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "    # Compare correlation of raw train data VS balanced train data\n",
        "    f, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,20))\n",
        "\n",
        "    # Imbalanced DataFrame\n",
        "    corr = train.corr()\n",
        "    # sns.heatmap(corr, annot_kws={'size':20}, ax=ax1)\n",
        "    # ax1.set_title(\"Imbalanced Correlation Matrix \\n (Biased)\", fontsize=14)\n",
        "\n",
        "    # Balanced DataFrame\n",
        "    bal_corr = balanced.corr()\n",
        "    # sns.heatmap(bal_corr, annot_kws={'size':20}, ax=ax2)\n",
        "    # ax2.set_title('Balanced Correlation Matrix', fontsize=14)\n",
        "    # plt.show()\n",
        "\n",
        "    # Each feature's correlation with Class\n",
        "    print(bal_corr.Label)\n",
        "\n",
        "    no_outliers=pd.DataFrame(balanced.copy())\n",
        "\n",
        "    # Removing Outliers from high-correlation features\n",
        "\n",
        "    cols = bal_corr.Label.index[:-1]\n",
        "\n",
        "    # For each feature correlated with Class...\n",
        "    for col in cols:\n",
        "        # If absolute correlation value is more than X percent...\n",
        "        correlation = bal_corr.loc['Label',col]\n",
        "\n",
        "        if np.absolute(correlation) > 0.1:\n",
        "          # Separate the classes of the high-correlation column\n",
        "          nonstrikes = no_outliers.loc[no_outliers.Label==0,col]\n",
        "          strikes = no_outliers.loc[no_outliers.Label==1,col]\n",
        "\n",
        "          # Identify the 25th and 75th quartiles\n",
        "          all_values = no_outliers.loc[:,col]\n",
        "          q25, q75 = np.percentile(all_values, 25), np.percentile(all_values, 75)\n",
        "          # Get the inter quartile range\n",
        "          iqr = q75 - q25\n",
        "          # Smaller cutoffs will remove more outliers\n",
        "          cutoff = iqr * 7\n",
        "          # Set the bounds of the desired portion to keep\n",
        "          lower, upper = q25 - cutoff, q75 + cutoff\n",
        "          \n",
        "          # If positively correlated...\n",
        "          # Drop nonstrikes above upper bound, and strikes below lower bound\n",
        "          if correlation > 0: \n",
        "              no_outliers.drop(index=nonstrikes[nonstrikes>upper].index,inplace=True)\n",
        "              no_outliers.drop(index=strikes[strikes<lower].index,inplace=True)\n",
        "          \n",
        "          # If negatively correlated...\n",
        "          # Drop non strikes below lower bound, and strikes above upper bound\n",
        "          elif correlation < 0: \n",
        "              no_outliers.drop(index=nonstrikes[nonstrikes<lower].index,inplace=True)\n",
        "              no_outliers.drop(index=strikes[strikes>upper].index,inplace=True)\n",
        "        \n",
        "    print('\\nData shape before removing outliers:', balanced.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in previous data:')\n",
        "    print(balanced.Label.value_counts())\n",
        "    print('-'*40)\n",
        "    print('-'*40)\n",
        "    print('\\nData shape after removing outliers:', no_outliers.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
        "    print(no_outliers.Label.value_counts())\n",
        "\n",
        "    no_outliers.iloc[:,:-1].boxplot(rot=90,figsize=(16,4))\n",
        "    plt.title('Distributions with Less Outliers', fontsize=17)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Feature selection\n",
        "    feat_sel =pd.DataFrame(no_outliers.copy())\n",
        "\n",
        "    # Make a dataframe with the label-correlations before removing outliers\n",
        "    corr_change = pd.DataFrame()\n",
        "    corr_change['correlation']= bal_corr.Label\n",
        "    corr_change['origin']= 'w/outliers'\n",
        "\n",
        "    # Make a dataframe with label-correlations after removing outliers \n",
        "    corr_other = pd.DataFrame()\n",
        "    corr_other['correlation']= feat_sel.corr().Label\n",
        "    corr_other['origin']= 'no_outliers'\n",
        "\n",
        "    # Join them\n",
        "    corr_change = corr_change.append(corr_other)\n",
        "\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.xticks(rotation=90)\n",
        "\n",
        "    # Plot them\n",
        "    sns.set_style('darkgrid')\n",
        "    plt.title('Label Correlation per Feature. With VS W/out Outliers', fontsize=17)\n",
        "    sns.barplot(data=corr_change,x=corr_change.index,y='correlation',hue='origin')\n",
        "    plt.show()\n",
        "\n",
        "    # Feature Selection based on correlation with Class\n",
        "    print('\\nData shape before feature selection:', feat_sel.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes before feature selection:')\n",
        "    print(feat_sel.Label.value_counts())\n",
        "    print('-'*40)\n",
        "\n",
        "    X_train = feat_sel.drop('Label',1)\n",
        "    y_train = feat_sel.Label\n",
        "\n",
        "    # After feature-selection, X_test needs to include only the same features as X_train\n",
        "    cols = X_train.columns\n",
        "    X_test = X_test[cols]\n",
        "\n",
        "    # Undersample and balance classes\n",
        "    X_train, y_train = RandomUnderSampler(sampling_strategy={1:100000,0:100000}, random_state=42).fit_resample(X_train,y_train)\n",
        "\n",
        "    print('\\nX_train shape after reduction:', X_train.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in y_train:')\n",
        "    print(np.unique(y_train, return_counts=True))\n",
        "\n",
        "    # First-Run: Predictions on Default Parameters\n",
        "    performance = pd.DataFrame(columns=['Train_Recall','Test_Recall','Test_Specificity'])\n",
        "\n",
        "    # Load simple classifiers\n",
        "    classifiers = [\n",
        "                   #SVC(max_iter=1000),\n",
        "                   #LogisticRegression(),\n",
        "                   DecisionTreeClassifier(),\n",
        "                   #KNeighborsClassifier(),\n",
        "                   xgb.XGBClassifier(n_jobs=4, random_state = 42,objective='binary:logistic')\n",
        "                   ]\n",
        "\n",
        "    \n",
        "    # Make a scoring callable from recall_score\n",
        "    # recall = make_scorer(recall_score)\n",
        "\n",
        "    # Get a classification report from each algorithm\n",
        "    for clf in classifiers:    \n",
        "    \n",
        "      # Heading\n",
        "      print('\\n','-'*40,'\\n',clf.__class__.__name__,'\\n','-'*40)\n",
        "      \n",
        "      # Cross-validate on the train data\n",
        "      print(\"TRAIN GROUP\")\n",
        "      train_cv = cross_val_score(X=X_train, y=y_train, estimator=clf, cv=3, n_jobs=4, scoring=optimize) # scoring=recall\n",
        "      print(\"\\nCross-validation recall scores:\",train_cv)\n",
        "      print(\"Mean recall score:\",train_cv.mean())\n",
        "\n",
        "      # Now predict on the test group\n",
        "      print(\"\\nTEST GROUP\")\n",
        "      y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "      print(\"\\nRecall:\",recall_score(y_test,y_pred))\n",
        "      \n",
        "      # Print confusion matrix\n",
        "      conf_matrix = confusion_matrix(y_test,y_pred)\n",
        "      sns.heatmap(conf_matrix, annot=True,fmt='d', cmap=plt.cm.copper)\n",
        "      plt.show()\n",
        "      \n",
        "      # Store results\n",
        "      performance.loc[clf.__class__.__name__+'_default',\n",
        "                      ['Train_Recall','Test_Recall','Test_Specificity']] = [\n",
        "          train_cv.mean(),\n",
        "          recall_score(y_test,y_pred),\n",
        "          conf_matrix[0,0]/conf_matrix[0,:].sum()\n",
        "      ]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okghQsdPeGmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%time predict_imbalanced(pd.datetime(2019,6,1), feature_matrix_selection)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5R6gStteG5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = feature_matrix_selection.drop(columns = ['NumberId', 'time','date', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "y = feature_matrix_selection.Label\n",
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u9V7WuIeCui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scatter plot of examples by class label\n",
        "# for label, _ in counter.items():\n",
        "# \trow_ix = np.where(y == label)[0]\n",
        "# \tplt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKGuxsxheC4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Gq0iPZ1C8ka",
        "colab": {}
      },
      "source": [
        "# def predict_imb(dt, feature_matrix): \n",
        "#     \"\"\"\n",
        "#     Reference:\n",
        "#       - https://xgboost.readthedocs.io/en/latest/parameter.html\n",
        "#       - https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html\n",
        "#       - https://stats.stackexchange.com/questions/224512/reduce-false-positives-with-xgboost\n",
        "#       - https://stackoverflow.com/questions/52499788/smotetomek-how-to-set-ratio-as-dictionary-for-fixed-balance\n",
        "#       - https://github.com/coding-maniacs/over-under-sampling/blob/master/src/main.py\n",
        "#     \"\"\"\n",
        "#     feature_matrix['date'] = feature_matrix['time']\n",
        "\n",
        "#     # Subset labels\n",
        "#     test_labels = feature_matrix.loc[feature_matrix['date'] == dt, 'Label']\n",
        "#     train_labels = feature_matrix.loc[feature_matrix['date'] < dt, 'Label']\n",
        "\n",
        "#     # Features\n",
        "#     X_train = feature_matrix[feature_matrix['date'] < dt].drop(columns = ['NumberId', 'time',\n",
        "#                                                                                      'date', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "#     X_test = feature_matrix[feature_matrix['date'] == dt].drop(columns = ['NumberId', 'time',\n",
        "#                                                                                      'date', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "#     feature_names = list(X_train.columns)\n",
        "    \n",
        "#     if type(train_labels) == np.ndarray:\n",
        "#       hit_ratio = float( len(np.where(train_labels == 0)[0]) / len(np.where(train_labels == 1)[0]) ) \n",
        "#     else:\n",
        "#       hit_ratio = float(train_labels.value_counts()[0]/train_labels.value_counts()[1]) \n",
        "    \n",
        "#     print(f\"Hit ratio before balancing - {hit_ratio}\\n\")\n",
        "\n",
        "#     # Labels\n",
        "#     y_train = np.array(train_labels).reshape((-1, ))\n",
        "#     y_test = np.array(test_labels).reshape((-1, ))\n",
        "    \n",
        "#     print('Training on {} observations.'.format(len(X_train)))\n",
        "#     print('Testing on {} observations.\\n'.format(len(X_test)))\n",
        "  \n",
        "#     # balancer = ClusterCentroids(sampling_strategy='auto', random_state=42, n_jobs=4)\n",
        "#     # balancer = SMOTE(sampling_strategy='auto', random_state=42, n_jobs=4)\n",
        "#     # # balancer = make_pipeline_imb(SMOTE(sampling_strategy='auto', random_state=42, n_jobs=4))\n",
        "#     # X_bal, y_bal = balancer.fit_resample(X_train, train_labels)\n",
        "#     # counter = Counter(y_bal)\n",
        "#     # print('Balanced data: {}'.format(Counter(y_bal)))\n",
        "#     # hit_ratio = float(counter[0] / counter[1])\n",
        "#     # print(f\"Hit ratio after balancing - {hit_ratio}\\n\")\n",
        "\n",
        "   \n",
        "#     # Sampling technique - https://stackoverflow.com/questions/52499788/smotetomek-how-to-set-ratio-as-dictionary-for-fixed-balance\n",
        "#     pipeline = make_pipeline_imb(\n",
        "#                                 SimpleImputer(strategy = 'constant', fill_value=0),\n",
        "#                                 StandardScaler(),\n",
        "#                                 SMOTE(sampling_strategy='auto', random_state=42, n_jobs=4)\n",
        "#                                 )\n",
        "    \n",
        "#     # Calculate the hit ratio after resampling\n",
        "#     X_bal, y_bal = pipeline.fit_resample(X_train, train_labels)\n",
        "#     counter = Counter(y_bal)\n",
        "#     print('Balanced data: {}'.format(Counter(y_bal)))\n",
        "#     hit_ratio = float(counter[0] / counter[1])\n",
        "#     print(f\"Hit ratio after balancing - {hit_ratio}\\n\")\n",
        "    \n",
        "#     return 1,1\n",
        "\n",
        "#     # Create the classifier\n",
        "#     classifier = xgb.XGBClassifier(\n",
        "#                              n_jobs=4, \n",
        "#                              random_state = 42,\n",
        "#                             #  n_estimators=300, \n",
        "#                             #  max_depth=5,\n",
        "#                             n_estimators=100, \n",
        "#                             max_depth=3,\n",
        "#                             # n_estimators=1000, \n",
        "#                             #  max_depth=5,\n",
        "#                             #  gamma=0,\n",
        "#                             #  subsample=0.8,\n",
        "#                             #  colsample_bytree=0.8,\n",
        "#                             #  learning_rate=0.1,\n",
        "#                              objective='binary:logistic',\n",
        "#                              min_child_weight=1,\n",
        "#                              scale_pos_weight=hit_ratio \n",
        "#                              )\n",
        "    \n",
        "#     # Create pipeline with classifier\n",
        "#     pipeline = make_pipeline_imb(\n",
        "#                                 SimpleImputer(strategy = 'constant', fill_value=0),\n",
        "#                                 StandardScaler(),\n",
        "#                                 SMOTE(sampling_strategy='auto', random_state=42, n_jobs=4),\n",
        "#                                 classifier\n",
        "#                                 )\n",
        "    \n",
        "#     # Train and predict\n",
        "#     model = pipeline.fit(X_train, train_labels)\n",
        "\n",
        "#     # Predict\n",
        "#     predictions = pipeline.predict(X_test)\n",
        "#     probs = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "#     # Total positive\n",
        "#     positive = np.where((predictions==1))\n",
        "#     print(f'Total predicted to be positive: {len(positive[0])} \\n')\n",
        "  \n",
        "#     # Calculate metrics\n",
        "#     rpt = classification_report(y_test, predictions)\n",
        "#     rpt_imb = classification_report_imbalanced(y_test, predictions)\n",
        "#     cm = confusion_matrix(y_test, predictions)\n",
        "#     print('Classification report')\n",
        "#     print(rpt)\n",
        "#     print('Classification report - imbalanced')\n",
        "#     print(rpt_imb)\n",
        "#     print(f'Confusion matrix:\\n {cm}\\n')\n",
        "\n",
        "#     # Total predicted matches\n",
        "#     print('Predicted matches')\n",
        "#     pred = np.where((predictions==1))\n",
        "#     print(len(pred[0]), pred[0][0:23])\n",
        "#     topN = np.argpartition(probs, -23)[-23:]\n",
        "#     print(f'\\n{topN}\\n')  # Top N most high probability numbers\n",
        "  \n",
        "#     if len(positive[0]) > 0:\n",
        "    \n",
        "#       # Matching draws\n",
        "#       print('Matched draws')\n",
        "#       md = np.where((predictions==1) & (y_test==1))\n",
        "#       print(f\"Count: {len(md[0])}, Index: {md}\")\n",
        "#       month_data = feature_matrix.loc[feature_matrix['date'] == dt]\n",
        "#       numbers = month_data.iloc[md[0]][['MAX(Results.LuckyNo)']]\n",
        "\n",
        "#       print('\\n\\nTop 23 Possibility')\n",
        "#       print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "#                           (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "#                           (origin_data['LuckyNo'].isin(topN))].head(23))  \n",
        "      \n",
        "#       print('\\n\\nFirst 23 Numbers')\n",
        "#       print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "#                           (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "#                           (origin_data['LuckyNo'].isin(pred[0][0:23]))].head(23))    \n",
        "             \n",
        "\n",
        "#       print('\\n\\nAll matched')\n",
        "#       print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "#                           (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "#                           (origin_data['LuckyNo'].isin(numbers['MAX(Results.LuckyNo)']))].head(100))    \n",
        "                                                  \n",
        "#     else:\n",
        "#       print('No luck this month')                 \n",
        "\n",
        "#     # Feature importances\n",
        "#     fi = pd.DataFrame({'feature': feature_names, 'importance': classifier.feature_importances_})\n",
        "    \n",
        "#     return fi, probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLXD2cxKYAq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%time fi, probs = predict_imb(pd.datetime(2019,6,1), feature_matrix_selection)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rV0niLRnfmsj",
        "colab": {}
      },
      "source": [
        "#normalized_fi = plot_feature_importances(fi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7itdGGHwprH",
        "colab": {}
      },
      "source": [
        "# Loop through from June to Dec\n",
        "# start_mt = pd.datetime(2019,6,1)\n",
        "# how_many_mt = 7\n",
        "# for i in range(how_many_mt):\n",
        "#   month_to_predict = start_mt + relativedelta(months=i)\n",
        "#   print(f\"\\n{month_to_predict}\\n-------------------\\n\")\n",
        "#   %time predict(month_to_predict, feature_matrix_selection)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q91OSb9M3xfj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGWj_dWBINp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feature_matrix_selection.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7uRdUxb6PUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}