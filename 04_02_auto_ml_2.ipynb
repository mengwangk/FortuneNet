{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "04_02_automated_machine_learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengwangk/dl-projects/blob/master/04_02_auto_ml_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4hyoPGdjpqa_"
      },
      "source": [
        "# Automated ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLxr2k_ue8yq",
        "colab": {}
      },
      "source": [
        "COLAB = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy5ww2zRfFGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e1ca6b6-13e6-4c57-c1ea-1ac8638036a5"
      },
      "source": [
        "if COLAB:\n",
        "  !sudo apt-get install git-lfs && git lfs install\n",
        "  !rm -rf dl-projects\n",
        "  !git clone https://github.com/mengwangk/dl-projects\n",
        "  #!cd dl-projects && ls -l --block-size=M"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 2,129 kB of archives.\n",
            "After this operation, 7,662 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n",
            "Fetched 2,129 kB in 1s (1,650 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 145674 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n",
            "Unpacking git-lfs (2.3.4-1) ...\n",
            "Setting up git-lfs (2.3.4-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n",
            "Git LFS initialized.\n",
            "Cloning into 'dl-projects'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 651 (delta 9), reused 9 (delta 3), pack-reused 627\u001b[K\n",
            "Receiving objects: 100% (651/651), 66.92 MiB | 26.30 MiB/s, done.\n",
            "Resolving deltas: 100% (363/363), done.\n",
            "total 6M\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 01_01_tensor.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 01_02_correlation.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 01_03_preprocessing.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 01_04_numpy.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 01_05_parallelization.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 01_06_pandas..ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 01_07_python_0.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 01_07_python_1.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 02_1_feature_engineer.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 02_2_feature_generation.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 02_3_feature_generation.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 02_4_feature_generation.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 03_1_feature_selection.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 03_2_feature_selection.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 04_01_machine_learning.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 04_02_auto_ml_0.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 04_02_auto_ml_1.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 04_02_auto_ml_2.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 04_10_basic_nn.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 04_11_cnn.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 04_12_rnn.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 04_13_embedding.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 05_calculus.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 06_stats.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 07_algebra.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 08_probability.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 09_evaluation.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 50_RL.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 999_Links.ipynb\n",
            "drwxr-xr-x 2 root root 1M Dec 27 08:35 archive\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 d01_download.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 d02_0_features.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 d02_1_features.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 d03_train_dl.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 d04_train_ml.ipynb\n",
            "drwxr-xr-x 2 root root 1M Dec 27 08:35 datasets\n",
            "drwxr-xr-x 2 root root 1M Dec 27 08:35 exp\n",
            "drwxr-xr-x 2 root root 1M Dec 27 08:35 featurelib\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 LICENSE\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 lstm_s1.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 lstm_s2.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 lstm_s3.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 lstm_s4.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 lstm_s5.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 lstm_s6.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 notebook2script.py\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 preprocess.py\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 README.md\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 run_notebook.py\n",
            "drwxr-xr-x 2 root root 1M Dec 27 08:35 scraper\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 stock.ipynb\n",
            "-rw-r--r-- 1 root root 1M Dec 27 08:35 utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G2xin10SfozR",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  !cp dl-projects/utils* .\n",
        "  !cp dl-projects/preprocess* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fC2-l3JBpqbE",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TP7V_IzepqbK",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as ss\n",
        "import math \n",
        "import matplotlib\n",
        "\n",
        "from scipy import stats\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "# Automated feature engineering\n",
        "import featuretools as ft\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import Imputer, MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "from utils import *\n",
        "from preprocess import *\n",
        "\n",
        "# The Answer to the Ultimate Question of Life, the Universe, and Everything.\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3bFT5CoxpqbP",
        "outputId": "746249d3-eae3-434d-9a96-6e8295b2bd74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "%aimport"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modules to reload:\n",
            "all-except-skipped\n",
            "\n",
            "Modules to skip:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3E16jPVPpqbV"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U421BuhtfYS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48df71d8-676d-47dd-edd2-eb249f982d88"
      },
      "source": [
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  GDRIVE_DATASET_FOLDER = Path('gdrive/My Drive/datasets/')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9IgnETKkpqbX",
        "outputId": "c2bf3625-c2dd-47d9-bea0-45e8ece73db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "if COLAB:\n",
        "  DATASET_PATH = GDRIVE_DATASET_FOLDER\n",
        "else:\n",
        "  DATASET_PATH = Path(\"datasets\")\n",
        "\n",
        "DATASET = DATASET_PATH/\"feature_matrix.csv\"\n",
        "\n",
        "if COLAB:\n",
        "  !ls -l gdrive/\"My Drive\"/datasets/ --block-size=M"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 317M\n",
            "-rw------- 1 root root 141M Dec 27 08:27 feature_matrix.csv\n",
            "-rw------- 1 root root 176M Dec 27 08:28 feature_matrix.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urQTD6DQNutw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(DATASET, header=0, sep=',', quotechar='\"', parse_dates=['time'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BjrERxV8WuT",
        "colab_type": "code",
        "outputId": "0667a24a-0845-44a5-c8ca-5bbbeefeb324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 699972 entries, 0 to 699971\n",
            "Data columns (total 53 columns):\n",
            "NumberId                                   699972 non-null int64\n",
            "time                                       699972 non-null datetime64[ns]\n",
            "SUM(Results.DrawNo)                        699972 non-null int64\n",
            "SUM(Results.LuckyNo)                       699972 non-null int64\n",
            "SUM(Results.TotalStrike)                   699972 non-null int64\n",
            "STD(Results.DrawNo)                        699575 non-null float64\n",
            "STD(Results.LuckyNo)                       699575 non-null float64\n",
            "STD(Results.TotalStrike)                   699575 non-null float64\n",
            "MAX(Results.DrawNo)                        699972 non-null int64\n",
            "MAX(Results.LuckyNo)                       699972 non-null int64\n",
            "MAX(Results.TotalStrike)                   699972 non-null int64\n",
            "SKEW(Results.DrawNo)                       696365 non-null float64\n",
            "SKEW(Results.LuckyNo)                      696365 non-null float64\n",
            "SKEW(Results.TotalStrike)                  696365 non-null float64\n",
            "MIN(Results.DrawNo)                        699972 non-null int64\n",
            "MIN(Results.LuckyNo)                       699972 non-null int64\n",
            "MIN(Results.TotalStrike)                   699972 non-null int64\n",
            "MEAN(Results.DrawNo)                       699972 non-null float64\n",
            "MEAN(Results.LuckyNo)                      699972 non-null int64\n",
            "MEAN(Results.TotalStrike)                  699972 non-null int64\n",
            "COUNT(Results)                             699972 non-null int64\n",
            "NUM_UNIQUE(Results.PrizeType)              699972 non-null int64\n",
            "DAY(first_Results_time)                    699972 non-null int64\n",
            "YEAR(first_Results_time)                   699972 non-null int64\n",
            "MONTH(first_Results_time)                  699972 non-null int64\n",
            "WEEKDAY(first_Results_time)                699972 non-null int64\n",
            "TotalStrike                                699972 non-null float64\n",
            "Label                                      699972 non-null int64\n",
            "MODE(Results.PrizeType)_1stPrizeNo         699972 non-null int64\n",
            "MODE(Results.PrizeType)_2ndPrizeNo         699972 non-null int64\n",
            "MODE(Results.PrizeType)_3rdPrizeNo         699972 non-null int64\n",
            "MODE(Results.PrizeType)_ConsolationNo1     699972 non-null int64\n",
            "MODE(Results.PrizeType)_ConsolationNo10    699972 non-null int64\n",
            "MODE(Results.PrizeType)_ConsolationNo2     699972 non-null int64\n",
            "MODE(Results.PrizeType)_ConsolationNo3     699972 non-null int64\n",
            "MODE(Results.PrizeType)_ConsolationNo4     699972 non-null int64\n",
            "MODE(Results.PrizeType)_ConsolationNo5     699972 non-null int64\n",
            "MODE(Results.PrizeType)_ConsolationNo6     699972 non-null int64\n",
            "MODE(Results.PrizeType)_ConsolationNo7     699972 non-null int64\n",
            "MODE(Results.PrizeType)_ConsolationNo8     699972 non-null int64\n",
            "MODE(Results.PrizeType)_ConsolationNo9     699972 non-null int64\n",
            "MODE(Results.PrizeType)_SpecialNo1         699972 non-null int64\n",
            "MODE(Results.PrizeType)_SpecialNo10        699972 non-null int64\n",
            "MODE(Results.PrizeType)_SpecialNo2         699972 non-null int64\n",
            "MODE(Results.PrizeType)_SpecialNo3         699972 non-null int64\n",
            "MODE(Results.PrizeType)_SpecialNo4         699972 non-null int64\n",
            "MODE(Results.PrizeType)_SpecialNo5         699972 non-null int64\n",
            "MODE(Results.PrizeType)_SpecialNo6         699972 non-null int64\n",
            "MODE(Results.PrizeType)_SpecialNo7         699972 non-null int64\n",
            "MODE(Results.PrizeType)_SpecialNo8         699972 non-null int64\n",
            "MODE(Results.PrizeType)_SpecialNo9         699972 non-null int64\n",
            "month                                      699972 non-null int64\n",
            "year                                       699972 non-null int64\n",
            "dtypes: datetime64[ns](1), float64(8), int64(44)\n",
            "memory usage: 283.0 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vOYlp-8Br61r"
      },
      "source": [
        "## Preliminary Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnQXyVqng5Cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_matrix = data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hTJQWmXAsCVo"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JuiMZl9rsMk1",
        "colab": {}
      },
      "source": [
        "model = RandomForestClassifier(n_estimators = 1000, \n",
        "                               random_state = 50,\n",
        "                               n_jobs = -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DtkZVlf1sOq2",
        "colab": {}
      },
      "source": [
        "def predict_dt(dt, feature_matrix, return_probs = False):\n",
        "\n",
        "    feature_matrix['date'] = feature_matrix['time']\n",
        "\n",
        "    # Subset labels\n",
        "    test_labels = feature_matrix.loc[feature_matrix['date'] == dt, 'Label']\n",
        "    train_labels = feature_matrix.loc[feature_matrix['date'] < dt, 'Label']\n",
        "\n",
        "    print(f\"Size of test labels {len(test_labels)}\")\n",
        "    print(f\"Size of train labels {len(train_labels)}\")\n",
        "    \n",
        "    # Features\n",
        "    X_train = feature_matrix[feature_matrix['date'] < dt].drop(columns = ['NumberId', 'time',\n",
        "                                                                                     'date', 'Label', 'TotalStrike', 'month', 'year'])\n",
        "    X_test = feature_matrix[feature_matrix['date'] == dt].drop(columns = ['NumberId', 'time',\n",
        "                                                                                     'date', 'Label', 'TotalStrike', 'month', 'year'])\n",
        "    print(f\"Size of X train {len(X_train)}\")\n",
        "    print(f\"Size of X test  {len(X_test)}\")\n",
        "   \n",
        "\n",
        "    feature_names = list(X_train.columns)\n",
        "    \n",
        "    # Impute and scale features\n",
        "    pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
        "                      ('scaler', MinMaxScaler())])\n",
        "\n",
        "    # Fit and transform training data\n",
        "    X_train = pipeline.fit_transform(X_train)\n",
        "    X_test = pipeline.transform(X_test)\n",
        "    \n",
        "    # Labels\n",
        "    y_train = np.array(train_labels).reshape((-1, ))\n",
        "    y_test = np.array(test_labels).reshape((-1, ))\n",
        "    \n",
        "    print('Training on {} observations.'.format(len(X_train)))\n",
        "    print('Testing on {} observations.\\n'.format(len(X_test)))\n",
        "    \n",
        "    # Train \n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions\n",
        "    predictions = model.predict(X_test)\n",
        "    probs = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Calculate metrics\n",
        "    p = precision_score(y_test, predictions)\n",
        "    r = recall_score(y_test, predictions)\n",
        "    f = f1_score(y_test, predictions)\n",
        "    auc = roc_auc_score(y_test, probs)\n",
        "    \n",
        "    print(f'Precision: {round(p, 5)}')\n",
        "    print(f'Recall: {round(r, 5)}')\n",
        "    print(f'F1 Score: {round(f, 5)}')\n",
        "    print(f'ROC AUC: {round(auc, 5)}')\n",
        "    \n",
        "    # Feature importances\n",
        "    fi = pd.DataFrame({'feature': feature_names, 'importance': model.feature_importances_})\n",
        "    \n",
        "    if return_probs:\n",
        "        return fi, probs\n",
        "    \n",
        "    return fi\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SwajXEsyuJOw",
        "outputId": "80b6d813-b3b1-453c-f539-26c7672fdc67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        }
      },
      "source": [
        "# All the months\n",
        "len(feature_matrix['time'].unique()), feature_matrix['time'].unique()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, array(['2014-01-01T00:00:00.000000000', '2014-02-01T00:00:00.000000000',\n",
              "        '2014-03-01T00:00:00.000000000', '2014-04-01T00:00:00.000000000',\n",
              "        '2014-05-01T00:00:00.000000000', '2014-06-01T00:00:00.000000000',\n",
              "        '2014-07-01T00:00:00.000000000', '2014-08-01T00:00:00.000000000',\n",
              "        '2014-09-01T00:00:00.000000000', '2014-10-01T00:00:00.000000000',\n",
              "        '2014-11-01T00:00:00.000000000', '2014-12-01T00:00:00.000000000',\n",
              "        '2015-01-01T00:00:00.000000000', '2015-02-01T00:00:00.000000000',\n",
              "        '2015-03-01T00:00:00.000000000', '2015-04-01T00:00:00.000000000',\n",
              "        '2015-05-01T00:00:00.000000000', '2015-06-01T00:00:00.000000000',\n",
              "        '2015-07-01T00:00:00.000000000', '2015-08-01T00:00:00.000000000',\n",
              "        '2015-09-01T00:00:00.000000000', '2015-10-01T00:00:00.000000000',\n",
              "        '2015-11-01T00:00:00.000000000', '2015-12-01T00:00:00.000000000',\n",
              "        '2016-01-01T00:00:00.000000000', '2016-02-01T00:00:00.000000000',\n",
              "        '2016-03-01T00:00:00.000000000', '2016-04-01T00:00:00.000000000',\n",
              "        '2016-05-01T00:00:00.000000000', '2016-06-01T00:00:00.000000000',\n",
              "        '2016-07-01T00:00:00.000000000', '2016-08-01T00:00:00.000000000',\n",
              "        '2016-09-01T00:00:00.000000000', '2016-10-01T00:00:00.000000000',\n",
              "        '2016-11-01T00:00:00.000000000', '2016-12-01T00:00:00.000000000',\n",
              "        '2017-01-01T00:00:00.000000000', '2017-02-01T00:00:00.000000000',\n",
              "        '2017-03-01T00:00:00.000000000', '2017-04-01T00:00:00.000000000',\n",
              "        '2017-05-01T00:00:00.000000000', '2017-06-01T00:00:00.000000000',\n",
              "        '2017-07-01T00:00:00.000000000', '2017-08-01T00:00:00.000000000',\n",
              "        '2017-09-01T00:00:00.000000000', '2017-10-01T00:00:00.000000000',\n",
              "        '2017-11-01T00:00:00.000000000', '2017-12-01T00:00:00.000000000',\n",
              "        '2018-01-01T00:00:00.000000000', '2018-02-01T00:00:00.000000000',\n",
              "        '2018-03-01T00:00:00.000000000', '2018-04-01T00:00:00.000000000',\n",
              "        '2018-05-01T00:00:00.000000000', '2018-06-01T00:00:00.000000000',\n",
              "        '2018-07-01T00:00:00.000000000', '2018-08-01T00:00:00.000000000',\n",
              "        '2018-09-01T00:00:00.000000000', '2018-10-01T00:00:00.000000000',\n",
              "        '2018-11-01T00:00:00.000000000', '2018-12-01T00:00:00.000000000',\n",
              "        '2019-01-01T00:00:00.000000000', '2019-02-01T00:00:00.000000000',\n",
              "        '2019-03-01T00:00:00.000000000', '2019-04-01T00:00:00.000000000',\n",
              "        '2019-05-01T00:00:00.000000000', '2019-06-01T00:00:00.000000000',\n",
              "        '2019-07-01T00:00:00.000000000', '2019-08-01T00:00:00.000000000',\n",
              "        '2019-09-01T00:00:00.000000000', '2019-10-01T00:00:00.000000000'],\n",
              "       dtype='datetime64[ns]'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "55CRISQM9VoV",
        "colab": {}
      },
      "source": [
        "june_2019 = predict_dt(pd.datetime(2019,6,1), feature_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VG_tWy2m9sjg",
        "colab": {}
      },
      "source": [
        "from utils import plot_feature_importances\n",
        "\n",
        "norm_june_fi = plot_feature_importances(june_2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RHO8sHSWEXp6"
      },
      "source": [
        "## Comparison to Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XsPab_k6F7jq",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}