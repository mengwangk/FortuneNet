{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "04_02_automated_machine_learning.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengwangk/dl-projects/blob/master/04_09_auto_ml_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4hyoPGdjpqa_"
      },
      "source": [
        "# Automated ML - Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLxr2k_ue8yq",
        "colab": {}
      },
      "source": [
        "COLAB = True\n",
        "\n",
        "DATASET_NAME = '4D.zip'\n",
        "\n",
        "FEATURE_DATASET_PREFIX = 'feature_matrix_d2_v3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wwYshXtLt7b7",
        "colab": {}
      },
      "source": [
        "#!pip install -U imblearn\n",
        "#!pip install -U xgboost\n",
        "# !pip install -U featuretools\n",
        "\n",
        "# https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28\n",
        "# https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
        "# https://machinelearningmastery.com/imbalanced-classification-model-to-detect-oil-spills/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oy5ww2zRfFGG",
        "outputId": "1fa144ef-d5d3-4984-af27-dfb19a7323a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "if COLAB:\n",
        "  !rm -rf dl-projects\n",
        "  !git clone https://github.com/mengwangk/dl-projects"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dl-projects'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 1920 (delta 73), reused 15 (delta 6), pack-reused 1802\u001b[K\n",
            "Receiving objects: 100% (1920/1920), 78.07 MiB | 13.03 MiB/s, done.\n",
            "Resolving deltas: 100% (1184/1184), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G2xin10SfozR",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  !cp dl-projects/utils* .\n",
        "  !cp dl-projects/preprocess* .\n",
        "  !cp dl-projects/plot* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fC2-l3JBpqbE",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "# %reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TP7V_IzepqbK",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "import matplotlib\n",
        "import sys\n",
        "import gc\n",
        "\n",
        "from scipy import stats\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import featuretools as ft\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, make_scorer, recall_score, roc_curve, mean_squared_error, accuracy_score, average_precision_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedShuffleSplit, RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from imblearn.under_sampling import (RandomUnderSampler, \n",
        "                                     ClusterCentroids,\n",
        "                                     TomekLinks,\n",
        "                                     NeighbourhoodCleaningRule,\n",
        "                                     AllKNN,\n",
        "                                     NearMiss,\n",
        "                                     OneSidedSelection,\n",
        "                                     EditedNearestNeighbours)\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN\n",
        "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
        "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
        "from imblearn.over_sampling import SMOTE, SMOTENC, ADASYN \n",
        "import pylab as pl\n",
        "import xgboost as xgb\n",
        "from collections import Counter\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "\n",
        "# from skopt import BayesSearchCV\n",
        "# from skopt.space import Real, Categorical, Integer\n",
        "# from scikitplot.plotters import plot_precision_recall_curve\n",
        "\n",
        "from utils import feature_selection, plot_feature_importances\n",
        "from preprocess import *\n",
        "from plot import plot_correlation_matrix, plot_labeled_scatter\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "# The Answer to the Ultimate Question of Life, the Universe, and Everything.\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3bFT5CoxpqbP",
        "outputId": "2307f6cb-890e-4078-f2f1-181084249c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%aimport"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modules to reload:\n",
            "all-except-skipped\n",
            "\n",
            "Modules to skip:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3E16jPVPpqbV"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U421BuhtfYS7",
        "outputId": "aedae685-5d4a-4ec4-b9aa-dcf75ebd80e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  GDRIVE_DATASET_FOLDER = Path('gdrive/My Drive/datasets/')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9IgnETKkpqbX",
        "outputId": "7a8a6d14-db5f-4b87-a4a5-6a439493a8b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "if COLAB:\n",
        "  DATASET_PATH = GDRIVE_DATASET_FOLDER\n",
        "  ORIGIN_DATASET_PATH = Path('dl-projects/datasets')\n",
        "else:\n",
        "  DATASET_PATH = Path(\"../datasets\")\n",
        "  ORIGIN_DATASET_PATH = Path('datasets')\n",
        "\n",
        "DATASET = DATASET_PATH/f\"{FEATURE_DATASET_PREFIX}.ft\"\n",
        "ORIGIN_DATASET = ORIGIN_DATASET_PATH/DATASET_NAME\n",
        "\n",
        "if COLAB:\n",
        "  !ls -l gdrive/\"My Drive\"/datasets/ --block-size=M\n",
        "  !ls -l dl-projects/datasets --block-size=M"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4830M\n",
            "-rw------- 1 root root   17M Mar  1 05:47 feature_matrix_2020_feb.ft\n",
            "-rw------- 1 root root   17M Mar  1 05:47 feature_matrix_2020_feb_orig.pkl\n",
            "-rw------- 1 root root   17M Mar  1 05:39 feature_matrix_2020_jan.ft\n",
            "-rw------- 1 root root   17M Mar  1 05:39 feature_matrix_2020_jan_orig.pkl\n",
            "-rw------- 1 root root   17M Mar  1 05:56 feature_matrix_2020_mar.ft\n",
            "-rw------- 1 root root   17M Mar  1 05:56 feature_matrix_2020_mar_orig.pkl\n",
            "-rw------- 1 root root 2454M Jan 12 01:24 feature_matrix_d2_v2.ft\n",
            "-rw------- 1 root root 1585M Jan 12 23:39 feature_matrix_d2_v3.ft\n",
            "-rw------- 1 root root   17M Feb 21 13:07 feature_matrix_snapshot.ft\n",
            "-rw------- 1 root root   17M Feb 21 13:07 feature_matrix_snapshot_origin.pkl\n",
            "-rw------- 1 root root    1M Mar  1 05:49 labels.csv\n",
            "-rw------- 1 root root    5M Jan 30 04:33 orig_X_test.ft\n",
            "-rw------- 1 root root  415M Jan 30 04:33 orig_X_train.ft\n",
            "-rw------- 1 root root    1M Jan 30 04:33 orig_y_test.ft\n",
            "-rw------- 1 root root    7M Jan 30 04:33 orig_y_train.ft\n",
            "-rw------- 1 root root    3M Feb 29 22:38 test_X_test.ft\n",
            "-rw------- 1 root root  225M Feb 29 22:38 test_X_train.ft\n",
            "-rw------- 1 root root    1M Feb 29 22:38 test_y_test.ft\n",
            "-rw------- 1 root root    8M Feb 29 22:38 test_y_train.ft\n",
            "total 25M\n",
            "-rw-r--r-- 1 root root  1M Mar  1 06:25 4D.zip\n",
            "-rw-r--r-- 1 root root 25M Mar  1 06:25 labels.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urQTD6DQNutw",
        "colab": {}
      },
      "source": [
        "# Read the data\n",
        "data = pd.read_feather(DATASET)\n",
        "origin_data = format_tabular(ORIGIN_DATASET)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zov05QHZxxiS",
        "colab_type": "text"
      },
      "source": [
        "## Add new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foPB8T1vx2tp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d11a2f1-2f2e-4d83-9065-38d23c955278"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(959893, 217)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43sc1Eaux25j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jan_2020 = pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_jan.ft\")\n",
        "feb_2020= pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_feb.ft\")\n",
        "mar_2020= pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_mar.ft\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vISxEbsyQG1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "112f57e0-cd6a-46f7-a4c3-eebe616a9914"
      },
      "source": [
        "new_data = data.append(jan_2020[data.columns],ignore_index=True)\n",
        "new_data = new_data.append(feb_2020[data.columns],ignore_index=True)\n",
        "new_data = new_data.append(mar_2020[data.columns],ignore_index=True)\n",
        "new_data.shape "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(989893, 217)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVVMXCj-zyaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3ed94b2-f88e-4185-838e-cec2b0dce77a"
      },
      "source": [
        "data = new_data\n",
        "data.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(989893, 217)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vOYlp-8Br61r"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kHiN1VVlG9Kh"
      },
      "source": [
        "### View data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JnQXyVqng5Cm",
        "colab": {}
      },
      "source": [
        "# Feature matrix\n",
        "feature_matrix = data.drop(columns=['NumberId', 'month', 'year'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apMYVNz9HK9e",
        "outputId": "f539bbd5-9a0d-41ff-dbdd-80a3d789ae0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Sort data\n",
        "feature_matrix.sort_values(by=['time', 'MAX(Results.LuckyNo)'], inplace=True)\n",
        "feature_matrix.info()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 989893 entries, 7020 to 986394\n",
            "Columns: 214 entries, time to LAST(Results.PrizeType)_Prize\n",
            "dtypes: datetime64[ns](1), float64(155), int64(56), uint8(2)\n",
            "memory usage: 1.6 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CZKTbWRFJNUq",
        "outputId": "675acbb0-59fb-44a7-bc58-f3ea0df633e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print('Distribution')\n",
        "print(feature_matrix['Label'].value_counts())\n",
        "print()\n",
        "print('Positive: ' + str(feature_matrix['Label'].value_counts()[0]) + ' which is ', round(feature_matrix['Label'].value_counts()[0]/len(feature_matrix) * 100,2), '% of the dataset')\n",
        "print('Negative: ' + str(feature_matrix['Label'].value_counts()[1]) + ' which is ', round(feature_matrix['Label'].value_counts()[1]/len(feature_matrix) * 100,2), '% of the dataset')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution\n",
            "0    957191\n",
            "1     32702\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Positive: 957191 which is  96.7 % of the dataset\n",
            "Negative: 32702 which is  3.3 % of the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plplpAQ6JrKb",
        "outputId": "8477d67a-0326-4a5d-8400-915d85bce6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "feature_matrix.isna().sum().sort_values(ascending=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))               7657\n",
              "CUM_MEAN(TREND(Results.LuckyNo, DrawDate))                7657\n",
              "TREND(Results.TIME_SINCE_PREVIOUS(DrawDate), DrawDate)    7657\n",
              "TREND(Results.CUM_MEAN(TotalStrike), DrawDate)            7657\n",
              "TREND(Results.CUM_SUM(LuckyNo), DrawDate)                 7657\n",
              "                                                          ... \n",
              "CUM_SUM(MIN(Results.DrawNo))                                 0\n",
              "NUM_UNIQUE(Results.DAY(DrawDate))                            0\n",
              "NUM_UNIQUE(Results.MONTH(DrawDate))                          0\n",
              "SUM(Results.PERCENTILE(LuckyNo))                             0\n",
              "time                                                         0\n",
              "Length: 214, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF_zCRksL1Ls"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1aLGsXSOa9K",
        "colab": {}
      },
      "source": [
        "# Fill all NaN with 0\n",
        "feature_matrix = feature_matrix.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5A8LZ805MqjP",
        "outputId": "a78c92c9-a138-40ee-f17c-b14f476a238b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feature_matrix.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(989893, 214)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rPFOkiGjhuKj",
        "outputId": "4ee02aa1-8481-47a2-8ee8-94ef7d69708c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "feature_matrix_selection = feature_selection(feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label']))\n",
        "# feature_matrix_selection = feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape:  (989893, 211)\n",
            "0 missing columns with threshold: 90.\n",
            "41 zero variance columns.\n",
            "108 collinear columns removed with threshold: 0.95.\n",
            "Total columns removed:  149\n",
            "Shape after feature selection: (989893, 62).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vT2K0WeJhugH",
        "outputId": "1c76b3d1-6f7c-4a2f-d3e8-fc97b25e870c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "feature_matrix_selection.shape, feature_matrix_selection.columns"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((989893, 62),\n",
              " Index(['STD(Results.DrawNo)', 'MAX(Results.DrawNo)', 'MAX(Results.LuckyNo)',\n",
              "        'MIN(Results.DrawNo)', 'MEAN(Results.DrawNo)', 'SKEW(Results.DrawNo)',\n",
              "        'AVG_TIME_BETWEEN(Results.DrawDate)', 'COUNT(Results)',\n",
              "        'SUM(Results.DrawNo)', 'SUM(Results.LuckyNo)',\n",
              "        'TREND(Results.DrawNo, DrawDate)', 'MONTH(first_Results_time)',\n",
              "        'DAY(first_Results_time)', 'TIME_SINCE(first_Results_time)',\n",
              "        'TIME_SINCE_PREVIOUS(first_Results_time)',\n",
              "        'STD(Results.PERCENTILE(DrawNo))',\n",
              "        'STD(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'STD(Results.CUM_SUM(DrawNo))', 'STD(Results.CUM_MEAN(LuckyNo))',\n",
              "        'MAX(Results.PERCENTILE(DrawNo))',\n",
              "        'MAX(Results.PERCENTILE(TotalStrike))',\n",
              "        'MAX(Results.CUM_MEAN(LuckyNo))',\n",
              "        'MIN(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'MIN(Results.CUM_SUM(DrawNo))', 'MIN(Results.CUM_MEAN(LuckyNo))',\n",
              "        'MODE(Results.MONTH(DrawDate))', 'MODE(Results.DAY(DrawDate))',\n",
              "        'MEAN(Results.TIME_SINCE(DrawDate))',\n",
              "        'MEAN(Results.PERCENTILE(DrawNo))',\n",
              "        'MEAN(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'MEAN(Results.CUM_MEAN(LuckyNo))',\n",
              "        'SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'SKEW(Results.CUM_SUM(DrawNo))', 'SKEW(Results.CUM_MEAN(LuckyNo))',\n",
              "        'LAST(Results.DAY(DrawDate))',\n",
              "        'LAST(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'LAST(Results.MONTH(DrawDate))', 'LAST(Results.CUM_MEAN(LuckyNo))',\n",
              "        'SUM(Results.TIME_SINCE(DrawDate))',\n",
              "        'SUM(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'TREND(Results.CUM_MEAN(LuckyNo), DrawDate)',\n",
              "        'TREND(Results.PERCENTILE(LuckyNo), DrawDate)',\n",
              "        'TREND(Results.PERCENTILE(DrawNo), DrawDate)',\n",
              "        'TREND(Results.PERCENTILE(TotalStrike), DrawDate)',\n",
              "        'TREND(Results.TIME_SINCE_PREVIOUS(DrawDate), DrawDate)',\n",
              "        'TREND(Results.CUM_SUM(DrawNo), DrawDate)',\n",
              "        'NUM_UNIQUE(Results.MONTH(DrawDate))',\n",
              "        'NUM_UNIQUE(Results.DAY(DrawDate))', 'CUM_SUM(MIN(Results.DrawNo))',\n",
              "        'CUM_SUM(SKEW(Results.DrawNo))',\n",
              "        'CUM_MEAN(AVG_TIME_BETWEEN(Results.DrawDate))',\n",
              "        'CUM_MEAN(SUM(Results.LuckyNo))', 'CUM_MEAN(SKEW(Results.DrawNo))',\n",
              "        'PERCENTILE(STD(Results.LuckyNo))', 'PERCENTILE(LAST(Results.DrawNo))',\n",
              "        'PERCENTILE(MAX(Results.TotalStrike))',\n",
              "        'PERCENTILE(AVG_TIME_BETWEEN(Results.DrawDate))',\n",
              "        'PERCENTILE(COUNT(Results))', 'PERCENTILE(STD(Results.DrawNo))',\n",
              "        'PERCENTILE(SKEW(Results.DrawNo))', 'PERCENTILE(SUM(Results.DrawNo))',\n",
              "        'PERCENTILE(TREND(Results.DrawNo, DrawDate))'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZUhYrWFiRod",
        "colab": {}
      },
      "source": [
        "feature_matrix_selection['time'] = feature_matrix['time']\n",
        "feature_matrix_selection['TotalStrike'] = feature_matrix['TotalStrike']\n",
        "feature_matrix_selection['Label'] = feature_matrix['Label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hugygOqSiR6K"
      },
      "source": [
        "### Feature Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "loagcqTEKOkO",
        "colab": {}
      },
      "source": [
        "#feature_matrix.isnull().sum().sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u7Ha8Zlkhuoe",
        "colab": {}
      },
      "source": [
        "# Check with feature selection\n",
        "#corrs = feature_matrix_selection.corr().sort_values('Label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EWRODfAdPk6j",
        "colab": {}
      },
      "source": [
        "#corrs['Label'].head(60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "waeD1ED_kqDB"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9yrJyIVLh5So",
        "colab": {}
      },
      "source": [
        "def recall_optim(y_true, y_pred):\n",
        "    \"\"\"Make a scoring function that improves specificity while identifying all strikes\n",
        "    \"\"\"\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    # Recall will be worth a greater value than specificity\n",
        "    rec = recall_score(y_true, y_pred) * 0.8 \n",
        "    spe = conf_matrix[0,0]/conf_matrix[0,:].sum() * 0.2 \n",
        "    \n",
        "    # Imperfect recalls will lose a penalty\n",
        "    # This means the best results will have perfect recalls and compete for specificity\n",
        "    if rec < 0.8:\n",
        "        rec -= 0.2\n",
        "    return rec + spe \n",
        "\n",
        "\n",
        "# Make a scoring callable from recall_score\n",
        "recall = make_scorer(recall_score)\n",
        "\n",
        "# Create a scoring callable based on the scoring function\n",
        "optimize = make_scorer(recall_optim)\n",
        "\n",
        "# Geometric mean scorer\n",
        "geo_mean_scorer = make_scorer(geometric_mean_score)\n",
        "\n",
        "# DataFrame to store classifier performance\n",
        "performance = pd.DataFrame(columns=['Train_Recall','Test_Recall','Test_Specificity', 'Optimize'])\n",
        "\n",
        "def to_labels(pos_probs, threshold):\n",
        "    \"\"\"Apply threshold to positive probabilities to create labels.\n",
        "    \"\"\"\n",
        "    return (pos_probs >= threshold).astype('int')\n",
        " \n",
        "\n",
        "def score_optimization(dt, feature_matrix, clf, params, X_train, y_train, X_test, y_test, skip_grid_search_cv=False, optimized_scorer=False):\n",
        "    \"\"\"Find the optimized classifier.\n",
        "    \"\"\"\n",
        "    if not skip_grid_search_cv:\n",
        "      print(\"\\nFinding the optimized classifier...\")\n",
        "\n",
        "      # Load GridSearchCV\n",
        "      # search = GridSearchCV(\n",
        "      search = RandomizedSearchCV(\n",
        "            estimator=clf,\n",
        "            #param_grid=params,\n",
        "            param_distributions=params,\n",
        "            n_jobs=4,\n",
        "            scoring=optimize  # Use custom scorer\n",
        "      )\n",
        "\n",
        "      # Train search object\n",
        "      search.fit(X_train, y_train)\n",
        "\n",
        "      # Heading\n",
        "      print('\\n','-'*40,'\\n',clf.__class__.__name__,'\\n','-'*40)\n",
        "\n",
        "      # Extract best estimator\n",
        "      best = search.best_estimator_\n",
        "      print('Best parameters: \\n\\n',search.best_params_,'\\n')\n",
        "    \n",
        "    else:\n",
        "      print(\"\\nUse the passed in classifier...\\n\")\n",
        "      best = clf\n",
        "\n",
        "    # Cross-validate on the train data\n",
        "    if not skip_grid_search_cv: \n",
        "      print(\"TRAIN GROUP\")\n",
        "      #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
        "      cv = 3\n",
        "      if not optimized_scorer:\n",
        "        print('\\nUse default scorer')\n",
        "        train_cv = cross_val_score(\n",
        "                                  n_jobs=4,\n",
        "                                  X=X_train, \n",
        "                                  y=y_train, \n",
        "                                  estimator=best, \n",
        "                                  scoring=recall,\n",
        "                                  cv=cv)\n",
        "      else:\n",
        "        print('\\nUse optimized scorer')\n",
        "        train_cv = cross_val_score(\n",
        "                                  n_jobs=4,\n",
        "                                  X=X_train, \n",
        "                                  y=y_train, \n",
        "                                  estimator=best, \n",
        "                                  #scoring=optimize,\n",
        "                                  scoring='roc_auc',\n",
        "                                  #scoring=geo_mean_scorer,\n",
        "                                  cv=cv)\n",
        "\n",
        "      print(\"\\nCross-validation recall scores:\",train_cv)\n",
        "      print(\"Mean recall score:\",train_cv.mean())\n",
        "      print('Mean G-Mean: %.3f (%.3f)' % (np.mean(train_cv), np.std(train_cv)))\n",
        "    else:\n",
        "      train_cv = np.zeros(3)\n",
        "\n",
        "    # Now predict on the test group\n",
        "    print(\"\\nTEST GROUP\")\n",
        "    y_pred = best.fit(X_train, y_train).predict(X_test)\n",
        "    # y_pred = best.fit(X_train, y_train,\n",
        "    #                   eval_set=[(X_test, y_test)],\n",
        "    #                   eval_metric='auc',\n",
        "    #                   early_stopping_rounds=10,\n",
        "    #                   verbose=True\n",
        "    #                   ).predict(X_test)\n",
        "\n",
        "    # keep probabilities for the positive outcome only\n",
        "    probas = best.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # define thresholds\n",
        "    thresholds = np.arange(0, 1, 0.001)\n",
        "\n",
        "    # evaluate each threshold\n",
        "    scores = [f1_score(y_test, to_labels(probas, t)) for t in thresholds]\n",
        "\n",
        "    # get best threshold\n",
        "    ix = np.argmax(scores)\n",
        "    print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))\n",
        "\n",
        "    # print recall\n",
        "    print(\"\\nRecall:\",recall_score(y_test,y_pred))\n",
        "\n",
        "    # Get imbalanced classification report\n",
        "    print(classification_report_imbalanced(y_test, y_pred))\n",
        "\n",
        "    # Print confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test,y_pred)\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
        "    plt.show()\n",
        "\n",
        "    # Store results\n",
        "    performance.loc[clf.__class__.__name__+'_optimize',:] = [\n",
        "        train_cv.mean(),\n",
        "        recall_score(y_test,y_pred),\n",
        "        conf_matrix[0,0]/conf_matrix[0,:].sum(),\n",
        "        recall_optim(y_test,y_pred)\n",
        "    ]\n",
        "    # Look at the parameters for the top best scores\n",
        "    if not skip_grid_search_cv:\n",
        "      display(pd.DataFrame(search.cv_results_).iloc[:,4:].sort_values(by='rank_test_score').head())\n",
        "    display(performance)\n",
        "\n",
        "    # Additionl info\n",
        "    print('\\n\\nAdditional Info')\n",
        "    print('='*40)\n",
        "    positive = np.where((y_pred==1))\n",
        "    print(f'Total predicted to be positive: {len(positive[0])} \\n')\n",
        "\n",
        "    pred = np.where((y_pred==1))\n",
        "    all_preds = pred[0]\n",
        "\n",
        "    # Total predicted matches\n",
        "    print('First 23 matches')\n",
        "    print(23, all_preds[0:23])\n",
        "    print(f'\\n{probas[all_preds[0:23]]}\\n') \n",
        "\n",
        "    print(\"\\nTop 23 Probable Matches\")\n",
        "    #print('probas', probas)\n",
        "    topN = np.argpartition(probas, -23)[-23:]\n",
        "    print(f'\\n{topN}\\n')          # Top N most high probability numbers\n",
        "    print(f'\\n{probas[topN]}\\n')  # Top N probability\n",
        "\n",
        "    # Check for 2 to 3 digits range \n",
        "    print('\\n2 To 3 Digits\\n')\n",
        "    idx_range = np.where((all_preds < 1000) & (all_preds >= 10))\n",
        "    #print(idx_range)\n",
        "    range_numbers = all_preds[idx_range]\n",
        "    print(len(range_numbers), range_numbers)\n",
        "    print(f'\\n{probas[range_numbers]}\\n') \n",
        "\n",
        "\n",
        "    # 2 to 3 Digits > Average Probas\n",
        "    print('\\n2 To 3 Digits Average Proba\\n')\n",
        "    avg_proba = np.average(probas[range_numbers])\n",
        "    print(f'Average proba {avg_proba}\\n')\n",
        "    idx_avg_proba = np.where(probas > avg_proba) \n",
        "    print(len(idx_avg_proba[0]), idx_avg_proba[0])\n",
        "\n",
        "    # 2 to 3 Digits > All Average Probas\n",
        "    print('\\n\\nAll Average Proba\\n')\n",
        "    all_avg_proba = np.average(probas[all_preds])\n",
        "    print(f'All average probas {all_avg_proba}\\n')\n",
        "    idx_all_avg_proba = np.where(probas > all_avg_proba) \n",
        "    print(len(idx_all_avg_proba[0]), idx_all_avg_proba[0])\n",
        "\n",
        "\n",
        "    # All predicted matches\n",
        "    print('\\n\\nAll Predictions\\n')\n",
        "    print(len(all_preds), all_preds)\n",
        "    print()\n",
        "    print(len(probas[all_preds]), probas[all_preds])\n",
        "    \n",
        "    #print('Debug')\n",
        "    #print(pred)\n",
        "    \n",
        "    if len(positive[0]) > 0:\n",
        "    \n",
        "      # Matching draws\n",
        "      print('\\nMatched draws')\n",
        "      md = np.where((y_pred==1) & (y_test==1))\n",
        "      print(f\"Count: {len(md[0])}, Index: {md}\")\n",
        "      month_data = feature_matrix.loc[feature_matrix['time'] == dt]\n",
        "      numbers = month_data.iloc[md[0]][['MAX(Results.LuckyNo)']]\n",
        "\n",
        "      print('\\n\\nTop 23 Possibility')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(topN))].head(23))  \n",
        "      \n",
        "      print('\\n\\nFirst 23 Numbers')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(pred[0][0:23]))].head(23))    \n",
        "             \n",
        "\n",
        "      print('\\n\\n2 To 3 Digits Numbers')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(range_numbers))].head(23))    \n",
        "     \n",
        "\n",
        "      print('\\n\\nAll matched')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(numbers['MAX(Results.LuckyNo)']))].head(100))    \n",
        "                                                  \n",
        "    else:\n",
        "      print('No luck this month')  \n",
        "\n",
        "    if len(range_numbers) >= 50:\n",
        "      return False\n",
        "\n",
        "    return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VrL8gYwjc-hd",
        "colab": {}
      },
      "source": [
        "def remove_outliers(balanced, threshold=0.001, remove=True):\n",
        "    \"\"\"Removing Outliers from high-correlation features.\n",
        "    \"\"\"\n",
        "\n",
        "    if not remove:\n",
        "      return balanced\n",
        "\n",
        "    bal_corr = balanced.corr()\n",
        "    no_outliers=pd.DataFrame(balanced.copy())\n",
        "\n",
        "    cols = bal_corr.Label.index[:-1]\n",
        "\n",
        "    # For each feature correlated with Class...\n",
        "    for col in cols:\n",
        "        # If absolute correlation value is more than X percent...\n",
        "        correlation = bal_corr.loc['Label',col]\n",
        "\n",
        "        if np.absolute(correlation) > threshold:\n",
        "          # Separate the classes of the high-correlation column\n",
        "          nonstrikes = no_outliers.loc[no_outliers.Label==0,col]\n",
        "          strikes = no_outliers.loc[no_outliers.Label==1,col]\n",
        "\n",
        "          # Identify the 25th and 75th quartiles\n",
        "          all_values = no_outliers.loc[:,col]\n",
        "          q25, q75 = np.percentile(all_values, 25), np.percentile(all_values, 75)\n",
        "          # Get the inter quartile range\n",
        "          iqr = q75 - q25\n",
        "          # Smaller cutoffs will remove more outliers\n",
        "          cutoff = iqr * 7\n",
        "          # Set the bounds of the desired portion to keep\n",
        "          lower, upper = q25 - cutoff, q75 + cutoff\n",
        "          \n",
        "          # If positively correlated...\n",
        "          # Drop nonstrikes above upper bound, and strikes below lower bound\n",
        "          if correlation > 0: \n",
        "              no_outliers.drop(index=nonstrikes[nonstrikes>upper].index,inplace=True)\n",
        "              no_outliers.drop(index=strikes[strikes<lower].index,inplace=True)\n",
        "          \n",
        "          # If negatively correlated...\n",
        "          # Drop non strikes below lower bound, and strikes above upper bound\n",
        "          elif correlation < 0: \n",
        "              no_outliers.drop(index=nonstrikes[nonstrikes<lower].index,inplace=True)\n",
        "              no_outliers.drop(index=strikes[strikes>upper].index,inplace=True)\n",
        "        \n",
        "    print('\\nData shape before removing outliers:', balanced.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in previous data:')\n",
        "    print(balanced.Label.value_counts())\n",
        "    print('-'*40)\n",
        "    print('-'*40)\n",
        "    print('\\nData shape after removing outliers:', no_outliers.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
        "    print(no_outliers.Label.value_counts())\n",
        "\n",
        "    # no_outliers.iloc[:,:-1].boxplot(rot=90,figsize=(16,4))\n",
        "    # plt.title('Distributions with Less Outliers', fontsize=17)\n",
        "    # plt.show()\n",
        "    \n",
        "    no_outliers.reset_index(drop=True, inplace=True)\n",
        "    return no_outliers\n",
        "\n",
        "\n",
        "def filter_features(no_outliers, threshold=0.001):\n",
        "    \"\"\"Feature selection.\n",
        "    \"\"\"\n",
        "    feat_sel = pd.DataFrame(no_outliers.copy())\n",
        "\n",
        "    # Make a dataframe with the label-correlations before removing outliers\n",
        "    # corr_change = pd.DataFrame()\n",
        "    # corr_change['correlation']= bal_corr.Label\n",
        "    # corr_change['origin']= 'w/outliers'\n",
        "\n",
        "    # Make a dataframe with label-correlations after removing outliers \n",
        "    # corr_other = pd.DataFrame()\n",
        "    # corr_other['correlation']= feat_sel.corr().Label\n",
        "    # corr_other['origin']= 'no_outliers'\n",
        "\n",
        "    # Join them\n",
        "    # corr_change = corr_change.append(corr_other)\n",
        "\n",
        "    # plt.figure(figsize=(14,6))\n",
        "    # plt.xticks(rotation=90)\n",
        "\n",
        "    # Plot them\n",
        "    # sns.set_style('darkgrid')\n",
        "    # plt.title('Label correlation per feature. With vs without outliers', fontsize=17)\n",
        "    # sns.barplot(data=corr_change,x=corr_change.index,y='correlation',hue='origin')\n",
        "    # plt.show()\n",
        "\n",
        "    # Feature Selection based on correlation with label\n",
        "\n",
        "    print('\\nData shape before feature selection:', feat_sel.shape)\n",
        "    print('\\nCounts of strikes vs non-strikes before feature selection:')\n",
        "    print(feat_sel.Label.value_counts())\n",
        "    print('-'*40)\n",
        "\n",
        "    # Correlation matrix after removing outliers\n",
        "    new_corr = feat_sel.corr()\n",
        "\n",
        "    for col in new_corr.Label.index[:-1]:\n",
        "        # Pick desired cutoff for dropping features. In absolute-value terms.\n",
        "        if np.absolute(new_corr.loc['Label',col]) < threshold:\n",
        "            # Drop the feature if correlation is below cutoff\n",
        "            feat_sel.drop(columns=col,inplace=True)\n",
        "\n",
        "    print('-'*40)\n",
        "    print('\\nData shape after feature selection:', feat_sel.shape)\n",
        "    print('\\nCounts of strikes vs non-strikes in new data:')\n",
        "    print(feat_sel.Label.value_counts())\n",
        "\n",
        "    return feat_sel\n",
        "\n",
        "    # feat_sel.iloc[:,:-1].boxplot(rot=90,figsize=(16,4))\n",
        "    # plt.title('Distribution of Features Selected', fontsize=17)\n",
        "    # plt.show()\n",
        "\n",
        "def under_sampler(data, sample_size=20000, sampling=False):\n",
        "    # Undersample model for efficiency and balance classes.\n",
        "\n",
        "    X_train = data.drop('Label',1)\n",
        "    y_train = data.Label\n",
        "\n",
        "    if not sampling:\n",
        "      return X_train, y_train\n",
        "\n",
        "    # After feature-selection, X_test needs to include only the same features as X_train\n",
        "    # cols = X_train.columns\n",
        "    # X_test = X_test[cols]\n",
        "\n",
        "    # Undersample and balance classes\n",
        "    X_train, y_train = RandomUnderSampler(sampling_strategy={1:sample_size,0:sample_size}).fit_resample(X_train,y_train)\n",
        "\n",
        "    print('\\nX_train shape after reduction:', X_train.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in y_train:')\n",
        "    print(np.unique(y_train, return_counts=True))\n",
        "\n",
        "    return X_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pl5ZoepSNPf4",
        "colab": {}
      },
      "source": [
        "def gen_train_test_set(dt, feature_matrix, file_prefix='data'): \n",
        "    \n",
        "    # Subset labels\n",
        "    test_labels = feature_matrix.loc[feature_matrix['time'] == dt, 'Label']\n",
        "    train_labels = feature_matrix.loc[feature_matrix['time'] < dt, 'Label']\n",
        "\n",
        "    # Features\n",
        "    X_train = feature_matrix[feature_matrix['time'] < dt].drop(columns = ['NumberId', 'time', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    X_test = feature_matrix[feature_matrix['time'] == dt].drop(columns = ['NumberId', 'time', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    feature_names = list(X_train.columns)\n",
        "    \n",
        "    # Labels\n",
        "    y_train = np.array(train_labels).reshape((-1, ))\n",
        "    y_test = np.array(test_labels).reshape((-1, ))\n",
        "    \n",
        "    print('Training on {} observations.'.format(len(X_train)))\n",
        "    print('Testing on {} observations.\\n'.format(len(X_test)))\n",
        "\n",
        "    # Join the train data\n",
        "    train = X_train.join(train_labels)\n",
        "\n",
        "    print('Data shape before balancing:', train.shape)\n",
        "    print('\\nCounts of strikes vs non-strikes in previous data:')\n",
        "    print(train.Label.value_counts())\n",
        "    print('-'*40)\n",
        "\n",
        "    # sklearn pipeline\n",
        "    pipeline = make_pipeline(\n",
        "        SimpleImputer(strategy = 'constant', fill_value=0),\n",
        "        StandardScaler())\n",
        "    \n",
        "    X_train = pipeline.fit_transform(X_train)\n",
        "    X_test = pipeline.transform(X_test)\n",
        "\n",
        "    # imblearn pipeline\n",
        "    imb_pipeline = make_pipeline_imb(\n",
        "          # NearMiss(version=3, n_neighbors_ver3=3, n_jobs=4)\n",
        "          # SMOTE(sampling_strategy='minority',random_state=42, n_jobs=4)\n",
        "          # ADASYN(sampling_strategy='minority',random_state=42, n_jobs=4)\n",
        "          # OneSidedSelection(n_neighbors=1, n_seeds_S=200, random_state=42, n_jobs=4)\n",
        "          SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='majority'))\n",
        "    )\n",
        "     \n",
        "    # Balance the data\n",
        "    to_balanced = False\n",
        "    if to_balanced:\n",
        "      print('\\nBalancing data')\n",
        "      X_bal, y_bal = imb_pipeline.fit_resample(X_train, y_train)\n",
        "      X_bal = pd.DataFrame(X_bal,columns=feature_names)\n",
        "      y_bal = pd.DataFrame(y_bal,columns=['Label'])\n",
        "    else:\n",
        "      print('\\nNO balancing')\n",
        "      X_bal = pd.DataFrame(X_train,columns=feature_names)\n",
        "      y_bal = pd.DataFrame(y_train,columns=['Label'])\n",
        "\n",
        "    balanced = X_bal.join(y_bal)\n",
        "\n",
        "    # print('-'*40)\n",
        "    print('Data shape after balancing:',balanced.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
        "    print(balanced.Label.value_counts())\n",
        "\n",
        "    # Remove high correlation outliers\n",
        "    no_outliers = remove_outliers(balanced, remove=False)\n",
        "   \n",
        "    # Remove features with low correlation\n",
        "    remove_features = True\n",
        "    if remove_features:\n",
        "      print('\\nFiltering features')\n",
        "      features_selected = filter_features(no_outliers)\n",
        "    else:\n",
        "      print('\\nNO filtering')\n",
        "      features_selected = no_outliers \n",
        "\n",
        "    columns_selected = features_selected.drop('Label',1).columns\n",
        "\n",
        "    # Under sampling\n",
        "    X_train, y_train = under_sampler(features_selected, sampling=False) \n",
        "    X_train = pd.DataFrame(X_train,columns=columns_selected)\n",
        "    y_train = pd.DataFrame(y_train,columns=['Label'])\n",
        "\n",
        "    # For X_test, now only use the selected features\n",
        "    X_test = pd.DataFrame(X_test,columns=feature_names)\n",
        "    X_test = X_test[columns_selected]\n",
        "    y_test = pd.DataFrame(y_test,columns=['Label'])\n",
        "\n",
        "    #print(X_train.describe())\n",
        "    #return\n",
        "\n",
        "    # Save data\n",
        "    # print(X_train.head(10))\n",
        "    # print(y_train.head(10)) \n",
        "\n",
        "    # print(X_test.head(10))\n",
        "    # print(y_test.head(10)) \n",
        "    X_train.to_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
        "    y_train.to_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
        "   \n",
        "    X_test.to_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
        "    y_test.to_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
        "\n",
        "    gc.collect()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PcKlL67TP9UM",
        "colab": {}
      },
      "source": [
        "def model(dt, feature_matrix, file_prefix='data', csv=False, class_weight=1.0):\n",
        "    \"\"\"Predict for a particular month.\n",
        "\n",
        "    - https://www.kaggle.com/miguelniblock/optimizing-imbalanced-classification-100-recall\n",
        "    - https://www.kaggle.com/saxinou/imbalanced-data-xgboost-tunning\n",
        "    - https://www.kaggle.com/andreanuzzo/balance-the-imbalanced-rf-and-xgboost-with-smote\n",
        "    - https://github.com/mengwangk/FraudDetection/blob/master/05_Sampling_techniques_for_extremely_imbalanced_data.ipynb\n",
        "    - https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
        "    - https://github.com/coding-maniacs/over-under-sampling/blob/master/src/main.py\n",
        "    - https://github.com/scikit-learn-contrib/imbalanced-learn/issues/552#issuecomment-466348310\n",
        "    - https://stackoverflow.com/questions/52499788/smotetomek-how-to-set-ratio-as-dictionary-for-fixed-balance\n",
        "    - https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.OneSidedSelection.html#imblearn.under_sampling.OneSidedSelection\n",
        "    - https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\n",
        "    - https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n",
        "    - https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
        "    - https://stats.stackexchange.com/questions/243207/what-is-the-proper-usage-of-scale-pos-weight-in-xgboost-for-imbalanced-datasets\n",
        "    - https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py\n",
        "    - https://machinelearningmastery.com/cost-sensitive-logistic-regression/\n",
        "    \n",
        "    - https://datascience.stackexchange.com/questions/28285/what-is-the-best-way-to-deal-with-imbalanced-data-for-xgboost/28292\n",
        "    - https://machinelearningmastery.com/xgboost-for-imbalanced-classification/\n",
        "    - https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # Read data\n",
        "    if not csv:\n",
        "      X_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
        "      y_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
        "    \n",
        "      X_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
        "      y_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
        "    else:\n",
        "      X_train = pd.read_csv(DATASET_PATH/f\"{file_prefix}_X_train.csv\", header=0, sep=',', quotechar='\"')\n",
        "      y_train = pd.read_csv(DATASET_PATH/f\"{file_prefix}_y_train.csv\", header=0, sep=',', quotechar='\"')\n",
        "    \n",
        "      X_test = pd.read_csv(DATASET_PATH/f\"{file_prefix}_X_test.csv\", header=0, sep=',', quotechar='\"')\n",
        "      y_test = pd.read_csv(DATASET_PATH/f\"{file_prefix}_y_test.csv\", header=0, sep=',', quotechar='\"')\n",
        "\n",
        "\n",
        "    print(f'\\n-----------{dt}-----------------\\n')\n",
        "\n",
        "    # Reshape\n",
        "    y_train = np.array(y_train).reshape((-1, ))\n",
        "    y_test = np.array(y_test).reshape((-1, ))\n",
        "    \n",
        "    print('Data shape')\n",
        "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "    # print(X_train.describe())\n",
        "    # return\n",
        "\n",
        "    # Calculate hit ratio for xgboost classifier\n",
        "    print(\"\\nCalculating scale pos weight\")\n",
        "    counter = Counter(y_train)\n",
        "    print(Counter(y_train))\n",
        "    #scale_pos_weight = float(counter[0] / counter[1])\n",
        "    scale_pos_weight = (float(counter[0] / counter[1])) * class_weight\n",
        "    print(f\"\\nscale_pos_weight - {scale_pos_weight}\\n\")\n",
        "    \n",
        "     # Modeling\n",
        "#     clf = xgb.XGBClassifier(\n",
        "#               n_jobs=4, \n",
        "#               random_state=42,\n",
        "#               #learning_rate=0.1,\n",
        "#               #n_estimators=500,\n",
        "#               #max_depth=6, \n",
        "#               #min_child_weight=3, \n",
        "#               #gamma=0,\n",
        "#               #subsample=0.8,\n",
        "#               #colsample_bytree=0.8,\n",
        "#               objective='binary:logistic', \n",
        "#               scale_pos_weight=scale_pos_weight,\n",
        "#               ##eval_metric=\"auc\",\n",
        "#               ##max_delta_step=1,\n",
        "#               seed=27)\n",
        "#     clf = xgb.XGBClassifier(n_jobs=4, \n",
        "#                             random_state=42,\n",
        "#                             objective='binary:logistic', \n",
        "#                             #scale_pos_weight=28)\n",
        "#                             scale_pos_weight=scale_pos_weight)\n",
        "    \n",
        "    clf = xgb.XGBClassifier(\n",
        "                    n_jobs=4, \n",
        "                    random_state=42,\n",
        "                    objective='binary:logistic',\n",
        "                    subsample=0.55, \n",
        "                    n_estimators=300,\n",
        "                    #n_estimators=500,\n",
        "                    min_child_weight=1,\n",
        "                    max_depth=3, \n",
        "                    learning_rate=0.007,\n",
        "                    gamma=0.1, \n",
        "                    colsample_bytree=0.95,\n",
        "                    tree_method='hist',\n",
        "                    booster='dart',\n",
        "                    scale_pos_weight=scale_pos_weight\n",
        "                    )\n",
        "\n",
        "    clf_params = clf.get_params()\n",
        "    print(clf_params)\n",
        "\n",
        "    # Set parameters\n",
        "    #clf_params['max_depth'] = 10\n",
        "    #clf.set_params(clf_params)\n",
        "\n",
        "    # Parameters to compare\n",
        "    weights = [i for i in range(1,36,1)]\n",
        "    weights.append(scale_pos_weight)\n",
        "    learn_params = {\n",
        "        'n_estimators': [100, 300, 500, 800, 1000], \n",
        "        'max_depth': range(3,10,2),\n",
        "        'min_child_weight': range(1,6,2),\n",
        "        #'gamma':[i/10.0 for i in range(0,5)],\n",
        "        'subsample':[i/100.0 for i in range(55,70,5)],\n",
        "        'colsample_bytree':[i/100.0 for i in range(85,100,5)],\n",
        "        #'learning_rate':[i/1000.0 for i in range(5,20,2)],\n",
        "        'scale_pos_weight': weights\n",
        "    }\n",
        "    print(f'Parameter distribution: {learn_params}')\n",
        "    \n",
        "    # Test and validate\n",
        "    ret_val = score_optimization(dt,\n",
        "                       feature_matrix,\n",
        "                       clf, \n",
        "                       learn_params,  \n",
        "                       X_train, \n",
        "                       y_train, \n",
        "                       X_test, \n",
        "                       y_test, \n",
        "                       skip_grid_search_cv=True,\n",
        "                       optimized_scorer=True)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    return ret_val\n",
        "    \n",
        "    # clf.fit(X_train, y_train)\n",
        "    # y_pred = clf.predict(X_test)\n",
        "\n",
        "    # # ROC score\n",
        "    # auc = roc_auc_score(y_test, y_pred)\n",
        "    # print(\"ROC score: \", auc)\n",
        "\n",
        "    # # Print confusion matrix\n",
        "    # conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    # sns.heatmap(conf_matrix, annot=True,fmt='d', cmap=plt.cm.copper)\n",
        "    # plt.show()\n",
        "\n",
        "    # Parameters to compare\n",
        "    # params = {\n",
        "    #     'criterion':['entropy','gini'],\n",
        "    #     'class_weight':[{1:1,0:0.3},{1:1,0:0.4},{1:1,0:0.5},{1:1,0:0.6},{1:1,0:7}]\n",
        "    # }\n",
        "\n",
        "    # Implement the classifier\n",
        "    # clf = RandomForestClassifier(\n",
        "    #     n_estimators=100,\n",
        "    #     max_features=None,\n",
        "    #     n_jobs=4,\n",
        "    # )\n",
        "\n",
        "    # # Test and validate\n",
        "    # score_optimization(clf, params, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m9UobqUWMI9b",
        "jupyter": {
          "source_hidden": true
        },
        "colab": {}
      },
      "source": [
        "# Predict for a particular month\n",
        "\n",
        "# %time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection)\n",
        "\n",
        "#%time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='test')\n",
        "#%time model(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='orig')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ns3Puh7Gnxl5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "faa5166d-5a9d-4e4d-96d0-d7719d884758"
      },
      "source": [
        "%time gen_train_test_set(pd.datetime(2020,1,1), feature_matrix_selection, file_prefix='test')\n",
        "%time model(pd.datetime(2020,1,1), feature_matrix_selection, file_prefix='test')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 959893 observations.\n",
            "Testing on 10000 observations.\n",
            "\n",
            "Data shape before balancing: (959893, 63)\n",
            "\n",
            "Counts of strikes vs non-strikes in previous data:\n",
            "0    927839\n",
            "1     32054\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "\n",
            "NO balancing\n",
            "Data shape after balancing: (959893, 63)\n",
            "\n",
            "Counts of strikes VS non-strikes in new data:\n",
            "0    927839\n",
            "1     32054\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Filtering features\n",
            "\n",
            "Data shape before feature selection: (959893, 63)\n",
            "\n",
            "Counts of strikes vs non-strikes before feature selection:\n",
            "0    927839\n",
            "1     32054\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "\n",
            "Data shape after feature selection: (959893, 33)\n",
            "\n",
            "Counts of strikes vs non-strikes in new data:\n",
            "0    927839\n",
            "1     32054\n",
            "Name: Label, dtype: int64\n",
            "CPU times: user 13 s, sys: 135 ms, total: 13.1 s\n",
            "Wall time: 20.5 s\n",
            "\n",
            "-----------2020-01-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(959893, 32) (959893,) (10000, 32) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 927839, 1: 32054})\n",
            "\n",
            "scale_pos_weight - 28.946122168840084\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.946122168840084, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.946122168840084]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.486, F-Score=0.06715\n",
            "\n",
            "Recall: 0.03625377643504532\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.95      0.04      0.96      0.19      0.04      9669\n",
            "          1       0.02      0.04      0.95      0.03      0.19      0.03       331\n",
            "\n",
            "avg / total       0.94      0.92      0.07      0.93      0.19      0.04     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0362538</td>\n",
              "      <td>0.949633</td>\n",
              "      <td>0.0189296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity   Optimize\n",
              "XGBClassifier_optimize            0   0.0362538         0.949633  0.0189296"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 499 \n",
            "\n",
            "First 23 matches\n",
            "23 [  0  19  28  33  35  42  52  54  72  83 113 121 131 151 152 163 193 197\n",
            " 201 203 210 216 219]\n",
            "\n",
            "[0.5003511  0.52248204 0.50784427 0.50191045 0.5057217  0.5048611\n",
            " 0.50451064 0.5039963  0.509949   0.5020125  0.5027646  0.5010643\n",
            " 0.5022977  0.5021906  0.5024378  0.50260496 0.5020971  0.5164497\n",
            " 0.50408435 0.50168    0.5068371  0.5028062  0.5048865 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[5378  535  854 5301 3114 5311 7455 1271  950 4609 8938 4562 7227 1949\n",
            " 1933   19  592  594 9258 2479  197 7139  903]\n",
            "\n",
            "\n",
            "[0.51189953 0.513232   0.51331276 0.5274233  0.5207647  0.5264696\n",
            " 0.53518885 0.5227687  0.51804614 0.5193527  0.5237212  0.524247\n",
            " 0.5159437  0.5180875  0.5142077  0.52248204 0.5338774  0.5165382\n",
            " 0.5216545  0.5173233  0.5164497  0.51689523 0.5152363 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "139 [ 19  28  33  35  42  52  54  72  83 113 121 131 151 152 163 193 197 201\n",
            " 203 210 216 219 226 230 249 270 271 272 279 282 283 291 298 314 317 323\n",
            " 328 330 344 352 363 382 384 385 391 392 421 430 431 437 446 450 468 479\n",
            " 495 496 498 500 507 510 519 535 537 538 544 546 557 559 567 568 569 575\n",
            " 581 586 591 592 594 603 604 613 616 622 623 628 630 634 637 641 649 650\n",
            " 657 661 669 674 691 706 708 709 716 720 731 736 743 744 757 769 771 799\n",
            " 802 803 806 810 816 817 818 823 854 859 862 871 874 877 886 892 895 903\n",
            " 905 921 922 923 925 947 950 952 954 961 963 974 987]\n",
            "\n",
            "[0.52248204 0.50784427 0.50191045 0.5057217  0.5048611  0.50451064\n",
            " 0.5039963  0.509949   0.5020125  0.5027646  0.5010643  0.5022977\n",
            " 0.5021906  0.5024378  0.50260496 0.5020971  0.5164497  0.50408435\n",
            " 0.50168    0.5068371  0.5028062  0.5048865  0.50117046 0.5003884\n",
            " 0.5025136  0.5028138  0.50133765 0.5030081  0.50470847 0.5055\n",
            " 0.50871474 0.5023006  0.5014946  0.50675607 0.5011072  0.5016996\n",
            " 0.5018122  0.5025067  0.5013677  0.50133723 0.5067313  0.5027823\n",
            " 0.5012851  0.5021433  0.5073786  0.5073692  0.50053626 0.5026247\n",
            " 0.50536674 0.5053073  0.50418335 0.50007397 0.5000084  0.5058769\n",
            " 0.5062603  0.5100016  0.5045754  0.501044   0.51017076 0.50104684\n",
            " 0.50578594 0.513232   0.5063866  0.5053521  0.5027292  0.51045257\n",
            " 0.50993836 0.5049929  0.51028883 0.50314444 0.5026871  0.5063198\n",
            " 0.5037849  0.50220287 0.5042706  0.5338774  0.5165382  0.5028768\n",
            " 0.5070117  0.50277925 0.5035427  0.51019454 0.5031667  0.5073112\n",
            " 0.5076562  0.50011355 0.5019239  0.5080432  0.50286573 0.5026484\n",
            " 0.50329924 0.5031065  0.50078833 0.50025135 0.5018161  0.50466675\n",
            " 0.51111573 0.5002238  0.5056728  0.503027   0.50159967 0.5016565\n",
            " 0.50640553 0.5018991  0.5060473  0.5023689  0.5017106  0.5051317\n",
            " 0.5034798  0.5044686  0.50603133 0.50975513 0.50053    0.50272375\n",
            " 0.5001502  0.5076552  0.51331276 0.50349104 0.50172275 0.50040615\n",
            " 0.50272894 0.5014006  0.50064915 0.5023373  0.5099846  0.5152363\n",
            " 0.509494   0.50127655 0.50588864 0.5073575  0.5114115  0.50101775\n",
            " 0.51804614 0.50017285 0.5008312  0.5047453  0.5074354  0.5058613\n",
            " 0.50231266]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.504860520362854\n",
            "\n",
            "125 [  19   28   35   42   72  197  210  219  282  283  314  363  391  392\n",
            "  431  437  479  495  496  507  519  535  537  538  546  557  559  567\n",
            "  575  592  594  604  622  628  630  641  708  716  743  757  799  806\n",
            "  810  823  854  895  903  905  922  923  925  950  963  974 1009 1017\n",
            " 1047 1085 1090 1112 1115 1124 1231 1255 1271 1445 1508 1519 1563 1597\n",
            " 1671 1684 1686 1702 1747 1773 1810 1933 1949 1979 2107 2144 2172 2185\n",
            " 2213 2302 2466 2479 2620 2679 3114 3591 3830 4012 4016 4267 4465 4562\n",
            " 4609 4709 4851 5084 5220 5227 5301 5311 5378 6045 6114 6968 6997 7139\n",
            " 7166 7227 7231 7455 7586 7730 7836 8476 8499 8690 8938 9028 9258]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5037346482276917\n",
            "\n",
            "161 [  19   28   35   42   52   54   72  197  201  210  219  279  282  283\n",
            "  314  363  391  392  431  437  446  479  495  496  498  507  519  535\n",
            "  537  538  546  557  559  567  575  581  591  592  594  604  622  628\n",
            "  630  641  706  708  716  743  757  799  803  806  810  823  854  895\n",
            "  903  905  922  923  925  950  961  963  974 1009 1017 1047 1064 1085\n",
            " 1088 1090 1112 1115 1124 1152 1231 1255 1271 1308 1445 1489 1508 1519\n",
            " 1550 1563 1597 1671 1684 1686 1702 1747 1773 1810 1933 1949 1979 2056\n",
            " 2107 2144 2172 2185 2213 2302 2466 2479 2489 2550 2620 2679 2842 2865\n",
            " 2958 3043 3090 3114 3359 3591 3830 3932 4012 4016 4267 4465 4562 4609\n",
            " 4709 4851 5084 5220 5227 5301 5311 5378 6045 6114 6391 6772 6806 6876\n",
            " 6945 6968 6997 7139 7166 7227 7231 7455 7586 7730 7775 7836 8476 8499\n",
            " 8690 8938 8981 9028 9258 9282 9755]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "499 [   0   19   28   33   35   42   52   54   72   83  113  121  131  151\n",
            "  152  163  193  197  201  203  210  216  219  226  230  249  270  271\n",
            "  272  279  282  283  291  298  314  317  323  328  330  344  352  363\n",
            "  382  384  385  391  392  421  430  431  437  446  450  468  479  495\n",
            "  496  498  500  507  510  519  535  537  538  544  546  557  559  567\n",
            "  568  569  575  581  586  591  592  594  603  604  613  616  622  623\n",
            "  628  630  634  637  641  649  650  657  661  669  674  691  706  708\n",
            "  709  716  720  731  736  743  744  757  769  771  799  802  803  806\n",
            "  810  816  817  818  823  854  859  862  871  874  877  886  892  895\n",
            "  903  905  921  922  923  925  947  950  952  954  961  963  974  987\n",
            " 1009 1017 1039 1047 1050 1061 1064 1085 1088 1090 1112 1115 1117 1124\n",
            " 1126 1152 1156 1164 1174 1175 1198 1216 1231 1249 1253 1255 1257 1260\n",
            " 1271 1287 1289 1296 1298 1304 1308 1320 1334 1340 1353 1378 1388 1445\n",
            " 1467 1472 1474 1475 1489 1508 1515 1516 1519 1531 1550 1555 1557 1563\n",
            " 1571 1580 1583 1593 1597 1615 1650 1671 1684 1686 1689 1700 1701 1702\n",
            " 1723 1736 1747 1766 1769 1773 1810 1828 1857 1862 1867 1879 1884 1933\n",
            " 1940 1942 1949 1950 1952 1957 1962 1979 1980 1984 1992 2011 2019 2036\n",
            " 2037 2053 2056 2064 2071 2097 2105 2107 2115 2144 2157 2171 2172 2185\n",
            " 2188 2209 2213 2237 2238 2241 2255 2260 2269 2272 2276 2278 2302 2326\n",
            " 2341 2393 2399 2403 2405 2418 2423 2441 2451 2461 2466 2479 2483 2489\n",
            " 2491 2509 2533 2536 2550 2552 2562 2572 2603 2620 2633 2645 2660 2679\n",
            " 2692 2704 2770 2786 2795 2833 2842 2865 2869 2871 2872 2889 2908 2936\n",
            " 2958 3009 3010 3029 3033 3034 3043 3072 3086 3090 3091 3094 3099 3113\n",
            " 3114 3138 3139 3145 3171 3216 3230 3251 3266 3269 3319 3334 3350 3356\n",
            " 3359 3400 3431 3482 3492 3494 3526 3545 3567 3591 3600 3618 3624 3675\n",
            " 3685 3732 3733 3781 3811 3830 3843 3919 3932 3960 3968 3988 4001 4012\n",
            " 4013 4016 4036 4098 4102 4123 4166 4267 4373 4435 4465 4479 4562 4567\n",
            " 4609 4615 4709 4725 4780 4789 4808 4813 4851 4859 4877 5067 5084 5213\n",
            " 5220 5227 5234 5237 5240 5301 5309 5311 5347 5378 5440 5442 5506 5628\n",
            " 5644 5673 5709 5725 5726 5797 5820 5825 5840 5858 5922 6019 6045 6055\n",
            " 6114 6152 6222 6286 6367 6379 6391 6481 6559 6620 6692 6742 6749 6772\n",
            " 6806 6876 6882 6918 6926 6928 6945 6962 6968 6978 6992 6997 7081 7097\n",
            " 7111 7126 7128 7139 7166 7210 7227 7231 7249 7294 7297 7320 7397 7402\n",
            " 7433 7455 7457 7492 7532 7539 7586 7730 7738 7775 7836 7943 7983 8009\n",
            " 8051 8186 8290 8307 8476 8490 8499 8524 8690 8701 8723 8938 8981 8983\n",
            " 9028 9258 9282 9372 9465 9595 9671 9692 9755]\n",
            "\n",
            "499 [0.5003511  0.52248204 0.50784427 0.50191045 0.5057217  0.5048611\n",
            " 0.50451064 0.5039963  0.509949   0.5020125  0.5027646  0.5010643\n",
            " 0.5022977  0.5021906  0.5024378  0.50260496 0.5020971  0.5164497\n",
            " 0.50408435 0.50168    0.5068371  0.5028062  0.5048865  0.50117046\n",
            " 0.5003884  0.5025136  0.5028138  0.50133765 0.5030081  0.50470847\n",
            " 0.5055     0.50871474 0.5023006  0.5014946  0.50675607 0.5011072\n",
            " 0.5016996  0.5018122  0.5025067  0.5013677  0.50133723 0.5067313\n",
            " 0.5027823  0.5012851  0.5021433  0.5073786  0.5073692  0.50053626\n",
            " 0.5026247  0.50536674 0.5053073  0.50418335 0.50007397 0.5000084\n",
            " 0.5058769  0.5062603  0.5100016  0.5045754  0.501044   0.51017076\n",
            " 0.50104684 0.50578594 0.513232   0.5063866  0.5053521  0.5027292\n",
            " 0.51045257 0.50993836 0.5049929  0.51028883 0.50314444 0.5026871\n",
            " 0.5063198  0.5037849  0.50220287 0.5042706  0.5338774  0.5165382\n",
            " 0.5028768  0.5070117  0.50277925 0.5035427  0.51019454 0.5031667\n",
            " 0.5073112  0.5076562  0.50011355 0.5019239  0.5080432  0.50286573\n",
            " 0.5026484  0.50329924 0.5031065  0.50078833 0.50025135 0.5018161\n",
            " 0.50466675 0.51111573 0.5002238  0.5056728  0.503027   0.50159967\n",
            " 0.5016565  0.50640553 0.5018991  0.5060473  0.5023689  0.5017106\n",
            " 0.5051317  0.5034798  0.5044686  0.50603133 0.50975513 0.50053\n",
            " 0.50272375 0.5001502  0.5076552  0.51331276 0.50349104 0.50172275\n",
            " 0.50040615 0.50272894 0.5014006  0.50064915 0.5023373  0.5099846\n",
            " 0.5152363  0.509494   0.50127655 0.50588864 0.5073575  0.5114115\n",
            " 0.50101775 0.51804614 0.50017285 0.5008312  0.5047453  0.5074354\n",
            " 0.5058613  0.50231266 0.50519043 0.5067419  0.5027104  0.50537485\n",
            " 0.5033197  0.5011895  0.5045382  0.50516135 0.50429684 0.5053881\n",
            " 0.50654525 0.50639546 0.500511   0.5113807  0.50303376 0.50468665\n",
            " 0.50250125 0.5003006  0.5008098  0.5001686  0.50284076 0.50357056\n",
            " 0.50489    0.501008   0.5008789  0.5052995  0.501116   0.5003353\n",
            " 0.5227687  0.50267607 0.50279516 0.5034297  0.5006537  0.5026675\n",
            " 0.5042548  0.50348127 0.50075406 0.5010153  0.5016317  0.5021651\n",
            " 0.5007681  0.504919   0.5011431  0.50122833 0.5001213  0.50217646\n",
            " 0.50449264 0.50611395 0.503413   0.5017338  0.5059886  0.50228363\n",
            " 0.50436264 0.5012527  0.5003366  0.50488573 0.50229263 0.50039124\n",
            " 0.5028025  0.50042796 0.5088883  0.5022468  0.50371754 0.5067246\n",
            " 0.5056808  0.5080082  0.50017947 0.50166845 0.50234133 0.50694084\n",
            " 0.5014281  0.5004545  0.50666535 0.50012976 0.5010901  0.50532013\n",
            " 0.5049537  0.501482   0.5008749  0.5009867  0.50006473 0.50255376\n",
            " 0.50075465 0.5142077  0.5035889  0.5033696  0.5180875  0.50297505\n",
            " 0.5029536  0.5007569  0.5015399  0.50581276 0.5007272  0.5000616\n",
            " 0.5007575  0.5008069  0.5005511  0.50108254 0.5016802  0.50256294\n",
            " 0.5044535  0.50257367 0.5011153  0.50141895 0.50132126 0.5064769\n",
            " 0.5019719  0.50708884 0.5008176  0.50159174 0.5096441  0.5060774\n",
            " 0.500904   0.5012206  0.505403   0.50247496 0.5006065  0.50128055\n",
            " 0.5019138  0.50114095 0.5018933  0.50179833 0.5017493  0.5014772\n",
            " 0.5056648  0.5001841  0.501524   0.5017295  0.5005708  0.50076395\n",
            " 0.5004045  0.50109017 0.5013791  0.50073427 0.5036622  0.5016156\n",
            " 0.5105219  0.5173233  0.50286525 0.50399023 0.5004119  0.50244206\n",
            " 0.5026509  0.50363785 0.5039497  0.5003184  0.50167805 0.5008776\n",
            " 0.5028903  0.507734   0.5025961  0.50050765 0.50345844 0.5055035\n",
            " 0.5014045  0.50179446 0.5026105  0.5004396  0.50279456 0.50096923\n",
            " 0.50455225 0.5048195  0.5002355  0.50181985 0.5006636  0.50078875\n",
            " 0.501681   0.5031641  0.50439185 0.5027303  0.5014436  0.5019937\n",
            " 0.50033325 0.5024191  0.5046285  0.500464   0.5028169  0.50389045\n",
            " 0.5032875  0.5032902  0.5025971  0.5017341  0.5207647  0.50149924\n",
            " 0.50013566 0.5012895  0.5032843  0.50029504 0.50225574 0.501756\n",
            " 0.50262296 0.50022054 0.5002448  0.50361246 0.5010592  0.50252795\n",
            " 0.50381094 0.5024969  0.50079846 0.50357217 0.50142336 0.5016774\n",
            " 0.5019194  0.50274986 0.500615   0.506279   0.5004397  0.50329953\n",
            " 0.5027782  0.5014529  0.5018564  0.5005106  0.5017879  0.50016177\n",
            " 0.50219464 0.5054565  0.50021964 0.5024495  0.5043269  0.5014249\n",
            " 0.50286686 0.50046194 0.5001995  0.5059587  0.50059366 0.50557494\n",
            " 0.50212014 0.5003603  0.50139415 0.50347596 0.50072443 0.5061113\n",
            " 0.50204647 0.5003465  0.5116624  0.5028855  0.524247   0.5037081\n",
            " 0.5193527  0.50112814 0.5060504  0.5004221  0.5012994  0.500213\n",
            " 0.5004896  0.5013476  0.5050086  0.50244296 0.5004675  0.5015824\n",
            " 0.5054314  0.5011358  0.5054858  0.5062073  0.50075305 0.5022744\n",
            " 0.50322175 0.5274233  0.5006698  0.5264696  0.50023097 0.51189953\n",
            " 0.50091743 0.50145924 0.5023199  0.50187606 0.5017801  0.5009645\n",
            " 0.5002382  0.50354016 0.50336486 0.5009919  0.50129896 0.5011878\n",
            " 0.5007111  0.5004217  0.5009532  0.50176543 0.50515676 0.5005477\n",
            " 0.5052177  0.5005183  0.5002723  0.50106156 0.50115174 0.50006264\n",
            " 0.50409156 0.50152296 0.5009079  0.50010085 0.50152975 0.5001474\n",
            " 0.50032455 0.50444067 0.5045199  0.50385445 0.5017019  0.5006076\n",
            " 0.5015045  0.5013372  0.5041872  0.50187016 0.50622576 0.5030804\n",
            " 0.50161535 0.5055178  0.50123614 0.50154245 0.5003346  0.5025405\n",
            " 0.5020591  0.51689523 0.5072355  0.5002202  0.5159437  0.5063022\n",
            " 0.50137895 0.5026437  0.50030047 0.5032854  0.5010801  0.5014058\n",
            " 0.5016636  0.53518885 0.5007284  0.50276446 0.50244975 0.5012055\n",
            " 0.5067268  0.5056736  0.50070006 0.50376034 0.50869143 0.5006901\n",
            " 0.5000065  0.502742   0.50026447 0.50015754 0.5002711  0.50342256\n",
            " 0.50493324 0.5000145  0.5071388  0.5014634  0.5074262  0.50271624\n",
            " 0.5011228  0.5237212  0.5041998  0.50299394 0.5062647  0.5216545\n",
            " 0.5042311  0.5006895  0.503648   0.5021829  0.5013047  0.50121516\n",
            " 0.50419456]\n",
            "\n",
            "Matched draws\n",
            "Count: 12, Index: (array([ 203,  216,  450,  905, 1340, 1701, 2483, 2795, 3960, 5227, 7210,\n",
            "       7294]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106955  505820 2020-01-12  ConsolationNo2      203\n",
            "107125  506520 2020-01-26     SpecialNo10      203\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106858  505420 2020-01-04      1stPrizeNo      450\n",
            "106955  505820 2020-01-12  ConsolationNo2      203\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "107125  506520 2020-01-26     SpecialNo10      203\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106856  505320 2020-01-01      SpecialNo8     3960\n",
            "106858  505420 2020-01-04      1stPrizeNo      450\n",
            "106859  505420 2020-01-04      2ndPrizeNo     2483\n",
            "106863  505420 2020-01-04  ConsolationNo2     7294\n",
            "106917  505620 2020-01-08      SpecialNo1     5227\n",
            "106940  505720 2020-01-11      SpecialNo1     1701\n",
            "106955  505820 2020-01-12  ConsolationNo2      203\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "106965  505820 2020-01-12      SpecialNo2     1340\n",
            "107077  506320 2020-01-22  ConsolationNo9     7210\n",
            "107119  506520 2020-01-26  ConsolationNo5     2795\n",
            "107125  506520 2020-01-26     SpecialNo10      203\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "CPU times: user 32min 25s, sys: 997 ms, total: 32min 26s\n",
            "Wall time: 8min 15s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VE6Xbz-IyvLj",
        "outputId": "01253b36-c7e7-4e4b-e459-a1088e1fa3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "weight=1.0\n",
        "decrement = 0.000\n",
        "to_stop=False\n",
        "\n",
        "dt = pd.datetime(2020,1,1)\n",
        "%time gen_train_test_set(dt, feature_matrix_selection, file_prefix='test')\n",
        "while not to_stop:\n",
        "  to_stop = model(dt, feature_matrix_selection, file_prefix='test', class_weight=(weight-decrement))\n",
        "  decrement = decrement + 0.005"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 959893 observations.\n",
            "Testing on 10000 observations.\n",
            "\n",
            "Data shape before balancing: (959893, 63)\n",
            "\n",
            "Counts of strikes vs non-strikes in previous data:\n",
            "0    927839\n",
            "1     32054\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "\n",
            "NO balancing\n",
            "Data shape after balancing: (959893, 63)\n",
            "\n",
            "Counts of strikes VS non-strikes in new data:\n",
            "0    927839\n",
            "1     32054\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Filtering features\n",
            "\n",
            "Data shape before feature selection: (959893, 63)\n",
            "\n",
            "Counts of strikes vs non-strikes before feature selection:\n",
            "0    927839\n",
            "1     32054\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "\n",
            "Data shape after feature selection: (959893, 33)\n",
            "\n",
            "Counts of strikes vs non-strikes in new data:\n",
            "0    927839\n",
            "1     32054\n",
            "Name: Label, dtype: int64\n",
            "CPU times: user 12.3 s, sys: 168 ms, total: 12.4 s\n",
            "Wall time: 12.5 s\n",
            "\n",
            "-----------2020-01-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(959893, 32) (959893,) (10000, 32) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 927839, 1: 32054})\n",
            "\n",
            "scale_pos_weight - 28.946122168840084\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.946122168840084, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.946122168840084]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.486, F-Score=0.06715\n",
            "\n",
            "Recall: 0.03625377643504532\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.95      0.04      0.96      0.19      0.04      9669\n",
            "          1       0.02      0.04      0.95      0.03      0.19      0.03       331\n",
            "\n",
            "avg / total       0.94      0.92      0.07      0.93      0.19      0.04     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0362538</td>\n",
              "      <td>0.949633</td>\n",
              "      <td>0.0189296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity   Optimize\n",
              "XGBClassifier_optimize            0   0.0362538         0.949633  0.0189296"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 499 \n",
            "\n",
            "First 23 matches\n",
            "23 [  0  19  28  33  35  42  52  54  72  83 113 121 131 151 152 163 193 197\n",
            " 201 203 210 216 219]\n",
            "\n",
            "[0.5003511  0.52248204 0.50784427 0.50191045 0.5057217  0.5048611\n",
            " 0.50451064 0.5039963  0.509949   0.5020125  0.5027646  0.5010643\n",
            " 0.5022977  0.5021906  0.5024378  0.50260496 0.5020971  0.5164497\n",
            " 0.50408435 0.50168    0.5068371  0.5028062  0.5048865 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[5378  535  854 5301 3114 5311 7455 1271  950 4609 8938 4562 7227 1949\n",
            " 1933   19  592  594 9258 2479  197 7139  903]\n",
            "\n",
            "\n",
            "[0.51189953 0.513232   0.51331276 0.5274233  0.5207647  0.5264696\n",
            " 0.53518885 0.5227687  0.51804614 0.5193527  0.5237212  0.524247\n",
            " 0.5159437  0.5180875  0.5142077  0.52248204 0.5338774  0.5165382\n",
            " 0.5216545  0.5173233  0.5164497  0.51689523 0.5152363 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "139 [ 19  28  33  35  42  52  54  72  83 113 121 131 151 152 163 193 197 201\n",
            " 203 210 216 219 226 230 249 270 271 272 279 282 283 291 298 314 317 323\n",
            " 328 330 344 352 363 382 384 385 391 392 421 430 431 437 446 450 468 479\n",
            " 495 496 498 500 507 510 519 535 537 538 544 546 557 559 567 568 569 575\n",
            " 581 586 591 592 594 603 604 613 616 622 623 628 630 634 637 641 649 650\n",
            " 657 661 669 674 691 706 708 709 716 720 731 736 743 744 757 769 771 799\n",
            " 802 803 806 810 816 817 818 823 854 859 862 871 874 877 886 892 895 903\n",
            " 905 921 922 923 925 947 950 952 954 961 963 974 987]\n",
            "\n",
            "[0.52248204 0.50784427 0.50191045 0.5057217  0.5048611  0.50451064\n",
            " 0.5039963  0.509949   0.5020125  0.5027646  0.5010643  0.5022977\n",
            " 0.5021906  0.5024378  0.50260496 0.5020971  0.5164497  0.50408435\n",
            " 0.50168    0.5068371  0.5028062  0.5048865  0.50117046 0.5003884\n",
            " 0.5025136  0.5028138  0.50133765 0.5030081  0.50470847 0.5055\n",
            " 0.50871474 0.5023006  0.5014946  0.50675607 0.5011072  0.5016996\n",
            " 0.5018122  0.5025067  0.5013677  0.50133723 0.5067313  0.5027823\n",
            " 0.5012851  0.5021433  0.5073786  0.5073692  0.50053626 0.5026247\n",
            " 0.50536674 0.5053073  0.50418335 0.50007397 0.5000084  0.5058769\n",
            " 0.5062603  0.5100016  0.5045754  0.501044   0.51017076 0.50104684\n",
            " 0.50578594 0.513232   0.5063866  0.5053521  0.5027292  0.51045257\n",
            " 0.50993836 0.5049929  0.51028883 0.50314444 0.5026871  0.5063198\n",
            " 0.5037849  0.50220287 0.5042706  0.5338774  0.5165382  0.5028768\n",
            " 0.5070117  0.50277925 0.5035427  0.51019454 0.5031667  0.5073112\n",
            " 0.5076562  0.50011355 0.5019239  0.5080432  0.50286573 0.5026484\n",
            " 0.50329924 0.5031065  0.50078833 0.50025135 0.5018161  0.50466675\n",
            " 0.51111573 0.5002238  0.5056728  0.503027   0.50159967 0.5016565\n",
            " 0.50640553 0.5018991  0.5060473  0.5023689  0.5017106  0.5051317\n",
            " 0.5034798  0.5044686  0.50603133 0.50975513 0.50053    0.50272375\n",
            " 0.5001502  0.5076552  0.51331276 0.50349104 0.50172275 0.50040615\n",
            " 0.50272894 0.5014006  0.50064915 0.5023373  0.5099846  0.5152363\n",
            " 0.509494   0.50127655 0.50588864 0.5073575  0.5114115  0.50101775\n",
            " 0.51804614 0.50017285 0.5008312  0.5047453  0.5074354  0.5058613\n",
            " 0.50231266]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.504860520362854\n",
            "\n",
            "125 [  19   28   35   42   72  197  210  219  282  283  314  363  391  392\n",
            "  431  437  479  495  496  507  519  535  537  538  546  557  559  567\n",
            "  575  592  594  604  622  628  630  641  708  716  743  757  799  806\n",
            "  810  823  854  895  903  905  922  923  925  950  963  974 1009 1017\n",
            " 1047 1085 1090 1112 1115 1124 1231 1255 1271 1445 1508 1519 1563 1597\n",
            " 1671 1684 1686 1702 1747 1773 1810 1933 1949 1979 2107 2144 2172 2185\n",
            " 2213 2302 2466 2479 2620 2679 3114 3591 3830 4012 4016 4267 4465 4562\n",
            " 4609 4709 4851 5084 5220 5227 5301 5311 5378 6045 6114 6968 6997 7139\n",
            " 7166 7227 7231 7455 7586 7730 7836 8476 8499 8690 8938 9028 9258]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5037346482276917\n",
            "\n",
            "161 [  19   28   35   42   52   54   72  197  201  210  219  279  282  283\n",
            "  314  363  391  392  431  437  446  479  495  496  498  507  519  535\n",
            "  537  538  546  557  559  567  575  581  591  592  594  604  622  628\n",
            "  630  641  706  708  716  743  757  799  803  806  810  823  854  895\n",
            "  903  905  922  923  925  950  961  963  974 1009 1017 1047 1064 1085\n",
            " 1088 1090 1112 1115 1124 1152 1231 1255 1271 1308 1445 1489 1508 1519\n",
            " 1550 1563 1597 1671 1684 1686 1702 1747 1773 1810 1933 1949 1979 2056\n",
            " 2107 2144 2172 2185 2213 2302 2466 2479 2489 2550 2620 2679 2842 2865\n",
            " 2958 3043 3090 3114 3359 3591 3830 3932 4012 4016 4267 4465 4562 4609\n",
            " 4709 4851 5084 5220 5227 5301 5311 5378 6045 6114 6391 6772 6806 6876\n",
            " 6945 6968 6997 7139 7166 7227 7231 7455 7586 7730 7775 7836 8476 8499\n",
            " 8690 8938 8981 9028 9258 9282 9755]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "499 [   0   19   28   33   35   42   52   54   72   83  113  121  131  151\n",
            "  152  163  193  197  201  203  210  216  219  226  230  249  270  271\n",
            "  272  279  282  283  291  298  314  317  323  328  330  344  352  363\n",
            "  382  384  385  391  392  421  430  431  437  446  450  468  479  495\n",
            "  496  498  500  507  510  519  535  537  538  544  546  557  559  567\n",
            "  568  569  575  581  586  591  592  594  603  604  613  616  622  623\n",
            "  628  630  634  637  641  649  650  657  661  669  674  691  706  708\n",
            "  709  716  720  731  736  743  744  757  769  771  799  802  803  806\n",
            "  810  816  817  818  823  854  859  862  871  874  877  886  892  895\n",
            "  903  905  921  922  923  925  947  950  952  954  961  963  974  987\n",
            " 1009 1017 1039 1047 1050 1061 1064 1085 1088 1090 1112 1115 1117 1124\n",
            " 1126 1152 1156 1164 1174 1175 1198 1216 1231 1249 1253 1255 1257 1260\n",
            " 1271 1287 1289 1296 1298 1304 1308 1320 1334 1340 1353 1378 1388 1445\n",
            " 1467 1472 1474 1475 1489 1508 1515 1516 1519 1531 1550 1555 1557 1563\n",
            " 1571 1580 1583 1593 1597 1615 1650 1671 1684 1686 1689 1700 1701 1702\n",
            " 1723 1736 1747 1766 1769 1773 1810 1828 1857 1862 1867 1879 1884 1933\n",
            " 1940 1942 1949 1950 1952 1957 1962 1979 1980 1984 1992 2011 2019 2036\n",
            " 2037 2053 2056 2064 2071 2097 2105 2107 2115 2144 2157 2171 2172 2185\n",
            " 2188 2209 2213 2237 2238 2241 2255 2260 2269 2272 2276 2278 2302 2326\n",
            " 2341 2393 2399 2403 2405 2418 2423 2441 2451 2461 2466 2479 2483 2489\n",
            " 2491 2509 2533 2536 2550 2552 2562 2572 2603 2620 2633 2645 2660 2679\n",
            " 2692 2704 2770 2786 2795 2833 2842 2865 2869 2871 2872 2889 2908 2936\n",
            " 2958 3009 3010 3029 3033 3034 3043 3072 3086 3090 3091 3094 3099 3113\n",
            " 3114 3138 3139 3145 3171 3216 3230 3251 3266 3269 3319 3334 3350 3356\n",
            " 3359 3400 3431 3482 3492 3494 3526 3545 3567 3591 3600 3618 3624 3675\n",
            " 3685 3732 3733 3781 3811 3830 3843 3919 3932 3960 3968 3988 4001 4012\n",
            " 4013 4016 4036 4098 4102 4123 4166 4267 4373 4435 4465 4479 4562 4567\n",
            " 4609 4615 4709 4725 4780 4789 4808 4813 4851 4859 4877 5067 5084 5213\n",
            " 5220 5227 5234 5237 5240 5301 5309 5311 5347 5378 5440 5442 5506 5628\n",
            " 5644 5673 5709 5725 5726 5797 5820 5825 5840 5858 5922 6019 6045 6055\n",
            " 6114 6152 6222 6286 6367 6379 6391 6481 6559 6620 6692 6742 6749 6772\n",
            " 6806 6876 6882 6918 6926 6928 6945 6962 6968 6978 6992 6997 7081 7097\n",
            " 7111 7126 7128 7139 7166 7210 7227 7231 7249 7294 7297 7320 7397 7402\n",
            " 7433 7455 7457 7492 7532 7539 7586 7730 7738 7775 7836 7943 7983 8009\n",
            " 8051 8186 8290 8307 8476 8490 8499 8524 8690 8701 8723 8938 8981 8983\n",
            " 9028 9258 9282 9372 9465 9595 9671 9692 9755]\n",
            "\n",
            "499 [0.5003511  0.52248204 0.50784427 0.50191045 0.5057217  0.5048611\n",
            " 0.50451064 0.5039963  0.509949   0.5020125  0.5027646  0.5010643\n",
            " 0.5022977  0.5021906  0.5024378  0.50260496 0.5020971  0.5164497\n",
            " 0.50408435 0.50168    0.5068371  0.5028062  0.5048865  0.50117046\n",
            " 0.5003884  0.5025136  0.5028138  0.50133765 0.5030081  0.50470847\n",
            " 0.5055     0.50871474 0.5023006  0.5014946  0.50675607 0.5011072\n",
            " 0.5016996  0.5018122  0.5025067  0.5013677  0.50133723 0.5067313\n",
            " 0.5027823  0.5012851  0.5021433  0.5073786  0.5073692  0.50053626\n",
            " 0.5026247  0.50536674 0.5053073  0.50418335 0.50007397 0.5000084\n",
            " 0.5058769  0.5062603  0.5100016  0.5045754  0.501044   0.51017076\n",
            " 0.50104684 0.50578594 0.513232   0.5063866  0.5053521  0.5027292\n",
            " 0.51045257 0.50993836 0.5049929  0.51028883 0.50314444 0.5026871\n",
            " 0.5063198  0.5037849  0.50220287 0.5042706  0.5338774  0.5165382\n",
            " 0.5028768  0.5070117  0.50277925 0.5035427  0.51019454 0.5031667\n",
            " 0.5073112  0.5076562  0.50011355 0.5019239  0.5080432  0.50286573\n",
            " 0.5026484  0.50329924 0.5031065  0.50078833 0.50025135 0.5018161\n",
            " 0.50466675 0.51111573 0.5002238  0.5056728  0.503027   0.50159967\n",
            " 0.5016565  0.50640553 0.5018991  0.5060473  0.5023689  0.5017106\n",
            " 0.5051317  0.5034798  0.5044686  0.50603133 0.50975513 0.50053\n",
            " 0.50272375 0.5001502  0.5076552  0.51331276 0.50349104 0.50172275\n",
            " 0.50040615 0.50272894 0.5014006  0.50064915 0.5023373  0.5099846\n",
            " 0.5152363  0.509494   0.50127655 0.50588864 0.5073575  0.5114115\n",
            " 0.50101775 0.51804614 0.50017285 0.5008312  0.5047453  0.5074354\n",
            " 0.5058613  0.50231266 0.50519043 0.5067419  0.5027104  0.50537485\n",
            " 0.5033197  0.5011895  0.5045382  0.50516135 0.50429684 0.5053881\n",
            " 0.50654525 0.50639546 0.500511   0.5113807  0.50303376 0.50468665\n",
            " 0.50250125 0.5003006  0.5008098  0.5001686  0.50284076 0.50357056\n",
            " 0.50489    0.501008   0.5008789  0.5052995  0.501116   0.5003353\n",
            " 0.5227687  0.50267607 0.50279516 0.5034297  0.5006537  0.5026675\n",
            " 0.5042548  0.50348127 0.50075406 0.5010153  0.5016317  0.5021651\n",
            " 0.5007681  0.504919   0.5011431  0.50122833 0.5001213  0.50217646\n",
            " 0.50449264 0.50611395 0.503413   0.5017338  0.5059886  0.50228363\n",
            " 0.50436264 0.5012527  0.5003366  0.50488573 0.50229263 0.50039124\n",
            " 0.5028025  0.50042796 0.5088883  0.5022468  0.50371754 0.5067246\n",
            " 0.5056808  0.5080082  0.50017947 0.50166845 0.50234133 0.50694084\n",
            " 0.5014281  0.5004545  0.50666535 0.50012976 0.5010901  0.50532013\n",
            " 0.5049537  0.501482   0.5008749  0.5009867  0.50006473 0.50255376\n",
            " 0.50075465 0.5142077  0.5035889  0.5033696  0.5180875  0.50297505\n",
            " 0.5029536  0.5007569  0.5015399  0.50581276 0.5007272  0.5000616\n",
            " 0.5007575  0.5008069  0.5005511  0.50108254 0.5016802  0.50256294\n",
            " 0.5044535  0.50257367 0.5011153  0.50141895 0.50132126 0.5064769\n",
            " 0.5019719  0.50708884 0.5008176  0.50159174 0.5096441  0.5060774\n",
            " 0.500904   0.5012206  0.505403   0.50247496 0.5006065  0.50128055\n",
            " 0.5019138  0.50114095 0.5018933  0.50179833 0.5017493  0.5014772\n",
            " 0.5056648  0.5001841  0.501524   0.5017295  0.5005708  0.50076395\n",
            " 0.5004045  0.50109017 0.5013791  0.50073427 0.5036622  0.5016156\n",
            " 0.5105219  0.5173233  0.50286525 0.50399023 0.5004119  0.50244206\n",
            " 0.5026509  0.50363785 0.5039497  0.5003184  0.50167805 0.5008776\n",
            " 0.5028903  0.507734   0.5025961  0.50050765 0.50345844 0.5055035\n",
            " 0.5014045  0.50179446 0.5026105  0.5004396  0.50279456 0.50096923\n",
            " 0.50455225 0.5048195  0.5002355  0.50181985 0.5006636  0.50078875\n",
            " 0.501681   0.5031641  0.50439185 0.5027303  0.5014436  0.5019937\n",
            " 0.50033325 0.5024191  0.5046285  0.500464   0.5028169  0.50389045\n",
            " 0.5032875  0.5032902  0.5025971  0.5017341  0.5207647  0.50149924\n",
            " 0.50013566 0.5012895  0.5032843  0.50029504 0.50225574 0.501756\n",
            " 0.50262296 0.50022054 0.5002448  0.50361246 0.5010592  0.50252795\n",
            " 0.50381094 0.5024969  0.50079846 0.50357217 0.50142336 0.5016774\n",
            " 0.5019194  0.50274986 0.500615   0.506279   0.5004397  0.50329953\n",
            " 0.5027782  0.5014529  0.5018564  0.5005106  0.5017879  0.50016177\n",
            " 0.50219464 0.5054565  0.50021964 0.5024495  0.5043269  0.5014249\n",
            " 0.50286686 0.50046194 0.5001995  0.5059587  0.50059366 0.50557494\n",
            " 0.50212014 0.5003603  0.50139415 0.50347596 0.50072443 0.5061113\n",
            " 0.50204647 0.5003465  0.5116624  0.5028855  0.524247   0.5037081\n",
            " 0.5193527  0.50112814 0.5060504  0.5004221  0.5012994  0.500213\n",
            " 0.5004896  0.5013476  0.5050086  0.50244296 0.5004675  0.5015824\n",
            " 0.5054314  0.5011358  0.5054858  0.5062073  0.50075305 0.5022744\n",
            " 0.50322175 0.5274233  0.5006698  0.5264696  0.50023097 0.51189953\n",
            " 0.50091743 0.50145924 0.5023199  0.50187606 0.5017801  0.5009645\n",
            " 0.5002382  0.50354016 0.50336486 0.5009919  0.50129896 0.5011878\n",
            " 0.5007111  0.5004217  0.5009532  0.50176543 0.50515676 0.5005477\n",
            " 0.5052177  0.5005183  0.5002723  0.50106156 0.50115174 0.50006264\n",
            " 0.50409156 0.50152296 0.5009079  0.50010085 0.50152975 0.5001474\n",
            " 0.50032455 0.50444067 0.5045199  0.50385445 0.5017019  0.5006076\n",
            " 0.5015045  0.5013372  0.5041872  0.50187016 0.50622576 0.5030804\n",
            " 0.50161535 0.5055178  0.50123614 0.50154245 0.5003346  0.5025405\n",
            " 0.5020591  0.51689523 0.5072355  0.5002202  0.5159437  0.5063022\n",
            " 0.50137895 0.5026437  0.50030047 0.5032854  0.5010801  0.5014058\n",
            " 0.5016636  0.53518885 0.5007284  0.50276446 0.50244975 0.5012055\n",
            " 0.5067268  0.5056736  0.50070006 0.50376034 0.50869143 0.5006901\n",
            " 0.5000065  0.502742   0.50026447 0.50015754 0.5002711  0.50342256\n",
            " 0.50493324 0.5000145  0.5071388  0.5014634  0.5074262  0.50271624\n",
            " 0.5011228  0.5237212  0.5041998  0.50299394 0.5062647  0.5216545\n",
            " 0.5042311  0.5006895  0.503648   0.5021829  0.5013047  0.50121516\n",
            " 0.50419456]\n",
            "\n",
            "Matched draws\n",
            "Count: 12, Index: (array([ 203,  216,  450,  905, 1340, 1701, 2483, 2795, 3960, 5227, 7210,\n",
            "       7294]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106955  505820 2020-01-12  ConsolationNo2      203\n",
            "107125  506520 2020-01-26     SpecialNo10      203\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106858  505420 2020-01-04      1stPrizeNo      450\n",
            "106955  505820 2020-01-12  ConsolationNo2      203\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "107125  506520 2020-01-26     SpecialNo10      203\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106856  505320 2020-01-01      SpecialNo8     3960\n",
            "106858  505420 2020-01-04      1stPrizeNo      450\n",
            "106859  505420 2020-01-04      2ndPrizeNo     2483\n",
            "106863  505420 2020-01-04  ConsolationNo2     7294\n",
            "106917  505620 2020-01-08      SpecialNo1     5227\n",
            "106940  505720 2020-01-11      SpecialNo1     1701\n",
            "106955  505820 2020-01-12  ConsolationNo2      203\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "106965  505820 2020-01-12      SpecialNo2     1340\n",
            "107077  506320 2020-01-22  ConsolationNo9     7210\n",
            "107119  506520 2020-01-26  ConsolationNo5     2795\n",
            "107125  506520 2020-01-26     SpecialNo10      203\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "\n",
            "-----------2020-01-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(959893, 32) (959893,) (10000, 32) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 927839, 1: 32054})\n",
            "\n",
            "scale_pos_weight - 28.801391557995885\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.801391557995885, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.801391557995885]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.485, F-Score=0.06604\n",
            "\n",
            "Recall: 0.027190332326283987\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.96      0.03      0.96      0.16      0.03      9669\n",
            "          1       0.02      0.03      0.96      0.03      0.16      0.02       331\n",
            "\n",
            "avg / total       0.94      0.93      0.06      0.93      0.16      0.03     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0271903</td>\n",
              "      <td>0.962147</td>\n",
              "      <td>0.0141817</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity   Optimize\n",
              "XGBClassifier_optimize            0   0.0271903         0.962147  0.0141817"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 375 \n",
            "\n",
            "First 23 matches\n",
            "23 [ 19  28  33  35  42  52  54  72  83 113 131 151 152 163 193 197 201 203\n",
            " 210 216 219 226 249]\n",
            "\n",
            "[0.5208924  0.50371003 0.5009011  0.50481457 0.5034442  0.50377077\n",
            " 0.5031822  0.509309   0.5003178  0.5013561  0.5013985  0.50155133\n",
            " 0.50124687 0.5010411  0.5006539  0.5150473  0.50170785 0.5009562\n",
            " 0.506032   0.501982   0.5043334  0.500439   0.5015716 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[4465 5378  903 7227  197  905  594 8938 1949 4609 1271  592 3114 7455\n",
            " 7139   19 4562 9258 1933 5301  950 5311 2479]\n",
            "\n",
            "\n",
            "[0.5126108  0.5133835  0.5141157  0.5151518  0.5150473  0.512918\n",
            " 0.5152339  0.5206104  0.5202903  0.5207531  0.51935965 0.5344044\n",
            " 0.5246713  0.5374415  0.5174888  0.5208924  0.52488583 0.51919097\n",
            " 0.51812166 0.5249315  0.5166281  0.5274575  0.5169565 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "118 [ 19  28  33  35  42  52  54  72  83 113 131 151 152 163 193 197 201 203\n",
            " 210 216 219 226 249 270 272 279 282 283 291 298 314 317 323 328 330 363\n",
            " 382 384 385 391 392 430 431 437 446 479 495 496 498 507 519 535 537 538\n",
            " 544 546 557 559 567 568 569 575 581 586 591 592 594 603 604 607 613 616\n",
            " 622 623 628 630 637 641 649 650 657 661 691 706 708 716 720 736 743 744\n",
            " 757 769 771 799 802 803 806 810 817 823 854 859 862 874 877 892 895 903\n",
            " 905 921 922 923 925 950 961 963 974 987]\n",
            "\n",
            "[0.5208924  0.50371003 0.5009011  0.50481457 0.5034442  0.50377077\n",
            " 0.5031822  0.509309   0.5003178  0.5013561  0.5013985  0.50155133\n",
            " 0.50124687 0.5010411  0.5006539  0.5150473  0.50170785 0.5009562\n",
            " 0.506032   0.501982   0.5043334  0.500439   0.5015716  0.50159883\n",
            " 0.5022111  0.5038923  0.504449   0.50771487 0.5011544  0.5004811\n",
            " 0.50575864 0.500232   0.5001808  0.50058156 0.50103235 0.50567466\n",
            " 0.5014824  0.5002452  0.5011541  0.50596035 0.5059715  0.50144887\n",
            " 0.5046103  0.504766   0.50334567 0.5046209  0.5052593  0.5091043\n",
            " 0.50322807 0.5094199  0.50455624 0.51147896 0.5047083  0.504067\n",
            " 0.5010231  0.50881594 0.5085633  0.50382066 0.5090136  0.50163805\n",
            " 0.50165755 0.5052733  0.50240266 0.50093645 0.5028679  0.5344044\n",
            " 0.5152339  0.50135845 0.5058914  0.5028552  0.50128114 0.5027443\n",
            " 0.50942343 0.50216234 0.50605404 0.50706923 0.5004059  0.5068713\n",
            " 0.50180435 0.50117004 0.502546   0.5019055  0.50038487 0.50330186\n",
            " 0.510299   0.50454086 0.5021612  0.50086063 0.5055658  0.5009001\n",
            " 0.5050523  0.5006959  0.5004576  0.5042664  0.50237906 0.50312895\n",
            " 0.5039966  0.5086933  0.5017782  0.5091994  0.5118983  0.5025622\n",
            " 0.5007116  0.50180155 0.50067973 0.501408   0.50946414 0.5141157\n",
            " 0.512918   0.50058407 0.5047641  0.5061775  0.51021236 0.5166281\n",
            " 0.5018925  0.5058679  0.5047959  0.5013833 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5045319199562073\n",
            "\n",
            "100 [  19   35   72  197  210  283  314  363  391  392  431  437  479  495\n",
            "  496  507  519  535  537  546  557  567  575  592  594  604  622  628\n",
            "  630  641  708  716  743  757  810  823  854  895  903  905  922  923\n",
            "  925  950  963  974 1017 1090 1112 1115 1124 1271 1508 1519 1597 1671\n",
            " 1684 1686 1747 1933 1949 1979 2107 2144 2172 2185 2213 2302 2466 2479\n",
            " 2620 2679 3114 3591 3830 4012 4016 4267 4465 4562 4609 4709 5227 5301\n",
            " 5311 5378 6114 6968 7139 7166 7227 7231 7455 7730 7836 8499 8690 8938\n",
            " 9028 9258]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5037940144538879\n",
            "\n",
            "122 [  19   35   72  197  210  219  279  282  283  314  363  391  392  431\n",
            "  437  479  495  496  507  519  535  537  538  546  557  559  567  575\n",
            "  592  594  604  622  628  630  641  708  716  743  757  799  806  810\n",
            "  823  854  895  903  905  922  923  925  950  963  974 1009 1017 1047\n",
            " 1090 1112 1115 1124 1231 1255 1271 1508 1519 1563 1597 1671 1684 1686\n",
            " 1747 1773 1933 1949 1979 2107 2144 2172 2185 2213 2302 2466 2479 2536\n",
            " 2620 2679 2865 3114 3591 3830 4012 4016 4267 4465 4562 4609 4709 4851\n",
            " 5084 5220 5227 5301 5311 5378 6045 6114 6968 6997 7139 7166 7227 7231\n",
            " 7455 7586 7730 7836 8476 8499 8690 8938 9028 9258]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "375 [  19   28   33   35   42   52   54   72   83  113  131  151  152  163\n",
            "  193  197  201  203  210  216  219  226  249  270  272  279  282  283\n",
            "  291  298  314  317  323  328  330  363  382  384  385  391  392  430\n",
            "  431  437  446  479  495  496  498  507  519  535  537  538  544  546\n",
            "  557  559  567  568  569  575  581  586  591  592  594  603  604  607\n",
            "  613  616  622  623  628  630  637  641  649  650  657  661  691  706\n",
            "  708  716  720  736  743  744  757  769  771  799  802  803  806  810\n",
            "  817  823  854  859  862  874  877  892  895  903  905  921  922  923\n",
            "  925  950  961  963  974  987 1009 1017 1039 1047 1050 1064 1085 1088\n",
            " 1090 1112 1115 1124 1126 1152 1156 1198 1216 1231 1253 1255 1257 1271\n",
            " 1287 1289 1296 1304 1308 1320 1353 1378 1388 1445 1467 1472 1475 1489\n",
            " 1508 1515 1516 1519 1531 1550 1555 1563 1571 1583 1597 1615 1650 1671\n",
            " 1684 1686 1700 1701 1702 1747 1773 1810 1862 1879 1933 1940 1942 1949\n",
            " 1950 1952 1957 1962 1979 2036 2053 2056 2064 2071 2097 2105 2107 2115\n",
            " 2144 2171 2172 2185 2209 2213 2237 2241 2255 2260 2269 2272 2276 2278\n",
            " 2302 2341 2393 2418 2423 2451 2461 2466 2479 2483 2489 2509 2533 2536\n",
            " 2550 2562 2603 2620 2633 2660 2679 2704 2770 2795 2842 2865 2871 2889\n",
            " 2908 2936 2958 3009 3010 3029 3034 3043 3086 3090 3091 3094 3099 3113\n",
            " 3114 3138 3171 3230 3266 3334 3356 3359 3400 3482 3492 3494 3526 3545\n",
            " 3591 3618 3624 3675 3685 3733 3811 3830 3919 3932 3960 3968 3988 4012\n",
            " 4016 4036 4102 4123 4267 4373 4465 4479 4562 4567 4609 4615 4709 4780\n",
            " 4851 4859 5067 5084 5220 5227 5237 5240 5301 5311 5378 5442 5506 5628\n",
            " 5644 5673 5725 5726 5820 5840 6019 6045 6114 6152 6286 6367 6391 6481\n",
            " 6692 6749 6772 6806 6876 6882 6926 6928 6945 6962 6968 6978 6992 6997\n",
            " 7081 7097 7126 7128 7139 7166 7227 7231 7249 7294 7320 7397 7402 7455\n",
            " 7492 7532 7586 7730 7775 7836 8009 8307 8476 8499 8524 8690 8701 8723\n",
            " 8938 8981 8983 9028 9258 9282 9465 9595 9671 9755 9963]\n",
            "\n",
            "375 [0.5208924  0.50371003 0.5009011  0.50481457 0.5034442  0.50377077\n",
            " 0.5031822  0.509309   0.5003178  0.5013561  0.5013985  0.50155133\n",
            " 0.50124687 0.5010411  0.5006539  0.5150473  0.50170785 0.5009562\n",
            " 0.506032   0.501982   0.5043334  0.500439   0.5015716  0.50159883\n",
            " 0.5022111  0.5038923  0.504449   0.50771487 0.5011544  0.5004811\n",
            " 0.50575864 0.500232   0.5001808  0.50058156 0.50103235 0.50567466\n",
            " 0.5014824  0.5002452  0.5011541  0.50596035 0.5059715  0.50144887\n",
            " 0.5046103  0.504766   0.50334567 0.5046209  0.5052593  0.5091043\n",
            " 0.50322807 0.5094199  0.50455624 0.51147896 0.5047083  0.504067\n",
            " 0.5010231  0.50881594 0.5085633  0.50382066 0.5090136  0.50163805\n",
            " 0.50165755 0.5052733  0.50240266 0.50093645 0.5028679  0.5344044\n",
            " 0.5152339  0.50135845 0.5058914  0.5028552  0.50128114 0.5027443\n",
            " 0.50942343 0.50216234 0.50605404 0.50706923 0.5004059  0.5068713\n",
            " 0.50180435 0.50117004 0.502546   0.5019055  0.50038487 0.50330186\n",
            " 0.510299   0.50454086 0.5021612  0.50086063 0.5055658  0.5009001\n",
            " 0.5050523  0.5006959  0.5004576  0.5042664  0.50237906 0.50312895\n",
            " 0.5039966  0.5086933  0.5017782  0.5091994  0.5118983  0.5025622\n",
            " 0.5007116  0.50180155 0.50067973 0.501408   0.50946414 0.5141157\n",
            " 0.512918   0.50058407 0.5047641  0.5061775  0.51021236 0.5166281\n",
            " 0.5018925  0.5058679  0.5047959  0.5013833  0.50383955 0.50508887\n",
            " 0.5013474  0.5038259  0.5024978  0.5035435  0.5036628  0.50252366\n",
            " 0.5049769  0.50554293 0.505491   0.50987816 0.50238    0.50334066\n",
            " 0.5005416  0.5017307  0.502547   0.5040707  0.5005744  0.5040266\n",
            " 0.50018954 0.51935965 0.501679   0.501818   0.5023443  0.50154996\n",
            " 0.5029875  0.5026027  0.5007483  0.50113046 0.5000527  0.50371826\n",
            " 0.5003395  0.5001729  0.50085074 0.50285494 0.5053626  0.5017578\n",
            " 0.5006994  0.50475484 0.5009029  0.50290614 0.50025076 0.50388765\n",
            " 0.5011605  0.50187254 0.50806195 0.5012509  0.50226253 0.50585353\n",
            " 0.5048212  0.5065137  0.5004082  0.5009939  0.5018299  0.5056101\n",
            " 0.50422704 0.50343204 0.50043064 0.5008774  0.51812166 0.5025096\n",
            " 0.5019995  0.5202903  0.5022635  0.501947   0.5001618  0.50101244\n",
            " 0.50453824 0.5001285  0.5015007  0.50342363 0.50174445 0.5001985\n",
            " 0.5004917  0.500319   0.5047154  0.5006814  0.5062895  0.50066227\n",
            " 0.5085583  0.50488067 0.50058866 0.50478476 0.50177455 0.50020254\n",
            " 0.50029546 0.5001197  0.5007192  0.50100845 0.5008955  0.50022626\n",
            " 0.50507    0.5005873  0.5007892  0.50019145 0.50030524 0.50233066\n",
            " 0.50053483 0.5094245  0.5169565  0.50232726 0.5026773  0.50124454\n",
            " 0.50141364 0.50385934 0.5028141  0.50033784 0.5020246  0.50700694\n",
            " 0.5013059  0.50252384 0.5045611  0.501002   0.5020695  0.50227773\n",
            " 0.5036313  0.5039757  0.5009377  0.50004685 0.5004039  0.5021096\n",
            " 0.5033433  0.5017893  0.5005507  0.501278   0.5013732  0.5036871\n",
            " 0.50231296 0.50326025 0.50233626 0.5019034  0.50198954 0.5006104\n",
            " 0.5246713  0.5003793  0.50292176 0.5013673  0.501742   0.50279784\n",
            " 0.50166833 0.5031336  0.5017158  0.50251013 0.50072813 0.5004999\n",
            " 0.50050914 0.5019523  0.5077007  0.5025928  0.5015863  0.500567\n",
            " 0.5003971  0.50082415 0.5011342  0.50457436 0.50171727 0.5031933\n",
            " 0.50038326 0.5019928  0.50012714 0.50470686 0.5047017  0.50105387\n",
            " 0.50055957 0.5026122  0.5054487  0.50101966 0.5126108  0.5018351\n",
            " 0.52488583 0.5018877  0.5207531  0.5000492  0.50519377 0.5000245\n",
            " 0.5039525  0.5012966  0.50063324 0.5043536  0.5039279  0.5048427\n",
            " 0.50123256 0.50228953 0.5249315  0.5274575  0.5133835  0.5004126\n",
            " 0.5011394  0.50037235 0.5006923  0.5004339  0.5028482  0.5023446\n",
            " 0.50076216 0.5002538  0.5002658  0.50415635 0.50578    0.50000864\n",
            " 0.50059146 0.50004053 0.5034575  0.5004191  0.50063336 0.50013435\n",
            " 0.503701   0.5035204  0.50301296 0.5009696  0.50055474 0.500317\n",
            " 0.5031422  0.5009961  0.50532    0.50211936 0.50074035 0.5045023\n",
            " 0.50086814 0.5003858  0.50077945 0.50120574 0.5174888  0.50623494\n",
            " 0.5151518  0.505223   0.5007531  0.50153404 0.5026664  0.500392\n",
            " 0.50020796 0.5374415  0.50200987 0.50152075 0.5038758  0.50494486\n",
            " 0.5025541  0.50837976 0.50169003 0.5025439  0.5038483  0.5056593\n",
            " 0.50029343 0.5064307  0.50065726 0.50008935 0.5206104  0.5022925\n",
            " 0.5020866  0.5054212  0.51919097 0.5030726  0.5025972  0.50098133\n",
            " 0.5002237  0.5031458  0.5006718 ]\n",
            "\n",
            "Matched draws\n",
            "Count: 9, Index: (array([ 203,  216,  905, 1701, 2483, 2795, 3960, 5227, 7294]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106955  505820 2020-01-12  ConsolationNo2      203\n",
            "107125  506520 2020-01-26     SpecialNo10      203\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106955  505820 2020-01-12  ConsolationNo2      203\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "107125  506520 2020-01-26     SpecialNo10      203\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106856  505320 2020-01-01      SpecialNo8     3960\n",
            "106859  505420 2020-01-04      2ndPrizeNo     2483\n",
            "106863  505420 2020-01-04  ConsolationNo2     7294\n",
            "106917  505620 2020-01-08      SpecialNo1     5227\n",
            "106940  505720 2020-01-11      SpecialNo1     1701\n",
            "106955  505820 2020-01-12  ConsolationNo2      203\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "107119  506520 2020-01-26  ConsolationNo5     2795\n",
            "107125  506520 2020-01-26     SpecialNo10      203\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "\n",
            "-----------2020-01-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(959893, 32) (959893,) (10000, 32) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 927839, 1: 32054})\n",
            "\n",
            "scale_pos_weight - 28.656660947151682\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.656660947151682, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.656660947151682]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.482, F-Score=0.06649\n",
            "\n",
            "Recall: 0.015105740181268883\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.97      0.02      0.97      0.12      0.02      9669\n",
            "          1       0.02      0.02      0.97      0.02      0.12      0.01       331\n",
            "\n",
            "avg / total       0.94      0.94      0.05      0.94      0.12      0.02     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJetrQW2GAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0151057</td>\n",
              "      <td>0.973834</td>\n",
              "      <td>0.00685137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity    Optimize\n",
              "XGBClassifier_optimize            0   0.0151057         0.973834  0.00685137"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 258 \n",
            "\n",
            "First 23 matches\n",
            "23 [ 19  28  35  42  52  54  72 113 152 197 201 210 216 219 249 270 272 279\n",
            " 282 283 298 314 330]\n",
            "\n",
            "[0.5178021  0.5057159  0.5040405  0.50267875 0.5020859  0.50188416\n",
            " 0.5071768  0.50000155 0.5003944  0.5133653  0.5015625  0.50489426\n",
            " 0.5002662  0.5024615  0.5000925  0.50007343 0.50186974 0.5019643\n",
            " 0.5030235  0.506222   0.5002846  0.50455004 0.5004196 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[5378  535  854  197  594 2479  903 7227 1933  950 5311 1949 8938 5301\n",
            "   19 4562 7139 3114 7455 9258 4609  592 1271]\n",
            "\n",
            "\n",
            "[0.51019084 0.5109425  0.51089174 0.5133653  0.51351005 0.5140539\n",
            " 0.513437   0.5136773  0.51229525 0.51466566 0.5256218  0.5148112\n",
            " 0.52253336 0.52655876 0.5178021  0.5217278  0.5151085  0.51826227\n",
            " 0.5345649  0.51916385 0.51684016 0.529571   0.51946455]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "94 [ 19  28  35  42  52  54  72 113 152 197 201 210 216 219 249 270 272 279\n",
            " 282 283 298 314 330 363 382 391 392 430 431 437 446 479 495 496 498 507\n",
            " 519 535 537 538 544 546 557 559 567 568 569 575 581 586 591 592 594 603\n",
            " 604 613 616 622 623 628 630 637 641 649 650 657 661 706 708 716 720 743\n",
            " 757 769 799 802 803 806 810 817 823 854 859 874 895 903 905 922 923 925\n",
            " 950 961 963 974]\n",
            "\n",
            "[0.5178021  0.5057159  0.5040405  0.50267875 0.5020859  0.50188416\n",
            " 0.5071768  0.50000155 0.5003944  0.5133653  0.5015625  0.50489426\n",
            " 0.5002662  0.5024615  0.5000925  0.50007343 0.50186974 0.5019643\n",
            " 0.5030235  0.506222   0.5002846  0.50455004 0.5004196  0.50439125\n",
            " 0.50048304 0.50474036 0.5046376  0.50059617 0.5029836  0.5029693\n",
            " 0.50195473 0.5042605  0.5041284  0.5081979  0.5018439  0.50802344\n",
            " 0.503517   0.5109425  0.50364786 0.5029257  0.50008243 0.50766706\n",
            " 0.5078519  0.50234133 0.50779617 0.5004114  0.50042486 0.50383776\n",
            " 0.5006883  0.5000874  0.501733   0.529571   0.51351005 0.50071543\n",
            " 0.5042769  0.5001153  0.5008952  0.5096441  0.50116307 0.504527\n",
            " 0.50483906 0.50030565 0.50566024 0.50050735 0.50054485 0.500947\n",
            " 0.50302285 0.5019991  0.5081618  0.50332075 0.5007363  0.50404227\n",
            " 0.50369644 0.5005674  0.50312835 0.5009885  0.50285476 0.5036975\n",
            " 0.50799465 0.5003988  0.50516015 0.51089174 0.50113744 0.50024575\n",
            " 0.508036   0.513437   0.5069975  0.5034802  0.5046166  0.50955987\n",
            " 0.51466566 0.5019271  0.5047838  0.5041229 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5042222142219543\n",
            "\n",
            "68 [  19   28   72  197  210  283  314  363  391  392  479  496  507  535\n",
            "  546  557  567  592  594  604  622  628  630  641  708  810  823  854\n",
            "  895  903  905  923  925  950  963 1124 1271 1597 1671 1686 1702 1933\n",
            " 1949 2144 2172 2185 2466 2479 2620 3114 4465 4562 4609 4851 5301 5311\n",
            " 5378 7139 7166 7227 7231 7455 7586 7836 8690 8938 9028 9258]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5038893222808838\n",
            "\n",
            "81 [  19   28   35   72  197  210  283  314  363  391  392  479  495  496\n",
            "  507  535  546  557  567  592  594  604  622  628  630  641  708  743\n",
            "  810  823  854  895  903  905  923  925  950  963  974 1017 1112 1124\n",
            " 1271 1519 1597 1671 1686 1702 1747 1933 1949 2107 2144 2172 2185 2466\n",
            " 2479 2620 3114 4267 4465 4562 4609 4851 5084 5301 5311 5378 6968 7139\n",
            " 7166 7227 7231 7455 7586 7730 7836 8690 8938 9028 9258]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "258 [  19   28   35   42   52   54   72  113  152  197  201  210  216  219\n",
            "  249  270  272  279  282  283  298  314  330  363  382  391  392  430\n",
            "  431  437  446  479  495  496  498  507  519  535  537  538  544  546\n",
            "  557  559  567  568  569  575  581  586  591  592  594  603  604  613\n",
            "  616  622  623  628  630  637  641  649  650  657  661  706  708  716\n",
            "  720  743  757  769  799  802  803  806  810  817  823  854  859  874\n",
            "  895  903  905  922  923  925  950  961  963  974 1009 1017 1039 1047\n",
            " 1050 1064 1085 1088 1090 1112 1115 1124 1126 1152 1198 1216 1231 1255\n",
            " 1271 1287 1289 1296 1308 1320 1378 1445 1489 1508 1515 1519 1550 1563\n",
            " 1583 1597 1650 1671 1684 1686 1702 1747 1773 1810 1933 1940 1942 1949\n",
            " 1950 1952 1979 2011 2053 2056 2107 2144 2172 2185 2213 2237 2272 2302\n",
            " 2393 2451 2466 2479 2483 2489 2533 2536 2550 2603 2620 2633 2660 2679\n",
            " 2770 2795 2842 2865 2936 2958 3009 3029 3043 3086 3090 3091 3094 3099\n",
            " 3114 3171 3266 3334 3359 3482 3545 3591 3618 3624 3685 3811 3830 3932\n",
            " 3968 4012 4016 4123 4267 4465 4479 4562 4567 4609 4709 4851 4859 5084\n",
            " 5220 5227 5240 5301 5311 5378 5644 5725 5726 6045 6114 6391 6772 6806\n",
            " 6876 6945 6968 6978 6997 7128 7139 7166 7227 7231 7320 7402 7455 7492\n",
            " 7532 7586 7730 7775 7836 8009 8307 8476 8499 8690 8701 8938 8981 8983\n",
            " 9028 9258 9282 9465 9595 9755]\n",
            "\n",
            "258 [0.5178021  0.5057159  0.5040405  0.50267875 0.5020859  0.50188416\n",
            " 0.5071768  0.50000155 0.5003944  0.5133653  0.5015625  0.50489426\n",
            " 0.5002662  0.5024615  0.5000925  0.50007343 0.50186974 0.5019643\n",
            " 0.5030235  0.506222   0.5002846  0.50455004 0.5004196  0.50439125\n",
            " 0.50048304 0.50474036 0.5046376  0.50059617 0.5029836  0.5029693\n",
            " 0.50195473 0.5042605  0.5041284  0.5081979  0.5018439  0.50802344\n",
            " 0.503517   0.5109425  0.50364786 0.5029257  0.50008243 0.50766706\n",
            " 0.5078519  0.50234133 0.50779617 0.5004114  0.50042486 0.50383776\n",
            " 0.5006883  0.5000874  0.501733   0.529571   0.51351005 0.50071543\n",
            " 0.5042769  0.5001153  0.5008952  0.5096441  0.50116307 0.504527\n",
            " 0.50483906 0.50030565 0.50566024 0.50050735 0.50054485 0.500947\n",
            " 0.50302285 0.5019991  0.5081618  0.50332075 0.5007363  0.50404227\n",
            " 0.50369644 0.5005674  0.50312835 0.5009885  0.50285476 0.5036975\n",
            " 0.50799465 0.5003988  0.50516015 0.51089174 0.50113744 0.50024575\n",
            " 0.508036   0.513437   0.5069975  0.5034802  0.5046166  0.50955987\n",
            " 0.51466566 0.5019271  0.5047838  0.5041229  0.50345045 0.50396913\n",
            " 0.5004058  0.5032586  0.50090486 0.5021733  0.5021807  0.5020888\n",
            " 0.503182   0.50401413 0.5036563  0.50747246 0.50030226 0.50189996\n",
            " 0.50010556 0.5017693  0.50236124 0.5028636  0.51946455 0.50030845\n",
            " 0.5003916  0.5007621  0.5017124  0.50093544 0.5013879  0.5021804\n",
            " 0.5019474  0.5033867  0.5006028  0.504054   0.50161576 0.5025213\n",
            " 0.5004302  0.5061326  0.5017419  0.5047655  0.5030751  0.5057933\n",
            " 0.5042396  0.50407046 0.50270563 0.50237346 0.51229525 0.50128734\n",
            " 0.50083905 0.5148112  0.5003552  0.5004266  0.50357586 0.50008684\n",
            " 0.50038224 0.5016583  0.50412    0.50440186 0.50695556 0.5042631\n",
            " 0.5034188  0.5004579  0.50047535 0.5033895  0.50001854 0.5019125\n",
            " 0.50833356 0.5140539  0.50053626 0.50158    0.500472   0.5016265\n",
            " 0.5022609  0.50027627 0.5061431  0.50065166 0.50103474 0.50324386\n",
            " 0.5000195  0.50010943 0.50193983 0.5030293  0.5005485  0.50178456\n",
            " 0.5004138  0.50029695 0.50231457 0.50030595 0.5012727  0.5006744\n",
            " 0.50068974 0.50030655 0.51826227 0.50070673 0.50101143 0.5018692\n",
            " 0.50219923 0.50102866 0.500917   0.5038212  0.5008042  0.50008404\n",
            " 0.50040704 0.5000184  0.5031789  0.50190306 0.5002509  0.50334597\n",
            " 0.5029621  0.50085914 0.50389016 0.50901467 0.5002712  0.5217278\n",
            " 0.50075066 0.51684016 0.503485   0.5045918  0.5004202  0.5041025\n",
            " 0.50350195 0.5035145  0.5005405  0.52655876 0.5256218  0.51019084\n",
            " 0.50136846 0.50092804 0.5006612  0.5032533  0.502907   0.501709\n",
            " 0.5018654  0.5028891  0.5019396  0.5016751  0.5041509  0.50107825\n",
            " 0.50349677 0.50049525 0.5151085  0.50522316 0.5136773  0.50496334\n",
            " 0.50126636 0.50000536 0.5345649  0.50008327 0.5014419  0.504249\n",
            " 0.5040612  0.5010641  0.50603974 0.50027376 0.5018871  0.50244886\n",
            " 0.50245106 0.5052669  0.50073725 0.52253336 0.5017272  0.50091827\n",
            " 0.5042398  0.51916385 0.501657   0.50096625 0.50027394 0.5014964 ]\n",
            "\n",
            "Matched draws\n",
            "Count: 5, Index: (array([ 216,  905, 2483, 2795, 5227]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106859  505420 2020-01-04      2ndPrizeNo     2483\n",
            "106917  505620 2020-01-08      SpecialNo1     5227\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "107119  506520 2020-01-26  ConsolationNo5     2795\n",
            "107163  506720 2020-01-29  ConsolationNo3      216\n",
            "\n",
            "-----------2020-01-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(959893, 32) (959893,) (10000, 32) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 927839, 1: 32054})\n",
            "\n",
            "scale_pos_weight - 28.511930336307483\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.511930336307483, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.511930336307483]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.482, F-Score=0.06573\n",
            "\n",
            "Recall: 0.006042296072507553\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.98      0.01      0.97      0.08      0.01      9669\n",
            "          1       0.01      0.01      0.98      0.01      0.08      0.01       331\n",
            "\n",
            "avg / total       0.93      0.95      0.04      0.94      0.08      0.01     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAGALQQIAsIUgAQDY8j/iFhhWCZgy2QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0060423</td>\n",
              "      <td>0.98128</td>\n",
              "      <td>0.00108991</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity    Optimize\n",
              "XGBClassifier_optimize            0   0.0060423          0.98128  0.00108991"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 183 \n",
            "\n",
            "First 23 matches\n",
            "23 [ 19  28  35  42  52  54  72 197 201 210 219 272 279 282 283 298 314 363\n",
            " 391 392 431 437 479]\n",
            "\n",
            "[0.5172349  0.5041952  0.5025538  0.50170386 0.5017232  0.50038844\n",
            " 0.5060683  0.5124804  0.5004314  0.5038299  0.5016818  0.50088596\n",
            " 0.501189   0.5020393  0.5052915  0.5008488  0.50390685 0.5032749\n",
            " 0.5037911  0.50315344 0.5016056  0.5014051  0.50296694]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[ 854  925 5378  592  903  950 7227 7139 4609 7455 1949 3114 2479 9258\n",
            " 4562   19 1933 8938 5301 1271  197 5311  594]\n",
            "\n",
            "\n",
            "[0.5093708  0.50986004 0.51102954 0.5316363  0.51206595 0.5146445\n",
            " 0.51265544 0.51196206 0.5176959  0.5294881  0.5166245  0.5188239\n",
            " 0.513486   0.5165518  0.5224785  0.5172349  0.5144812  0.5197915\n",
            " 0.5227097  0.5173102  0.5124804  0.5213798  0.51391083]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "67 [ 19  28  35  42  52  54  72 197 201 210 219 272 279 282 283 298 314 363\n",
            " 391 392 431 437 479 495 496 498 507 519 535 537 538 546 557 559 567 575\n",
            " 592 594 604 607 622 628 630 641 650 657 661 706 708 716 743 757 799 803\n",
            " 806 810 823 854 895 903 905 922 923 925 950 963 974]\n",
            "\n",
            "[0.5172349  0.5041952  0.5025538  0.50170386 0.5017232  0.50038844\n",
            " 0.5060683  0.5124804  0.5004314  0.5038299  0.5016818  0.50088596\n",
            " 0.501189   0.5020393  0.5052915  0.5008488  0.50390685 0.5032749\n",
            " 0.5037911  0.50315344 0.5016056  0.5014051  0.50296694 0.5030338\n",
            " 0.50639665 0.5007545  0.5065349  0.5022868  0.50928926 0.5032986\n",
            " 0.50156707 0.50695354 0.50663126 0.50235885 0.5066976  0.5016937\n",
            " 0.5316363  0.51391083 0.5036752  0.5002765  0.50843483 0.5039649\n",
            " 0.50342405 0.50473684 0.5008136  0.5003616  0.5029862  0.5007075\n",
            " 0.5055442  0.5019468  0.50271654 0.502587   0.50193375 0.5015588\n",
            " 0.5021908  0.50637424 0.5020453  0.5093708  0.5073901  0.51206595\n",
            " 0.50656414 0.5021971  0.50356895 0.50986004 0.5146445  0.503201\n",
            " 0.503341  ]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5046892166137695\n",
            "\n",
            "45 [  19   72  197  283  496  507  535  546  557  567  592  594  622  641\n",
            "  708  810  854  895  903  905  925  950 1124 1271 1597 1686 1933 1949\n",
            " 2172 2466 2479 2620 3114 4465 4562 4609 5301 5311 5378 7139 7227 7455\n",
            " 7836 8938 9258]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5043519139289856\n",
            "\n",
            "45 [  19   72  197  283  496  507  535  546  557  567  592  594  622  641\n",
            "  708  810  854  895  903  905  925  950 1124 1271 1597 1686 1933 1949\n",
            " 2172 2466 2479 2620 3114 4465 4562 4609 5301 5311 5378 7139 7227 7455\n",
            " 7836 8938 9258]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "183 [  19   28   35   42   52   54   72  197  201  210  219  272  279  282\n",
            "  283  298  314  363  391  392  431  437  479  495  496  498  507  519\n",
            "  535  537  538  546  557  559  567  575  592  594  604  607  622  628\n",
            "  630  641  650  657  661  706  708  716  743  757  799  803  806  810\n",
            "  823  854  895  903  905  922  923  925  950  963  974 1009 1017 1047\n",
            " 1064 1085 1088 1090 1112 1115 1124 1152 1216 1231 1255 1271 1308 1378\n",
            " 1445 1489 1508 1515 1519 1550 1563 1597 1650 1671 1684 1686 1702 1747\n",
            " 1773 1810 1933 1940 1949 1979 2011 2056 2107 2144 2172 2185 2213 2302\n",
            " 2451 2466 2479 2489 2536 2550 2620 2679 2842 2865 2958 3009 3043 3094\n",
            " 3114 3334 3359 3591 3618 3830 3932 4012 4016 4123 4267 4465 4562 4609\n",
            " 4709 4851 5084 5220 5227 5301 5311 5378 5644 5726 6045 6114 6391 6772\n",
            " 6806 6876 6945 6968 6978 6997 7128 7139 7166 7227 7231 7320 7455 7586\n",
            " 7730 7775 7836 8307 8476 8499 8690 8938 8981 9028 9258 9282 9465 9755\n",
            " 9963]\n",
            "\n",
            "183 [0.5172349  0.5041952  0.5025538  0.50170386 0.5017232  0.50038844\n",
            " 0.5060683  0.5124804  0.5004314  0.5038299  0.5016818  0.50088596\n",
            " 0.501189   0.5020393  0.5052915  0.5008488  0.50390685 0.5032749\n",
            " 0.5037911  0.50315344 0.5016056  0.5014051  0.50296694 0.5030338\n",
            " 0.50639665 0.5007545  0.5065349  0.5022868  0.50928926 0.5032986\n",
            " 0.50156707 0.50695354 0.50663126 0.50235885 0.5066976  0.5016937\n",
            " 0.5316363  0.51391083 0.5036752  0.5002765  0.50843483 0.5039649\n",
            " 0.50342405 0.50473684 0.5008136  0.5003616  0.5029862  0.5007075\n",
            " 0.5055442  0.5019468  0.50271654 0.502587   0.50193375 0.5015588\n",
            " 0.5021908  0.50637424 0.5020453  0.5093708  0.5073901  0.51206595\n",
            " 0.50656414 0.5021971  0.50356895 0.50986004 0.5146445  0.503201\n",
            " 0.503341   0.5018168  0.50351256 0.50311065 0.50080115 0.5008598\n",
            " 0.5009228  0.5018642  0.5036375  0.5026547  0.50924975 0.5009791\n",
            " 0.50080943 0.50197923 0.50135916 0.5173102  0.50144124 0.50145274\n",
            " 0.5009545  0.5014214  0.5024913  0.5003618  0.5040494  0.50057155\n",
            " 0.50057936 0.5049618  0.50208676 0.5037089  0.50218457 0.504945\n",
            " 0.5031109  0.50250715 0.50137717 0.50065684 0.5144812  0.50018954\n",
            " 0.5166245  0.5028142  0.5003128  0.5006639  0.50288403 0.50330025\n",
            " 0.506427   0.5028405  0.5017923  0.5022298  0.50054044 0.5074384\n",
            " 0.513486   0.500334   0.5013601  0.5005926  0.5053917  0.502305\n",
            " 0.50088936 0.50231594 0.50061536 0.5000215  0.5020339  0.50031805\n",
            " 0.5188239  0.5006004  0.50128365 0.503952   0.50011694 0.5023675\n",
            " 0.5017138  0.50228184 0.5018013  0.5000847  0.50270325 0.50897676\n",
            " 0.5224785  0.5176959  0.50244904 0.50293595 0.50267214 0.50170666\n",
            " 0.5024537  0.5227097  0.5213798  0.51102954 0.50137943 0.5005823\n",
            " 0.502278   0.5039891  0.5004285  0.5004427  0.5018367  0.5008874\n",
            " 0.5004439  0.50317764 0.5015133  0.50211865 0.50118715 0.51196206\n",
            " 0.5039869  0.51265544 0.5042055  0.500053   0.5294881  0.50357753\n",
            " 0.5030607  0.50000405 0.50624585 0.501549   0.50180423 0.5025565\n",
            " 0.5028186  0.5197915  0.5021451  0.50392926 0.5165518  0.5005929\n",
            " 0.500022   0.50056845 0.5002409 ]\n",
            "\n",
            "Matched draws\n",
            "Count: 2, Index: (array([ 905, 5227]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106917  505620 2020-01-08      SpecialNo1     5227\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "\n",
            "-----------2020-01-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(959893, 32) (959893,) (10000, 32) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 927839, 1: 32054})\n",
            "\n",
            "scale_pos_weight - 28.367199725463283\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.367199725463283, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.367199725463283]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.481, F-Score=0.06554\n",
            "\n",
            "Recall: 0.006042296072507553\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.99      0.01      0.98      0.08      0.01      9669\n",
            "          1       0.01      0.01      0.99      0.01      0.08      0.01       331\n",
            "\n",
            "avg / total       0.94      0.95      0.04      0.94      0.08      0.01     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0060423</td>\n",
              "      <td>0.985728</td>\n",
              "      <td>0.00197935</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity    Optimize\n",
              "XGBClassifier_optimize            0   0.0060423         0.985728  0.00197935"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 140 \n",
            "\n",
            "First 23 matches\n",
            "23 [ 19  28  35  42  52  72 197 210 219 279 282 283 314 363 391 392 431 437\n",
            " 479 495 496 507 519]\n",
            "\n",
            "[0.51618123 0.50308275 0.5014431  0.5005918  0.5006074  0.5049523\n",
            " 0.5113679  0.5027208  0.50056493 0.5000723  0.50092274 0.5041749\n",
            " 0.50279087 0.5021599  0.50267947 0.502037   0.50049233 0.5002931\n",
            " 0.5018502  0.50192004 0.5052848  0.50541884 0.501175  ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[ 854  925 5378 7139  903 7227  197 2479  594 1949 8938 1271 4609 1933\n",
            " 9258   19  950 3114 5311  592 5301 7455 4562]\n",
            "\n",
            "\n",
            "[0.50825685 0.5087481  0.5099732  0.510901   0.5109504  0.5115573\n",
            " 0.5113679  0.5123933  0.5128006  0.51554406 0.5187099  0.5162223\n",
            " 0.5165963  0.5133998  0.5154687  0.51618123 0.51355904 0.5177354\n",
            " 0.5202916  0.5305612  0.521624   0.52840465 0.52138585]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "58 [ 19  28  35  42  52  72 197 210 219 279 282 283 314 363 391 392 431 437\n",
            " 479 495 496 507 519 535 537 538 546 557 559 567 575 592 594 604 622 628\n",
            " 630 641 661 708 716 743 757 799 803 806 810 823 854 895 903 905 922 923\n",
            " 925 950 963 974]\n",
            "\n",
            "[0.51618123 0.50308275 0.5014431  0.5005918  0.5006074  0.5049523\n",
            " 0.5113679  0.5027208  0.50056493 0.5000723  0.50092274 0.5041749\n",
            " 0.50279087 0.5021599  0.50267947 0.502037   0.50049233 0.5002931\n",
            " 0.5018502  0.50192004 0.5052848  0.50541884 0.501175   0.5081756\n",
            " 0.50218236 0.50045127 0.50583935 0.5055153  0.50124854 0.5055812\n",
            " 0.500581   0.5305612  0.5128006  0.50255823 0.5073594  0.50285274\n",
            " 0.5023081  0.50362456 0.50187033 0.5044407  0.50083137 0.5016215\n",
            " 0.5014714  0.50081706 0.50044173 0.50107926 0.5052616  0.50098866\n",
            " 0.50825685 0.50627375 0.5109504  0.5055017  0.50108045 0.5024523\n",
            " 0.5087481  0.51355904 0.5020865  0.5022247 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5042134523391724\n",
            "\n",
            "41 [  19   72  197  496  507  535  546  557  567  592  594  622  708  810\n",
            "  854  895  903  905  925  950 1124 1271 1933 1949 2172 2466 2479 2620\n",
            " 3114 4465 4562 4609 5301 5311 5378 7139 7227 7455 7836 8938 9258]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5044214725494385\n",
            "\n",
            "40 [  19   72  197  496  507  535  546  557  567  592  594  622  708  810\n",
            "  854  895  903  905  925  950 1124 1271 1933 1949 2172 2466 2479 3114\n",
            " 4465 4562 4609 5301 5311 5378 7139 7227 7455 7836 8938 9258]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "140 [  19   28   35   42   52   72  197  210  219  279  282  283  314  363\n",
            "  391  392  431  437  479  495  496  507  519  535  537  538  546  557\n",
            "  559  567  575  592  594  604  622  628  630  641  661  708  716  743\n",
            "  757  799  803  806  810  823  854  895  903  905  922  923  925  950\n",
            "  963  974 1009 1017 1047 1090 1112 1115 1124 1231 1255 1271 1308 1378\n",
            " 1489 1508 1519 1597 1650 1671 1684 1686 1702 1747 1773 1933 1949 1979\n",
            " 2107 2144 2172 2185 2213 2302 2466 2479 2536 2620 2679 2865 3043 3114\n",
            " 3359 3591 3830 3932 4012 4016 4267 4465 4562 4609 4709 4851 5084 5220\n",
            " 5227 5301 5311 5378 5644 6045 6114 6806 6968 6978 6997 7128 7139 7166\n",
            " 7227 7231 7455 7586 7730 7836 8307 8476 8499 8690 8938 8981 9028 9258]\n",
            "\n",
            "140 [0.51618123 0.50308275 0.5014431  0.5005918  0.5006074  0.5049523\n",
            " 0.5113679  0.5027208  0.50056493 0.5000723  0.50092274 0.5041749\n",
            " 0.50279087 0.5021599  0.50267947 0.502037   0.50049233 0.5002931\n",
            " 0.5018502  0.50192004 0.5052848  0.50541884 0.501175   0.5081756\n",
            " 0.50218236 0.50045127 0.50583935 0.5055153  0.50124854 0.5055812\n",
            " 0.500581   0.5305612  0.5128006  0.50255823 0.5073594  0.50285274\n",
            " 0.5023081  0.50362456 0.50187033 0.5044407  0.50083137 0.5016215\n",
            " 0.5014714  0.50081706 0.50044173 0.50107926 0.5052616  0.50098866\n",
            " 0.50825685 0.50627375 0.5109504  0.5055017  0.50108045 0.5024523\n",
            " 0.5087481  0.51355904 0.5020865  0.5022247  0.50069994 0.5024\n",
            " 0.5020115  0.5007546  0.5025239  0.50153774 0.5081641  0.5008652\n",
            " 0.5002441  0.5162223  0.50032496 0.50034446 0.5003076  0.5013997\n",
            " 0.5029359  0.50384486 0.5009703  0.50259215 0.5010887  0.50385296\n",
            " 0.5019949  0.50139195 0.50026023 0.5133998  0.51554406 0.5016972\n",
            " 0.501768   0.50218314 0.505312   0.50172323 0.50067925 0.5011151\n",
            " 0.50632435 0.5123933  0.50025094 0.504293   0.5011894  0.5012002\n",
            " 0.50091887 0.5177354  0.5001667  0.5028721  0.501251   0.5005975\n",
            " 0.5011651  0.50068444 0.5015992  0.5078998  0.52138585 0.5165963\n",
            " 0.5013354  0.5018193  0.50156015 0.5005991  0.50133705 0.521624\n",
            " 0.5202916  0.5099732  0.5002633  0.5011622  0.50292414 0.5007218\n",
            " 0.50206083 0.50039655 0.5010018  0.5000725  0.510901   0.50287014\n",
            " 0.5115573  0.50308913 0.52840465 0.50249106 0.5019446  0.50515413\n",
            " 0.5004386  0.50069165 0.5014612  0.5017353  0.5187099  0.5010699\n",
            " 0.502813   0.5154687 ]\n",
            "\n",
            "Matched draws\n",
            "Count: 2, Index: (array([ 905, 5227]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106917  505620 2020-01-08      SpecialNo1     5227\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "\n",
            "-----------2020-01-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(959893, 32) (959893,) (10000, 32) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 927839, 1: 32054})\n",
            "\n",
            "scale_pos_weight - 28.22246911461908\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.22246911461908, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.22246911461908]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.479, F-Score=0.06564\n",
            "\n",
            "Recall: 0.006042296072507553\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.99      0.01      0.98      0.08      0.01      9669\n",
            "          1       0.02      0.01      0.99      0.01      0.08      0.01       331\n",
            "\n",
            "avg / total       0.94      0.96      0.04      0.95      0.08      0.01     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMAWggQAYMv/AlMjuodEMlp/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0060423</td>\n",
              "      <td>0.990485</td>\n",
              "      <td>0.00293085</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity    Optimize\n",
              "XGBClassifier_optimize            0   0.0060423         0.990485  0.00293085"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 94 \n",
            "\n",
            "First 23 matches\n",
            "23 [ 19  28  35  72 197 210 283 314 363 391 392 479 495 496 507 535 537 546\n",
            " 557 567 592 594 604]\n",
            "\n",
            "[0.51610625 0.501807   0.500277   0.5036504  0.51001096 0.5011061\n",
            " 0.5028043  0.501661   0.5011076  0.5014424  0.50087297 0.5005436\n",
            " 0.5006614  0.5041082  0.5041986  0.50701416 0.5009809  0.504601\n",
            " 0.5043028  0.5044412  0.52731055 0.5112852  0.501332  ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[ 925 4465 5378 7227  903  197  950 2479 7139 1933  594 1271 8938  592\n",
            " 4609   19 9258 5301 5311 4562 3114 7455 1949]\n",
            "\n",
            "\n",
            "[0.50722355 0.5073982  0.5074037  0.50898653 0.5097008  0.51001096\n",
            " 0.5107107  0.51079106 0.5110331  0.5111846  0.5112852  0.51606625\n",
            " 0.51853424 0.52731055 0.515261   0.51610625 0.51561344 0.5218922\n",
            " 0.52010936 0.51946586 0.5153743  0.5282456  0.5125302 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "42 [ 19  28  35  72 197 210 283 314 363 391 392 479 495 496 507 535 537 546\n",
            " 557 567 592 594 604 622 628 630 641 661 708 743 757 810 823 854 895 903\n",
            " 905 923 925 950 963 974]\n",
            "\n",
            "[0.51610625 0.501807   0.500277   0.5036504  0.51001096 0.5011061\n",
            " 0.5028043  0.501661   0.5011076  0.5014424  0.50087297 0.5005436\n",
            " 0.5006614  0.5041082  0.5041986  0.50701416 0.5009809  0.504601\n",
            " 0.5043028  0.5044412  0.52731055 0.5112852  0.501332   0.50645757\n",
            " 0.5016741  0.5009096  0.5022962  0.5008457  0.50293434 0.5003572\n",
            " 0.5004173  0.5042034  0.5022985  0.5069841  0.5050483  0.5097008\n",
            " 0.50468355 0.5012836  0.50722355 0.5107107  0.5007409  0.5009151 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5043168663978577\n",
            "\n",
            "32 [  19  197  535  546  567  592  594  622  854  895  903  905  925  950\n",
            " 1124 1271 1933 1949 2466 2479 3114 4465 4562 4609 5301 5311 5378 7139\n",
            " 7227 7455 8938 9258]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5050286054611206\n",
            "\n",
            "29 [  19  197  535  592  594  622  854  895  903  925  950 1124 1271 1933\n",
            " 1949 2466 2479 3114 4465 4562 4609 5301 5311 5378 7139 7227 7455 8938\n",
            " 9258]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "94 [  19   28   35   72  197  210  283  314  363  391  392  479  495  496\n",
            "  507  535  537  546  557  567  592  594  604  622  628  630  641  661\n",
            "  708  743  757  810  823  854  895  903  905  923  925  950  963  974\n",
            " 1017 1047 1112 1115 1124 1271 1508 1519 1597 1650 1671 1686 1702 1933\n",
            " 1949 1979 2107 2144 2172 2185 2466 2479 2620 2679 2865 3114 3591 3830\n",
            " 4267 4465 4562 4609 4851 5084 5227 5301 5311 5378 6114 6968 7139 7166\n",
            " 7227 7231 7455 7586 7730 7836 8690 8938 9028 9258]\n",
            "\n",
            "94 [0.51610625 0.501807   0.500277   0.5036504  0.51001096 0.5011061\n",
            " 0.5028043  0.501661   0.5011076  0.5014424  0.50087297 0.5005436\n",
            " 0.5006614  0.5041082  0.5041986  0.50701416 0.5009809  0.504601\n",
            " 0.5043028  0.5044412  0.52731055 0.5112852  0.501332   0.50645757\n",
            " 0.5016741  0.5009096  0.5022962  0.5008457  0.50293434 0.5003572\n",
            " 0.5004173  0.5042034  0.5022985  0.5069841  0.5050483  0.5097008\n",
            " 0.50468355 0.5012836  0.50722355 0.5107107  0.5007409  0.5009151\n",
            " 0.5010311  0.50150394 0.50122815 0.50030744 0.50531536 0.51606625\n",
            " 0.5003371  0.50193447 0.5025842  0.5000659  0.50142735 0.50253826\n",
            " 0.5007247  0.5111846  0.5125302  0.50046146 0.5004981  0.50089955\n",
            " 0.5040395  0.5007064  0.50531405 0.51079106 0.5030267  0.500171\n",
            " 0.50006235 0.5153743  0.50205845 0.5000795  0.5002242  0.5073982\n",
            " 0.51946586 0.515261   0.50060344 0.50040615 0.50012124 0.5218922\n",
            " 0.52010936 0.5074037  0.50022763 0.5009149  0.5110331  0.50161415\n",
            " 0.50898653 0.5016251  0.5282456  0.50223976 0.50072503 0.50272197\n",
            " 0.50204325 0.51853424 0.50170094 0.51561344]\n",
            "\n",
            "Matched draws\n",
            "Count: 2, Index: (array([ 905, 5227]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "106917  505620 2020-01-08      SpecialNo1     5227\n",
            "106961  505820 2020-01-12  ConsolationNo8      905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qktZbi7OGqP3",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# start_mt = pd.datetime(2019,7,1)\n",
        "# how_many_mt = 6 \n",
        "# for i in range(how_many_mt):\n",
        "#   month_to_predict = start_mt + relativedelta(months=i)\n",
        "#   print(f\"\\n{month_to_predict}\\n-------------------\\n\")\n",
        "\n",
        "#   weight=1.0\n",
        "#   decrement = 0.000\n",
        "#   to_stop=False\n",
        "\n",
        "#   gen_train_test_set(month_to_predict, feature_matrix_selection, file_prefix='test')\n",
        "#   while not to_stop:\n",
        "#     to_stop = model(month_to_predict, feature_matrix_selection, file_prefix='test', class_weight=(weight-decrement))\n",
        "#     decrement = decrement + 0.001\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N8tcqn4yIl21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ca86f08-0e45-42fd-f5bc-f6b7709b9bed"
      },
      "source": [
        "weight=1.0\n",
        "decrement = 0.000\n",
        "to_stop=False\n",
        "\n",
        "dt = pd.datetime(2020,2,1)\n",
        "%time gen_train_test_set(dt, feature_matrix_selection, file_prefix='test')\n",
        "while not to_stop:\n",
        "  to_stop = model(dt, feature_matrix_selection, file_prefix='test', class_weight=(weight-decrement))\n",
        "  decrement = decrement + 0.005"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 969893 observations.\n",
            "Testing on 10000 observations.\n",
            "\n",
            "Data shape before balancing: (969893, 63)\n",
            "\n",
            "Counts of strikes vs non-strikes in previous data:\n",
            "0    937508\n",
            "1     32385\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "\n",
            "NO balancing\n",
            "Data shape after balancing: (969893, 63)\n",
            "\n",
            "Counts of strikes VS non-strikes in new data:\n",
            "0    937508\n",
            "1     32385\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Filtering features\n",
            "\n",
            "Data shape before feature selection: (969893, 63)\n",
            "\n",
            "Counts of strikes vs non-strikes before feature selection:\n",
            "0    937508\n",
            "1     32385\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "\n",
            "Data shape after feature selection: (969893, 36)\n",
            "\n",
            "Counts of strikes vs non-strikes in new data:\n",
            "0    937508\n",
            "1     32385\n",
            "Name: Label, dtype: int64\n",
            "CPU times: user 12.5 s, sys: 182 ms, total: 12.7 s\n",
            "Wall time: 12.9 s\n",
            "\n",
            "-----------2020-02-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(969893, 35) (969893,) (10000, 35) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 937508, 1: 32385})\n",
            "\n",
            "scale_pos_weight - 28.94883433688436\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.94883433688436, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.94883433688436]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.471, F-Score=0.06217\n",
            "\n",
            "Recall: 0.050473186119873815\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.93      0.05      0.95      0.22      0.05      9683\n",
            "          1       0.02      0.05      0.93      0.03      0.22      0.04       317\n",
            "\n",
            "avg / total       0.94      0.90      0.08      0.92      0.22      0.05     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmg0rWpYidwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0504732</td>\n",
              "      <td>0.927915</td>\n",
              "      <td>0.0259615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity   Optimize\n",
              "XGBClassifier_optimize            0   0.0504732         0.927915  0.0259615"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 714 \n",
            "\n",
            "First 23 matches\n",
            "23 [  0  13  17  19  28  29  33  35  42  45  52  54  72  92 111 139 151 163\n",
            " 191 193 197 199 201]\n",
            "\n",
            "[0.50685877 0.5033251  0.50277746 0.51575655 0.5039137  0.5026578\n",
            " 0.50536865 0.5088764  0.50419843 0.500126   0.50590575 0.50413275\n",
            " 0.51133925 0.50342876 0.5018266  0.5011236  0.50322425 0.50321686\n",
            " 0.500613   0.50859404 0.50753075 0.5055681  0.50231284]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[1933 4465 8981 9595  905 3111 1230 2479 7836   19 1271 4562 5311  950\n",
            " 6114  823 1047  592 8938 8690 1949 5301 7455]\n",
            "\n",
            "\n",
            "[0.5153783  0.5177647  0.51862836 0.5163709  0.5159055  0.51613307\n",
            " 0.51648396 0.5168489  0.5159804  0.51575655 0.5192052  0.52193505\n",
            " 0.53189355 0.52347255 0.527189   0.5305465  0.52050555 0.53662175\n",
            " 0.52050716 0.5227675  0.524571   0.537097   0.52512646]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "192 [ 13  17  19  28  29  33  35  42  45  52  54  72  92 111 139 151 163 191\n",
            " 193 197 199 201 210 216 219 226 230 239 253 260 262 270 271 272 278 279\n",
            " 282 283 291 298 314 316 317 325 328 330 336 344 352 353 354 363 365 382\n",
            " 384 392 421 422 431 437 446 451 468 479 490 495 496 498 500 507 510 520\n",
            " 535 537 538 540 546 553 557 559 560 567 568 569 573 575 580 581 591 592\n",
            " 594 598 599 604 607 608 613 614 616 618 621 622 623 626 628 630 634 637\n",
            " 641 643 644 649 657 661 666 667 674 691 697 706 708 709 716 720 728 731\n",
            " 736 743 744 749 752 757 760 764 765 767 769 771 776 782 787 792 793 799\n",
            " 800 802 803 804 806 809 810 816 817 818 823 831 839 847 848 854 855 859\n",
            " 866 868 874 876 877 882 885 886 887 895 900 903 905 921 922 923 925 929\n",
            " 942 944 947 950 952 954 957 963 966 971 974 987]\n",
            "\n",
            "[0.5033251  0.50277746 0.51575655 0.5039137  0.5026578  0.50536865\n",
            " 0.5088764  0.50419843 0.500126   0.50590575 0.50413275 0.51133925\n",
            " 0.50342876 0.5018266  0.5011236  0.50322425 0.50321686 0.500613\n",
            " 0.50859404 0.50753075 0.5055681  0.50231284 0.5108487  0.50420636\n",
            " 0.50732    0.5026786  0.5048685  0.50104076 0.50174785 0.5032388\n",
            " 0.50017667 0.5028019  0.50254035 0.50752324 0.5042445  0.5064163\n",
            " 0.503481   0.5101219  0.5046015  0.50686884 0.5058063  0.50102687\n",
            " 0.5039492  0.5016582  0.5022074  0.50125    0.5031476  0.5066384\n",
            " 0.501196   0.5010004  0.504877   0.5008732  0.5024251  0.50066584\n",
            " 0.50330245 0.510123   0.5050188  0.5029317  0.50214326 0.5029084\n",
            " 0.501368   0.50204676 0.50291646 0.50660056 0.5021567  0.50587136\n",
            " 0.50277746 0.50875187 0.50490963 0.5097872  0.50185204 0.50125813\n",
            " 0.5062684  0.50630015 0.50188786 0.5025088  0.5023292  0.5050775\n",
            " 0.51296335 0.503987   0.5018754  0.5094072  0.505909   0.5005597\n",
            " 0.50053674 0.5069004  0.5028312  0.5014504  0.5022013  0.53662175\n",
            " 0.5081985  0.50265336 0.5016347  0.50648105 0.50337845 0.5042921\n",
            " 0.5022363  0.50067043 0.5020813  0.51073295 0.50491035 0.5099787\n",
            " 0.5039105  0.5061329  0.50059634 0.5072162  0.504721   0.50441766\n",
            " 0.5086733  0.5003537  0.502569   0.5007634  0.5022341  0.50659233\n",
            " 0.5019185  0.50046206 0.5013717  0.5031962  0.5025548  0.5076831\n",
            " 0.50901306 0.5008765  0.5026399  0.503215   0.50264984 0.50148565\n",
            " 0.5035591  0.5027905  0.5001812  0.5001145  0.5009595  0.5048831\n",
            " 0.50091046 0.50365406 0.50309324 0.5001872  0.50136065 0.50007206\n",
            " 0.50318944 0.50235283 0.50213635 0.50034124 0.5021423  0.50690556\n",
            " 0.50085557 0.50816476 0.5043129  0.50326693 0.5047201  0.5022856\n",
            " 0.5031094  0.50286025 0.50074977 0.5014732  0.5305465  0.50425845\n",
            " 0.51260334 0.5006182  0.5019607  0.50713736 0.5046649  0.50132513\n",
            " 0.50065    0.5007896  0.5036353  0.50088996 0.5026527  0.5009667\n",
            " 0.5015936  0.50396305 0.50344634 0.5144131  0.5002391  0.51384616\n",
            " 0.5159055  0.50494707 0.5070739  0.50782514 0.51303136 0.50276804\n",
            " 0.50237834 0.5045125  0.50329775 0.52347255 0.50771123 0.5040152\n",
            " 0.5019433  0.5033317  0.5059402  0.50086385 0.50840855 0.5026856 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5044637322425842\n",
            "\n",
            "175 [   0   19   33   35   52   72  193  197  199  210  219  230  272  279\n",
            "  283  291  298  314  344  354  392  421  479  495  498  500  507  535\n",
            "  537  553  557  567  568  575  592  594  604  618  621  622  626  630\n",
            "  634  641  661  706  708  757  799  802  806  823  839  854  855  895\n",
            "  903  905  921  922  923  925  944  950  952  966  974 1009 1047 1050\n",
            " 1115 1126 1156 1198 1216 1221 1230 1231 1255 1271 1304 1320 1378 1438\n",
            " 1445 1508 1519 1553 1563 1577 1597 1671 1686 1773 1807 1933 1949 1950\n",
            " 1962 1979 2011 2029 2030 2036 2071 2144 2185 2190 2213 2255 2260 2451\n",
            " 2466 2479 2532 2533 2536 2609 2722 2759 2769 2958 3029 3034 3111 3138\n",
            " 3163 3183 3269 3350 3411 3830 3927 4012 4016 4060 4116 4339 4465 4562\n",
            " 4851 4855 4859 4923 5261 5301 5311 5378 5437 5464 6045 6114 6117 6326\n",
            " 6367 6439 6772 6874 7166 7231 7302 7455 7730 7836 8260 8360 8499 8690\n",
            " 8938 8981 9028 9192 9258 9431 9595]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.503632128238678\n",
            "\n",
            "235 [   0   19   28   33   35   42   52   54   72  193  197  199  210  216\n",
            "  219  230  272  278  279  283  291  298  314  317  344  354  392  421\n",
            "  479  495  498  500  507  535  537  553  557  559  567  568  575  592\n",
            "  594  604  608  618  621  622  623  626  630  634  637  641  661  706\n",
            "  708  757  764  799  802  803  806  823  831  839  854  855  874  886\n",
            "  895  903  905  921  922  923  925  944  950  952  954  966  974 1009\n",
            " 1017 1018 1039 1047 1050 1115 1126 1142 1156 1198 1216 1221 1230 1231\n",
            " 1255 1271 1304 1320 1378 1438 1445 1450 1474 1489 1502 1508 1519 1550\n",
            " 1553 1555 1563 1577 1597 1671 1686 1702 1773 1807 1811 1853 1933 1949\n",
            " 1950 1962 1979 2011 2029 2030 2036 2071 2144 2153 2185 2190 2213 2255\n",
            " 2260 2269 2276 2451 2466 2479 2532 2533 2536 2550 2603 2609 2701 2722\n",
            " 2759 2769 2936 2958 3029 3034 3081 3090 3091 3111 3138 3163 3183 3269\n",
            " 3350 3400 3411 3526 3733 3811 3830 3927 3988 4012 4016 4060 4116 4339\n",
            " 4465 4562 4851 4855 4859 4923 5045 5084 5261 5301 5311 5378 5437 5464\n",
            " 5523 5725 5820 6045 6114 6117 6326 6352 6367 6439 6772 6874 6997 7081\n",
            " 7166 7231 7302 7318 7402 7405 7455 7730 7836 8009 8031 8216 8260 8360\n",
            " 8499 8690 8938 8981 9028 9192 9258 9431 9595 9610 9895]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "714 [   0   13   17   19   28   29   33   35   42   45   52   54   72   92\n",
            "  111  139  151  163  191  193  197  199  201  210  216  219  226  230\n",
            "  239  253  260  262  270  271  272  278  279  282  283  291  298  314\n",
            "  316  317  325  328  330  336  344  352  353  354  363  365  382  384\n",
            "  392  421  422  431  437  446  451  468  479  490  495  496  498  500\n",
            "  507  510  520  535  537  538  540  546  553  557  559  560  567  568\n",
            "  569  573  575  580  581  591  592  594  598  599  604  607  608  613\n",
            "  614  616  618  621  622  623  626  628  630  634  637  641  643  644\n",
            "  649  657  661  666  667  674  691  697  706  708  709  716  720  728\n",
            "  731  736  743  744  749  752  757  760  764  765  767  769  771  776\n",
            "  782  787  792  793  799  800  802  803  804  806  809  810  816  817\n",
            "  818  823  831  839  847  848  854  855  859  866  868  874  876  877\n",
            "  882  885  886  887  895  900  903  905  921  922  923  925  929  942\n",
            "  944  947  950  952  954  957  963  966  971  974  987 1009 1016 1017\n",
            " 1018 1022 1027 1029 1030 1031 1039 1044 1046 1047 1050 1055 1061 1064\n",
            " 1071 1083 1085 1088 1102 1103 1112 1115 1126 1127 1142 1152 1156 1174\n",
            " 1175 1178 1198 1207 1216 1221 1228 1230 1231 1255 1256 1260 1271 1279\n",
            " 1284 1296 1298 1304 1308 1315 1316 1320 1321 1334 1336 1348 1349 1353\n",
            " 1354 1360 1362 1378 1399 1412 1414 1423 1431 1435 1438 1445 1450 1454\n",
            " 1456 1463 1467 1474 1475 1489 1502 1506 1508 1516 1519 1531 1534 1550\n",
            " 1553 1554 1555 1557 1563 1571 1577 1580 1581 1585 1597 1631 1649 1651\n",
            " 1655 1671 1684 1686 1689 1695 1700 1702 1710 1723 1736 1747 1748 1754\n",
            " 1766 1773 1777 1789 1807 1810 1811 1828 1830 1832 1834 1853 1857 1862\n",
            " 1867 1879 1884 1888 1896 1905 1907 1914 1933 1942 1949 1950 1957 1962\n",
            " 1979 1984 1992 2011 2019 2029 2030 2036 2050 2053 2056 2064 2071 2075\n",
            " 2093 2097 2105 2107 2115 2144 2145 2153 2157 2158 2172 2178 2185 2188\n",
            " 2190 2196 2209 2213 2241 2243 2248 2254 2255 2260 2266 2268 2269 2275\n",
            " 2276 2278 2302 2303 2325 2326 2331 2346 2353 2376 2398 2399 2414 2415\n",
            " 2418 2425 2439 2441 2446 2449 2451 2461 2466 2474 2479 2485 2495 2497\n",
            " 2502 2509 2520 2532 2533 2536 2550 2560 2571 2603 2609 2628 2633 2679\n",
            " 2701 2704 2722 2723 2749 2759 2760 2765 2769 2786 2842 2860 2865 2869\n",
            " 2872 2879 2889 2897 2936 2952 2958 2989 3003 3009 3010 3018 3029 3030\n",
            " 3034 3043 3081 3086 3090 3091 3099 3111 3113 3138 3139 3152 3156 3163\n",
            " 3171 3183 3209 3251 3254 3266 3269 3283 3306 3319 3334 3350 3356 3387\n",
            " 3400 3411 3428 3436 3448 3468 3482 3492 3494 3521 3526 3545 3591 3600\n",
            " 3613 3618 3624 3632 3675 3710 3732 3733 3772 3781 3791 3805 3811 3816\n",
            " 3828 3830 3845 3879 3890 3920 3927 3931 3932 3935 3968 3988 4012 4016\n",
            " 4036 4043 4044 4053 4060 4080 4098 4116 4123 4166 4242 4253 4257 4282\n",
            " 4315 4321 4336 4339 4369 4373 4465 4472 4473 4479 4514 4562 4578 4592\n",
            " 4609 4661 4669 4725 4753 4763 4780 4789 4826 4849 4851 4855 4859 4923\n",
            " 4932 4974 5009 5032 5045 5067 5070 5084 5087 5092 5213 5237 5240 5261\n",
            " 5294 5301 5309 5311 5331 5338 5340 5365 5371 5378 5426 5430 5437 5440\n",
            " 5442 5464 5506 5521 5523 5587 5631 5648 5709 5725 5726 5792 5797 5820\n",
            " 5825 5899 5960 6019 6045 6055 6092 6094 6114 6117 6131 6156 6215 6241\n",
            " 6281 6326 6352 6367 6379 6408 6439 6447 6451 6453 6481 6510 6586 6603\n",
            " 6620 6742 6749 6772 6806 6874 6918 6926 6945 6960 6962 6992 6997 7058\n",
            " 7081 7097 7136 7139 7143 7144 7160 7166 7222 7227 7231 7249 7302 7318\n",
            " 7320 7339 7397 7400 7402 7405 7433 7455 7486 7495 7513 7532 7649 7682\n",
            " 7730 7836 7904 7936 7956 8009 8031 8051 8078 8186 8216 8260 8360 8490\n",
            " 8499 8524 8690 8697 8701 8919 8938 8981 8983 9028 9110 9122 9192 9254\n",
            " 9258 9282 9364 9431 9465 9595 9610 9671 9692 9702 9755 9766 9895 9963]\n",
            "\n",
            "714 [0.50685877 0.5033251  0.50277746 0.51575655 0.5039137  0.5026578\n",
            " 0.50536865 0.5088764  0.50419843 0.500126   0.50590575 0.50413275\n",
            " 0.51133925 0.50342876 0.5018266  0.5011236  0.50322425 0.50321686\n",
            " 0.500613   0.50859404 0.50753075 0.5055681  0.50231284 0.5108487\n",
            " 0.50420636 0.50732    0.5026786  0.5048685  0.50104076 0.50174785\n",
            " 0.5032388  0.50017667 0.5028019  0.50254035 0.50752324 0.5042445\n",
            " 0.5064163  0.503481   0.5101219  0.5046015  0.50686884 0.5058063\n",
            " 0.50102687 0.5039492  0.5016582  0.5022074  0.50125    0.5031476\n",
            " 0.5066384  0.501196   0.5010004  0.504877   0.5008732  0.5024251\n",
            " 0.50066584 0.50330245 0.510123   0.5050188  0.5029317  0.50214326\n",
            " 0.5029084  0.501368   0.50204676 0.50291646 0.50660056 0.5021567\n",
            " 0.50587136 0.50277746 0.50875187 0.50490963 0.5097872  0.50185204\n",
            " 0.50125813 0.5062684  0.50630015 0.50188786 0.5025088  0.5023292\n",
            " 0.5050775  0.51296335 0.503987   0.5018754  0.5094072  0.505909\n",
            " 0.5005597  0.50053674 0.5069004  0.5028312  0.5014504  0.5022013\n",
            " 0.53662175 0.5081985  0.50265336 0.5016347  0.50648105 0.50337845\n",
            " 0.5042921  0.5022363  0.50067043 0.5020813  0.51073295 0.50491035\n",
            " 0.5099787  0.5039105  0.5061329  0.50059634 0.5072162  0.504721\n",
            " 0.50441766 0.5086733  0.5003537  0.502569   0.5007634  0.5022341\n",
            " 0.50659233 0.5019185  0.50046206 0.5013717  0.5031962  0.5025548\n",
            " 0.5076831  0.50901306 0.5008765  0.5026399  0.503215   0.50264984\n",
            " 0.50148565 0.5035591  0.5027905  0.5001812  0.5001145  0.5009595\n",
            " 0.5048831  0.50091046 0.50365406 0.50309324 0.5001872  0.50136065\n",
            " 0.50007206 0.50318944 0.50235283 0.50213635 0.50034124 0.5021423\n",
            " 0.50690556 0.50085557 0.50816476 0.5043129  0.50326693 0.5047201\n",
            " 0.5022856  0.5031094  0.50286025 0.50074977 0.5014732  0.5305465\n",
            " 0.50425845 0.51260334 0.5006182  0.5019607  0.50713736 0.5046649\n",
            " 0.50132513 0.50065    0.5007896  0.5036353  0.50088996 0.5026527\n",
            " 0.5009667  0.5015936  0.50396305 0.50344634 0.5144131  0.5002391\n",
            " 0.51384616 0.5159055  0.50494707 0.5070739  0.50782514 0.51303136\n",
            " 0.50276804 0.50237834 0.5045125  0.50329775 0.52347255 0.50771123\n",
            " 0.5040152  0.5019433  0.5033317  0.5059402  0.50086385 0.50840855\n",
            " 0.5026856  0.50841856 0.50154334 0.503787   0.50427    0.50044906\n",
            " 0.5017425  0.5004651  0.5000313  0.5014536  0.5043593  0.50357246\n",
            " 0.50033087 0.52050555 0.5045967  0.50156444 0.5007373  0.5003508\n",
            " 0.5024047  0.5029101  0.5004017  0.5016965  0.500803   0.5023658\n",
            " 0.5025465  0.5057849  0.50451374 0.5013619  0.5038482  0.5002992\n",
            " 0.5046192  0.5028597  0.5029118  0.5014137  0.5055436  0.50127476\n",
            " 0.50495905 0.50791967 0.502195   0.51648396 0.5073899  0.5053183\n",
            " 0.50281    0.5028662  0.5192052  0.50049454 0.5009887  0.50339013\n",
            " 0.5012148  0.50483656 0.50359565 0.50169754 0.5015026  0.506712\n",
            " 0.50117624 0.50200665 0.5006097  0.50215465 0.50047284 0.50154465\n",
            " 0.50029176 0.50218636 0.5000992  0.5064659  0.50146514 0.5002631\n",
            " 0.5028232  0.50334513 0.50314957 0.5001669  0.5061792  0.50608784\n",
            " 0.5044343  0.501712   0.5011323  0.5003228  0.50013816 0.5036404\n",
            " 0.50299054 0.50380576 0.503767   0.50066376 0.50985557 0.50355405\n",
            " 0.50735563 0.502148   0.50264233 0.50403106 0.507069   0.501775\n",
            " 0.5038209  0.5021604  0.5057468  0.50157857 0.50446415 0.50064814\n",
            " 0.5001455  0.50045216 0.5082264  0.50105876 0.5013851  0.50204676\n",
            " 0.50139046 0.50732994 0.50336635 0.5068786  0.5021466  0.50268596\n",
            " 0.50288314 0.5038956  0.5024081  0.5020695  0.50113016 0.50269634\n",
            " 0.5018927  0.50085896 0.5008103  0.50577927 0.5002313  0.5010563\n",
            " 0.50624555 0.502441   0.50399    0.5005074  0.50244    0.5003694\n",
            " 0.50012034 0.5042389  0.5006541  0.5014113  0.50166655 0.502483\n",
            " 0.50292563 0.5003188  0.50232285 0.5002798  0.5035721  0.5020565\n",
            " 0.5153783  0.50211465 0.524571   0.5044686  0.5013608  0.50524765\n",
            " 0.5046865  0.50122195 0.5025193  0.5081406  0.501375   0.5085194\n",
            " 0.50964576 0.5049924  0.5010123  0.5003502  0.50237066 0.5029011\n",
            " 0.5048311  0.5024367  0.5003247  0.5017004  0.5021941  0.5032726\n",
            " 0.5012788  0.50811297 0.5018194  0.50390345 0.5018206  0.5024254\n",
            " 0.50308853 0.50214136 0.5098019  0.5002953  0.505823   0.50123954\n",
            " 0.5031589  0.50471187 0.5005304  0.50272954 0.5001359  0.5005849\n",
            " 0.50643766 0.5078951  0.5019198  0.5008998  0.50437343 0.5016336\n",
            " 0.5040752  0.50145745 0.5014729  0.50083345 0.50079805 0.5005628\n",
            " 0.5006692  0.50126743 0.50130713 0.5019525  0.50195044 0.5006651\n",
            " 0.5008894  0.5006941  0.5000487  0.5029745  0.5019373  0.5026598\n",
            " 0.50070626 0.50192106 0.5104835  0.50291026 0.50496185 0.50039285\n",
            " 0.5168489  0.5031465  0.50002986 0.50197697 0.50111264 0.50059783\n",
            " 0.5003783  0.5094527  0.5051587  0.50597143 0.50423205 0.50181186\n",
            " 0.502836   0.50372857 0.50792176 0.5010226  0.502797   0.50244325\n",
            " 0.5040057  0.5016804  0.5066852  0.5015866  0.5007022  0.50808614\n",
            " 0.50355387 0.50181586 0.5059085  0.50167674 0.50118715 0.5004774\n",
            " 0.50212264 0.50242746 0.50067425 0.50085735 0.50163484 0.50027454\n",
            " 0.504079   0.50220376 0.5057851  0.50101423 0.5014687  0.50012004\n",
            " 0.5035923  0.5013094  0.5050372  0.5000697  0.50481236 0.501347\n",
            " 0.5037575  0.500818   0.50428826 0.504439   0.5007044  0.51613307\n",
            " 0.5014867  0.5050195  0.5035706  0.50018656 0.50037724 0.50472975\n",
            " 0.50355995 0.5062454  0.5006811  0.5007373  0.5029009  0.5017483\n",
            " 0.50595    0.5000145  0.50360644 0.5023081  0.50213397 0.50800973\n",
            " 0.5019753  0.5002658  0.504204   0.50906575 0.50250447 0.5016806\n",
            " 0.5011264  0.50186807 0.5033243  0.5015433  0.5031763  0.50264204\n",
            " 0.50379616 0.50089395 0.50361997 0.50345963 0.5023287  0.50204176\n",
            " 0.5027799  0.50030375 0.5007931  0.50090325 0.5000773  0.504206\n",
            " 0.5011725  0.50072235 0.50258756 0.5025913  0.50363874 0.5012729\n",
            " 0.5001984  0.5046513  0.5004545  0.50011605 0.5001905  0.5000942\n",
            " 0.5053113  0.5029039  0.50082666 0.5024229  0.5027096  0.5041277\n",
            " 0.50489664 0.50509083 0.5024161  0.50038844 0.5019473  0.500238\n",
            " 0.50613594 0.5011014  0.5011082  0.5045728  0.5029831  0.5010353\n",
            " 0.50273365 0.50063616 0.50095147 0.50036114 0.50125617 0.50025463\n",
            " 0.5005453  0.5057319  0.50153106 0.5021447  0.5177647  0.5011362\n",
            " 0.50185204 0.5028946  0.5008979  0.52193505 0.5031183  0.50002927\n",
            " 0.50115204 0.50015664 0.5027212  0.5012342  0.50120145 0.5030948\n",
            " 0.5011489  0.5019517  0.5002654  0.5006439  0.5067328  0.5131891\n",
            " 0.50645703 0.50890857 0.50157475 0.5003626  0.5003599  0.5003415\n",
            " 0.5039153  0.50225407 0.5010567  0.50442874 0.5017869  0.5012431\n",
            " 0.50080997 0.5016814  0.50263244 0.5048933  0.5018826  0.537097\n",
            " 0.5013993  0.53189355 0.50147563 0.5021643  0.5007052  0.50057423\n",
            " 0.5028453  0.5125847  0.50006    0.50045    0.5052608  0.5008791\n",
            " 0.5025042  0.50677186 0.50256246 0.5019234  0.50363433 0.50318336\n",
            " 0.50022817 0.50260264 0.50048745 0.5042128  0.5014091  0.5007672\n",
            " 0.50056493 0.50372136 0.5014009  0.50022995 0.5017133  0.50162965\n",
            " 0.5069014  0.5010886  0.5008286  0.50050515 0.527189   0.5048404\n",
            " 0.5002506  0.50124586 0.5019663  0.50059927 0.500865   0.5110358\n",
            " 0.5044396  0.505342   0.50078917 0.5008489  0.50639915 0.50153804\n",
            " 0.50151837 0.5011308  0.50084245 0.5023073  0.502385   0.50181115\n",
            " 0.50348246 0.5002157  0.5018016  0.50518894 0.5034153  0.5083002\n",
            " 0.5016356  0.50174415 0.5027394  0.50305176 0.50291026 0.5007446\n",
            " 0.5037645  0.50078607 0.50380087 0.5026269  0.5002395  0.5034211\n",
            " 0.5025038  0.50007045 0.5003852  0.50641966 0.50224906 0.50030273\n",
            " 0.50652725 0.50165117 0.50765485 0.50393957 0.5020605  0.5026991\n",
            " 0.50079936 0.50023866 0.50416493 0.5038186  0.5018578  0.52512646\n",
            " 0.50347495 0.50130194 0.5003486  0.50230217 0.5005666  0.5010101\n",
            " 0.50471824 0.5159804  0.5022859  0.5005313  0.50036585 0.5044589\n",
            " 0.5037253  0.5007172  0.50290716 0.503269   0.50401413 0.5051937\n",
            " 0.5061917  0.5008115  0.51249105 0.5018159  0.5227675  0.50113094\n",
            " 0.50125545 0.50199115 0.52050716 0.51862836 0.50170404 0.5047022\n",
            " 0.5014479  0.5011994  0.50455844 0.50082594 0.5134311  0.50356054\n",
            " 0.5007379  0.5063558  0.5029683  0.5163709  0.5039889  0.50257957\n",
            " 0.5001333  0.502546   0.503238   0.5002408  0.5037342  0.50285476]\n",
            "\n",
            "Matched draws\n",
            "Count: 16, Index: (array([ 392,  422, 1228, 1284, 1467, 1475, 1519, 1789, 1884, 2030, 2145,\n",
            "       2889, 3400, 3927, 4116, 6439]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "107279  507220 2020-02-08  ConsolationNo4      422\n",
            "107356  507520 2020-02-15      SpecialNo2      392\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate        PrizeType  LuckyNo\n",
            "107187  506820 2020-02-01   ConsolationNo4     1789\n",
            "107199  506820 2020-02-01       SpecialNo6     2030\n",
            "107206  506920 2020-02-02   ConsolationNo1     1519\n",
            "107216  506920 2020-02-02       SpecialNo1     1467\n",
            "107223  506920 2020-02-02       SpecialNo7     1284\n",
            "107243  507020 2020-02-04       SpecialNo4     1884\n",
            "107279  507220 2020-02-08   ConsolationNo4      422\n",
            "107289  507220 2020-02-08       SpecialNo4     4116\n",
            "107356  507520 2020-02-15       SpecialNo2      392\n",
            "107365  507620 2020-02-16       2ndPrizeNo     1228\n",
            "107385  507620 2020-02-16       SpecialNo8     3400\n",
            "107402  507720 2020-02-19       SpecialNo2     2145\n",
            "107414  507820 2020-02-22  ConsolationNo10     2889\n",
            "107456  508020 2020-02-26       1stPrizeNo     3927\n",
            "107466  508020 2020-02-26   ConsolationNo7     1475\n",
            "107475  508020 2020-02-26       SpecialNo6     6439\n",
            "\n",
            "-----------2020-02-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(969893, 35) (969893,) (10000, 35) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 937508, 1: 32385})\n",
            "\n",
            "scale_pos_weight - 28.804090165199938\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.804090165199938, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.804090165199938]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.476, F-Score=0.06204\n",
            "\n",
            "Recall: 0.04100946372239748\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.95      0.04      0.96      0.20      0.04      9683\n",
            "          1       0.02      0.04      0.95      0.03      0.20      0.04       317\n",
            "\n",
            "avg / total       0.94      0.92      0.07      0.93      0.20      0.04     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC0ECALCFIAEA2EKQAABs+V8l41zFiKCOzgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0410095</td>\n",
              "      <td>0.945162</td>\n",
              "      <td>0.0218399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity   Optimize\n",
              "XGBClassifier_optimize            0   0.0410095         0.945162  0.0218399"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 544 \n",
            "\n",
            "First 23 matches\n",
            "23 [  0  13  17  19  28  29  33  35  42  52  54  72  92 111 139 151 163 193\n",
            " 197 199 201 210 216]\n",
            "\n",
            "[0.50576746 0.5023222  0.50154537 0.5168275  0.5029909  0.50151676\n",
            " 0.50428337 0.50785387 0.50315654 0.5049013  0.5031138  0.51023525\n",
            " 0.5025329  0.50059986 0.50012165 0.50221723 0.5021767  0.5074531\n",
            " 0.50652117 0.50402546 0.5018452  0.50982714 0.5032523 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[2479 7836 1271 3111 4465 1230 1933 1047 8938  905 9595 8981   19 4562\n",
            "  950 7455 5301  592 5311  823 8690 6114 1949]\n",
            "\n",
            "\n",
            "[0.51487327 0.5149468  0.5180897  0.5150032  0.51650524 0.5153568\n",
            " 0.51582414 0.5193552  0.5199594  0.51720154 0.5155516  0.5185087\n",
            " 0.5168275  0.52164394 0.5235262  0.52399576 0.5359719  0.5366672\n",
            " 0.5318491  0.5322321  0.5232902  0.52760464 0.5236816 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "162 [ 13  17  19  28  29  33  35  42  52  54  72  92 111 139 151 163 193 197\n",
            " 199 201 210 216 219 226 230 253 260 270 271 272 278 279 282 283 291 298\n",
            " 314 317 325 328 330 336 344 352 353 354 365 384 392 421 422 431 437 446\n",
            " 451 468 479 490 495 496 498 500 507 510 520 535 537 538 540 546 553 557\n",
            " 559 560 567 568 575 580 581 591 592 594 598 599 604 607 608 613 616 618\n",
            " 621 622 623 626 630 634 637 641 644 657 661 666 674 691 697 706 708 716\n",
            " 720 728 731 736 743 757 764 765 769 776 782 787 793 799 802 803 804 806\n",
            " 809 810 816 818 823 831 839 848 854 855 859 874 876 877 885 886 887 895\n",
            " 903 905 921 922 923 925 929 942 944 947 950 952 954 957 963 966 974 987]\n",
            "\n",
            "[0.5023222  0.50154537 0.5168275  0.5029909  0.50151676 0.50428337\n",
            " 0.50785387 0.50315654 0.5049013  0.5031138  0.51023525 0.5025329\n",
            " 0.50059986 0.50012165 0.50221723 0.5021767  0.5074531  0.50652117\n",
            " 0.50402546 0.5018452  0.50982714 0.5032523  0.506194   0.50167423\n",
            " 0.5037586  0.50063837 0.50213    0.5018181  0.50141495 0.506296\n",
            " 0.5032418  0.5054313  0.5022528  0.5089777  0.503372   0.50575924\n",
            " 0.5046577  0.50294536 0.5005569  0.5010954  0.50011915 0.5020247\n",
            " 0.5055307  0.5002779  0.50000167 0.5037315  0.5013168  0.50226456\n",
            " 0.50910044 0.5041001  0.50184983 0.5010245  0.50188833 0.50033027\n",
            " 0.5008422  0.5018301  0.5054919  0.5011543  0.504936   0.50186163\n",
            " 0.50764734 0.50380135 0.50876325 0.5008498  0.5001413  0.5048088\n",
            " 0.5051586  0.5008513  0.5014277  0.50119483 0.5043761  0.51185787\n",
            " 0.50301486 0.50087297 0.50817853 0.5048005  0.50587773 0.50183123\n",
            " 0.50041616 0.5012845  0.5366672  0.5073337  0.50152576 0.5005257\n",
            " 0.50537753 0.5022541  0.5031852  0.5011337  0.5009599  0.5084863\n",
            " 0.50368583 0.50898    0.50280106 0.50490636 0.5061176  0.5036969\n",
            " 0.503339   0.5076742  0.5014626  0.50133854 0.50548124 0.50102586\n",
            " 0.50033015 0.5021706  0.50143194 0.50655544 0.5081078  0.5016394\n",
            " 0.5020755  0.5015156  0.50025713 0.50255895 0.50187427 0.50384283\n",
            " 0.50261194 0.5019711  0.5003224  0.50208193 0.5012303  0.5010143\n",
            " 0.50098145 0.50578    0.5071404  0.5032268  0.50233173 0.50380427\n",
            " 0.50126797 0.5020768  0.50183773 0.50034434 0.5322321  0.5034528\n",
            " 0.5114754  0.5008377  0.5057973  0.50365037 0.5003875  0.50250894\n",
            " 0.500952   0.50162977 0.50057226 0.5028363  0.50222105 0.5132891\n",
            " 0.5126196  0.51720154 0.503699   0.50597143 0.5067173  0.5119932\n",
            " 0.50164664 0.50115645 0.5033713  0.50217104 0.5235262  0.5065931\n",
            " 0.50279045 0.5006962  0.5021925  0.50372523 0.5072808  0.50134397]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5041558742523193\n",
            "\n",
            "134 [   0   19   33   35   52   72  193  197  210  219  272  279  283  298\n",
            "  314  344  392  479  495  498  507  535  537  553  557  567  568  575\n",
            "  592  594  604  618  622  626  630  641  661  706  708  799  802  823\n",
            "  839  854  895  903  905  922  923  925  950  952  974 1009 1047 1115\n",
            " 1198 1221 1230 1231 1255 1271 1320 1378 1438 1445 1508 1519 1553 1563\n",
            " 1597 1671 1686 1773 1807 1933 1949 2011 2029 2030 2144 2185 2190 2255\n",
            " 2260 2451 2479 2532 2536 2609 2722 2759 2769 2958 3111 3183 3269 3350\n",
            " 3411 4060 4339 4465 4562 4851 4855 4859 4923 5301 5311 5378 5437 5464\n",
            " 5825 6045 6114 6326 6367 6439 6874 7166 7231 7302 7455 7836 8216 8360\n",
            " 8499 8690 8938 8981 9258 9431 9595 9610]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5035794377326965\n",
            "\n",
            "169 [   0   19   33   35   52   72  193  197  199  210  219  230  272  279\n",
            "  283  298  314  344  354  392  421  479  495  498  500  507  535  537\n",
            "  553  557  567  568  575  592  594  604  618  621  622  626  630  634\n",
            "  641  661  706  708  757  799  802  806  823  839  854  855  895  903\n",
            "  905  921  922  923  925  950  952  966  974 1009 1047 1115 1156 1198\n",
            " 1216 1221 1230 1231 1255 1271 1304 1320 1378 1438 1445 1508 1519 1553\n",
            " 1563 1597 1671 1686 1773 1807 1933 1949 1962 2011 2029 2030 2036 2071\n",
            " 2144 2185 2190 2213 2255 2260 2451 2466 2479 2532 2533 2536 2609 2722\n",
            " 2759 2769 2958 3029 3034 3111 3138 3163 3183 3269 3306 3350 3411 3830\n",
            " 3927 3988 4012 4016 4060 4339 4465 4562 4851 4855 4859 4923 5261 5301\n",
            " 5311 5378 5437 5464 5825 6045 6114 6117 6326 6367 6439 6772 6874 7166\n",
            " 7231 7302 7455 7836 8216 8260 8360 8499 8690 8938 8981 9258 9431 9595\n",
            " 9610]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "544 [   0   13   17   19   28   29   33   35   42   52   54   72   92  111\n",
            "  139  151  163  193  197  199  201  210  216  219  226  230  253  260\n",
            "  270  271  272  278  279  282  283  291  298  314  317  325  328  330\n",
            "  336  344  352  353  354  365  384  392  421  422  431  437  446  451\n",
            "  468  479  490  495  496  498  500  507  510  520  535  537  538  540\n",
            "  546  553  557  559  560  567  568  575  580  581  591  592  594  598\n",
            "  599  604  607  608  613  616  618  621  622  623  626  630  634  637\n",
            "  641  644  657  661  666  674  691  697  706  708  716  720  728  731\n",
            "  736  743  757  764  765  769  776  782  787  793  799  802  803  804\n",
            "  806  809  810  816  818  823  831  839  848  854  855  859  874  876\n",
            "  877  885  886  887  895  903  905  921  922  923  925  929  942  944\n",
            "  947  950  952  954  957  963  966  974  987 1009 1016 1017 1018 1027\n",
            " 1031 1039 1044 1047 1050 1055 1071 1083 1088 1103 1112 1115 1126 1127\n",
            " 1142 1156 1174 1175 1178 1198 1207 1216 1221 1228 1230 1231 1255 1256\n",
            " 1260 1271 1296 1298 1304 1308 1315 1316 1320 1321 1334 1348 1353 1360\n",
            " 1378 1399 1414 1423 1431 1438 1445 1450 1454 1456 1474 1475 1489 1502\n",
            " 1508 1516 1519 1531 1534 1550 1553 1554 1555 1557 1563 1571 1577 1597\n",
            " 1631 1649 1651 1655 1671 1684 1686 1689 1695 1700 1702 1710 1723 1736\n",
            " 1747 1748 1773 1807 1810 1811 1830 1853 1862 1867 1879 1884 1896 1905\n",
            " 1907 1914 1933 1942 1949 1950 1957 1962 1979 1984 1992 2011 2019 2029\n",
            " 2030 2036 2050 2056 2064 2071 2075 2097 2105 2107 2115 2144 2145 2153\n",
            " 2157 2158 2172 2178 2185 2190 2196 2209 2213 2243 2255 2260 2266 2269\n",
            " 2275 2276 2278 2302 2303 2346 2353 2376 2398 2425 2439 2441 2449 2451\n",
            " 2461 2466 2479 2485 2497 2532 2533 2536 2550 2560 2571 2603 2609 2628\n",
            " 2633 2679 2701 2704 2722 2723 2759 2760 2765 2769 2786 2842 2860 2865\n",
            " 2869 2889 2936 2952 2958 3003 3010 3018 3029 3034 3043 3081 3090 3091\n",
            " 3111 3113 3138 3139 3163 3171 3183 3254 3266 3269 3306 3319 3334 3350\n",
            " 3356 3400 3411 3428 3436 3448 3468 3482 3492 3494 3521 3526 3591 3600\n",
            " 3613 3618 3624 3733 3772 3791 3805 3811 3816 3830 3927 3931 3935 3968\n",
            " 3988 4012 4016 4036 4044 4060 4116 4123 4242 4315 4339 4369 4373 4465\n",
            " 4472 4473 4479 4562 4578 4669 4725 4763 4780 4789 4851 4855 4859 4923\n",
            " 4932 5045 5067 5084 5087 5092 5237 5240 5261 5294 5301 5309 5311 5331\n",
            " 5338 5371 5378 5437 5442 5464 5506 5521 5523 5587 5648 5725 5726 5820\n",
            " 5825 5960 6019 6045 6114 6117 6156 6215 6326 6352 6367 6439 6447 6451\n",
            " 6510 6586 6603 6620 6749 6772 6806 6874 6918 6926 6945 6960 6962 6997\n",
            " 7081 7097 7139 7143 7166 7222 7231 7249 7302 7318 7320 7339 7402 7405\n",
            " 7433 7455 7486 7495 7532 7730 7836 7904 8009 8031 8078 8186 8216 8260\n",
            " 8360 8499 8524 8690 8697 8701 8919 8938 8981 8983 9028 9110 9122 9192\n",
            " 9223 9258 9282 9431 9465 9595 9610 9671 9702 9755 9895 9963]\n",
            "\n",
            "544 [0.50576746 0.5023222  0.50154537 0.5168275  0.5029909  0.50151676\n",
            " 0.50428337 0.50785387 0.50315654 0.5049013  0.5031138  0.51023525\n",
            " 0.5025329  0.50059986 0.50012165 0.50221723 0.5021767  0.5074531\n",
            " 0.50652117 0.50402546 0.5018452  0.50982714 0.5032523  0.506194\n",
            " 0.50167423 0.5037586  0.50063837 0.50213    0.5018181  0.50141495\n",
            " 0.506296   0.5032418  0.5054313  0.5022528  0.5089777  0.503372\n",
            " 0.50575924 0.5046577  0.50294536 0.5005569  0.5010954  0.50011915\n",
            " 0.5020247  0.5055307  0.5002779  0.50000167 0.5037315  0.5013168\n",
            " 0.50226456 0.50910044 0.5041001  0.50184983 0.5010245  0.50188833\n",
            " 0.50033027 0.5008422  0.5018301  0.5054919  0.5011543  0.504936\n",
            " 0.50186163 0.50764734 0.50380135 0.50876325 0.5008498  0.5001413\n",
            " 0.5048088  0.5051586  0.5008513  0.5014277  0.50119483 0.5043761\n",
            " 0.51185787 0.50301486 0.50087297 0.50817853 0.5048005  0.50587773\n",
            " 0.50183123 0.50041616 0.5012845  0.5366672  0.5073337  0.50152576\n",
            " 0.5005257  0.50537753 0.5022541  0.5031852  0.5011337  0.5009599\n",
            " 0.5084863  0.50368583 0.50898    0.50280106 0.50490636 0.5061176\n",
            " 0.5036969  0.503339   0.5076742  0.5014626  0.50133854 0.50548124\n",
            " 0.50102586 0.50033015 0.5021706  0.50143194 0.50655544 0.5081078\n",
            " 0.5016394  0.5020755  0.5015156  0.50025713 0.50255895 0.50187427\n",
            " 0.50384283 0.50261194 0.5019711  0.5003224  0.50208193 0.5012303\n",
            " 0.5010143  0.50098145 0.50578    0.5071404  0.5032268  0.50233173\n",
            " 0.50380427 0.50126797 0.5020768  0.50183773 0.50034434 0.5322321\n",
            " 0.5034528  0.5114754  0.5008377  0.5057973  0.50365037 0.5003875\n",
            " 0.50250894 0.500952   0.50162977 0.50057226 0.5028363  0.50222105\n",
            " 0.5132891  0.5126196  0.51720154 0.503699   0.50597143 0.5067173\n",
            " 0.5119932  0.50164664 0.50115645 0.5033713  0.50217104 0.5235262\n",
            " 0.5065931  0.50279045 0.5006962  0.5021925  0.50372523 0.5072808\n",
            " 0.50134397 0.5072943  0.5005223  0.5027746  0.50312924 0.50051826\n",
            " 0.5003272  0.5031307  0.5023251  0.5193552  0.5034737  0.5005461\n",
            " 0.501241   0.50177664 0.5006613  0.5014347  0.5013448  0.504537\n",
            " 0.5035764  0.5002341  0.50282645 0.5037324  0.501753   0.50190836\n",
            " 0.50031084 0.5044336  0.5001577  0.50385743 0.50680524 0.5009878\n",
            " 0.5153568  0.5062688  0.50442237 0.5018907  0.5017631  0.5180897\n",
            " 0.50228393 0.5001949  0.5038326  0.5023904  0.5004952  0.50029653\n",
            " 0.5056081  0.5001399  0.5010042  0.5009813  0.5005416  0.5009598\n",
            " 0.505381   0.5003641  0.5018223  0.50224185 0.50201637 0.5051788\n",
            " 0.5050671  0.5035249  0.50060767 0.5000118  0.50274307 0.50186604\n",
            " 0.50270176 0.5026622  0.5088184  0.5024478  0.5062469  0.501132\n",
            " 0.5015362  0.5029095  0.50594264 0.50075144 0.5026975  0.5010532\n",
            " 0.5047267  0.5003508  0.5033689  0.5070996  0.5000555  0.5002784\n",
            " 0.50102496 0.5003047  0.5062242  0.50214225 0.5058434  0.5010407\n",
            " 0.5016642  0.5016853  0.502751   0.5012794  0.50084126 0.500128\n",
            " 0.5017774  0.5007716  0.504673   0.5051196  0.50121766 0.5028618\n",
            " 0.50133616 0.503134   0.5004102  0.5004591  0.50133795 0.5018049\n",
            " 0.50132686 0.5015459  0.5025739  0.5011385  0.51582414 0.50109255\n",
            " 0.5236816  0.50346607 0.50032324 0.5041482  0.5034568  0.5001202\n",
            " 0.50148153 0.50703853 0.5002664  0.5074232  0.5085161  0.50388575\n",
            " 0.50001097 0.50124896 0.5018992  0.50360346 0.5015191  0.5004728\n",
            " 0.5011939  0.50212836 0.500194   0.50698733 0.50059503 0.5028775\n",
            " 0.5007139  0.50136715 0.5019748  0.5010176  0.5085764  0.5047255\n",
            " 0.5001177  0.5021494  0.5038264  0.5017253  0.50541013 0.5067922\n",
            " 0.50081843 0.50333416 0.5004079  0.5029685  0.50031555 0.50055534\n",
            " 0.50003326 0.5002494  0.50030637 0.5008489  0.50212264 0.50189036\n",
            " 0.5007142  0.5015189  0.500943   0.50938404 0.50178874 0.5037341\n",
            " 0.51487327 0.5021098  0.50098085 0.50832254 0.504053   0.50486815\n",
            " 0.50312614 0.50089216 0.5018338  0.5027246  0.5069098  0.50002813\n",
            " 0.50169164 0.501422   0.5029022  0.5006411  0.5056065  0.50066674\n",
            " 0.5080423  0.5023281  0.50058985 0.50478745 0.50044817 0.5001488\n",
            " 0.50043416 0.5009165  0.50139135 0.5005307  0.50296897 0.50097966\n",
            " 0.5045557  0.50028807 0.5026732  0.5000862  0.5039311  0.50370395\n",
            " 0.5002068  0.50253046 0.5032844  0.50321156 0.5150032  0.50037706\n",
            " 0.5040149  0.5027567  0.50362164 0.5024407  0.5051641  0.5018077\n",
            " 0.5005222  0.50484824 0.5037797  0.50119853 0.50090986 0.5067783\n",
            " 0.50085443 0.50308347 0.50793594 0.50138813 0.50055444 0.50012517\n",
            " 0.50074553 0.5022174  0.5005411  0.5019737  0.50164294 0.5025715\n",
            " 0.5023792  0.50223243 0.50122476 0.5010191  0.5015517  0.503083\n",
            " 0.50019    0.5016992  0.50148356 0.5025337  0.5001711  0.50361395\n",
            " 0.5040969  0.50239104 0.5013195  0.50158626 0.5036681  0.5037746\n",
            " 0.5039832  0.5013066  0.5007248  0.5060168  0.50354904 0.5018602\n",
            " 0.5017122  0.50025403 0.50460213 0.50042856 0.5010226  0.51650524\n",
            " 0.50013506 0.50073934 0.5017852  0.52164394 0.50201845 0.5014926\n",
            " 0.5001103  0.50200945 0.500111   0.5009496  0.50562716 0.5120884\n",
            " 0.50535005 0.5078111  0.50046325 0.5028984  0.50113046 0.503492\n",
            " 0.5005664  0.50013685 0.50065655 0.5015091  0.50376606 0.5014869\n",
            " 0.5359719  0.5002911  0.5318491  0.500368   0.500945   0.5017825\n",
            " 0.5130172  0.50416094 0.5012751  0.5056593  0.50133437 0.5008122\n",
            " 0.5025299  0.5020791  0.5017969  0.5032081  0.5001827  0.5027182\n",
            " 0.50431585 0.5007155  0.50040346 0.5057936  0.52760464 0.50391304\n",
            " 0.50010484 0.50095034 0.5110011  0.5035124  0.5043436  0.50525624\n",
            " 0.50039744 0.5005035  0.5011632  0.50138736 0.50070363 0.5022556\n",
            " 0.5007837  0.5040643  0.50241506 0.5071788  0.5005126  0.50051516\n",
            " 0.5015149  0.50194824 0.5019063  0.50276065 0.50279856 0.50152266\n",
            " 0.5023435  0.50139725 0.50519234 0.50102514 0.50530183 0.5006478\n",
            " 0.50656366 0.5028457  0.50095856 0.5021617  0.5030498  0.50271237\n",
            " 0.5008738  0.52399576 0.50245523 0.5000773  0.5011948  0.5034923\n",
            " 0.5149468  0.50117815 0.5033574  0.50262177 0.50167924 0.50216305\n",
            " 0.50422025 0.5037476  0.5050923  0.5112666  0.50071687 0.5232902\n",
            " 0.5001363  0.5001713  0.50054586 0.5199594  0.5185087  0.50058377\n",
            " 0.5034744  0.5003433  0.5001053  0.5034645  0.5009903  0.51341075\n",
            " 0.50243723 0.50526553 0.50184464 0.5155516  0.5042578  0.5017731\n",
            " 0.50163764 0.5024139  0.5030329  0.501689  ]\n",
            "\n",
            "Matched draws\n",
            "Count: 13, Index: (array([ 392,  422, 1228, 1475, 1519, 1884, 2030, 2145, 2889, 3400, 3927,\n",
            "       4116, 6439]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "107279  507220 2020-02-08  ConsolationNo4      422\n",
            "107356  507520 2020-02-15      SpecialNo2      392\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate        PrizeType  LuckyNo\n",
            "107199  506820 2020-02-01       SpecialNo6     2030\n",
            "107206  506920 2020-02-02   ConsolationNo1     1519\n",
            "107243  507020 2020-02-04       SpecialNo4     1884\n",
            "107279  507220 2020-02-08   ConsolationNo4      422\n",
            "107289  507220 2020-02-08       SpecialNo4     4116\n",
            "107356  507520 2020-02-15       SpecialNo2      392\n",
            "107365  507620 2020-02-16       2ndPrizeNo     1228\n",
            "107385  507620 2020-02-16       SpecialNo8     3400\n",
            "107402  507720 2020-02-19       SpecialNo2     2145\n",
            "107414  507820 2020-02-22  ConsolationNo10     2889\n",
            "107456  508020 2020-02-26       1stPrizeNo     3927\n",
            "107466  508020 2020-02-26   ConsolationNo7     1475\n",
            "107475  508020 2020-02-26       SpecialNo6     6439\n",
            "\n",
            "-----------2020-02-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(969893, 35) (969893,) (10000, 35) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 937508, 1: 32385})\n",
            "\n",
            "scale_pos_weight - 28.659345993515515\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.659345993515515, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.659345993515515]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.468, F-Score=0.06199\n",
            "\n",
            "Recall: 0.031545741324921134\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.96      0.03      0.96      0.17      0.03      9683\n",
            "          1       0.03      0.03      0.96      0.03      0.17      0.03       317\n",
            "\n",
            "avg / total       0.94      0.93      0.06      0.93      0.17      0.03     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0315457</td>\n",
              "      <td>0.960033</td>\n",
              "      <td>0.0172432</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity   Optimize\n",
              "XGBClassifier_optimize            0   0.0315457         0.960033  0.0172432"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 397 \n",
            "\n",
            "First 23 matches\n",
            "23 [  0  13  17  19  28  29  33  35  42  52  54  72  92 151 163 193 197 199\n",
            " 201 210 216 219 226]\n",
            "\n",
            "[0.50466895 0.50121933 0.50044817 0.5159179  0.5018902  0.50041384\n",
            " 0.50324976 0.50675625 0.50205606 0.5037968  0.50305307 0.509135\n",
            " 0.5014298  0.5011146  0.50107497 0.5063489  0.5054186  0.50189936\n",
            " 0.500743   0.5087253  0.5026726  0.5050918  0.50057   ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[3111 7836 1047 1230 1271 8981 4465 1933   19 5378  905 9595 4562  950\n",
            " 8938 6114 5311 5301  592  823 1949 7455 8690]\n",
            "\n",
            "\n",
            "[0.51391286 0.51398253 0.51826465 0.51426506 0.51713634 0.5175625\n",
            " 0.5155469  0.5148893  0.5159179  0.515812   0.5162878  0.5144692\n",
            " 0.5206904  0.52256846 0.52275234 0.5266449  0.5309009  0.5350187\n",
            " 0.5357254  0.5312914  0.522741   0.52305037 0.5223422 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "134 [ 13  17  19  28  29  33  35  42  52  54  72  92 151 163 193 197 199 201\n",
            " 210 216 219 226 230 260 270 271 272 278 279 282 283 291 298 314 317 330\n",
            " 336 344 354 365 384 392 421 422 431 437 468 479 490 495 496 498 500 507\n",
            " 535 537 540 546 553 557 559 567 568 575 580 591 592 594 598 604 607 608\n",
            " 613 618 621 622 623 626 630 634 637 641 644 657 661 691 697 706 708 716\n",
            " 720 728 736 743 757 764 765 776 782 799 802 803 804 806 809 810 816 823\n",
            " 831 839 854 855 874 877 886 887 895 903 905 921 922 923 925 929 942 944\n",
            " 947 950 952 954 963 966 974 987]\n",
            "\n",
            "[0.50121933 0.50044817 0.5159179  0.5018902  0.50041384 0.50324976\n",
            " 0.50675625 0.50205606 0.5037968  0.50305307 0.509135   0.5014298\n",
            " 0.5011146  0.50107497 0.5063489  0.5054186  0.50189936 0.500743\n",
            " 0.5087253  0.5026726  0.5050918  0.50057    0.50265884 0.5010323\n",
            " 0.50071675 0.50031286 0.50519466 0.502138   0.50432974 0.50115174\n",
            " 0.50787246 0.50226647 0.5046574  0.5035578  0.501841   0.50006455\n",
            " 0.5009251  0.5044296  0.5026455  0.5002157  0.5011579  0.50799626\n",
            " 0.5029955  0.5008218  0.5009644  0.50084877 0.5007281  0.5043914\n",
            " 0.5000503  0.5038363  0.50076145 0.5065431  0.5026984  0.50765866\n",
            " 0.50470275 0.5040521  0.5003311  0.50009763 0.5032704  0.5107585\n",
            " 0.5019121  0.5070767  0.5036984  0.5048409  0.50072455 0.5001789\n",
            " 0.5357254  0.5062293  0.5004273  0.50427437 0.5011504  0.50208443\n",
            " 0.50003153 0.507405   0.5025868  0.5089303  0.50169766 0.5038063\n",
            " 0.50501204 0.5025916  0.5022424  0.507615   0.5003569  0.5002334\n",
            " 0.5043808  0.50106746 0.50033    0.50545317 0.5070059  0.5006036\n",
            " 0.5009723  0.5004144  0.5014527  0.50076914 0.5037375  0.501507\n",
            " 0.50087    0.50097775 0.5001304  0.5046748  0.5060387  0.50212467\n",
            " 0.5012282  0.50281024 0.5011651  0.50098103 0.500731   0.5312914\n",
            " 0.5024137  0.5103893  0.50475836 0.50254595 0.5014051  0.50052726\n",
            " 0.5017327  0.5006892  0.51218706 0.51151776 0.5162878  0.50259775\n",
            " 0.50486946 0.5056114  0.5109568  0.5005462  0.5000557  0.5022725\n",
            " 0.50106514 0.52256846 0.5064878  0.5016841  0.50208694 0.5026542\n",
            " 0.50617975 0.5012393 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5038849115371704\n",
            "\n",
            "113 [   0   19   35   72  193  197  210  219  272  279  283  298  344  392\n",
            "  479  498  507  535  537  557  567  575  592  594  604  618  622  630\n",
            "  641  661  706  708  799  802  823  839  854  895  903  905  922  923\n",
            "  925  950  952  974 1009 1047 1221 1230 1231 1271 1320 1378 1438 1445\n",
            " 1508 1519 1553 1563 1597 1671 1686 1807 1933 1949 2011 2029 2030 2144\n",
            " 2185 2255 2260 2451 2479 2532 2609 2722 2759 3111 3183 3350 3411 4060\n",
            " 4465 4562 4851 4855 4859 4923 5301 5311 5378 5464 5825 6045 6114 6326\n",
            " 6439 6874 7166 7231 7302 7455 7836 8360 8499 8690 8938 8981 9258 9431\n",
            " 9595]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5036854147911072\n",
            "\n",
            "121 [   0   19   35   52   72  193  197  210  219  272  279  283  298  344\n",
            "  392  479  495  498  507  535  537  557  567  568  575  592  594  604\n",
            "  618  622  626  630  641  661  706  708  757  799  802  823  839  854\n",
            "  895  903  905  922  923  925  950  952  974 1009 1047 1221 1230 1231\n",
            " 1271 1320 1378 1438 1445 1508 1519 1553 1563 1597 1671 1686 1807 1933\n",
            " 1949 2011 2029 2030 2144 2185 2255 2260 2451 2479 2532 2536 2609 2722\n",
            " 2759 2769 3111 3183 3269 3350 3411 4060 4465 4562 4851 4855 4859 4923\n",
            " 5301 5311 5378 5464 5825 6045 6114 6326 6439 6874 7166 7231 7302 7455\n",
            " 7836 8360 8499 8690 8938 8981 9258 9431 9595]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "397 [   0   13   17   19   28   29   33   35   42   52   54   72   92  151\n",
            "  163  193  197  199  201  210  216  219  226  230  260  270  271  272\n",
            "  278  279  282  283  291  298  314  317  330  336  344  354  365  384\n",
            "  392  421  422  431  437  468  479  490  495  496  498  500  507  535\n",
            "  537  540  546  553  557  559  567  568  575  580  591  592  594  598\n",
            "  604  607  608  613  618  621  622  623  626  630  634  637  641  644\n",
            "  657  661  691  697  706  708  716  720  728  736  743  757  764  765\n",
            "  776  782  799  802  803  804  806  809  810  816  823  831  839  854\n",
            "  855  874  877  886  887  895  903  905  921  922  923  925  929  942\n",
            "  944  947  950  952  954  963  966  974  987 1009 1017 1018 1039 1044\n",
            " 1047 1050 1071 1083 1088 1103 1112 1115 1126 1142 1156 1174 1175 1198\n",
            " 1216 1221 1230 1231 1255 1256 1260 1271 1296 1304 1308 1320 1378 1414\n",
            " 1423 1431 1438 1445 1450 1474 1475 1489 1502 1508 1516 1519 1531 1534\n",
            " 1550 1553 1555 1563 1577 1597 1671 1684 1686 1695 1700 1702 1710 1747\n",
            " 1773 1807 1810 1811 1830 1853 1879 1884 1896 1905 1907 1914 1933 1949\n",
            " 1950 1962 1979 1992 2011 2029 2030 2036 2056 2064 2071 2075 2105 2107\n",
            " 2144 2153 2158 2172 2185 2190 2209 2213 2243 2255 2260 2269 2276 2398\n",
            " 2425 2441 2451 2461 2466 2479 2485 2532 2533 2536 2550 2571 2603 2609\n",
            " 2633 2679 2701 2722 2759 2760 2769 2869 2936 2958 3010 3029 3034 3043\n",
            " 3081 3090 3091 3111 3138 3139 3163 3171 3183 3254 3269 3306 3319 3350\n",
            " 3400 3411 3428 3482 3494 3521 3526 3591 3600 3613 3624 3733 3791 3805\n",
            " 3811 3830 3927 3931 3935 3968 3988 4012 4016 4036 4060 4116 4123 4242\n",
            " 4339 4465 4479 4562 4578 4669 4763 4851 4855 4859 4923 5045 5067 5084\n",
            " 5240 5261 5294 5301 5311 5371 5378 5437 5442 5464 5506 5523 5587 5648\n",
            " 5725 5820 5825 6045 6114 6117 6215 6326 6352 6367 6439 6510 6586 6620\n",
            " 6772 6806 6874 6945 6960 6962 6997 7081 7097 7139 7143 7166 7231 7302\n",
            " 7318 7339 7402 7405 7455 7486 7532 7730 7836 7904 8009 8031 8078 8186\n",
            " 8216 8260 8360 8499 8690 8938 8981 9028 9192 9258 9282 9431 9465 9595\n",
            " 9610 9671 9702 9755 9895]\n",
            "\n",
            "397 [0.50466895 0.50121933 0.50044817 0.5159179  0.5018902  0.50041384\n",
            " 0.50324976 0.50675625 0.50205606 0.5037968  0.50305307 0.509135\n",
            " 0.5014298  0.5011146  0.50107497 0.5063489  0.5054186  0.50189936\n",
            " 0.500743   0.5087253  0.5026726  0.5050918  0.50057    0.50265884\n",
            " 0.5010323  0.50071675 0.50031286 0.50519466 0.502138   0.50432974\n",
            " 0.50115174 0.50787246 0.50226647 0.5046574  0.5035578  0.501841\n",
            " 0.50006455 0.5009251  0.5044296  0.5026455  0.5002157  0.5011579\n",
            " 0.50799626 0.5029955  0.5008218  0.5009644  0.50084877 0.5007281\n",
            " 0.5043914  0.5000503  0.5038363  0.50076145 0.5065431  0.5026984\n",
            " 0.50765866 0.50470275 0.5040521  0.5003311  0.50009763 0.5032704\n",
            " 0.5107585  0.5019121  0.5070767  0.5036984  0.5048409  0.50072455\n",
            " 0.5001789  0.5357254  0.5062293  0.5004273  0.50427437 0.5011504\n",
            " 0.50208443 0.50003153 0.507405   0.5025868  0.5089303  0.50169766\n",
            " 0.5038063  0.50501204 0.5025916  0.5022424  0.507615   0.5003569\n",
            " 0.5002334  0.5043808  0.50106746 0.50033    0.50545317 0.5070059\n",
            " 0.5006036  0.5009723  0.5004144  0.5014527  0.50076914 0.5037375\n",
            " 0.501507   0.50087    0.50097775 0.5001304  0.5046748  0.5060387\n",
            " 0.50212467 0.5012282  0.50281024 0.5011651  0.50098103 0.500731\n",
            " 0.5312914  0.5024137  0.5103893  0.50475836 0.50254595 0.5014051\n",
            " 0.50052726 0.5017327  0.5006892  0.51218706 0.51151776 0.5162878\n",
            " 0.50259775 0.50486946 0.5056114  0.5109568  0.5005462  0.5000557\n",
            " 0.5022725  0.50106514 0.52256846 0.5064878  0.5016841  0.50208694\n",
            " 0.5026542  0.50617975 0.5012393  0.5061939  0.5026748  0.50202376\n",
            " 0.50202894 0.50122416 0.51826465 0.50237155 0.50013953 0.5006775\n",
            " 0.5005995  0.5003343  0.5002395  0.50343066 0.5024713  0.50172895\n",
            " 0.5026282  0.5006469  0.50080204 0.50332767 0.50276464 0.5057183\n",
            " 0.51426506 0.5052305  0.50338626 0.5007844  0.50065917 0.51713634\n",
            " 0.5011783  0.502727   0.50128376 0.5045032  0.504277   0.50071895\n",
            " 0.5011559  0.5009205  0.5040885  0.50396156 0.5024344  0.50163853\n",
            " 0.5007619  0.5015975  0.5015596  0.50771254 0.5013414  0.50514704\n",
            " 0.50002635 0.5004322  0.50180316 0.5048416  0.5015918  0.5046646\n",
            " 0.5022927  0.50599635 0.5051187  0.50103784 0.5047405  0.5005587\n",
            " 0.500666   0.5016445  0.5001772  0.50067115 0.50356674 0.5040186\n",
            " 0.50018233 0.5017602  0.50023425 0.50204164 0.5002313  0.5007074\n",
            " 0.50022644 0.5004462  0.50147337 0.50003225 0.5148893  0.522741\n",
            " 0.5023598  0.50304836 0.50235337 0.5003769  0.50594366 0.50634164\n",
            " 0.5074218  0.5027815  0.50014293 0.50079393 0.5025008  0.5004148\n",
            " 0.5000896  0.5010216  0.5058843  0.5018866  0.5002907  0.50187474\n",
            " 0.50747216 0.5036378  0.50062513 0.50272495 0.50062114 0.50433517\n",
            " 0.5056916  0.50222725 0.5018619  0.50103855 0.50078815 0.5004127\n",
            " 0.5082933  0.5006837  0.50263226 0.51391214 0.5010051  0.5072273\n",
            " 0.50294966 0.50377476 0.50202006 0.5007289  0.50161815 0.50582623\n",
            " 0.50058556 0.50042593 0.50180054 0.5045115  0.50695425 0.5012239\n",
            " 0.5037509  0.5002851  0.50186265 0.5034491  0.5015669  0.5028257\n",
            " 0.50259835 0.50014347 0.5014253  0.5021777  0.50210595 0.51391286\n",
            " 0.5029094  0.50165164 0.50251603 0.5013357  0.5040689  0.5007181\n",
            " 0.503748   0.5026951  0.50009286 0.50567836 0.5019776  0.50684196\n",
            " 0.500287   0.50111085 0.50087124 0.5005427  0.5014665  0.501439\n",
            " 0.50112647 0.5001232  0.5004454  0.5019766  0.50059545 0.50037944\n",
            " 0.5014289  0.50250727 0.5030019  0.5012928  0.50021666 0.5004795\n",
            " 0.5025706  0.5026688  0.5028772  0.5002019  0.5049397  0.5024797\n",
            " 0.5007539  0.5006743  0.50350696 0.5155469  0.5006785  0.5206904\n",
            " 0.5009227  0.500386   0.500903   0.50452316 0.51099867 0.50424486\n",
            " 0.50671923 0.5018111  0.500024   0.50239    0.500402   0.5026674\n",
            " 0.5003838  0.5350187  0.5309009  0.50068164 0.515812   0.5030621\n",
            " 0.5001688  0.50456834 0.5002276  0.50142634 0.5009789  0.5007596\n",
            " 0.5021015  0.50161225 0.50709903 0.50468886 0.5266449  0.5028165\n",
            " 0.5008465  0.50991935 0.5024155  0.5032438  0.50415164 0.5000576\n",
            " 0.50028664 0.50115055 0.5029578  0.501379   0.5060837  0.50040835\n",
            " 0.500854   0.50079995 0.50165534 0.5016923  0.5004176  0.501431\n",
            " 0.5002933  0.50408596 0.5041958  0.5054791  0.50175637 0.5011295\n",
            " 0.50196683 0.5016378  0.52305037 0.50141823 0.50008863 0.5023857\n",
            " 0.51398253 0.5001058  0.5022554  0.50152    0.50057316 0.50105774\n",
            " 0.5031401  0.502711   0.50400037 0.51016945 0.5223422  0.52275234\n",
            " 0.5175625  0.5023681  0.5023654  0.512468   0.50133175 0.50419295\n",
            " 0.5007382  0.5144692  0.5031781  0.5006681  0.50054944 0.5013073\n",
            " 0.5019464 ]\n",
            "\n",
            "Matched draws\n",
            "Count: 10, Index: (array([ 392,  422, 1475, 1519, 1884, 2030, 3400, 3927, 4116, 6439]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "107279  507220 2020-02-08  ConsolationNo4      422\n",
            "107356  507520 2020-02-15      SpecialNo2      392\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "107199  506820 2020-02-01      SpecialNo6     2030\n",
            "107206  506920 2020-02-02  ConsolationNo1     1519\n",
            "107243  507020 2020-02-04      SpecialNo4     1884\n",
            "107279  507220 2020-02-08  ConsolationNo4      422\n",
            "107289  507220 2020-02-08      SpecialNo4     4116\n",
            "107356  507520 2020-02-15      SpecialNo2      392\n",
            "107385  507620 2020-02-16      SpecialNo8     3400\n",
            "107456  508020 2020-02-26      1stPrizeNo     3927\n",
            "107466  508020 2020-02-26  ConsolationNo7     1475\n",
            "107475  508020 2020-02-26      SpecialNo6     6439\n",
            "\n",
            "-----------2020-02-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(969893, 35) (969893,) (10000, 35) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 937508, 1: 32385})\n",
            "\n",
            "scale_pos_weight - 28.514601821831093\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.514601821831093, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.514601821831093]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.467, F-Score=0.06200\n",
            "\n",
            "Recall: 0.022082018927444796\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.97      0.02      0.97      0.15      0.02      9683\n",
            "          1       0.03      0.02      0.97      0.02      0.15      0.02       317\n",
            "\n",
            "avg / total       0.94      0.94      0.05      0.94      0.15      0.02     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHDhusbfPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.022082</td>\n",
              "      <td>0.973046</td>\n",
              "      <td>0.0122747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity   Optimize\n",
              "XGBClassifier_optimize            0    0.022082         0.973046  0.0122747"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 268 \n",
            "\n",
            "First 23 matches\n",
            "23 [  0  19  28  33  35  42  52  54  72  92 193 197 199 210 216 219 230 272\n",
            " 278 279 282 283 291]\n",
            "\n",
            "[0.5037264  0.51485854 0.5006792  0.50202405 0.5053965  0.5007985\n",
            " 0.5025833  0.50194377 0.5080435  0.5001159  0.5051583  0.50429475\n",
            " 0.5009126  0.5074442  0.50023603 0.5039982  0.5017511  0.5042721\n",
            " 0.50109684 0.502961   0.50023156 0.5068986  0.50118834]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[3111 2479 1933 9595 1230 5378 1271 5311 1047 6114  823 8981 5301 4562\n",
            "   19  592 7455  950 4465 1949  905 8690 8938]\n",
            "\n",
            "\n",
            "[0.51284415 0.51301795 0.5133393  0.51334083 0.51355004 0.5142503\n",
            " 0.51598793 0.5298046  0.5171957  0.5250701  0.5296496  0.51655143\n",
            " 0.533963   0.5189888  0.51485854 0.5346791  0.52201694 0.5216755\n",
            " 0.51452464 0.5216522  0.5151018  0.52068555 0.52105194]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "90 [ 19  28  33  35  42  52  54  72  92 193 197 199 210 216 219 230 272 278\n",
            " 279 282 283 291 298 314 317 344 354 384 392 421 479 495 498 500 507 535\n",
            " 537 553 557 559 567 568 575 592 594 604 607 608 618 621 622 623 626 630\n",
            " 634 637 641 661 691 706 708 736 757 764 799 802 803 806 823 831 839 854\n",
            " 855 874 886 895 903 905 921 922 923 925 944 950 952 954 963 966 974 987]\n",
            "\n",
            "[0.51485854 0.5006792  0.50202405 0.5053965  0.5007985  0.5025833\n",
            " 0.50194377 0.5080435  0.5001159  0.5051583  0.50429475 0.5009126\n",
            " 0.5074442  0.50023603 0.5039982  0.5017511  0.5042721  0.50109684\n",
            " 0.502961   0.50023156 0.5068986  0.50118834 0.50361425 0.50265473\n",
            " 0.5005391  0.50358504 0.50161195 0.5000574  0.5067157  0.5015236\n",
            " 0.5032833  0.5024768  0.50527966 0.5017664  0.5063115  0.5036106\n",
            " 0.5028567  0.5021723  0.5098512  0.5009068  0.5060862  0.50250024\n",
            " 0.5035279  0.5346791  0.5049822  0.5032776  0.5000215  0.50098056\n",
            " 0.5073647  0.5015111  0.5078291  0.5004674  0.502787   0.5039851\n",
            " 0.5012429  0.5010386  0.50650305 0.50315386 0.5001395  0.5042741\n",
            " 0.50552714 0.5002042  0.50264376 0.50015926 0.50349563 0.50504607\n",
            " 0.5010811  0.50160056 0.5296496  0.5014215  0.50952226 0.50354594\n",
            " 0.501252   0.5001911  0.5004906  0.5110942  0.51052845 0.5151018\n",
            " 0.5016305  0.50377536 0.5043687  0.5098703  0.50104713 0.5216755\n",
            " 0.5054935  0.5005377  0.5008939  0.50262564 0.5050912  0.50004363]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.504351794719696\n",
            "\n",
            "68 [  19   35   72  193  210  283  392  498  507  557  567  592  594  618\n",
            "  622  641  708  802  823  839  895  903  905  923  925  950  952  974\n",
            " 1009 1047 1230 1271 1508 1597 1933 1949 2011 2029 2030 2144 2185 2260\n",
            " 2451 2479 2532 2609 2759 3111 3350 3411 4465 4562 4855 4923 5301 5311\n",
            " 5378 6114 6326 6874 7455 7836 8499 8690 8938 8981 9258 9595]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.504052460193634\n",
            "\n",
            "74 [  19   35   72  193  197  210  272  283  392  498  507  557  567  592\n",
            "  594  618  622  641  706  708  802  823  839  895  903  905  923  925\n",
            "  950  952  974 1009 1047 1221 1230 1231 1271 1508 1597 1671 1933 1949\n",
            " 2011 2029 2030 2144 2185 2260 2451 2479 2532 2609 2759 3111 3350 3411\n",
            " 4465 4562 4855 4923 5301 5311 5378 6114 6326 6874 7455 7836 8499 8690\n",
            " 8938 8981 9258 9595]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "268 [   0   19   28   33   35   42   52   54   72   92  193  197  199  210\n",
            "  216  219  230  272  278  279  282  283  291  298  314  317  344  354\n",
            "  384  392  421  479  495  498  500  507  535  537  553  557  559  567\n",
            "  568  575  592  594  604  607  608  618  621  622  623  626  630  634\n",
            "  637  641  661  691  706  708  736  757  764  799  802  803  806  823\n",
            "  831  839  854  855  874  886  895  903  905  921  922  923  925  944\n",
            "  950  952  954  963  966  974  987 1009 1017 1018 1039 1044 1047 1050\n",
            " 1115 1126 1142 1156 1198 1216 1221 1230 1231 1255 1271 1296 1304 1308\n",
            " 1320 1378 1438 1445 1450 1474 1489 1502 1508 1516 1519 1550 1553 1555\n",
            " 1563 1577 1597 1671 1684 1686 1702 1773 1807 1811 1853 1907 1933 1949\n",
            " 1950 1962 1979 2011 2029 2030 2036 2071 2107 2144 2153 2172 2185 2190\n",
            " 2213 2255 2260 2269 2276 2451 2466 2479 2532 2533 2536 2550 2603 2609\n",
            " 2701 2722 2759 2760 2769 2936 2958 3010 3029 3034 3081 3090 3091 3111\n",
            " 3138 3139 3163 3171 3183 3269 3306 3350 3400 3411 3482 3526 3591 3600\n",
            " 3733 3811 3830 3927 3988 4012 4016 4060 4116 4339 4465 4562 4851 4855\n",
            " 4859 4923 5045 5084 5261 5301 5311 5378 5437 5464 5523 5587 5725 5820\n",
            " 5825 6045 6114 6117 6326 6352 6367 6439 6620 6772 6806 6874 6997 7081\n",
            " 7139 7166 7231 7302 7318 7402 7405 7455 7486 7730 7836 8009 8031 8186\n",
            " 8216 8260 8360 8499 8690 8938 8981 9028 9192 9258 9282 9431 9595 9610\n",
            " 9755 9895]\n",
            "\n",
            "268 [0.5037264  0.51485854 0.5006792  0.50202405 0.5053965  0.5007985\n",
            " 0.5025833  0.50194377 0.5080435  0.5001159  0.5051583  0.50429475\n",
            " 0.5009126  0.5074442  0.50023603 0.5039982  0.5017511  0.5042721\n",
            " 0.50109684 0.502961   0.50023156 0.5068986  0.50118834 0.50361425\n",
            " 0.50265473 0.5005391  0.50358504 0.50161195 0.5000574  0.5067157\n",
            " 0.5015236  0.5032833  0.5024768  0.50527966 0.5017664  0.5063115\n",
            " 0.5036106  0.5028567  0.5021723  0.5098512  0.5009068  0.5060862\n",
            " 0.50250024 0.5035279  0.5346791  0.5049822  0.5032776  0.5000215\n",
            " 0.50098056 0.5073647  0.5015111  0.5078291  0.5004674  0.502787\n",
            " 0.5039851  0.5012429  0.5010386  0.50650305 0.50315386 0.5001395\n",
            " 0.5042741  0.50552714 0.5002042  0.50264376 0.50015926 0.50349563\n",
            " 0.50504607 0.5010811  0.50160056 0.5296496  0.5014215  0.50952226\n",
            " 0.50354594 0.501252   0.5001911  0.5004906  0.5110942  0.51052845\n",
            " 0.5151018  0.5016305  0.50377536 0.5043687  0.5098703  0.50104713\n",
            " 0.5216755  0.5054935  0.5005377  0.5008939  0.50262564 0.5050912\n",
            " 0.50004363 0.50517243 0.5015883  0.500861   0.5009621  0.5003186\n",
            " 0.5171957  0.50127685 0.5023062  0.501105   0.50072014 0.5011469\n",
            " 0.50208414 0.5016828  0.50434184 0.51355004 0.50425583 0.5021903\n",
            " 0.51598793 0.5000558  0.5017332  0.50029325 0.5032579  0.5034554\n",
            " 0.5029194  0.502698   0.501476   0.500188   0.50057477 0.5004781\n",
            " 0.50665325 0.5000748  0.5039605  0.50089407 0.50359666 0.50036204\n",
            " 0.50357676 0.5009177  0.5049237  0.50409526 0.50013524 0.5036852\n",
            " 0.5007567  0.5024758  0.5029462  0.5006938  0.50097084 0.50012887\n",
            " 0.5133393  0.5216522  0.501166   0.50196373 0.50126326 0.5048677\n",
            " 0.50517935 0.50634885 0.5016936  0.5014127  0.500047   0.50487816\n",
            " 0.50079894 0.5007052  0.50650406 0.50256884 0.5013321  0.50319767\n",
            " 0.5048068  0.5012332  0.5007377  0.5068042  0.50166214 0.51301795\n",
            " 0.50615364 0.5017063  0.50252295 0.5009962  0.5004243  0.5048347\n",
            " 0.50055987 0.50363284 0.50584143 0.50015783 0.5027765  0.50077516\n",
            " 0.50232476 0.5007239  0.5017365  0.5015104  0.50030154 0.500984\n",
            " 0.5009818  0.51284415 0.5019166  0.50064754 0.5014951  0.5002627\n",
            " 0.50319195 0.5026637  0.5014708  0.5046779  0.50090444 0.5057694\n",
            " 0.50001997 0.5005966  0.5004344  0.5000371  0.501001   0.5003389\n",
            " 0.5011959  0.5019199  0.5005099  0.5015952  0.5017871  0.5039224\n",
            " 0.5011679  0.50243384 0.51452464 0.5189888  0.5036351  0.5099301\n",
            " 0.50335497 0.50564605 0.5006604  0.50142515 0.5016048  0.533963\n",
            " 0.5298046  0.5142503  0.5021782  0.50319296 0.5004055  0.50009596\n",
            " 0.50090826 0.5006184  0.5017481  0.50378025 0.5250701  0.50185466\n",
            " 0.508805   0.50145316 0.5022563  0.5035326  0.50018084 0.5018845\n",
            " 0.50028735 0.50482196 0.5003064  0.5004988  0.50029427 0.50311553\n",
            " 0.50329125 0.5039963  0.5003667  0.50090045 0.50039923 0.52201694\n",
            " 0.5003225  0.5014147  0.5126655  0.5013618  0.5004338  0.5000334\n",
            " 0.5018172  0.5016164  0.5003634  0.5092106  0.52068555 0.52105194\n",
            " 0.51655143 0.50139785 0.50154126 0.51136756 0.50025797 0.50313914\n",
            " 0.51334083 0.50176495 0.50003093 0.5005924 ]\n",
            "\n",
            "Matched draws\n",
            "Count: 7, Index: (array([ 392, 1519, 2030, 3400, 3927, 4116, 6439]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "107356  507520 2020-02-15  SpecialNo2      392\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "107199  506820 2020-02-01      SpecialNo6     2030\n",
            "107206  506920 2020-02-02  ConsolationNo1     1519\n",
            "107289  507220 2020-02-08      SpecialNo4     4116\n",
            "107356  507520 2020-02-15      SpecialNo2      392\n",
            "107385  507620 2020-02-16      SpecialNo8     3400\n",
            "107456  508020 2020-02-26      1stPrizeNo     3927\n",
            "107475  508020 2020-02-26      SpecialNo6     6439\n",
            "\n",
            "-----------2020-02-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(969893, 35) (969893,) (10000, 35) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 937508, 1: 32385})\n",
            "\n",
            "scale_pos_weight - 28.369857650146674\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.369857650146674, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.369857650146674]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.473, F-Score=0.06207\n",
            "\n",
            "Recall: 0.01892744479495268\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.98      0.02      0.97      0.14      0.02      9683\n",
            "          1       0.03      0.02      0.98      0.02      0.14      0.02       317\n",
            "\n",
            "avg / total       0.94      0.95      0.05      0.94      0.14      0.02     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0189274</td>\n",
              "      <td>0.981101</td>\n",
              "      <td>0.0113621</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity   Optimize\n",
              "XGBClassifier_optimize            0   0.0189274         0.981101  0.0113621"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 189 \n",
            "\n",
            "First 23 matches\n",
            "23 [  0  19  33  35  52  54  72 193 197 199 210 219 230 272 278 279 283 291\n",
            " 298 314 344 354 392]\n",
            "\n",
            "[0.5026831  0.51371413 0.5008936  0.50436944 0.50161964 0.5007517\n",
            " 0.5070148  0.504169   0.5035882  0.5000481  0.506377   0.5029531\n",
            " 0.50064653 0.50324476 0.5001331  0.50201815 0.50590396 0.5002816\n",
            " 0.5025079  0.50170094 0.5024789  0.50063425 0.5056466 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[2479 7836 9595 1230 1933   19 5378 1047 1271  950 8981 5311 1949  823\n",
            " 7455 8938 8690  592 4465 6114 4562 5301  905]\n",
            "\n",
            "\n",
            "[0.5119231  0.51192534 0.51226074 0.5124315  0.5131332  0.51371413\n",
            " 0.514036   0.51606524 0.51529014 0.52093595 0.5165708  0.52972037\n",
            " 0.52125996 0.5295752  0.5213164  0.5203272  0.52061284 0.5339763\n",
            " 0.5143027  0.5245956  0.51859534 0.5332186  0.5149112 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "69 [ 19  33  35  52  54  72 193 197 199 210 219 230 272 278 279 283 291 298\n",
            " 314 344 354 392 421 479 495 498 500 507 535 537 553 557 559 567 568 575\n",
            " 592 594 604 618 621 622 626 630 634 641 661 706 708 757 799 802 806 823\n",
            " 831 839 854 855 895 903 905 921 922 923 925 950 952 966 974]\n",
            "\n",
            "[0.51371413 0.5008936  0.50436944 0.50161964 0.5007517  0.5070148\n",
            " 0.504169   0.5035882  0.5000481  0.506377   0.5029531  0.50064653\n",
            " 0.50324476 0.5001331  0.50201815 0.50590396 0.5002816  0.5025079\n",
            " 0.50170094 0.5024789  0.50063425 0.5056466  0.500593   0.50217885\n",
            " 0.50155246 0.50421065 0.5003257  0.50534475 0.502759   0.501866\n",
            " 0.5012846  0.50874716 0.5001876  0.5050534  0.50143254 0.50253457\n",
            " 0.5339763  0.5040302  0.50212944 0.50622815 0.50043297 0.50688714\n",
            " 0.5017589  0.5032858  0.50007635 0.50536627 0.5020502  0.5033689\n",
            " 0.5046     0.5014518  0.5024269  0.5040428  0.50074935 0.5295752\n",
            " 0.50046664 0.50841665 0.5026938  0.5005521  0.51016486 0.5094967\n",
            " 0.5149112  0.5005245  0.5027054  0.5033193  0.50888234 0.52093595\n",
            " 0.5045474  0.50184643 0.5041485 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.504562497138977\n",
            "\n",
            "50 [  19   72  210  283  392  507  557  567  592  618  622  641  708  823\n",
            "  839  895  903  905  925  950 1047 1230 1271 1508 1933 1949 2030 2185\n",
            " 2451 2479 2532 2759 3111 3411 4465 4562 4855 5301 5311 5378 6114 6326\n",
            " 7455 7836 8499 8690 8938 8981 9258 9595]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5045830011367798\n",
            "\n",
            "50 [  19   72  210  283  392  507  557  567  592  618  622  641  708  823\n",
            "  839  895  903  905  925  950 1047 1230 1271 1508 1933 1949 2030 2185\n",
            " 2451 2479 2532 2759 3111 3411 4465 4562 4855 5301 5311 5378 6114 6326\n",
            " 7455 7836 8499 8690 8938 8981 9258 9595]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "189 [   0   19   33   35   52   54   72  193  197  199  210  219  230  272\n",
            "  278  279  283  291  298  314  344  354  392  421  479  495  498  500\n",
            "  507  535  537  553  557  559  567  568  575  592  594  604  618  621\n",
            "  622  626  630  634  641  661  706  708  757  799  802  806  823  831\n",
            "  839  854  855  895  903  905  921  922  923  925  950  952  966  974\n",
            " 1009 1017 1047 1050 1115 1156 1198 1216 1221 1230 1231 1255 1271 1304\n",
            " 1320 1378 1438 1445 1450 1508 1519 1550 1553 1563 1597 1671 1686 1773\n",
            " 1807 1933 1949 1950 1962 1979 2011 2029 2030 2036 2071 2144 2185 2190\n",
            " 2213 2255 2260 2269 2451 2466 2479 2532 2533 2536 2609 2722 2759 2769\n",
            " 2958 3029 3034 3090 3111 3138 3163 3183 3269 3306 3350 3411 3591 3733\n",
            " 3830 3927 4012 4016 4060 4116 4339 4465 4562 4851 4855 4859 4923 5084\n",
            " 5261 5301 5311 5378 5437 5464 5825 6045 6114 6117 6326 6352 6367 6439\n",
            " 6772 6874 7166 7231 7302 7455 7730 7836 8009 8216 8260 8499 8690 8938\n",
            " 8981 9028 9192 9258 9431 9595 9610]\n",
            "\n",
            "189 [0.5026831  0.51371413 0.5008936  0.50436944 0.50161964 0.5007517\n",
            " 0.5070148  0.504169   0.5035882  0.5000481  0.506377   0.5029531\n",
            " 0.50064653 0.50324476 0.5001331  0.50201815 0.50590396 0.5002816\n",
            " 0.5025079  0.50170094 0.5024789  0.50063425 0.5056466  0.500593\n",
            " 0.50217885 0.50155246 0.50421065 0.5003257  0.50534475 0.502759\n",
            " 0.501866   0.5012846  0.50874716 0.5001876  0.5050534  0.50143254\n",
            " 0.50253457 0.5339763  0.5040302  0.50212944 0.50622815 0.50043297\n",
            " 0.50688714 0.5017589  0.5032858  0.50007635 0.50536627 0.5020502\n",
            " 0.5033689  0.5046     0.5014518  0.5024269  0.5040428  0.50074935\n",
            " 0.5295752  0.50046664 0.50841665 0.5026938  0.5005521  0.51016486\n",
            " 0.5094967  0.5149112  0.5005245  0.5027054  0.5033193  0.50888234\n",
            " 0.52093595 0.5045474  0.50184643 0.5041485  0.5040685  0.50046045\n",
            " 0.51606524 0.500274   0.50123703 0.50021976 0.50104946 0.5006431\n",
            " 0.50324243 0.5124315  0.50331044 0.50123817 0.51529014 0.5007666\n",
            " 0.5021915  0.5023666  0.5018808  0.50163114 0.5003731  0.505763\n",
            " 0.50292933 0.5000046  0.5024717  0.50238466 0.50399446 0.50298655\n",
            " 0.502942   0.50136834 0.50201625 0.5131332  0.52125996 0.5001999\n",
            " 0.5008643  0.5002323  0.50377023 0.5043144  0.5052643  0.50058854\n",
            " 0.50041974 0.5040926  0.5055637  0.501644   0.500406   0.5021702\n",
            " 0.50370467 0.5003439  0.50538224 0.50065243 0.5119231  0.5050668\n",
            " 0.50076324 0.50140435 0.50382924 0.5025265  0.50466096 0.5016416\n",
            " 0.501254   0.50063133 0.5004407  0.5000187  0.51175004 0.50107205\n",
            " 0.50046444 0.5021161  0.5015625  0.50040156 0.5036442  0.50468177\n",
            " 0.50022995 0.50014645 0.50018543 0.50074726 0.50070536 0.5006787\n",
            " 0.50266826 0.5001381  0.5013495  0.5143027  0.51859534 0.502528\n",
            " 0.5088374  0.50224483 0.50454485 0.5003212  0.5002776  0.5332186\n",
            " 0.52972037 0.514036   0.50107837 0.5020903  0.50102    0.50266945\n",
            " 0.5245956  0.5007584  0.507696   0.50035673 0.5012566  0.50253946\n",
            " 0.5009545  0.50350666 0.5020824  0.5021365  0.50257987 0.5213164\n",
            " 0.50026053 0.51192534 0.50025797 0.5009425  0.5005864  0.5080625\n",
            " 0.52061284 0.5203272  0.5165708  0.50036633 0.5004449  0.5114858\n",
            " 0.50217116 0.51226074 0.50084233]\n",
            "\n",
            "Matched draws\n",
            "Count: 6, Index: (array([ 392, 1519, 2030, 3927, 4116, 6439]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "107356  507520 2020-02-15  SpecialNo2      392\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "107356  507520 2020-02-15  SpecialNo2      392\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "107199  506820 2020-02-01      SpecialNo6     2030\n",
            "107206  506920 2020-02-02  ConsolationNo1     1519\n",
            "107289  507220 2020-02-08      SpecialNo4     4116\n",
            "107356  507520 2020-02-15      SpecialNo2      392\n",
            "107456  508020 2020-02-26      1stPrizeNo     3927\n",
            "107475  508020 2020-02-26      SpecialNo6     6439\n",
            "\n",
            "-----------2020-02-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(969893, 35) (969893,) (10000, 35) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 937508, 1: 32385})\n",
            "\n",
            "scale_pos_weight - 28.22511347846225\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.22511347846225, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.22511347846225]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.472, F-Score=0.06204\n",
            "\n",
            "Recall: 0.015772870662460567\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.99      0.02      0.98      0.12      0.02      9683\n",
            "          1       0.04      0.02      0.99      0.02      0.12      0.01       317\n",
            "\n",
            "avg / total       0.94      0.96      0.05      0.95      0.12      0.02     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvwmRLasRW1IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0157729</td>\n",
              "      <td>0.986884</td>\n",
              "      <td>0.00999514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity    Optimize\n",
              "XGBClassifier_optimize            0   0.0157729         0.986884  0.00999514"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 132 \n",
            "\n",
            "First 23 matches\n",
            "23 [  0  19  28  35  42  52  72 193 197 210 219 272 279 283 298 314 344 392\n",
            " 479 495 498 507 535]\n",
            "\n",
            "[0.5015638  0.5126757  0.50015795 0.5046991  0.50030583 0.5004971\n",
            " 0.5058934  0.5030491  0.5024115  0.5052559  0.50183064 0.502124\n",
            " 0.500896   0.5047813  0.50138617 0.5005238  0.5013576  0.5045259\n",
            " 0.50105953 0.50043416 0.50308925 0.50422233 0.50158966]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[2479 9595 1230 3111 1933 5378 4465   19  905 8938 8981 1271 1047  950\n",
            " 7455 8690  823  592 1949 4562 5301 5311 6114]\n",
            "\n",
            "\n",
            "[0.5108397  0.51110816 0.51132095 0.5114181  0.51202744 0.51291823\n",
            " 0.51317257 0.5126757  0.51382565 0.51925945 0.5154526  0.5141637\n",
            " 0.51495534 0.51985306 0.5210246  0.51949227 0.52845865 0.53290856\n",
            " 0.5209737  0.5174692  0.53214276 0.5285992  0.52346396]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "55 [ 19  28  35  42  52  72 193 197 210 219 272 279 283 298 314 344 392 479\n",
            " 495 498 507 535 537 553 557 567 568 575 592 594 604 618 622 626 630 641\n",
            " 661 706 708 757 799 802 823 839 854 895 903 905 922 923 925 950 952 966\n",
            " 974]\n",
            "\n",
            "[0.5126757  0.50015795 0.5046991  0.50030583 0.5004971  0.5058934\n",
            " 0.5030491  0.5024115  0.5052559  0.50183064 0.502124   0.500896\n",
            " 0.5047813  0.50138617 0.5005238  0.5013576  0.5045259  0.50105953\n",
            " 0.50043416 0.50308925 0.50422233 0.50158966 0.5007438  0.500164\n",
            " 0.5076284  0.5039314  0.5003111  0.5014134  0.53290856 0.5028581\n",
            " 0.501007   0.5050793  0.505732   0.5006401  0.5021645  0.50424635\n",
            " 0.5009314  0.50224656 0.5034296  0.5002794  0.501304   0.50292116\n",
            " 0.52845865 0.5073113  0.50152415 0.5090432  0.5083755  0.51382565\n",
            " 0.50158405 0.50219685 0.5077664  0.51985306 0.5034262  0.5007085\n",
            " 0.5030275 ]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5045419335365295\n",
            "\n",
            "40 [  19   35   72  210  283  557  592  618  622  823  839  895  903  905\n",
            "  925  950 1047 1230 1271 1508 1933 1949 2479 3111 4465 4562 4855 5301\n",
            " 5311 5378 6114 6326 7455 7836 8499 8690 8938 8981 9258 9595]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5052757859230042\n",
            "\n",
            "35 [  19   72  557  592  622  823  839  895  903  905  925  950 1047 1230\n",
            " 1271 1933 1949 2479 3111 4465 4562 4855 5301 5311 5378 6114 6326 7455\n",
            " 7836 8499 8690 8938 8981 9258 9595]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "132 [   0   19   28   35   42   52   72  193  197  210  219  272  279  283\n",
            "  298  314  344  392  479  495  498  507  535  537  553  557  567  568\n",
            "  575  592  594  604  618  622  626  630  641  661  706  708  757  799\n",
            "  802  823  839  854  895  903  905  922  923  925  950  952  966  974\n",
            " 1009 1047 1115 1221 1230 1231 1255 1271 1320 1378 1438 1445 1508 1519\n",
            " 1553 1563 1597 1671 1686 1773 1807 1933 1949 2011 2029 2030 2144 2185\n",
            " 2190 2255 2260 2451 2479 2532 2536 2609 2722 2759 2769 2958 3111 3183\n",
            " 3269 3350 3411 3927 4060 4339 4465 4562 4851 4855 4859 4923 5301 5311\n",
            " 5378 5464 6045 6114 6326 6367 6439 6874 7166 7231 7302 7455 7836 8499\n",
            " 8690 8938 8981 9258 9431 9595]\n",
            "\n",
            "132 [0.5015638  0.5126757  0.50015795 0.5046991  0.50030583 0.5004971\n",
            " 0.5058934  0.5030491  0.5024115  0.5052559  0.50183064 0.502124\n",
            " 0.500896   0.5047813  0.50138617 0.5005238  0.5013576  0.5045259\n",
            " 0.50105953 0.50043416 0.50308925 0.50422233 0.50158966 0.5007438\n",
            " 0.500164   0.5076284  0.5039314  0.5003111  0.5014134  0.53290856\n",
            " 0.5028581  0.501007   0.5050793  0.505732   0.5006401  0.5021645\n",
            " 0.50424635 0.5009314  0.50224656 0.5034296  0.5002794  0.501304\n",
            " 0.50292116 0.52845865 0.5073113  0.50152415 0.5090432  0.5083755\n",
            " 0.51382565 0.50158405 0.50219685 0.5077664  0.51985306 0.5034262\n",
            " 0.5007085  0.5030275  0.50294876 0.51495534 0.5001141  0.50213677\n",
            " 0.51132095 0.502189   0.50006706 0.5141637  0.50107044 0.5012455\n",
            " 0.5007205  0.50050914 0.5046403  0.50180846 0.5013525  0.50121623\n",
            " 0.5028719  0.5018644  0.5018228  0.50024575 0.50089455 0.51202744\n",
            " 0.5209737  0.50265956 0.50321585 0.5041516  0.50297034 0.50444347\n",
            " 0.5005409  0.5010265  0.50258803 0.50427645 0.5108397  0.5039019\n",
            " 0.50029296 0.5027276  0.5014155  0.5035042  0.5005209  0.500131\n",
            " 0.5114181  0.5010053  0.50044626 0.50252396 0.503569   0.50041145\n",
            " 0.50152266 0.50023687 0.51317257 0.5174692  0.5014076  0.507732\n",
            " 0.5011227  0.50343794 0.53214276 0.5285992  0.51291823 0.50098443\n",
            " 0.50154746 0.52346396 0.50654566 0.5001402  0.5014182  0.5023929\n",
            " 0.50096005 0.50101423 0.50148016 0.5210246  0.51083916 0.5069497\n",
            " 0.51949227 0.51925945 0.5154526  0.5103707  0.5010824  0.51110816]\n",
            "\n",
            "Matched draws\n",
            "Count: 5, Index: (array([ 392, 1519, 2030, 3927, 6439]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "107356  507520 2020-02-15  SpecialNo2      392\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "107356  507520 2020-02-15  SpecialNo2      392\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "107199  506820 2020-02-01      SpecialNo6     2030\n",
            "107206  506920 2020-02-02  ConsolationNo1     1519\n",
            "107356  507520 2020-02-15      SpecialNo2      392\n",
            "107456  508020 2020-02-26      1stPrizeNo     3927\n",
            "107475  508020 2020-02-26      SpecialNo6     6439\n",
            "\n",
            "-----------2020-02-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(969893, 35) (969893,) (10000, 35) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 937508, 1: 32385})\n",
            "\n",
            "scale_pos_weight - 28.08036930677783\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.08036930677783, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.08036930677783]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.471, F-Score=0.06201\n",
            "\n",
            "Recall: 0.012618296529968454\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.99      0.01      0.98      0.11      0.01      9683\n",
            "          1       0.04      0.01      0.99      0.02      0.11      0.01       317\n",
            "\n",
            "avg / total       0.94      0.96      0.04      0.95      0.11      0.01     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwBaCBABgC0ECALDlfwEk9Lg0beTffQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0126183</td>\n",
              "      <td>0.990602</td>\n",
              "      <td>0.00821505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity    Optimize\n",
              "XGBClassifier_optimize            0   0.0126183         0.990602  0.00821505"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 95 \n",
            "\n",
            "First 23 matches\n",
            "23 [  0  19  35  72 193 197 210 219 272 283 298 344 392 498 507 535 557 567\n",
            " 575 592 594 618 622]\n",
            "\n",
            "[0.50043935 0.512902   0.5036652  0.5047664  0.5019232  0.5012859\n",
            " 0.50421894 0.5007025  0.5009978  0.50365263 0.5002581  0.50023043\n",
            " 0.50339854 0.50196207 0.50309366 0.500465   0.5065037  0.50280297\n",
            " 0.50028545 0.533104   0.5018183  0.5040611  0.5047098 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[3111 9258 7836 8981  592 5378 1949 2479 1933  823 7455  905 4465 4562\n",
            "   19 5311 5301 8938 1047 6114 8690 1271  950]\n",
            "\n",
            "\n",
            "[0.51030195 0.5105709  0.51102036 0.5156511  0.533104   0.51311576\n",
            " 0.5211716  0.51102304 0.51223683 0.5286561  0.52122253 0.5141427\n",
            " 0.51335937 0.51766205 0.512902   0.52878916 0.532329   0.5194636\n",
            " 0.5138369  0.5236508  0.51968837 0.51435685 0.52003706]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "40 [ 19  35  72 193 197 210 219 272 283 298 344 392 498 507 535 557 567 575\n",
            " 592 594 618 622 630 641 706 708 799 802 823 839 854 895 903 905 922 923\n",
            " 925 950 952 974]\n",
            "\n",
            "[0.512902   0.5036652  0.5047664  0.5019232  0.5012859  0.50421894\n",
            " 0.5007025  0.5009978  0.50365263 0.5002581  0.50023043 0.50339854\n",
            " 0.50196207 0.50309366 0.500465   0.5065037  0.50280297 0.50028545\n",
            " 0.533104   0.5018183  0.5040611  0.5047098  0.5010363  0.5031187\n",
            " 0.50111824 0.50239366 0.50017476 0.5017939  0.5286561  0.5034951\n",
            " 0.50039923 0.5079151  0.5072475  0.5141427  0.50045615 0.5010679\n",
            " 0.506643   0.52003706 0.5022973  0.50190055]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.5050175189971924\n",
            "\n",
            "31 [  19  557  592  823  895  903  905  925  950 1047 1230 1271 1933 1949\n",
            " 2479 3111 4465 4562 5301 5311 5378 6114 6326 7455 7836 8499 8690 8938\n",
            " 8981 9258 9595]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5061960816383362\n",
            "\n",
            "29 [  19  557  592  823  895  903  905  925  950 1047 1230 1271 1933 1949\n",
            " 2479 3111 4465 4562 5301 5311 5378 6114 7455 7836 8690 8938 8981 9258\n",
            " 9595]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "95 [   0   19   35   72  193  197  210  219  272  283  298  344  392  498\n",
            "  507  535  557  567  575  592  594  618  622  630  641  706  708  799\n",
            "  802  823  839  854  895  903  905  922  923  925  950  952  974 1009\n",
            " 1047 1221 1230 1231 1271 1378 1508 1519 1553 1563 1597 1671 1686 1933\n",
            " 1949 2011 2029 2030 2144 2185 2260 2451 2479 2532 2609 2722 2759 3111\n",
            " 3350 3411 4060 4465 4562 4851 4855 4923 5301 5311 5378 5825 6045 6114\n",
            " 6326 6439 6874 7455 7836 8499 8690 8938 8981 9258 9595]\n",
            "\n",
            "95 [0.50043935 0.512902   0.5036652  0.5047664  0.5019232  0.5012859\n",
            " 0.50421894 0.5007025  0.5009978  0.50365263 0.5002581  0.50023043\n",
            " 0.50339854 0.50196207 0.50309366 0.500465   0.5065037  0.50280297\n",
            " 0.50028545 0.533104   0.5018183  0.5040611  0.5047098  0.5010363\n",
            " 0.5031187  0.50111824 0.50239366 0.50017476 0.5017939  0.5286561\n",
            " 0.5034951  0.50039923 0.5079151  0.5072475  0.5141427  0.50045615\n",
            " 0.5010679  0.506643   0.52003706 0.5022973  0.50190055 0.5018229\n",
            " 0.5138369  0.5010253  0.5102029  0.50105995 0.51435685 0.50011784\n",
            " 0.5035111  0.5006814  0.50022626 0.5000913  0.5017428  0.5007358\n",
            " 0.50069684 0.51223683 0.5211716  0.5009854  0.5015551  0.5030325\n",
            " 0.5018414  0.5033173  0.50146514 0.50260705 0.51102304 0.5027814\n",
            " 0.5016181  0.50029886 0.50238925 0.51030195 0.501397   0.50244933\n",
            " 0.5004187  0.51335937 0.51766205 0.5002814  0.50391495 0.5017669\n",
            " 0.532329   0.52878916 0.51311576 0.50121367 0.5005095  0.5236508\n",
            " 0.50543845 0.5002902  0.50127274 0.52122253 0.51102036 0.5052743\n",
            " 0.51968837 0.5194636  0.5156511  0.5105709  0.5100009 ]\n",
            "\n",
            "Matched draws\n",
            "Count: 4, Index: (array([ 392, 1519, 2030, 6439]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "107356  507520 2020-02-15  SpecialNo2      392\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "107356  507520 2020-02-15  SpecialNo2      392\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "107199  506820 2020-02-01      SpecialNo6     2030\n",
            "107206  506920 2020-02-02  ConsolationNo1     1519\n",
            "107356  507520 2020-02-15      SpecialNo2      392\n",
            "107475  508020 2020-02-26      SpecialNo6     6439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SC8YG8P_ljs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "532d2900-d2ff-4614-c972-00e38bdae152"
      },
      "source": [
        "weight=1.0\n",
        "decrement = 0.000\n",
        "to_stop=False\n",
        "\n",
        "dt = pd.datetime(2020,3,1)\n",
        "%time gen_train_test_set(dt, feature_matrix_selection, file_prefix='test')\n",
        "while not to_stop:\n",
        "  to_stop = model(dt, feature_matrix_selection, file_prefix='test', class_weight=(weight-decrement))\n",
        "  decrement = decrement + 0.00"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 979893 observations.\n",
            "Testing on 10000 observations.\n",
            "\n",
            "Data shape before balancing: (979893, 63)\n",
            "\n",
            "Counts of strikes vs non-strikes in previous data:\n",
            "0    947191\n",
            "1     32702\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "\n",
            "NO balancing\n",
            "Data shape after balancing: (979893, 63)\n",
            "\n",
            "Counts of strikes VS non-strikes in new data:\n",
            "0    947191\n",
            "1     32702\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Filtering features\n",
            "\n",
            "Data shape before feature selection: (979893, 63)\n",
            "\n",
            "Counts of strikes vs non-strikes before feature selection:\n",
            "0    947191\n",
            "1     32702\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "\n",
            "Data shape after feature selection: (979893, 35)\n",
            "\n",
            "Counts of strikes vs non-strikes in new data:\n",
            "0    947191\n",
            "1     32702\n",
            "Name: Label, dtype: int64\n",
            "CPU times: user 12.4 s, sys: 168 ms, total: 12.6 s\n",
            "Wall time: 17.1 s\n",
            "\n",
            "-----------2020-03-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(979893, 34) (979893,) (10000, 34) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 947191, 1: 32702})\n",
            "\n",
            "scale_pos_weight - 28.964314109228795\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.964314109228795, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.964314109228795]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.000, F-Score=0.00000\n",
            "\n",
            "Recall: 0.0\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
            "          1       0.00      0.00      0.95      0.00      0.00      0.00         0\n",
            "\n",
            "avg / total       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCBIAgCMECQDAkf8DggskRHfu+VcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9469</td>\n",
              "      <td>-0.01062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity Optimize\n",
              "XGBClassifier_optimize            0           0           0.9469 -0.01062"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 531 \n",
            "\n",
            "First 23 matches\n",
            "23 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
            " 314 315 325 344 363]\n",
            "\n",
            "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[9254 2255 9258 1933 2479  905 4562 4609 9595 1949  824 3111 1047 5378\n",
            " 8938 5311 1271  950 7455   19  823  592 5301]\n",
            "\n",
            "\n",
            "[0.5162541  0.516391   0.51641345 0.5169088  0.51692504 0.5199717\n",
            " 0.517191   0.52135193 0.5219561  0.5214425  0.51795864 0.51976407\n",
            " 0.5233011  0.5244196  0.53384894 0.5305647  0.5237737  0.5277239\n",
            " 0.53266937 0.52574754 0.52792144 0.53220713 0.53645223]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "107 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
            " 314 315 325 344 363 372 391 392 422 430 437 446 473 479 486 495 496 498\n",
            " 504 507 509 519 520 535 537 546 553 557 567 568 572 575 581 591 592 594\n",
            " 604 607 622 623 625 626 628 630 641 661 691 706 708 716 720 728 736 743\n",
            " 744 746 757 758 764 767 799 802 803 806 810 816 818 823 824 854 859 874\n",
            " 895 900 903 905 916 921 922 923 925 928 932 945 950 952 954 974 993]\n",
            "\n",
            "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
            " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
            " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
            " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
            " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
            " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
            " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
            " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
            " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
            " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
            " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
            " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
            " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
            " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
            " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.505134642124176\n",
            "\n",
            "130 [  19   35  147  210  216  283  422  495  504  507  509  546  567  572\n",
            "  592  594  622  641  661  708  743  758  799  802  806  810  823  824\n",
            "  854  895  900  903  905  923  925  950 1047 1083 1216 1230 1271 1457\n",
            " 1467 1508 1553 1597 1686 1702 1754 1807 1811 1933 1949 1979 1989 2017\n",
            " 2107 2144 2185 2209 2243 2255 2266 2377 2479 2532 2536 2609 2908 3111\n",
            " 3114 3224 3411 3545 3576 3591 3981 4016 4339 4465 4562 4603 4609 4859\n",
            " 4879 5018 5045 5154 5199 5261 5301 5311 5378 5401 5825 6114 6152 6326\n",
            " 6770 6772 6874 6945 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635\n",
            " 7730 7770 7781 7904 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258\n",
            " 9282 9364 9595 9963]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5041610598564148\n",
            "\n",
            "173 [  19   35  147  210  216  283  315  422  473  495  498  504  507  509\n",
            "  535  546  553  557  567  572  575  592  594  604  622  625  641  661\n",
            "  708  743  758  799  802  806  810  823  824  854  895  900  903  905\n",
            "  923  925  950 1047 1083 1126 1216 1230 1271 1378 1409 1457 1467 1508\n",
            " 1531 1553 1597 1671 1686 1702 1747 1754 1807 1811 1905 1933 1949 1979\n",
            " 1989 2017 2107 2144 2185 2209 2243 2255 2260 2266 2269 2377 2479 2532\n",
            " 2536 2609 2641 2865 2871 2908 2958 3010 3090 3111 3114 3209 3224 3242\n",
            " 3411 3436 3453 3545 3576 3591 3854 3981 4016 4060 4267 4339 4369 4465\n",
            " 4562 4603 4609 4780 4859 4879 4912 5018 5045 5154 5199 5261 5301 5311\n",
            " 5378 5401 5825 6114 6152 6326 6451 6749 6770 6772 6874 6930 6945 7081\n",
            " 7136 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635 7730 7770 7781\n",
            " 7809 7904 8078 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258 9282\n",
            " 9364 9465 9595 9755 9963]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "531 [  19   35   42  114  131  147  160  193  197  210  216  219  270  272\n",
            "  279  283  298  305  314  315  325  344  363  372  391  392  422  430\n",
            "  437  446  473  479  486  495  496  498  504  507  509  519  520  535\n",
            "  537  546  553  557  567  568  572  575  581  591  592  594  604  607\n",
            "  622  623  625  626  628  630  641  661  691  706  708  716  720  728\n",
            "  736  743  744  746  757  758  764  767  799  802  803  806  810  816\n",
            "  818  823  824  854  859  874  895  900  903  905  916  921  922  923\n",
            "  925  928  932  945  950  952  954  974  993 1025 1047 1055 1062 1064\n",
            " 1083 1085 1088 1112 1115 1124 1126 1138 1148 1152 1156 1198 1207 1216\n",
            " 1221 1230 1249 1255 1256 1270 1271 1287 1289 1296 1302 1320 1353 1378\n",
            " 1403 1408 1409 1432 1445 1457 1467 1472 1475 1489 1508 1516 1531 1549\n",
            " 1550 1553 1563 1571 1597 1601 1606 1650 1651 1655 1671 1684 1686 1689\n",
            " 1700 1702 1710 1713 1718 1747 1754 1761 1766 1773 1775 1807 1811 1879\n",
            " 1892 1905 1914 1933 1942 1949 1950 1979 1980 1989 1992 2017 2020 2036\n",
            " 2037 2048 2056 2071 2074 2075 2087 2097 2107 2128 2144 2158 2162 2172\n",
            " 2185 2188 2209 2213 2243 2255 2256 2260 2266 2269 2276 2311 2320 2326\n",
            " 2335 2350 2369 2376 2377 2398 2414 2451 2466 2479 2485 2497 2515 2525\n",
            " 2532 2533 2536 2550 2603 2609 2633 2641 2645 2670 2674 2679 2692 2704\n",
            " 2723 2750 2759 2785 2804 2842 2865 2869 2871 2892 2895 2899 2908 2936\n",
            " 2958 2989 3000 3009 3010 3029 3034 3043 3057 3066 3090 3091 3111 3113\n",
            " 3114 3138 3156 3171 3209 3210 3224 3242 3251 3266 3289 3319 3334 3350\n",
            " 3356 3411 3416 3431 3436 3453 3492 3494 3526 3545 3567 3569 3576 3591\n",
            " 3616 3621 3673 3675 3733 3751 3772 3830 3845 3854 3859 3928 3968 3981\n",
            " 3988 4012 4016 4036 4060 4100 4116 4166 4180 4253 4267 4282 4315 4321\n",
            " 4336 4339 4369 4373 4465 4473 4479 4554 4562 4578 4603 4609 4662 4669\n",
            " 4725 4730 4780 4789 4813 4836 4848 4851 4859 4879 4912 5018 5045 5067\n",
            " 5084 5154 5191 5199 5237 5240 5261 5297 5301 5309 5311 5378 5401 5440\n",
            " 5442 5506 5508 5523 5587 5709 5725 5773 5796 5803 5820 5825 5875 5913\n",
            " 5915 5937 5991 5994 6033 6045 6077 6103 6114 6117 6152 6156 6210 6222\n",
            " 6237 6241 6275 6326 6391 6401 6451 6481 6510 6520 6559 6603 6620 6642\n",
            " 6660 6698 6742 6749 6770 6772 6874 6881 6911 6919 6926 6930 6945 6960\n",
            " 6962 6982 6992 6997 7041 7055 7081 7097 7100 7126 7136 7165 7166 7196\n",
            " 7202 7222 7227 7231 7249 7317 7320 7339 7397 7402 7405 7410 7433 7438\n",
            " 7454 7455 7457 7532 7539 7567 7586 7635 7682 7709 7722 7730 7770 7772\n",
            " 7780 7781 7809 7836 7904 7917 7931 7956 8009 8031 8037 8051 8078 8260\n",
            " 8265 8287 8307 8353 8413 8446 8490 8499 8524 8690 8701 8747 8872 8938\n",
            " 8950 8981 8983 9028 9064 9110 9223 9254 9258 9282 9308 9315 9317 9364\n",
            " 9372 9465 9482 9571 9595 9598 9671 9692 9755 9761 9909 9947 9963]\n",
            "\n",
            "531 [0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
            " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
            " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
            " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
            " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
            " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
            " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
            " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
            " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
            " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
            " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
            " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
            " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
            " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
            " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003 0.50193864\n",
            " 0.5233011  0.5019427  0.5018813  0.50333184 0.5077932  0.50032276\n",
            " 0.50399214 0.5019776  0.5021962  0.5033606  0.5050345  0.5007271\n",
            " 0.5004271  0.5017781  0.5036346  0.50294876 0.50129485 0.5051949\n",
            " 0.5017786  0.5161055  0.50030917 0.5002334  0.50054634 0.502441\n",
            " 0.5237737  0.5001335  0.5006088  0.50079876 0.5014565  0.50006247\n",
            " 0.50135255 0.50461596 0.5019814  0.5039658  0.5043177  0.5013857\n",
            " 0.502333   0.5085428  0.5096458  0.50051713 0.50184417 0.50187564\n",
            " 0.5099776  0.5015396  0.5042541  0.5000276  0.5010012  0.50823355\n",
            " 0.50321233 0.5006847  0.50657576 0.5020534  0.5022483  0.5023252\n",
            " 0.5014854  0.5001313  0.5045973  0.50070107 0.507189   0.5002941\n",
            " 0.5032144  0.5077739  0.50406307 0.5028727  0.50317496 0.50501096\n",
            " 0.50741047 0.5005272  0.5007295  0.5030393  0.50157464 0.5061432\n",
            " 0.5058737  0.50209904 0.500265   0.5042856  0.5025591  0.5169088\n",
            " 0.500369   0.5214425  0.5026731  0.5059941  0.5012068  0.505363\n",
            " 0.5002419  0.50673103 0.5031148  0.5022421  0.50023556 0.5003679\n",
            " 0.50088286 0.5002486  0.5011168  0.500298   0.50125176 0.50034547\n",
            " 0.5058143  0.5004563  0.5068892  0.5018134  0.5005777  0.5015998\n",
            " 0.50586724 0.5013415  0.5067641  0.5007844  0.50625074 0.516391\n",
            " 0.5032432  0.50455743 0.5083711  0.50418454 0.5023767  0.50140953\n",
            " 0.5024658  0.5008551  0.5035298  0.50405866 0.5040264  0.5013136\n",
            " 0.5051417  0.50176305 0.5002963  0.50232077 0.5040539  0.51692504\n",
            " 0.5022951  0.50303423 0.5035956  0.5005876  0.5138081  0.50151676\n",
            " 0.50688004 0.5035969  0.50227123 0.5066609  0.5006303  0.50437456\n",
            " 0.5034663  0.501092   0.50317615 0.5015915  0.5000509  0.50150824\n",
            " 0.5033506  0.501502   0.5015722  0.50149184 0.5027045  0.5010111\n",
            " 0.5048253  0.50238866 0.50417536 0.50079346 0.50387055 0.5008435\n",
            " 0.50570333 0.50241864 0.5049395  0.50353813 0.50055224 0.5001007\n",
            " 0.50495845 0.5020584  0.5029562  0.50052553 0.50013536 0.50102925\n",
            " 0.5042794  0.50152725 0.51976407 0.50223374 0.5095835  0.50119936\n",
            " 0.50206643 0.50154394 0.50441885 0.50040376 0.5090414  0.50425774\n",
            " 0.50005317 0.50170726 0.50056136 0.5039086  0.50194675 0.5036079\n",
            " 0.500602   0.51120573 0.5003541  0.5008197  0.5046707  0.5047756\n",
            " 0.5013298  0.5008607  0.5029928  0.5081413  0.50048333 0.5002262\n",
            " 0.5062425  0.51041156 0.5010636  0.50207835 0.5004797  0.5024966\n",
            " 0.5009555  0.50120705 0.50257754 0.5039481  0.5017446  0.5046624\n",
            " 0.50180703 0.50295836 0.50405467 0.5089567  0.50125986 0.50239694\n",
            " 0.5055027  0.5020613  0.50466657 0.5017311  0.50364494 0.5028926\n",
            " 0.502351   0.5008175  0.5048126  0.50009435 0.5000998  0.50252193\n",
            " 0.5009848  0.5095472  0.50449383 0.5014222  0.50868195 0.5000881\n",
            " 0.5028848  0.5000194  0.517191   0.5017843  0.51050824 0.52135193\n",
            " 0.50004286 0.500251   0.5026527  0.5033862  0.50450546 0.5012733\n",
            " 0.50316685 0.5001279  0.50104624 0.50388986 0.5065444  0.5117828\n",
            " 0.5046769  0.5077476  0.5073464  0.5024187  0.502269   0.5068733\n",
            " 0.5025758  0.50690585 0.50012517 0.50204784 0.51100546 0.5031314\n",
            " 0.53645223 0.50260043 0.5305647  0.5244196  0.5123694  0.50030005\n",
            " 0.50179744 0.50070655 0.50187504 0.50241065 0.50097615 0.5004209\n",
            " 0.50410026 0.50412995 0.50075006 0.50034535 0.5006251  0.50871956\n",
            " 0.50043744 0.50387764 0.50013226 0.5001125  0.5010285  0.50263464\n",
            " 0.5017195  0.50063664 0.50241137 0.5002141  0.51622677 0.5017507\n",
            " 0.5054098  0.5012449  0.5019777  0.50268674 0.501439   0.5006176\n",
            " 0.50002676 0.51473963 0.5032707  0.50065583 0.5042906  0.50046515\n",
            " 0.5008358  0.50289613 0.50163007 0.50055    0.5006611  0.50001824\n",
            " 0.500902   0.5025525  0.50301874 0.50429374 0.5061972  0.50630987\n",
            " 0.5104396  0.5004639  0.5016632  0.5005977  0.50134534 0.5041905\n",
            " 0.5057943  0.5005898  0.5011946  0.5020207  0.50016475 0.50245583\n",
            " 0.5004136  0.5007595  0.5042677  0.5003235  0.5001593  0.50168556\n",
            " 0.5041696  0.50180286 0.50803363 0.50103134 0.50168335 0.507005\n",
            " 0.5105519  0.5059834  0.5016305  0.50811034 0.5013556  0.5019086\n",
            " 0.50172263 0.5073309  0.5156956  0.50974417 0.5032969  0.5011608\n",
            " 0.50009733 0.53266937 0.5035469  0.5028987  0.50063163 0.500409\n",
            " 0.50032055 0.5122719  0.5012948  0.5000725  0.50118923 0.5057144\n",
            " 0.506186   0.501088   0.5000707  0.5078673  0.5045751  0.50388914\n",
            " 0.51368195 0.5019669  0.50036156 0.50219053 0.5032656  0.5004837\n",
            " 0.5024662  0.5008789  0.50419086 0.50123715 0.50037897 0.5009113\n",
            " 0.50567675 0.5000989  0.5010555  0.5028809  0.50204444 0.51495695\n",
            " 0.5028022  0.5118773  0.50547427 0.50415117 0.500101   0.53384894\n",
            " 0.5004925  0.5157178  0.5012213  0.5075401  0.50168836 0.5015672\n",
            " 0.50564915 0.5162541  0.51641345 0.5074288  0.5005564  0.5019221\n",
            " 0.50063413 0.5065996  0.5004202  0.5044905  0.50132984 0.5010047\n",
            " 0.5219561  0.5008338  0.5003478  0.50031644 0.5042497  0.5006778\n",
            " 0.50030535 0.5016988  0.506133  ]\n",
            "\n",
            "Matched draws\n",
            "Count: 0, Index: (array([], dtype=int64),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "All matched\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "-----------2020-03-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(979893, 34) (979893,) (10000, 34) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 947191, 1: 32702})\n",
            "\n",
            "scale_pos_weight - 28.964314109228795\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.964314109228795, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.964314109228795]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.000, F-Score=0.00000\n",
            "\n",
            "Recall: 0.0\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
            "          1       0.00      0.00      0.95      0.00      0.00      0.00         0\n",
            "\n",
            "avg / total       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXiklEQVR4nO3de3hU9Z3H8U9mAkHUMQyYEAIKeMEg\nLVjiUqlKBTTsGoJRayCrjbXKqhuEfSpCbU247T4EWKs1IGp3fWJV8FKLEtDgVtfrakGFLSQKRCK3\nXEouDFiBZubsH3ZHMSRy5uQ3kzl5v3zO8zjnd07Ob+SQj9/f71wSLMuyBABAhDyx7gAAIL4RJAAA\nRwgSAIAjBAkAwBGCBADgCEECAHAkMapHe29eVA+H7sE/cXGsuwAXajp8pPN+mN3ffd+3uX2MRTdI\nAKA7cvntegxtAQAcoSIBANNcXpEQJABgmrtzhCABAONcXpEwRwIAcISKBABMc3lFQpAAgGnuzhGC\nBACMoyIBADji7hwhSADAOCoSAIAjBAkAwBF35whBAgDGubwi4YZEAIAjVCQAYJrLKxKCBABMc3eO\nECQAYJzLKxLmSAAAjlCRAIBpLq9ICBIAMC1EkAAAnHB3jhAkAGCeu5OEIAEA09ydIwQJABjHZDsA\nwBF35whBAgDmuTtJCBIAMM3dOUKQAIBxzJEAABxxd44QJABgnMsrEh7aCACmWZa9xYbXX39d11xz\njaZMmaKcnBxt2LBBkrRr1y7l5eUpKytLeXl5qqmpCe8TaVt7CBIAMM2yuZzsj7Us3XPPPVqyZIle\nfPFFLVmyRHPmzFEoFFJxcbHy8/NVUVGh/Px8FRUVhfeLtK09BAkAmGawIvF4PDp06JAk6dChQ0pJ\nSVFzc7MqKyuVnZ0tScrOzlZlZaWamprU2NgYUVtHmCMBgC4mEAgoEAi0We/z+eTz+cKfExIS9MAD\nD+jOO+9U79699fnnn+vRRx9VbW2tUlNT5fV6JUler1cpKSmqra2VZVkRtfn9/nb7S5AAgGk2q4yy\nsjKVlpa2WV9YWKgZM2aEP7e2tuqRRx7RihUrNHr0aH3wwQeaNWuWlixZ4rjLdhAkAGCazYu2CgoK\nlJub22b916sRSaqqqlJDQ4NGjx4tSRo9erROOeUUJSUlqb6+XsFgUF6vV8FgUA0NDUpLS5NlWRG1\ndYQ5EgAwzeYcic/n08CBA9ss3wyS/v37q66uTp9++qkkqbq6Wo2NjTr77LOVkZGh8vJySVJ5ebky\nMjLk9/vVt2/fiNo6kmBZUbzA+b15UTsUug//xMWx7gJcqOnwkc77Yav+2d7205af9KYvvfSSHnvs\nMSUkJEiS7rrrLk2cOFHV1dWaO3euAoGAfD6fSkpKNHToUEmKuK09BAniHkECEzo3SO60t/20FZ13\n7ChgjgQATHP3je0ECQAYF3J3khAkAGAaz9oCAKB9VCQAYJjda5oSDPXDFIIEAAyzO7JFkAAAjhPN\nuyxigSABAMPcHSMECQAYR0UCAHDE5beRECQAYJrLCxKCBABMC7k8Sbgh0bDq/Qf148V/0Ojbn9eV\ns9fq1U172mxTumarhhWs0rvb6o5b/+62OuUWvaJRtz2ry2et0fr3d4fbXvton7LvXa+Lpj+nqQtf\n1c59B41/F3RtL728QfsPtGh33QHtrjug9z/8X0nSpZeP09vvb9KuvXXa+dk+PbHqGaWlDQjvd821\n1+mV/3pdexua9NLLG2LVfVcLWZatJd4QJAa1BkO684G3dMWodP1xxbVa8JOLNfuR/9Guuq9eobm7\n/pAqNu7WmcmnHLfvzn0H9bOH39Ws676rTSuv14uL/l4jBveRJNXUHdLdK9/VvJsv1saHr9MVowbo\njgfeVGswFNXvh65nzs/+RWf176ez+vfTmO99V5L0ycdVun7KZA0Z2F/DzxuiT3fu1LIHfh3ep7mp\nWStXlOrB+5fFqtuuZ/CV7V0CQWLQp7UBNbR8oZuzhsnr8eiS4f31vfPO1Ivv1IS3mf/bTbr7hlHq\nmXj8H8XDL21T3hXnatzIAUr0etTntCSdlXq6JOntP9Uqc1iKMs8/U4lej267erjqm7/Qxo8bovn1\nECf+3NCgurra8OdgMKSh55wT/vzGf7+mNS/8TnW1tSfaHZ3AsixbS7w5qSBpbm5WVVWVqqqq1Nzc\nbLpPrmbJ0o69Xw5DvfzH3eqZ6NW4kQPabLe5+oAkafIv1uvSu36vu1e+q5bDR7/6OV872ay//bOd\n4a1u7775C7Tjs716+dXX9YPLLg+vTx84SLv21mn/gRYVzpylX//q/hj2svuxbC7xpsPJ9t27d+u+\n++5TZWWlUlJSJEkNDQ0aPny45s+fr8GDB59wv0AgoEAg0Gb9QOf9jStD+vvk9yXpN+urdHPWBXq/\nql4bP/6zxmSk6PAXf9Wvnt+i/5x9xQn3rW/6Qi+9W6P/mP1DpSSformPvaeFT36gf799rC65sL+W\nPbtZ71fV66Lz+umxdVX6a2tIR462RvkboiuZf98v9MnHVTp27Jiuvf4GPf3s7zRu7BjV7PpU+/bu\n0ZCB/ZXcp49+fPMt2rH9k1h3t1uJx3kPOzoMknvuuUf5+fl6/PHH5fF8WbyEQiGtXbtWc+bM0TPP\nPHPC/crKylRaWtpm/Sdl0zqhy/GjR6JHy++6TIue/EC/WVelEUP8mvR3g9Szh1ela/6knLFDNPDM\n0064b1JPr669dIiG9P/yHc3/lH2hfrLkNUnSOQN8Wjz9+1r42w/055YvNHnsYJ074Ayl+ntH7buh\n6/lg08bwv69++kld96MbdGVWlh5b+XB4fUtzs1Y/9aTefO+PuvC8oQoGg7Hoarfj8hzpOEhaWlqU\nk5Nz3DqPx6MpU6bo4YcfbmcvqaCgQLm5uW0b9v4msl7GsQvO6qMn750Y/jx14au65tIhWvXaDtU1\n/UWrXtshSWoKHNWs5e/o1qszNP3q4Ro2KFlK+OrRbQnfeIrbpIvP0qSLz5IkBT4/pt+9+am+M6Sv\n+S+EuGFZVvg93l+XmJiolJRUne7zqYWh6qiIx3kPOzoMkuTkZJWXl+vqq68On5CWZWnt2rXy+Xzt\n7ufz+U7cvtdZZ+PRx7ubNaS/TyHL0tN/2KGGli907aVDlHXxILW2fnWV1fXzN2jutIt0+XfTJEnX\nXjZEK17cpiljB6vfGb30aHmlfjgqPbz91l1Nyjg7WQcPH9P8JzZp/EXpOmdA+38mcDffGWcoM/Ni\nvfP2W2ptbVXudT/SJT+4VD+/52fKzpmij6sqVb1zp/x9+2rR4hJt2fxROEQ8Ho969Oghb6JXHo9H\nSUlJCgaDam1lqLSzuDxHOg6SxYsXq7i4WAsWLFBqaqokqb6+XhdccIEWL14clQ7GuxffrdHzb1Sr\nNWhp9Pln6vF7rlDPHl717OE9bjuvJ0FnnNpTp/bqIUm6/vJztP/AX/SjBV9e13/Zd9L0yxtHh7f/\n16c+0Md7WtTD69Gkiwdpbv73ovel0OX06NFD9xbN03nnD1MoGNSO7Z/opqk3qHrnTo2feKUW/luJ\n+p15pg4fPqR33npTN03LC++bN+0ftfyRx8KfaxsP6uknf6vC22+LxVdxpVBcTqGfvATrJGqupqYm\n1f7t0sC0tDT5/f7IjvbevMj2Azrgn8j/1KDzNR0+0mk/q+6hH9vavv+MJzrt2NFwUo9I8fv9kYcH\nAHRz3XpoCwDgnOXyoS2CBAAM4zHyAABHuvXlvwAA51yeIwQJAJhGRQIAcMTtL3ggSADAMCoSAIAj\nLs8RggQATKMiAQA4EiRIAABOuDxHCBIAMI2hLQCAIzwiBQDgCA9tBAA44vKRLYIEAExjjgQA4IjL\nc4QgAQDTQi5PEk+sOwAAbmfZXOw4evSoiouLddVVV2ny5Mm67777JEm7du1SXl6esrKylJeXp5qa\nmvA+kba1hyABAMNCIcvWYsfSpUuVlJSkiooKrV27VjNnzpQkFRcXKz8/XxUVFcrPz1dRUVF4n0jb\n2kOQAIBhIcuytQQCAe3du7fNEggEjvu5n3/+udasWaOZM2cqISFBktSvXz81NjaqsrJS2dnZkqTs\n7GxVVlaqqakp4raOMEcCAIbZHa4qKytTaWlpm/WFhYWaMWNG+POePXuUnJys0tJSvf/++zr11FM1\nc+ZM9erVS6mpqfJ6vZIkr9erlJQU1dbWyrKsiNr8fn+7/SVIAMAwu5f/FhQUKDc3t816n8933Odg\nMKg9e/Zo+PDhmjNnjrZs2aLbb79dDz74oKP+2kWQAIBhdi/a8vl8bULjRNLS0pSYmBgeiho5cqT6\n9OmjXr16qb6+XsFgUF6vV8FgUA0NDUpLS5NlWRG1dYQ5EgAwzO4cycny+/0aM2aM3nnnHUlfXnHV\n2NiowYMHKyMjQ+Xl5ZKk8vJyZWRkyO/3q2/fvhG1dSTBiuYtl+/Ni9qh0H34Jy6OdRfgQk2Hj3Ta\nz3r7l9fY2v7SRWtOets9e/bo3nvvVUtLixITEzVr1iyNGzdO1dXVmjt3rgKBgHw+n0pKSjR06FBJ\niritPQQJ4h5BAhM6M0je+uUUW9tftujFTjt2NDBHAgCGufzGdoIEAExz+yNSCBIAMIwgAQA44vIc\nIUgAwDTeRwIAcIR3tgMAHKEiAQA44u4YIUgAwDgqEgCAI8yRAAAcoSIBADji8hwhSADAtKDLk4Qg\nAQDDGNoCADji8hwhSADANMvld5IQJABgGJf/AgAcYY4EAOCIy3OEIAEA06hIAACOuDtGCBIAMI5X\n7QIAHHF5jhAkAGAaFQkAwBGCpBMlXDI/mocDgC7B5TlCRQIApnH5LwDAEZfnCEECAKaFXH4nCUEC\nAIZRkQAAHGGOBADgiMtzhCABANOYIwEAOBJy+ZutCBIAMIyhLQCAI0y2AwAcCcW6A4YRJABgGBUJ\nAMARl+cIQQIAprm9IvHEugMA4HYhy94SidLSUg0bNkzbt2+XJG3evFk5OTnKysrSLbfcosbGxvC2\nkba1hyABAMMsm//YtW3bNm3evFnp6emSpFAopNmzZ6uoqEgVFRXKzMzUsmXLHLV1hCABAMMsy95i\nx7Fjx7RgwQLNmzcvvG7r1q1KSkpSZmamJGnq1Kl65ZVXHLV1hDkSADAsaHO8KhAIKBAItFnv8/nk\n8/mOW/fggw8qJydHAwcODK+rra3VgAEDwp/9fr9CoZBaWloibktOTm63vwQJABhmd7iqrKxMpaWl\nbdYXFhZqxowZ4c8fffSRtm7dqrvvvttxH50gSADAMLvDVQUFBcrNzW2z/pvVyMaNG1VdXa0JEyZI\nkurq6vTTn/5UN910k/bv3x/erqmpSR6PR8nJyUpLS4uorSMECQAYZvfy3xMNYZ3I9OnTNX369PDn\n8ePHa+XKlTr33HP17LPPatOmTcrMzNTq1as1adIkSdKIESN05MgR220dIUgAwLBoP/zX4/FoyZIl\nKi4u1tGjR5Wenq6lS5c6autIghXFO2USEhKidSgAcKQzfzXOy820t/3vN3XasaOBigQADHP3fe0E\nCQAY5/ZHpBAkAGCYy3OEIAEA00IuTxKCBAAMI0gAAI64PEcIEgAwjYoEAOCIy3OEIAEA0yJ5x0g8\nIUgAwDAqEgCAI8yRAAAccXmOECQAYBpzJAAAR6hIAACOMEcCAHAkFO03W0UZQQIAhrk7RggSADCO\n95EAABxx+cgWQQIAplGRAAAccXmOECQAYBo3JAIAHGGOBADgCHMkAABHXJ4jBAkAmBZ0eZIQJABg\nGENbAABHXJ4jBAkAmEZFAgBwJBTrDhjmiXUHcLw+ffrohRde0OHDh1VTU6Np06bFuktwAc6r2LIs\ny9YSb6hIupjly5fr2LFjSk1N1ahRo7Ru3Tpt2bJFlZWVse4a4hjnVWzFYTbYkmBFMf4SEhKidai4\n1Lt3bzU3N2vEiBHasWOHJOmJJ57Qvn379POf/zzGvUO84ryKTGf+arz+4qG2tn9+46edduxoYGir\nCzn//PPV2toa/ssuSVu2bNGFF14Yw14h3nFexZ5lc4k3EQ9tTZ48WWvXrj1hWyAQUCAQiLhT3dVp\np53W5r/bwYMHdfrpp8eoR3ADzqvY69bvbN+5c2e7bc3Nze22lZWVqbS0NPJedVOHDx+Wz+c7bp3P\n59OhQ4di1CO4AedV7HXrd7ZnZ2crPT39hGOFLS0t7e5XUFCg3NzcNusHDRoUQRe7j+3btysxMVHn\nnntuOMRHjhypbdu2xbhniGecV7Hn8oKk48n2CRMm6Omnn1ZqamqbtnHjxumNN96wdzAm27/VqlWr\nZFmWbr31Vo0aNUrr16/X2LFjuboGjnBe2deZk+3ZF51ta/vyjz7rtGNHQ4eT7VdddZX27dt3wrYr\nr7zSSIe6uzvvvFOnnHKKGhoatGrVKt1xxx38ZYdjnFexZVn2lnjD5b8AcAKd+avxH0aeZWv79Vt2\nd9qxo4HLfwHAMFMVSXNzs2677TZlZWVp8uTJKiwsVFNTkyRp8+bNysnJUVZWlm655RY1NjaG94u0\nrT0ECQAYFpJlazlZCQkJuvXWW1VRUaG1a9dq0KBBWrZsmUKhkGbPnq2ioiJVVFQoMzNTy5Yt+7Iv\nEbZ1hCABAMNMVSTJyckaM2ZM+POoUaO0f/9+bd26VUlJScrMzJQkTZ06Va+88ookRdzWEZ61BQCG\n2Z1vae+mbp/P1+aeoP8XCoW0atUqjR8/XrW1tRowYEC4ze/3KxQKqaWlJeK25OTkdvtLkACAYXbn\n7du7qbuwsFAzZsw44T4LFy5U7969deONN+rVV1+NpJsRI0gAwDC7j0hp76bu9qqRkpISffbZZ1q5\ncqU8Ho/S0tK0f//+cHtTU5M8Ho+Sk5MjbusIQQIAhtkNko6GsL7p/vvv19atW/Xoo4+qZ8+ekqQR\nI0boyJEj2rRpkzIzM7V69WpNmjTJUVtHuI8EAE6gM381jrtgwLdv9DVvfLz/2zeStGPHDmVnZ2vw\n4MHq1auXJGngwIFavny5PvzwQxUXF+vo0aNKT0/X0qVL1a9fP0mKuK09BAkAnEBn/mq8fFiare3f\n/KS2044dDQxtAYBhLn/4L0ECAKZZcfm6qpNHkACAYfH4IEY7CBIAMCyKU9ExQZAAgGHMkQAAHGGO\nBADgiMtHtggSADAt6PKxLYIEAAxjsh0A4Ii7Y4QgAQDjqEgAAI64fIqEIAEA06hIAACOuDtGCBIA\nMI6KBADgiMtzhCABANPsvmo33hAkAGAYQQIAcMTlOUKQAIBpVCQAAEdcniMECQCYxvtIAACOUJEA\nABxhjgQA4IjLc4QgAQDTeEQKAMARd8cIQQIAxvHOdgCAIwxtAQAccXmOECQAYBo3JAIAHHH5FAlB\nAgCmMUcCAHDE5TlCkACAacyRAAAcYY4EAOAIcyQAAEdcniMECQCYFnR5khAkAGCY24e2PLHuAAC4\nnWXZW+zYtWuX8vLylJWVpby8PNXU1Bj5Dh0hSADAMMuybC12FBcXKz8/XxUVFcrPz1dRUZGhb9E+\nggQADAvZXE5WY2OjKisrlZ2dLUnKzs5WZWWlmpqaOrH33445EgAwzG6VEQgEFAgE2qz3+Xzy+Xzh\nz7W1tUpNTZXX65Ukeb1epaSkqLa2Vn6/31mnbYhqkLh9wqmzBAIBlZWVqaCg4LiTBnCC8yp2Qjbv\nSHzooYdUWlraZn1hYaFmzJjRWd3qNFQkXVAgEFBpaalyc3P5C49Ow3kVPwoKCpSbm9tm/Tf/3NLS\n0lRfX69gMCiv16tgMKiGhgalpaVFq6uSCBIA6HK+OYTVnr59+yojI0Pl5eWaMmWKysvLlZGREdVh\nLYkgAYC4Nm/ePM2dO1crVqyQz+dTSUlJ1PtAkABAHDvnnHP03HPPxbQPXP4LAHCEIOmCfD6fCgsL\nmRBFp+K8gikJFtfkAgAcoCIBADhCkAAAHCFIupiu8CRPuE9JSYnGjx+vYcOGafv27bHuDlyGIOli\nusKTPOE+EyZM0FNPPaX09PRYdwUuRJB0IV3lSZ5wn8zMzKg/NgPdB0HShXT0JE8A6KoIEgCAIwRJ\nF/L1J3lKitmTPAHADoKkC/n6kzwlxexJngBgB3e2dzHV1dWaO3euAoFA+EmeQ4cOjXW3EOcWLVqk\nDRs26MCBA+rTp4+Sk5O1bt26WHcLLkGQAAAcYWgLAOAIQQIAcIQgAQA4QpAAABwhSAAAjhAkAABH\nCBIAgCMECQDAkf8DggskRHfu+VcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9469</td>\n",
              "      <td>-0.01062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity Optimize\n",
              "XGBClassifier_optimize            0           0           0.9469 -0.01062"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 531 \n",
            "\n",
            "First 23 matches\n",
            "23 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
            " 314 315 325 344 363]\n",
            "\n",
            "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[9254 2255 9258 1933 2479  905 4562 4609 9595 1949  824 3111 1047 5378\n",
            " 8938 5311 1271  950 7455   19  823  592 5301]\n",
            "\n",
            "\n",
            "[0.5162541  0.516391   0.51641345 0.5169088  0.51692504 0.5199717\n",
            " 0.517191   0.52135193 0.5219561  0.5214425  0.51795864 0.51976407\n",
            " 0.5233011  0.5244196  0.53384894 0.5305647  0.5237737  0.5277239\n",
            " 0.53266937 0.52574754 0.52792144 0.53220713 0.53645223]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "107 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
            " 314 315 325 344 363 372 391 392 422 430 437 446 473 479 486 495 496 498\n",
            " 504 507 509 519 520 535 537 546 553 557 567 568 572 575 581 591 592 594\n",
            " 604 607 622 623 625 626 628 630 641 661 691 706 708 716 720 728 736 743\n",
            " 744 746 757 758 764 767 799 802 803 806 810 816 818 823 824 854 859 874\n",
            " 895 900 903 905 916 921 922 923 925 928 932 945 950 952 954 974 993]\n",
            "\n",
            "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
            " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
            " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
            " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
            " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
            " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
            " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
            " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
            " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
            " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
            " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
            " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
            " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
            " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
            " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.505134642124176\n",
            "\n",
            "130 [  19   35  147  210  216  283  422  495  504  507  509  546  567  572\n",
            "  592  594  622  641  661  708  743  758  799  802  806  810  823  824\n",
            "  854  895  900  903  905  923  925  950 1047 1083 1216 1230 1271 1457\n",
            " 1467 1508 1553 1597 1686 1702 1754 1807 1811 1933 1949 1979 1989 2017\n",
            " 2107 2144 2185 2209 2243 2255 2266 2377 2479 2532 2536 2609 2908 3111\n",
            " 3114 3224 3411 3545 3576 3591 3981 4016 4339 4465 4562 4603 4609 4859\n",
            " 4879 5018 5045 5154 5199 5261 5301 5311 5378 5401 5825 6114 6152 6326\n",
            " 6770 6772 6874 6945 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635\n",
            " 7730 7770 7781 7904 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258\n",
            " 9282 9364 9595 9963]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5041610598564148\n",
            "\n",
            "173 [  19   35  147  210  216  283  315  422  473  495  498  504  507  509\n",
            "  535  546  553  557  567  572  575  592  594  604  622  625  641  661\n",
            "  708  743  758  799  802  806  810  823  824  854  895  900  903  905\n",
            "  923  925  950 1047 1083 1126 1216 1230 1271 1378 1409 1457 1467 1508\n",
            " 1531 1553 1597 1671 1686 1702 1747 1754 1807 1811 1905 1933 1949 1979\n",
            " 1989 2017 2107 2144 2185 2209 2243 2255 2260 2266 2269 2377 2479 2532\n",
            " 2536 2609 2641 2865 2871 2908 2958 3010 3090 3111 3114 3209 3224 3242\n",
            " 3411 3436 3453 3545 3576 3591 3854 3981 4016 4060 4267 4339 4369 4465\n",
            " 4562 4603 4609 4780 4859 4879 4912 5018 5045 5154 5199 5261 5301 5311\n",
            " 5378 5401 5825 6114 6152 6326 6451 6749 6770 6772 6874 6930 6945 7081\n",
            " 7136 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635 7730 7770 7781\n",
            " 7809 7904 8078 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258 9282\n",
            " 9364 9465 9595 9755 9963]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "531 [  19   35   42  114  131  147  160  193  197  210  216  219  270  272\n",
            "  279  283  298  305  314  315  325  344  363  372  391  392  422  430\n",
            "  437  446  473  479  486  495  496  498  504  507  509  519  520  535\n",
            "  537  546  553  557  567  568  572  575  581  591  592  594  604  607\n",
            "  622  623  625  626  628  630  641  661  691  706  708  716  720  728\n",
            "  736  743  744  746  757  758  764  767  799  802  803  806  810  816\n",
            "  818  823  824  854  859  874  895  900  903  905  916  921  922  923\n",
            "  925  928  932  945  950  952  954  974  993 1025 1047 1055 1062 1064\n",
            " 1083 1085 1088 1112 1115 1124 1126 1138 1148 1152 1156 1198 1207 1216\n",
            " 1221 1230 1249 1255 1256 1270 1271 1287 1289 1296 1302 1320 1353 1378\n",
            " 1403 1408 1409 1432 1445 1457 1467 1472 1475 1489 1508 1516 1531 1549\n",
            " 1550 1553 1563 1571 1597 1601 1606 1650 1651 1655 1671 1684 1686 1689\n",
            " 1700 1702 1710 1713 1718 1747 1754 1761 1766 1773 1775 1807 1811 1879\n",
            " 1892 1905 1914 1933 1942 1949 1950 1979 1980 1989 1992 2017 2020 2036\n",
            " 2037 2048 2056 2071 2074 2075 2087 2097 2107 2128 2144 2158 2162 2172\n",
            " 2185 2188 2209 2213 2243 2255 2256 2260 2266 2269 2276 2311 2320 2326\n",
            " 2335 2350 2369 2376 2377 2398 2414 2451 2466 2479 2485 2497 2515 2525\n",
            " 2532 2533 2536 2550 2603 2609 2633 2641 2645 2670 2674 2679 2692 2704\n",
            " 2723 2750 2759 2785 2804 2842 2865 2869 2871 2892 2895 2899 2908 2936\n",
            " 2958 2989 3000 3009 3010 3029 3034 3043 3057 3066 3090 3091 3111 3113\n",
            " 3114 3138 3156 3171 3209 3210 3224 3242 3251 3266 3289 3319 3334 3350\n",
            " 3356 3411 3416 3431 3436 3453 3492 3494 3526 3545 3567 3569 3576 3591\n",
            " 3616 3621 3673 3675 3733 3751 3772 3830 3845 3854 3859 3928 3968 3981\n",
            " 3988 4012 4016 4036 4060 4100 4116 4166 4180 4253 4267 4282 4315 4321\n",
            " 4336 4339 4369 4373 4465 4473 4479 4554 4562 4578 4603 4609 4662 4669\n",
            " 4725 4730 4780 4789 4813 4836 4848 4851 4859 4879 4912 5018 5045 5067\n",
            " 5084 5154 5191 5199 5237 5240 5261 5297 5301 5309 5311 5378 5401 5440\n",
            " 5442 5506 5508 5523 5587 5709 5725 5773 5796 5803 5820 5825 5875 5913\n",
            " 5915 5937 5991 5994 6033 6045 6077 6103 6114 6117 6152 6156 6210 6222\n",
            " 6237 6241 6275 6326 6391 6401 6451 6481 6510 6520 6559 6603 6620 6642\n",
            " 6660 6698 6742 6749 6770 6772 6874 6881 6911 6919 6926 6930 6945 6960\n",
            " 6962 6982 6992 6997 7041 7055 7081 7097 7100 7126 7136 7165 7166 7196\n",
            " 7202 7222 7227 7231 7249 7317 7320 7339 7397 7402 7405 7410 7433 7438\n",
            " 7454 7455 7457 7532 7539 7567 7586 7635 7682 7709 7722 7730 7770 7772\n",
            " 7780 7781 7809 7836 7904 7917 7931 7956 8009 8031 8037 8051 8078 8260\n",
            " 8265 8287 8307 8353 8413 8446 8490 8499 8524 8690 8701 8747 8872 8938\n",
            " 8950 8981 8983 9028 9064 9110 9223 9254 9258 9282 9308 9315 9317 9364\n",
            " 9372 9465 9482 9571 9595 9598 9671 9692 9755 9761 9909 9947 9963]\n",
            "\n",
            "531 [0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
            " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
            " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
            " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
            " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
            " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
            " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
            " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
            " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
            " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
            " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
            " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
            " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
            " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
            " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003 0.50193864\n",
            " 0.5233011  0.5019427  0.5018813  0.50333184 0.5077932  0.50032276\n",
            " 0.50399214 0.5019776  0.5021962  0.5033606  0.5050345  0.5007271\n",
            " 0.5004271  0.5017781  0.5036346  0.50294876 0.50129485 0.5051949\n",
            " 0.5017786  0.5161055  0.50030917 0.5002334  0.50054634 0.502441\n",
            " 0.5237737  0.5001335  0.5006088  0.50079876 0.5014565  0.50006247\n",
            " 0.50135255 0.50461596 0.5019814  0.5039658  0.5043177  0.5013857\n",
            " 0.502333   0.5085428  0.5096458  0.50051713 0.50184417 0.50187564\n",
            " 0.5099776  0.5015396  0.5042541  0.5000276  0.5010012  0.50823355\n",
            " 0.50321233 0.5006847  0.50657576 0.5020534  0.5022483  0.5023252\n",
            " 0.5014854  0.5001313  0.5045973  0.50070107 0.507189   0.5002941\n",
            " 0.5032144  0.5077739  0.50406307 0.5028727  0.50317496 0.50501096\n",
            " 0.50741047 0.5005272  0.5007295  0.5030393  0.50157464 0.5061432\n",
            " 0.5058737  0.50209904 0.500265   0.5042856  0.5025591  0.5169088\n",
            " 0.500369   0.5214425  0.5026731  0.5059941  0.5012068  0.505363\n",
            " 0.5002419  0.50673103 0.5031148  0.5022421  0.50023556 0.5003679\n",
            " 0.50088286 0.5002486  0.5011168  0.500298   0.50125176 0.50034547\n",
            " 0.5058143  0.5004563  0.5068892  0.5018134  0.5005777  0.5015998\n",
            " 0.50586724 0.5013415  0.5067641  0.5007844  0.50625074 0.516391\n",
            " 0.5032432  0.50455743 0.5083711  0.50418454 0.5023767  0.50140953\n",
            " 0.5024658  0.5008551  0.5035298  0.50405866 0.5040264  0.5013136\n",
            " 0.5051417  0.50176305 0.5002963  0.50232077 0.5040539  0.51692504\n",
            " 0.5022951  0.50303423 0.5035956  0.5005876  0.5138081  0.50151676\n",
            " 0.50688004 0.5035969  0.50227123 0.5066609  0.5006303  0.50437456\n",
            " 0.5034663  0.501092   0.50317615 0.5015915  0.5000509  0.50150824\n",
            " 0.5033506  0.501502   0.5015722  0.50149184 0.5027045  0.5010111\n",
            " 0.5048253  0.50238866 0.50417536 0.50079346 0.50387055 0.5008435\n",
            " 0.50570333 0.50241864 0.5049395  0.50353813 0.50055224 0.5001007\n",
            " 0.50495845 0.5020584  0.5029562  0.50052553 0.50013536 0.50102925\n",
            " 0.5042794  0.50152725 0.51976407 0.50223374 0.5095835  0.50119936\n",
            " 0.50206643 0.50154394 0.50441885 0.50040376 0.5090414  0.50425774\n",
            " 0.50005317 0.50170726 0.50056136 0.5039086  0.50194675 0.5036079\n",
            " 0.500602   0.51120573 0.5003541  0.5008197  0.5046707  0.5047756\n",
            " 0.5013298  0.5008607  0.5029928  0.5081413  0.50048333 0.5002262\n",
            " 0.5062425  0.51041156 0.5010636  0.50207835 0.5004797  0.5024966\n",
            " 0.5009555  0.50120705 0.50257754 0.5039481  0.5017446  0.5046624\n",
            " 0.50180703 0.50295836 0.50405467 0.5089567  0.50125986 0.50239694\n",
            " 0.5055027  0.5020613  0.50466657 0.5017311  0.50364494 0.5028926\n",
            " 0.502351   0.5008175  0.5048126  0.50009435 0.5000998  0.50252193\n",
            " 0.5009848  0.5095472  0.50449383 0.5014222  0.50868195 0.5000881\n",
            " 0.5028848  0.5000194  0.517191   0.5017843  0.51050824 0.52135193\n",
            " 0.50004286 0.500251   0.5026527  0.5033862  0.50450546 0.5012733\n",
            " 0.50316685 0.5001279  0.50104624 0.50388986 0.5065444  0.5117828\n",
            " 0.5046769  0.5077476  0.5073464  0.5024187  0.502269   0.5068733\n",
            " 0.5025758  0.50690585 0.50012517 0.50204784 0.51100546 0.5031314\n",
            " 0.53645223 0.50260043 0.5305647  0.5244196  0.5123694  0.50030005\n",
            " 0.50179744 0.50070655 0.50187504 0.50241065 0.50097615 0.5004209\n",
            " 0.50410026 0.50412995 0.50075006 0.50034535 0.5006251  0.50871956\n",
            " 0.50043744 0.50387764 0.50013226 0.5001125  0.5010285  0.50263464\n",
            " 0.5017195  0.50063664 0.50241137 0.5002141  0.51622677 0.5017507\n",
            " 0.5054098  0.5012449  0.5019777  0.50268674 0.501439   0.5006176\n",
            " 0.50002676 0.51473963 0.5032707  0.50065583 0.5042906  0.50046515\n",
            " 0.5008358  0.50289613 0.50163007 0.50055    0.5006611  0.50001824\n",
            " 0.500902   0.5025525  0.50301874 0.50429374 0.5061972  0.50630987\n",
            " 0.5104396  0.5004639  0.5016632  0.5005977  0.50134534 0.5041905\n",
            " 0.5057943  0.5005898  0.5011946  0.5020207  0.50016475 0.50245583\n",
            " 0.5004136  0.5007595  0.5042677  0.5003235  0.5001593  0.50168556\n",
            " 0.5041696  0.50180286 0.50803363 0.50103134 0.50168335 0.507005\n",
            " 0.5105519  0.5059834  0.5016305  0.50811034 0.5013556  0.5019086\n",
            " 0.50172263 0.5073309  0.5156956  0.50974417 0.5032969  0.5011608\n",
            " 0.50009733 0.53266937 0.5035469  0.5028987  0.50063163 0.500409\n",
            " 0.50032055 0.5122719  0.5012948  0.5000725  0.50118923 0.5057144\n",
            " 0.506186   0.501088   0.5000707  0.5078673  0.5045751  0.50388914\n",
            " 0.51368195 0.5019669  0.50036156 0.50219053 0.5032656  0.5004837\n",
            " 0.5024662  0.5008789  0.50419086 0.50123715 0.50037897 0.5009113\n",
            " 0.50567675 0.5000989  0.5010555  0.5028809  0.50204444 0.51495695\n",
            " 0.5028022  0.5118773  0.50547427 0.50415117 0.500101   0.53384894\n",
            " 0.5004925  0.5157178  0.5012213  0.5075401  0.50168836 0.5015672\n",
            " 0.50564915 0.5162541  0.51641345 0.5074288  0.5005564  0.5019221\n",
            " 0.50063413 0.5065996  0.5004202  0.5044905  0.50132984 0.5010047\n",
            " 0.5219561  0.5008338  0.5003478  0.50031644 0.5042497  0.5006778\n",
            " 0.50030535 0.5016988  0.506133  ]\n",
            "\n",
            "Matched draws\n",
            "Count: 0, Index: (array([], dtype=int64),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "All matched\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "-----------2020-03-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(979893, 34) (979893,) (10000, 34) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 947191, 1: 32702})\n",
            "\n",
            "scale_pos_weight - 28.964314109228795\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.964314109228795, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.964314109228795]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.000, F-Score=0.00000\n",
            "\n",
            "Recall: 0.0\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
            "          1       0.00      0.00      0.95      0.00      0.00      0.00         0\n",
            "\n",
            "avg / total       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCBIAgCMECQDAkf8DggskRHfu+VcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9469</td>\n",
              "      <td>-0.01062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity Optimize\n",
              "XGBClassifier_optimize            0           0           0.9469 -0.01062"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 531 \n",
            "\n",
            "First 23 matches\n",
            "23 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
            " 314 315 325 344 363]\n",
            "\n",
            "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[9254 2255 9258 1933 2479  905 4562 4609 9595 1949  824 3111 1047 5378\n",
            " 8938 5311 1271  950 7455   19  823  592 5301]\n",
            "\n",
            "\n",
            "[0.5162541  0.516391   0.51641345 0.5169088  0.51692504 0.5199717\n",
            " 0.517191   0.52135193 0.5219561  0.5214425  0.51795864 0.51976407\n",
            " 0.5233011  0.5244196  0.53384894 0.5305647  0.5237737  0.5277239\n",
            " 0.53266937 0.52574754 0.52792144 0.53220713 0.53645223]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "107 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
            " 314 315 325 344 363 372 391 392 422 430 437 446 473 479 486 495 496 498\n",
            " 504 507 509 519 520 535 537 546 553 557 567 568 572 575 581 591 592 594\n",
            " 604 607 622 623 625 626 628 630 641 661 691 706 708 716 720 728 736 743\n",
            " 744 746 757 758 764 767 799 802 803 806 810 816 818 823 824 854 859 874\n",
            " 895 900 903 905 916 921 922 923 925 928 932 945 950 952 954 974 993]\n",
            "\n",
            "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
            " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
            " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
            " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
            " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
            " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
            " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
            " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
            " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
            " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
            " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
            " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
            " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
            " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
            " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.505134642124176\n",
            "\n",
            "130 [  19   35  147  210  216  283  422  495  504  507  509  546  567  572\n",
            "  592  594  622  641  661  708  743  758  799  802  806  810  823  824\n",
            "  854  895  900  903  905  923  925  950 1047 1083 1216 1230 1271 1457\n",
            " 1467 1508 1553 1597 1686 1702 1754 1807 1811 1933 1949 1979 1989 2017\n",
            " 2107 2144 2185 2209 2243 2255 2266 2377 2479 2532 2536 2609 2908 3111\n",
            " 3114 3224 3411 3545 3576 3591 3981 4016 4339 4465 4562 4603 4609 4859\n",
            " 4879 5018 5045 5154 5199 5261 5301 5311 5378 5401 5825 6114 6152 6326\n",
            " 6770 6772 6874 6945 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635\n",
            " 7730 7770 7781 7904 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258\n",
            " 9282 9364 9595 9963]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5041610598564148\n",
            "\n",
            "173 [  19   35  147  210  216  283  315  422  473  495  498  504  507  509\n",
            "  535  546  553  557  567  572  575  592  594  604  622  625  641  661\n",
            "  708  743  758  799  802  806  810  823  824  854  895  900  903  905\n",
            "  923  925  950 1047 1083 1126 1216 1230 1271 1378 1409 1457 1467 1508\n",
            " 1531 1553 1597 1671 1686 1702 1747 1754 1807 1811 1905 1933 1949 1979\n",
            " 1989 2017 2107 2144 2185 2209 2243 2255 2260 2266 2269 2377 2479 2532\n",
            " 2536 2609 2641 2865 2871 2908 2958 3010 3090 3111 3114 3209 3224 3242\n",
            " 3411 3436 3453 3545 3576 3591 3854 3981 4016 4060 4267 4339 4369 4465\n",
            " 4562 4603 4609 4780 4859 4879 4912 5018 5045 5154 5199 5261 5301 5311\n",
            " 5378 5401 5825 6114 6152 6326 6451 6749 6770 6772 6874 6930 6945 7081\n",
            " 7136 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635 7730 7770 7781\n",
            " 7809 7904 8078 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258 9282\n",
            " 9364 9465 9595 9755 9963]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "531 [  19   35   42  114  131  147  160  193  197  210  216  219  270  272\n",
            "  279  283  298  305  314  315  325  344  363  372  391  392  422  430\n",
            "  437  446  473  479  486  495  496  498  504  507  509  519  520  535\n",
            "  537  546  553  557  567  568  572  575  581  591  592  594  604  607\n",
            "  622  623  625  626  628  630  641  661  691  706  708  716  720  728\n",
            "  736  743  744  746  757  758  764  767  799  802  803  806  810  816\n",
            "  818  823  824  854  859  874  895  900  903  905  916  921  922  923\n",
            "  925  928  932  945  950  952  954  974  993 1025 1047 1055 1062 1064\n",
            " 1083 1085 1088 1112 1115 1124 1126 1138 1148 1152 1156 1198 1207 1216\n",
            " 1221 1230 1249 1255 1256 1270 1271 1287 1289 1296 1302 1320 1353 1378\n",
            " 1403 1408 1409 1432 1445 1457 1467 1472 1475 1489 1508 1516 1531 1549\n",
            " 1550 1553 1563 1571 1597 1601 1606 1650 1651 1655 1671 1684 1686 1689\n",
            " 1700 1702 1710 1713 1718 1747 1754 1761 1766 1773 1775 1807 1811 1879\n",
            " 1892 1905 1914 1933 1942 1949 1950 1979 1980 1989 1992 2017 2020 2036\n",
            " 2037 2048 2056 2071 2074 2075 2087 2097 2107 2128 2144 2158 2162 2172\n",
            " 2185 2188 2209 2213 2243 2255 2256 2260 2266 2269 2276 2311 2320 2326\n",
            " 2335 2350 2369 2376 2377 2398 2414 2451 2466 2479 2485 2497 2515 2525\n",
            " 2532 2533 2536 2550 2603 2609 2633 2641 2645 2670 2674 2679 2692 2704\n",
            " 2723 2750 2759 2785 2804 2842 2865 2869 2871 2892 2895 2899 2908 2936\n",
            " 2958 2989 3000 3009 3010 3029 3034 3043 3057 3066 3090 3091 3111 3113\n",
            " 3114 3138 3156 3171 3209 3210 3224 3242 3251 3266 3289 3319 3334 3350\n",
            " 3356 3411 3416 3431 3436 3453 3492 3494 3526 3545 3567 3569 3576 3591\n",
            " 3616 3621 3673 3675 3733 3751 3772 3830 3845 3854 3859 3928 3968 3981\n",
            " 3988 4012 4016 4036 4060 4100 4116 4166 4180 4253 4267 4282 4315 4321\n",
            " 4336 4339 4369 4373 4465 4473 4479 4554 4562 4578 4603 4609 4662 4669\n",
            " 4725 4730 4780 4789 4813 4836 4848 4851 4859 4879 4912 5018 5045 5067\n",
            " 5084 5154 5191 5199 5237 5240 5261 5297 5301 5309 5311 5378 5401 5440\n",
            " 5442 5506 5508 5523 5587 5709 5725 5773 5796 5803 5820 5825 5875 5913\n",
            " 5915 5937 5991 5994 6033 6045 6077 6103 6114 6117 6152 6156 6210 6222\n",
            " 6237 6241 6275 6326 6391 6401 6451 6481 6510 6520 6559 6603 6620 6642\n",
            " 6660 6698 6742 6749 6770 6772 6874 6881 6911 6919 6926 6930 6945 6960\n",
            " 6962 6982 6992 6997 7041 7055 7081 7097 7100 7126 7136 7165 7166 7196\n",
            " 7202 7222 7227 7231 7249 7317 7320 7339 7397 7402 7405 7410 7433 7438\n",
            " 7454 7455 7457 7532 7539 7567 7586 7635 7682 7709 7722 7730 7770 7772\n",
            " 7780 7781 7809 7836 7904 7917 7931 7956 8009 8031 8037 8051 8078 8260\n",
            " 8265 8287 8307 8353 8413 8446 8490 8499 8524 8690 8701 8747 8872 8938\n",
            " 8950 8981 8983 9028 9064 9110 9223 9254 9258 9282 9308 9315 9317 9364\n",
            " 9372 9465 9482 9571 9595 9598 9671 9692 9755 9761 9909 9947 9963]\n",
            "\n",
            "531 [0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
            " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
            " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
            " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
            " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
            " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
            " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
            " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
            " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
            " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
            " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
            " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
            " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
            " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
            " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003 0.50193864\n",
            " 0.5233011  0.5019427  0.5018813  0.50333184 0.5077932  0.50032276\n",
            " 0.50399214 0.5019776  0.5021962  0.5033606  0.5050345  0.5007271\n",
            " 0.5004271  0.5017781  0.5036346  0.50294876 0.50129485 0.5051949\n",
            " 0.5017786  0.5161055  0.50030917 0.5002334  0.50054634 0.502441\n",
            " 0.5237737  0.5001335  0.5006088  0.50079876 0.5014565  0.50006247\n",
            " 0.50135255 0.50461596 0.5019814  0.5039658  0.5043177  0.5013857\n",
            " 0.502333   0.5085428  0.5096458  0.50051713 0.50184417 0.50187564\n",
            " 0.5099776  0.5015396  0.5042541  0.5000276  0.5010012  0.50823355\n",
            " 0.50321233 0.5006847  0.50657576 0.5020534  0.5022483  0.5023252\n",
            " 0.5014854  0.5001313  0.5045973  0.50070107 0.507189   0.5002941\n",
            " 0.5032144  0.5077739  0.50406307 0.5028727  0.50317496 0.50501096\n",
            " 0.50741047 0.5005272  0.5007295  0.5030393  0.50157464 0.5061432\n",
            " 0.5058737  0.50209904 0.500265   0.5042856  0.5025591  0.5169088\n",
            " 0.500369   0.5214425  0.5026731  0.5059941  0.5012068  0.505363\n",
            " 0.5002419  0.50673103 0.5031148  0.5022421  0.50023556 0.5003679\n",
            " 0.50088286 0.5002486  0.5011168  0.500298   0.50125176 0.50034547\n",
            " 0.5058143  0.5004563  0.5068892  0.5018134  0.5005777  0.5015998\n",
            " 0.50586724 0.5013415  0.5067641  0.5007844  0.50625074 0.516391\n",
            " 0.5032432  0.50455743 0.5083711  0.50418454 0.5023767  0.50140953\n",
            " 0.5024658  0.5008551  0.5035298  0.50405866 0.5040264  0.5013136\n",
            " 0.5051417  0.50176305 0.5002963  0.50232077 0.5040539  0.51692504\n",
            " 0.5022951  0.50303423 0.5035956  0.5005876  0.5138081  0.50151676\n",
            " 0.50688004 0.5035969  0.50227123 0.5066609  0.5006303  0.50437456\n",
            " 0.5034663  0.501092   0.50317615 0.5015915  0.5000509  0.50150824\n",
            " 0.5033506  0.501502   0.5015722  0.50149184 0.5027045  0.5010111\n",
            " 0.5048253  0.50238866 0.50417536 0.50079346 0.50387055 0.5008435\n",
            " 0.50570333 0.50241864 0.5049395  0.50353813 0.50055224 0.5001007\n",
            " 0.50495845 0.5020584  0.5029562  0.50052553 0.50013536 0.50102925\n",
            " 0.5042794  0.50152725 0.51976407 0.50223374 0.5095835  0.50119936\n",
            " 0.50206643 0.50154394 0.50441885 0.50040376 0.5090414  0.50425774\n",
            " 0.50005317 0.50170726 0.50056136 0.5039086  0.50194675 0.5036079\n",
            " 0.500602   0.51120573 0.5003541  0.5008197  0.5046707  0.5047756\n",
            " 0.5013298  0.5008607  0.5029928  0.5081413  0.50048333 0.5002262\n",
            " 0.5062425  0.51041156 0.5010636  0.50207835 0.5004797  0.5024966\n",
            " 0.5009555  0.50120705 0.50257754 0.5039481  0.5017446  0.5046624\n",
            " 0.50180703 0.50295836 0.50405467 0.5089567  0.50125986 0.50239694\n",
            " 0.5055027  0.5020613  0.50466657 0.5017311  0.50364494 0.5028926\n",
            " 0.502351   0.5008175  0.5048126  0.50009435 0.5000998  0.50252193\n",
            " 0.5009848  0.5095472  0.50449383 0.5014222  0.50868195 0.5000881\n",
            " 0.5028848  0.5000194  0.517191   0.5017843  0.51050824 0.52135193\n",
            " 0.50004286 0.500251   0.5026527  0.5033862  0.50450546 0.5012733\n",
            " 0.50316685 0.5001279  0.50104624 0.50388986 0.5065444  0.5117828\n",
            " 0.5046769  0.5077476  0.5073464  0.5024187  0.502269   0.5068733\n",
            " 0.5025758  0.50690585 0.50012517 0.50204784 0.51100546 0.5031314\n",
            " 0.53645223 0.50260043 0.5305647  0.5244196  0.5123694  0.50030005\n",
            " 0.50179744 0.50070655 0.50187504 0.50241065 0.50097615 0.5004209\n",
            " 0.50410026 0.50412995 0.50075006 0.50034535 0.5006251  0.50871956\n",
            " 0.50043744 0.50387764 0.50013226 0.5001125  0.5010285  0.50263464\n",
            " 0.5017195  0.50063664 0.50241137 0.5002141  0.51622677 0.5017507\n",
            " 0.5054098  0.5012449  0.5019777  0.50268674 0.501439   0.5006176\n",
            " 0.50002676 0.51473963 0.5032707  0.50065583 0.5042906  0.50046515\n",
            " 0.5008358  0.50289613 0.50163007 0.50055    0.5006611  0.50001824\n",
            " 0.500902   0.5025525  0.50301874 0.50429374 0.5061972  0.50630987\n",
            " 0.5104396  0.5004639  0.5016632  0.5005977  0.50134534 0.5041905\n",
            " 0.5057943  0.5005898  0.5011946  0.5020207  0.50016475 0.50245583\n",
            " 0.5004136  0.5007595  0.5042677  0.5003235  0.5001593  0.50168556\n",
            " 0.5041696  0.50180286 0.50803363 0.50103134 0.50168335 0.507005\n",
            " 0.5105519  0.5059834  0.5016305  0.50811034 0.5013556  0.5019086\n",
            " 0.50172263 0.5073309  0.5156956  0.50974417 0.5032969  0.5011608\n",
            " 0.50009733 0.53266937 0.5035469  0.5028987  0.50063163 0.500409\n",
            " 0.50032055 0.5122719  0.5012948  0.5000725  0.50118923 0.5057144\n",
            " 0.506186   0.501088   0.5000707  0.5078673  0.5045751  0.50388914\n",
            " 0.51368195 0.5019669  0.50036156 0.50219053 0.5032656  0.5004837\n",
            " 0.5024662  0.5008789  0.50419086 0.50123715 0.50037897 0.5009113\n",
            " 0.50567675 0.5000989  0.5010555  0.5028809  0.50204444 0.51495695\n",
            " 0.5028022  0.5118773  0.50547427 0.50415117 0.500101   0.53384894\n",
            " 0.5004925  0.5157178  0.5012213  0.5075401  0.50168836 0.5015672\n",
            " 0.50564915 0.5162541  0.51641345 0.5074288  0.5005564  0.5019221\n",
            " 0.50063413 0.5065996  0.5004202  0.5044905  0.50132984 0.5010047\n",
            " 0.5219561  0.5008338  0.5003478  0.50031644 0.5042497  0.5006778\n",
            " 0.50030535 0.5016988  0.506133  ]\n",
            "\n",
            "Matched draws\n",
            "Count: 0, Index: (array([], dtype=int64),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "All matched\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "-----------2020-03-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(979893, 34) (979893,) (10000, 34) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 947191, 1: 32702})\n",
            "\n",
            "scale_pos_weight - 28.964314109228795\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.964314109228795, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.964314109228795]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.000, F-Score=0.00000\n",
            "\n",
            "Recall: 0.0\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
            "          1       0.00      0.00      0.95      0.00      0.00      0.00         0\n",
            "\n",
            "avg / total       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCBIAgCMECQDAkf8DggskRHfu+VcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9469</td>\n",
              "      <td>-0.01062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity Optimize\n",
              "XGBClassifier_optimize            0           0           0.9469 -0.01062"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 531 \n",
            "\n",
            "First 23 matches\n",
            "23 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
            " 314 315 325 344 363]\n",
            "\n",
            "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[9254 2255 9258 1933 2479  905 4562 4609 9595 1949  824 3111 1047 5378\n",
            " 8938 5311 1271  950 7455   19  823  592 5301]\n",
            "\n",
            "\n",
            "[0.5162541  0.516391   0.51641345 0.5169088  0.51692504 0.5199717\n",
            " 0.517191   0.52135193 0.5219561  0.5214425  0.51795864 0.51976407\n",
            " 0.5233011  0.5244196  0.53384894 0.5305647  0.5237737  0.5277239\n",
            " 0.53266937 0.52574754 0.52792144 0.53220713 0.53645223]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "107 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
            " 314 315 325 344 363 372 391 392 422 430 437 446 473 479 486 495 496 498\n",
            " 504 507 509 519 520 535 537 546 553 557 567 568 572 575 581 591 592 594\n",
            " 604 607 622 623 625 626 628 630 641 661 691 706 708 716 720 728 736 743\n",
            " 744 746 757 758 764 767 799 802 803 806 810 816 818 823 824 854 859 874\n",
            " 895 900 903 905 916 921 922 923 925 928 932 945 950 952 954 974 993]\n",
            "\n",
            "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
            " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
            " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
            " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
            " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
            " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
            " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
            " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
            " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
            " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
            " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
            " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
            " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
            " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
            " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.505134642124176\n",
            "\n",
            "130 [  19   35  147  210  216  283  422  495  504  507  509  546  567  572\n",
            "  592  594  622  641  661  708  743  758  799  802  806  810  823  824\n",
            "  854  895  900  903  905  923  925  950 1047 1083 1216 1230 1271 1457\n",
            " 1467 1508 1553 1597 1686 1702 1754 1807 1811 1933 1949 1979 1989 2017\n",
            " 2107 2144 2185 2209 2243 2255 2266 2377 2479 2532 2536 2609 2908 3111\n",
            " 3114 3224 3411 3545 3576 3591 3981 4016 4339 4465 4562 4603 4609 4859\n",
            " 4879 5018 5045 5154 5199 5261 5301 5311 5378 5401 5825 6114 6152 6326\n",
            " 6770 6772 6874 6945 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635\n",
            " 7730 7770 7781 7904 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258\n",
            " 9282 9364 9595 9963]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5041610598564148\n",
            "\n",
            "173 [  19   35  147  210  216  283  315  422  473  495  498  504  507  509\n",
            "  535  546  553  557  567  572  575  592  594  604  622  625  641  661\n",
            "  708  743  758  799  802  806  810  823  824  854  895  900  903  905\n",
            "  923  925  950 1047 1083 1126 1216 1230 1271 1378 1409 1457 1467 1508\n",
            " 1531 1553 1597 1671 1686 1702 1747 1754 1807 1811 1905 1933 1949 1979\n",
            " 1989 2017 2107 2144 2185 2209 2243 2255 2260 2266 2269 2377 2479 2532\n",
            " 2536 2609 2641 2865 2871 2908 2958 3010 3090 3111 3114 3209 3224 3242\n",
            " 3411 3436 3453 3545 3576 3591 3854 3981 4016 4060 4267 4339 4369 4465\n",
            " 4562 4603 4609 4780 4859 4879 4912 5018 5045 5154 5199 5261 5301 5311\n",
            " 5378 5401 5825 6114 6152 6326 6451 6749 6770 6772 6874 6930 6945 7081\n",
            " 7136 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635 7730 7770 7781\n",
            " 7809 7904 8078 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258 9282\n",
            " 9364 9465 9595 9755 9963]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "531 [  19   35   42  114  131  147  160  193  197  210  216  219  270  272\n",
            "  279  283  298  305  314  315  325  344  363  372  391  392  422  430\n",
            "  437  446  473  479  486  495  496  498  504  507  509  519  520  535\n",
            "  537  546  553  557  567  568  572  575  581  591  592  594  604  607\n",
            "  622  623  625  626  628  630  641  661  691  706  708  716  720  728\n",
            "  736  743  744  746  757  758  764  767  799  802  803  806  810  816\n",
            "  818  823  824  854  859  874  895  900  903  905  916  921  922  923\n",
            "  925  928  932  945  950  952  954  974  993 1025 1047 1055 1062 1064\n",
            " 1083 1085 1088 1112 1115 1124 1126 1138 1148 1152 1156 1198 1207 1216\n",
            " 1221 1230 1249 1255 1256 1270 1271 1287 1289 1296 1302 1320 1353 1378\n",
            " 1403 1408 1409 1432 1445 1457 1467 1472 1475 1489 1508 1516 1531 1549\n",
            " 1550 1553 1563 1571 1597 1601 1606 1650 1651 1655 1671 1684 1686 1689\n",
            " 1700 1702 1710 1713 1718 1747 1754 1761 1766 1773 1775 1807 1811 1879\n",
            " 1892 1905 1914 1933 1942 1949 1950 1979 1980 1989 1992 2017 2020 2036\n",
            " 2037 2048 2056 2071 2074 2075 2087 2097 2107 2128 2144 2158 2162 2172\n",
            " 2185 2188 2209 2213 2243 2255 2256 2260 2266 2269 2276 2311 2320 2326\n",
            " 2335 2350 2369 2376 2377 2398 2414 2451 2466 2479 2485 2497 2515 2525\n",
            " 2532 2533 2536 2550 2603 2609 2633 2641 2645 2670 2674 2679 2692 2704\n",
            " 2723 2750 2759 2785 2804 2842 2865 2869 2871 2892 2895 2899 2908 2936\n",
            " 2958 2989 3000 3009 3010 3029 3034 3043 3057 3066 3090 3091 3111 3113\n",
            " 3114 3138 3156 3171 3209 3210 3224 3242 3251 3266 3289 3319 3334 3350\n",
            " 3356 3411 3416 3431 3436 3453 3492 3494 3526 3545 3567 3569 3576 3591\n",
            " 3616 3621 3673 3675 3733 3751 3772 3830 3845 3854 3859 3928 3968 3981\n",
            " 3988 4012 4016 4036 4060 4100 4116 4166 4180 4253 4267 4282 4315 4321\n",
            " 4336 4339 4369 4373 4465 4473 4479 4554 4562 4578 4603 4609 4662 4669\n",
            " 4725 4730 4780 4789 4813 4836 4848 4851 4859 4879 4912 5018 5045 5067\n",
            " 5084 5154 5191 5199 5237 5240 5261 5297 5301 5309 5311 5378 5401 5440\n",
            " 5442 5506 5508 5523 5587 5709 5725 5773 5796 5803 5820 5825 5875 5913\n",
            " 5915 5937 5991 5994 6033 6045 6077 6103 6114 6117 6152 6156 6210 6222\n",
            " 6237 6241 6275 6326 6391 6401 6451 6481 6510 6520 6559 6603 6620 6642\n",
            " 6660 6698 6742 6749 6770 6772 6874 6881 6911 6919 6926 6930 6945 6960\n",
            " 6962 6982 6992 6997 7041 7055 7081 7097 7100 7126 7136 7165 7166 7196\n",
            " 7202 7222 7227 7231 7249 7317 7320 7339 7397 7402 7405 7410 7433 7438\n",
            " 7454 7455 7457 7532 7539 7567 7586 7635 7682 7709 7722 7730 7770 7772\n",
            " 7780 7781 7809 7836 7904 7917 7931 7956 8009 8031 8037 8051 8078 8260\n",
            " 8265 8287 8307 8353 8413 8446 8490 8499 8524 8690 8701 8747 8872 8938\n",
            " 8950 8981 8983 9028 9064 9110 9223 9254 9258 9282 9308 9315 9317 9364\n",
            " 9372 9465 9482 9571 9595 9598 9671 9692 9755 9761 9909 9947 9963]\n",
            "\n",
            "531 [0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
            " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
            " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
            " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
            " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
            " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
            " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
            " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
            " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
            " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
            " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
            " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
            " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
            " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
            " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003 0.50193864\n",
            " 0.5233011  0.5019427  0.5018813  0.50333184 0.5077932  0.50032276\n",
            " 0.50399214 0.5019776  0.5021962  0.5033606  0.5050345  0.5007271\n",
            " 0.5004271  0.5017781  0.5036346  0.50294876 0.50129485 0.5051949\n",
            " 0.5017786  0.5161055  0.50030917 0.5002334  0.50054634 0.502441\n",
            " 0.5237737  0.5001335  0.5006088  0.50079876 0.5014565  0.50006247\n",
            " 0.50135255 0.50461596 0.5019814  0.5039658  0.5043177  0.5013857\n",
            " 0.502333   0.5085428  0.5096458  0.50051713 0.50184417 0.50187564\n",
            " 0.5099776  0.5015396  0.5042541  0.5000276  0.5010012  0.50823355\n",
            " 0.50321233 0.5006847  0.50657576 0.5020534  0.5022483  0.5023252\n",
            " 0.5014854  0.5001313  0.5045973  0.50070107 0.507189   0.5002941\n",
            " 0.5032144  0.5077739  0.50406307 0.5028727  0.50317496 0.50501096\n",
            " 0.50741047 0.5005272  0.5007295  0.5030393  0.50157464 0.5061432\n",
            " 0.5058737  0.50209904 0.500265   0.5042856  0.5025591  0.5169088\n",
            " 0.500369   0.5214425  0.5026731  0.5059941  0.5012068  0.505363\n",
            " 0.5002419  0.50673103 0.5031148  0.5022421  0.50023556 0.5003679\n",
            " 0.50088286 0.5002486  0.5011168  0.500298   0.50125176 0.50034547\n",
            " 0.5058143  0.5004563  0.5068892  0.5018134  0.5005777  0.5015998\n",
            " 0.50586724 0.5013415  0.5067641  0.5007844  0.50625074 0.516391\n",
            " 0.5032432  0.50455743 0.5083711  0.50418454 0.5023767  0.50140953\n",
            " 0.5024658  0.5008551  0.5035298  0.50405866 0.5040264  0.5013136\n",
            " 0.5051417  0.50176305 0.5002963  0.50232077 0.5040539  0.51692504\n",
            " 0.5022951  0.50303423 0.5035956  0.5005876  0.5138081  0.50151676\n",
            " 0.50688004 0.5035969  0.50227123 0.5066609  0.5006303  0.50437456\n",
            " 0.5034663  0.501092   0.50317615 0.5015915  0.5000509  0.50150824\n",
            " 0.5033506  0.501502   0.5015722  0.50149184 0.5027045  0.5010111\n",
            " 0.5048253  0.50238866 0.50417536 0.50079346 0.50387055 0.5008435\n",
            " 0.50570333 0.50241864 0.5049395  0.50353813 0.50055224 0.5001007\n",
            " 0.50495845 0.5020584  0.5029562  0.50052553 0.50013536 0.50102925\n",
            " 0.5042794  0.50152725 0.51976407 0.50223374 0.5095835  0.50119936\n",
            " 0.50206643 0.50154394 0.50441885 0.50040376 0.5090414  0.50425774\n",
            " 0.50005317 0.50170726 0.50056136 0.5039086  0.50194675 0.5036079\n",
            " 0.500602   0.51120573 0.5003541  0.5008197  0.5046707  0.5047756\n",
            " 0.5013298  0.5008607  0.5029928  0.5081413  0.50048333 0.5002262\n",
            " 0.5062425  0.51041156 0.5010636  0.50207835 0.5004797  0.5024966\n",
            " 0.5009555  0.50120705 0.50257754 0.5039481  0.5017446  0.5046624\n",
            " 0.50180703 0.50295836 0.50405467 0.5089567  0.50125986 0.50239694\n",
            " 0.5055027  0.5020613  0.50466657 0.5017311  0.50364494 0.5028926\n",
            " 0.502351   0.5008175  0.5048126  0.50009435 0.5000998  0.50252193\n",
            " 0.5009848  0.5095472  0.50449383 0.5014222  0.50868195 0.5000881\n",
            " 0.5028848  0.5000194  0.517191   0.5017843  0.51050824 0.52135193\n",
            " 0.50004286 0.500251   0.5026527  0.5033862  0.50450546 0.5012733\n",
            " 0.50316685 0.5001279  0.50104624 0.50388986 0.5065444  0.5117828\n",
            " 0.5046769  0.5077476  0.5073464  0.5024187  0.502269   0.5068733\n",
            " 0.5025758  0.50690585 0.50012517 0.50204784 0.51100546 0.5031314\n",
            " 0.53645223 0.50260043 0.5305647  0.5244196  0.5123694  0.50030005\n",
            " 0.50179744 0.50070655 0.50187504 0.50241065 0.50097615 0.5004209\n",
            " 0.50410026 0.50412995 0.50075006 0.50034535 0.5006251  0.50871956\n",
            " 0.50043744 0.50387764 0.50013226 0.5001125  0.5010285  0.50263464\n",
            " 0.5017195  0.50063664 0.50241137 0.5002141  0.51622677 0.5017507\n",
            " 0.5054098  0.5012449  0.5019777  0.50268674 0.501439   0.5006176\n",
            " 0.50002676 0.51473963 0.5032707  0.50065583 0.5042906  0.50046515\n",
            " 0.5008358  0.50289613 0.50163007 0.50055    0.5006611  0.50001824\n",
            " 0.500902   0.5025525  0.50301874 0.50429374 0.5061972  0.50630987\n",
            " 0.5104396  0.5004639  0.5016632  0.5005977  0.50134534 0.5041905\n",
            " 0.5057943  0.5005898  0.5011946  0.5020207  0.50016475 0.50245583\n",
            " 0.5004136  0.5007595  0.5042677  0.5003235  0.5001593  0.50168556\n",
            " 0.5041696  0.50180286 0.50803363 0.50103134 0.50168335 0.507005\n",
            " 0.5105519  0.5059834  0.5016305  0.50811034 0.5013556  0.5019086\n",
            " 0.50172263 0.5073309  0.5156956  0.50974417 0.5032969  0.5011608\n",
            " 0.50009733 0.53266937 0.5035469  0.5028987  0.50063163 0.500409\n",
            " 0.50032055 0.5122719  0.5012948  0.5000725  0.50118923 0.5057144\n",
            " 0.506186   0.501088   0.5000707  0.5078673  0.5045751  0.50388914\n",
            " 0.51368195 0.5019669  0.50036156 0.50219053 0.5032656  0.5004837\n",
            " 0.5024662  0.5008789  0.50419086 0.50123715 0.50037897 0.5009113\n",
            " 0.50567675 0.5000989  0.5010555  0.5028809  0.50204444 0.51495695\n",
            " 0.5028022  0.5118773  0.50547427 0.50415117 0.500101   0.53384894\n",
            " 0.5004925  0.5157178  0.5012213  0.5075401  0.50168836 0.5015672\n",
            " 0.50564915 0.5162541  0.51641345 0.5074288  0.5005564  0.5019221\n",
            " 0.50063413 0.5065996  0.5004202  0.5044905  0.50132984 0.5010047\n",
            " 0.5219561  0.5008338  0.5003478  0.50031644 0.5042497  0.5006778\n",
            " 0.50030535 0.5016988  0.506133  ]\n",
            "\n",
            "Matched draws\n",
            "Count: 0, Index: (array([], dtype=int64),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "All matched\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "-----------2020-03-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(979893, 34) (979893,) (10000, 34) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 947191, 1: 32702})\n",
            "\n",
            "scale_pos_weight - 28.964314109228795\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.964314109228795, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.964314109228795]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.000, F-Score=0.00000\n",
            "\n",
            "Recall: 0.0\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
            "          1       0.00      0.00      0.95      0.00      0.00      0.00         0\n",
            "\n",
            "avg / total       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCBIAgCMECQDAkf8DggskRHfu+VcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9469</td>\n",
              "      <td>-0.01062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity Optimize\n",
              "XGBClassifier_optimize            0           0           0.9469 -0.01062"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 531 \n",
            "\n",
            "First 23 matches\n",
            "23 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
            " 314 315 325 344 363]\n",
            "\n",
            "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[9254 2255 9258 1933 2479  905 4562 4609 9595 1949  824 3111 1047 5378\n",
            " 8938 5311 1271  950 7455   19  823  592 5301]\n",
            "\n",
            "\n",
            "[0.5162541  0.516391   0.51641345 0.5169088  0.51692504 0.5199717\n",
            " 0.517191   0.52135193 0.5219561  0.5214425  0.51795864 0.51976407\n",
            " 0.5233011  0.5244196  0.53384894 0.5305647  0.5237737  0.5277239\n",
            " 0.53266937 0.52574754 0.52792144 0.53220713 0.53645223]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "107 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
            " 314 315 325 344 363 372 391 392 422 430 437 446 473 479 486 495 496 498\n",
            " 504 507 509 519 520 535 537 546 553 557 567 568 572 575 581 591 592 594\n",
            " 604 607 622 623 625 626 628 630 641 661 691 706 708 716 720 728 736 743\n",
            " 744 746 757 758 764 767 799 802 803 806 810 816 818 823 824 854 859 874\n",
            " 895 900 903 905 916 921 922 923 925 928 932 945 950 952 954 974 993]\n",
            "\n",
            "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
            " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
            " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
            " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
            " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
            " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
            " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
            " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
            " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
            " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
            " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
            " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
            " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
            " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
            " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.505134642124176\n",
            "\n",
            "130 [  19   35  147  210  216  283  422  495  504  507  509  546  567  572\n",
            "  592  594  622  641  661  708  743  758  799  802  806  810  823  824\n",
            "  854  895  900  903  905  923  925  950 1047 1083 1216 1230 1271 1457\n",
            " 1467 1508 1553 1597 1686 1702 1754 1807 1811 1933 1949 1979 1989 2017\n",
            " 2107 2144 2185 2209 2243 2255 2266 2377 2479 2532 2536 2609 2908 3111\n",
            " 3114 3224 3411 3545 3576 3591 3981 4016 4339 4465 4562 4603 4609 4859\n",
            " 4879 5018 5045 5154 5199 5261 5301 5311 5378 5401 5825 6114 6152 6326\n",
            " 6770 6772 6874 6945 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635\n",
            " 7730 7770 7781 7904 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258\n",
            " 9282 9364 9595 9963]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5041610598564148\n",
            "\n",
            "173 [  19   35  147  210  216  283  315  422  473  495  498  504  507  509\n",
            "  535  546  553  557  567  572  575  592  594  604  622  625  641  661\n",
            "  708  743  758  799  802  806  810  823  824  854  895  900  903  905\n",
            "  923  925  950 1047 1083 1126 1216 1230 1271 1378 1409 1457 1467 1508\n",
            " 1531 1553 1597 1671 1686 1702 1747 1754 1807 1811 1905 1933 1949 1979\n",
            " 1989 2017 2107 2144 2185 2209 2243 2255 2260 2266 2269 2377 2479 2532\n",
            " 2536 2609 2641 2865 2871 2908 2958 3010 3090 3111 3114 3209 3224 3242\n",
            " 3411 3436 3453 3545 3576 3591 3854 3981 4016 4060 4267 4339 4369 4465\n",
            " 4562 4603 4609 4780 4859 4879 4912 5018 5045 5154 5199 5261 5301 5311\n",
            " 5378 5401 5825 6114 6152 6326 6451 6749 6770 6772 6874 6930 6945 7081\n",
            " 7136 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635 7730 7770 7781\n",
            " 7809 7904 8078 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258 9282\n",
            " 9364 9465 9595 9755 9963]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "531 [  19   35   42  114  131  147  160  193  197  210  216  219  270  272\n",
            "  279  283  298  305  314  315  325  344  363  372  391  392  422  430\n",
            "  437  446  473  479  486  495  496  498  504  507  509  519  520  535\n",
            "  537  546  553  557  567  568  572  575  581  591  592  594  604  607\n",
            "  622  623  625  626  628  630  641  661  691  706  708  716  720  728\n",
            "  736  743  744  746  757  758  764  767  799  802  803  806  810  816\n",
            "  818  823  824  854  859  874  895  900  903  905  916  921  922  923\n",
            "  925  928  932  945  950  952  954  974  993 1025 1047 1055 1062 1064\n",
            " 1083 1085 1088 1112 1115 1124 1126 1138 1148 1152 1156 1198 1207 1216\n",
            " 1221 1230 1249 1255 1256 1270 1271 1287 1289 1296 1302 1320 1353 1378\n",
            " 1403 1408 1409 1432 1445 1457 1467 1472 1475 1489 1508 1516 1531 1549\n",
            " 1550 1553 1563 1571 1597 1601 1606 1650 1651 1655 1671 1684 1686 1689\n",
            " 1700 1702 1710 1713 1718 1747 1754 1761 1766 1773 1775 1807 1811 1879\n",
            " 1892 1905 1914 1933 1942 1949 1950 1979 1980 1989 1992 2017 2020 2036\n",
            " 2037 2048 2056 2071 2074 2075 2087 2097 2107 2128 2144 2158 2162 2172\n",
            " 2185 2188 2209 2213 2243 2255 2256 2260 2266 2269 2276 2311 2320 2326\n",
            " 2335 2350 2369 2376 2377 2398 2414 2451 2466 2479 2485 2497 2515 2525\n",
            " 2532 2533 2536 2550 2603 2609 2633 2641 2645 2670 2674 2679 2692 2704\n",
            " 2723 2750 2759 2785 2804 2842 2865 2869 2871 2892 2895 2899 2908 2936\n",
            " 2958 2989 3000 3009 3010 3029 3034 3043 3057 3066 3090 3091 3111 3113\n",
            " 3114 3138 3156 3171 3209 3210 3224 3242 3251 3266 3289 3319 3334 3350\n",
            " 3356 3411 3416 3431 3436 3453 3492 3494 3526 3545 3567 3569 3576 3591\n",
            " 3616 3621 3673 3675 3733 3751 3772 3830 3845 3854 3859 3928 3968 3981\n",
            " 3988 4012 4016 4036 4060 4100 4116 4166 4180 4253 4267 4282 4315 4321\n",
            " 4336 4339 4369 4373 4465 4473 4479 4554 4562 4578 4603 4609 4662 4669\n",
            " 4725 4730 4780 4789 4813 4836 4848 4851 4859 4879 4912 5018 5045 5067\n",
            " 5084 5154 5191 5199 5237 5240 5261 5297 5301 5309 5311 5378 5401 5440\n",
            " 5442 5506 5508 5523 5587 5709 5725 5773 5796 5803 5820 5825 5875 5913\n",
            " 5915 5937 5991 5994 6033 6045 6077 6103 6114 6117 6152 6156 6210 6222\n",
            " 6237 6241 6275 6326 6391 6401 6451 6481 6510 6520 6559 6603 6620 6642\n",
            " 6660 6698 6742 6749 6770 6772 6874 6881 6911 6919 6926 6930 6945 6960\n",
            " 6962 6982 6992 6997 7041 7055 7081 7097 7100 7126 7136 7165 7166 7196\n",
            " 7202 7222 7227 7231 7249 7317 7320 7339 7397 7402 7405 7410 7433 7438\n",
            " 7454 7455 7457 7532 7539 7567 7586 7635 7682 7709 7722 7730 7770 7772\n",
            " 7780 7781 7809 7836 7904 7917 7931 7956 8009 8031 8037 8051 8078 8260\n",
            " 8265 8287 8307 8353 8413 8446 8490 8499 8524 8690 8701 8747 8872 8938\n",
            " 8950 8981 8983 9028 9064 9110 9223 9254 9258 9282 9308 9315 9317 9364\n",
            " 9372 9465 9482 9571 9595 9598 9671 9692 9755 9761 9909 9947 9963]\n",
            "\n",
            "531 [0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
            " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
            " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
            " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
            " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
            " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
            " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
            " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
            " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
            " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
            " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
            " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
            " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
            " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
            " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
            " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
            " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
            " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003 0.50193864\n",
            " 0.5233011  0.5019427  0.5018813  0.50333184 0.5077932  0.50032276\n",
            " 0.50399214 0.5019776  0.5021962  0.5033606  0.5050345  0.5007271\n",
            " 0.5004271  0.5017781  0.5036346  0.50294876 0.50129485 0.5051949\n",
            " 0.5017786  0.5161055  0.50030917 0.5002334  0.50054634 0.502441\n",
            " 0.5237737  0.5001335  0.5006088  0.50079876 0.5014565  0.50006247\n",
            " 0.50135255 0.50461596 0.5019814  0.5039658  0.5043177  0.5013857\n",
            " 0.502333   0.5085428  0.5096458  0.50051713 0.50184417 0.50187564\n",
            " 0.5099776  0.5015396  0.5042541  0.5000276  0.5010012  0.50823355\n",
            " 0.50321233 0.5006847  0.50657576 0.5020534  0.5022483  0.5023252\n",
            " 0.5014854  0.5001313  0.5045973  0.50070107 0.507189   0.5002941\n",
            " 0.5032144  0.5077739  0.50406307 0.5028727  0.50317496 0.50501096\n",
            " 0.50741047 0.5005272  0.5007295  0.5030393  0.50157464 0.5061432\n",
            " 0.5058737  0.50209904 0.500265   0.5042856  0.5025591  0.5169088\n",
            " 0.500369   0.5214425  0.5026731  0.5059941  0.5012068  0.505363\n",
            " 0.5002419  0.50673103 0.5031148  0.5022421  0.50023556 0.5003679\n",
            " 0.50088286 0.5002486  0.5011168  0.500298   0.50125176 0.50034547\n",
            " 0.5058143  0.5004563  0.5068892  0.5018134  0.5005777  0.5015998\n",
            " 0.50586724 0.5013415  0.5067641  0.5007844  0.50625074 0.516391\n",
            " 0.5032432  0.50455743 0.5083711  0.50418454 0.5023767  0.50140953\n",
            " 0.5024658  0.5008551  0.5035298  0.50405866 0.5040264  0.5013136\n",
            " 0.5051417  0.50176305 0.5002963  0.50232077 0.5040539  0.51692504\n",
            " 0.5022951  0.50303423 0.5035956  0.5005876  0.5138081  0.50151676\n",
            " 0.50688004 0.5035969  0.50227123 0.5066609  0.5006303  0.50437456\n",
            " 0.5034663  0.501092   0.50317615 0.5015915  0.5000509  0.50150824\n",
            " 0.5033506  0.501502   0.5015722  0.50149184 0.5027045  0.5010111\n",
            " 0.5048253  0.50238866 0.50417536 0.50079346 0.50387055 0.5008435\n",
            " 0.50570333 0.50241864 0.5049395  0.50353813 0.50055224 0.5001007\n",
            " 0.50495845 0.5020584  0.5029562  0.50052553 0.50013536 0.50102925\n",
            " 0.5042794  0.50152725 0.51976407 0.50223374 0.5095835  0.50119936\n",
            " 0.50206643 0.50154394 0.50441885 0.50040376 0.5090414  0.50425774\n",
            " 0.50005317 0.50170726 0.50056136 0.5039086  0.50194675 0.5036079\n",
            " 0.500602   0.51120573 0.5003541  0.5008197  0.5046707  0.5047756\n",
            " 0.5013298  0.5008607  0.5029928  0.5081413  0.50048333 0.5002262\n",
            " 0.5062425  0.51041156 0.5010636  0.50207835 0.5004797  0.5024966\n",
            " 0.5009555  0.50120705 0.50257754 0.5039481  0.5017446  0.5046624\n",
            " 0.50180703 0.50295836 0.50405467 0.5089567  0.50125986 0.50239694\n",
            " 0.5055027  0.5020613  0.50466657 0.5017311  0.50364494 0.5028926\n",
            " 0.502351   0.5008175  0.5048126  0.50009435 0.5000998  0.50252193\n",
            " 0.5009848  0.5095472  0.50449383 0.5014222  0.50868195 0.5000881\n",
            " 0.5028848  0.5000194  0.517191   0.5017843  0.51050824 0.52135193\n",
            " 0.50004286 0.500251   0.5026527  0.5033862  0.50450546 0.5012733\n",
            " 0.50316685 0.5001279  0.50104624 0.50388986 0.5065444  0.5117828\n",
            " 0.5046769  0.5077476  0.5073464  0.5024187  0.502269   0.5068733\n",
            " 0.5025758  0.50690585 0.50012517 0.50204784 0.51100546 0.5031314\n",
            " 0.53645223 0.50260043 0.5305647  0.5244196  0.5123694  0.50030005\n",
            " 0.50179744 0.50070655 0.50187504 0.50241065 0.50097615 0.5004209\n",
            " 0.50410026 0.50412995 0.50075006 0.50034535 0.5006251  0.50871956\n",
            " 0.50043744 0.50387764 0.50013226 0.5001125  0.5010285  0.50263464\n",
            " 0.5017195  0.50063664 0.50241137 0.5002141  0.51622677 0.5017507\n",
            " 0.5054098  0.5012449  0.5019777  0.50268674 0.501439   0.5006176\n",
            " 0.50002676 0.51473963 0.5032707  0.50065583 0.5042906  0.50046515\n",
            " 0.5008358  0.50289613 0.50163007 0.50055    0.5006611  0.50001824\n",
            " 0.500902   0.5025525  0.50301874 0.50429374 0.5061972  0.50630987\n",
            " 0.5104396  0.5004639  0.5016632  0.5005977  0.50134534 0.5041905\n",
            " 0.5057943  0.5005898  0.5011946  0.5020207  0.50016475 0.50245583\n",
            " 0.5004136  0.5007595  0.5042677  0.5003235  0.5001593  0.50168556\n",
            " 0.5041696  0.50180286 0.50803363 0.50103134 0.50168335 0.507005\n",
            " 0.5105519  0.5059834  0.5016305  0.50811034 0.5013556  0.5019086\n",
            " 0.50172263 0.5073309  0.5156956  0.50974417 0.5032969  0.5011608\n",
            " 0.50009733 0.53266937 0.5035469  0.5028987  0.50063163 0.500409\n",
            " 0.50032055 0.5122719  0.5012948  0.5000725  0.50118923 0.5057144\n",
            " 0.506186   0.501088   0.5000707  0.5078673  0.5045751  0.50388914\n",
            " 0.51368195 0.5019669  0.50036156 0.50219053 0.5032656  0.5004837\n",
            " 0.5024662  0.5008789  0.50419086 0.50123715 0.50037897 0.5009113\n",
            " 0.50567675 0.5000989  0.5010555  0.5028809  0.50204444 0.51495695\n",
            " 0.5028022  0.5118773  0.50547427 0.50415117 0.500101   0.53384894\n",
            " 0.5004925  0.5157178  0.5012213  0.5075401  0.50168836 0.5015672\n",
            " 0.50564915 0.5162541  0.51641345 0.5074288  0.5005564  0.5019221\n",
            " 0.50063413 0.5065996  0.5004202  0.5044905  0.50132984 0.5010047\n",
            " 0.5219561  0.5008338  0.5003478  0.50031644 0.5042497  0.5006778\n",
            " 0.50030535 0.5016988  0.506133  ]\n",
            "\n",
            "Matched draws\n",
            "Count: 0, Index: (array([], dtype=int64),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "All matched\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "-----------2020-03-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(979893, 34) (979893,) (10000, 34) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 947191, 1: 32702})\n",
            "\n",
            "scale_pos_weight - 28.964314109228795\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.964314109228795, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.964314109228795]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yASd8nZFR7Qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}