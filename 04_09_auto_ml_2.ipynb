{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mengwangk/dl-projects/blob/master/04_09_auto_ml_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hyoPGdjpqa_"
   },
   "source": [
    "# Automated ML - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLxr2k_ue8yq"
   },
   "outputs": [],
   "source": [
    "COLAB = False\n",
    "\n",
    "DATASET_NAME = '4D.zip'\n",
    "\n",
    "FEATURE_DATASET_PREFIX = 'feature_matrix_d2_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwYshXtLt7b7"
   },
   "outputs": [],
   "source": [
    "#!pip install -U imblearn\n",
    "#!pip install -U xgboost\n",
    "# !pip install -U featuretools\n",
    "\n",
    "# https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28\n",
    "# https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "# https://machinelearningmastery.com/imbalanced-classification-model-to-detect-oil-spills/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "oy5ww2zRfFGG",
    "outputId": "b6993f5a-c160-4ff2-c7cc-f0cfba445745"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  !rm -rf dl-projects\n",
    "  !git clone https://github.com/mengwangk/dl-projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G2xin10SfozR"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  !cp dl-projects/utils* .\n",
    "  !cp dl-projects/preprocess* .\n",
    "  !cp dl-projects/plot* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fC2-l3JBpqbE"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TP7V_IzepqbK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import matplotlib\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import featuretools as ft\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, make_scorer, recall_score, roc_curve, mean_squared_error, accuracy_score, average_precision_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedShuffleSplit, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.under_sampling import (RandomUnderSampler, \n",
    "                                     ClusterCentroids,\n",
    "                                     TomekLinks,\n",
    "                                     NeighbourhoodCleaningRule,\n",
    "                                     AllKNN,\n",
    "                                     NearMiss,\n",
    "                                     OneSidedSelection,\n",
    "                                     EditedNearestNeighbours)\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC, ADASYN \n",
    "import pylab as pl\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "# from skopt import BayesSearchCV\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "# from scikitplot.plotters import plot_precision_recall_curve\n",
    "\n",
    "from utils import feature_selection, plot_feature_importances\n",
    "from preprocess import *\n",
    "from plot import plot_correlation_matrix, plot_labeled_scatter\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# The Answer to the Ultimate Question of Life, the Universe, and Everything.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "3bFT5CoxpqbP",
    "outputId": "e4844e9d-cee3-43e0-892d-4ca882566f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%aimport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3E16jPVPpqbV"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "U421BuhtfYS7",
    "outputId": "9a157e21-fd51-47ad-b659-b4771be7bd19"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  GDRIVE_DATASET_FOLDER = Path('gdrive/My Drive/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "9IgnETKkpqbX",
    "outputId": "8fc6b30e-f86e-4dc2-b43b-f310011b207a"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  DATASET_PATH = GDRIVE_DATASET_FOLDER\n",
    "  ORIGIN_DATASET_PATH = Path('dl-projects/datasets')\n",
    "else:\n",
    "  DATASET_PATH = Path(\"../datasets\")\n",
    "  ORIGIN_DATASET_PATH = Path('datasets')\n",
    "\n",
    "DATASET = DATASET_PATH/f\"{FEATURE_DATASET_PREFIX}.ft\"\n",
    "ORIGIN_DATASET = ORIGIN_DATASET_PATH/DATASET_NAME\n",
    "\n",
    "if COLAB:\n",
    "  !ls -l gdrive/\"My Drive\"/datasets/ --block-size=M\n",
    "  !ls -l dl-projects/datasets --block-size=M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urQTD6DQNutw"
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_feather(DATASET)\n",
    "origin_data = format_tabular(ORIGIN_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vOYlp-8Br61r"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHiN1VVlG9Kh"
   },
   "source": [
    "### View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnQXyVqng5Cm"
   },
   "outputs": [],
   "source": [
    "# Feature matrix\n",
    "feature_matrix = data.drop(columns=['NumberId', 'month', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "apMYVNz9HK9e",
    "outputId": "62c0a1de-f1a8-4733-a5eb-52be84a26120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 959893 entries, 7020 to 956511\n",
      "Columns: 214 entries, time to LAST(Results.PrizeType)_Prize\n",
      "dtypes: datetime64[ns](1), float64(155), int64(56), uint8(2)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "# Sort data\n",
    "feature_matrix.sort_values(by=['time', 'MAX(Results.LuckyNo)'], inplace=True)\n",
    "feature_matrix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "CZKTbWRFJNUq",
    "outputId": "ca2a0f35-d8e8-47f0-bf99-e7abf07a6012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution\n",
      "0    927839\n",
      "1     32054\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Positive: 927839 which is  96.66 % of the dataset\n",
      "Negative: 32054 which is  3.34 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "print('Distribution')\n",
    "print(feature_matrix['Label'].value_counts())\n",
    "print()\n",
    "print('Positive: ' + str(feature_matrix['Label'].value_counts()[0]) + ' which is ', round(feature_matrix['Label'].value_counts()[0]/len(feature_matrix) * 100,2), '% of the dataset')\n",
    "print('Negative: ' + str(feature_matrix['Label'].value_counts()[1]) + ' which is ', round(feature_matrix['Label'].value_counts()[1]/len(feature_matrix) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "plplpAQ6JrKb",
    "outputId": "df104827-9ea5-41b7-b3cd-e105f51c45aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))               7636\n",
       "CUM_MEAN(TREND(Results.LuckyNo, DrawDate))                7636\n",
       "TREND(Results.TIME_SINCE_PREVIOUS(DrawDate), DrawDate)    7636\n",
       "TREND(Results.CUM_MEAN(TotalStrike), DrawDate)            7636\n",
       "TREND(Results.CUM_SUM(LuckyNo), DrawDate)                 7636\n",
       "                                                          ... \n",
       "CUM_SUM(MIN(Results.DrawNo))                                 0\n",
       "NUM_UNIQUE(Results.DAY(DrawDate))                            0\n",
       "NUM_UNIQUE(Results.MONTH(DrawDate))                          0\n",
       "SUM(Results.PERCENTILE(LuckyNo))                             0\n",
       "time                                                         0\n",
       "Length: 214, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zF_zCRksL1Ls"
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1aLGsXSOa9K"
   },
   "outputs": [],
   "source": [
    "# Fill all NaN with 0\n",
    "feature_matrix = feature_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5A8LZ805MqjP",
    "outputId": "6f331732-b8c9-4fe5-b691-00a7823b0134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959893, 214)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "rPFOkiGjhuKj",
    "outputId": "2807d472-bf3d-43ba-fad1-10df8f77abaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:  (959893, 211)\n",
      "0 missing columns with threshold: 90.\n",
      "41 zero variance columns.\n",
      "109 collinear columns removed with threshold: 0.95.\n",
      "Total columns removed:  150\n",
      "Shape after feature selection: (959893, 61).\n"
     ]
    }
   ],
   "source": [
    "feature_matrix_selection = feature_selection(feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label']))\n",
    "# feature_matrix_selection = feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "id": "vT2K0WeJhugH",
    "outputId": "bfdf2ca8-708b-458d-8a7a-1f9e43a7751a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((959893, 61),\n",
       " Index(['STD(Results.DrawNo)', 'MAX(Results.DrawNo)', 'MAX(Results.LuckyNo)',\n",
       "        'MIN(Results.DrawNo)', 'MEAN(Results.DrawNo)', 'SKEW(Results.DrawNo)',\n",
       "        'AVG_TIME_BETWEEN(Results.DrawDate)', 'COUNT(Results)',\n",
       "        'SUM(Results.DrawNo)', 'SUM(Results.LuckyNo)',\n",
       "        'TREND(Results.DrawNo, DrawDate)', 'MONTH(first_Results_time)',\n",
       "        'DAY(first_Results_time)', 'TIME_SINCE(first_Results_time)',\n",
       "        'TIME_SINCE_PREVIOUS(first_Results_time)',\n",
       "        'STD(Results.PERCENTILE(DrawNo))',\n",
       "        'STD(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'STD(Results.CUM_SUM(DrawNo))', 'STD(Results.CUM_MEAN(LuckyNo))',\n",
       "        'MAX(Results.PERCENTILE(DrawNo))',\n",
       "        'MAX(Results.PERCENTILE(TotalStrike))',\n",
       "        'MAX(Results.CUM_MEAN(LuckyNo))',\n",
       "        'MIN(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'MIN(Results.CUM_MEAN(LuckyNo))', 'MODE(Results.MONTH(DrawDate))',\n",
       "        'MODE(Results.DAY(DrawDate))', 'MEAN(Results.TIME_SINCE(DrawDate))',\n",
       "        'MEAN(Results.PERCENTILE(DrawNo))',\n",
       "        'MEAN(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'MEAN(Results.CUM_MEAN(LuckyNo))',\n",
       "        'SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'SKEW(Results.CUM_SUM(DrawNo))', 'SKEW(Results.CUM_MEAN(LuckyNo))',\n",
       "        'LAST(Results.DAY(DrawDate))',\n",
       "        'LAST(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'LAST(Results.MONTH(DrawDate))', 'LAST(Results.CUM_MEAN(LuckyNo))',\n",
       "        'SUM(Results.TIME_SINCE(DrawDate))',\n",
       "        'SUM(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'TREND(Results.CUM_MEAN(LuckyNo), DrawDate)',\n",
       "        'TREND(Results.PERCENTILE(LuckyNo), DrawDate)',\n",
       "        'TREND(Results.PERCENTILE(DrawNo), DrawDate)',\n",
       "        'TREND(Results.PERCENTILE(TotalStrike), DrawDate)',\n",
       "        'TREND(Results.TIME_SINCE_PREVIOUS(DrawDate), DrawDate)',\n",
       "        'TREND(Results.CUM_SUM(DrawNo), DrawDate)',\n",
       "        'NUM_UNIQUE(Results.MONTH(DrawDate))',\n",
       "        'NUM_UNIQUE(Results.DAY(DrawDate))', 'CUM_SUM(MIN(Results.DrawNo))',\n",
       "        'CUM_SUM(SKEW(Results.DrawNo))',\n",
       "        'CUM_MEAN(AVG_TIME_BETWEEN(Results.DrawDate))',\n",
       "        'CUM_MEAN(SUM(Results.LuckyNo))', 'CUM_MEAN(SKEW(Results.DrawNo))',\n",
       "        'PERCENTILE(STD(Results.LuckyNo))', 'PERCENTILE(LAST(Results.DrawNo))',\n",
       "        'PERCENTILE(MAX(Results.TotalStrike))',\n",
       "        'PERCENTILE(AVG_TIME_BETWEEN(Results.DrawDate))',\n",
       "        'PERCENTILE(COUNT(Results))', 'PERCENTILE(STD(Results.DrawNo))',\n",
       "        'PERCENTILE(SKEW(Results.DrawNo))', 'PERCENTILE(SUM(Results.DrawNo))',\n",
       "        'PERCENTILE(TREND(Results.DrawNo, DrawDate))'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_selection.shape, feature_matrix_selection.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZUhYrWFiRod"
   },
   "outputs": [],
   "source": [
    "feature_matrix_selection['time'] = feature_matrix['time']\n",
    "feature_matrix_selection['TotalStrike'] = feature_matrix['TotalStrike']\n",
    "feature_matrix_selection['Label'] = feature_matrix['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hugygOqSiR6K"
   },
   "source": [
    "### Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "loagcqTEKOkO",
    "outputId": "9ae17a8d-2306-43d8-9189-b3af7f92928c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LAST(Results.PrizeType)_Prize                  0\n",
       "SKEW(Results.TIME_SINCE(DrawDate))             0\n",
       "MEAN(Results.CUM_MEAN(TotalStrike))            0\n",
       "MEAN(Results.CUM_MEAN(LuckyNo))                0\n",
       "MEAN(Results.CUM_SUM(DrawNo))                  0\n",
       "                                              ..\n",
       "CUM_SUM(COUNT(Results))                        0\n",
       "CUM_SUM(MAX(Results.DrawNo))                   0\n",
       "CUM_SUM(MEAN(Results.LuckyNo))                 0\n",
       "CUM_SUM(AVG_TIME_BETWEEN(Results.DrawDate))    0\n",
       "time                                           0\n",
       "Length: 214, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7Ha8Zlkhuoe"
   },
   "outputs": [],
   "source": [
    "# Check with feature selection\n",
    "corrs = feature_matrix_selection.corr().sort_values('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EWRODfAdPk6j",
    "outputId": "aca05752-9251-4054-afd9-762f62517343"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUM_MEAN(SUM(Results.LuckyNo))                           -0.003288\n",
       "TIME_SINCE(first_Results_time)                           -0.002944\n",
       "STD(Results.DrawNo)                                      -0.002877\n",
       "STD(Results.CUM_SUM(DrawNo))                             -0.002778\n",
       "MAX(Results.LuckyNo)                                     -0.002680\n",
       "SUM(Results.LuckyNo)                                     -0.002426\n",
       "MAX(Results.DrawNo)                                      -0.002377\n",
       "MIN(Results.CUM_MEAN(LuckyNo))                           -0.002333\n",
       "CUM_MEAN(AVG_TIME_BETWEEN(Results.DrawDate))             -0.002238\n",
       "MEAN(Results.TIME_SINCE(DrawDate))                       -0.002056\n",
       "STD(Results.PERCENTILE(DrawNo))                          -0.001937\n",
       "PERCENTILE(STD(Results.LuckyNo))                         -0.001931\n",
       "PERCENTILE(STD(Results.DrawNo))                          -0.001814\n",
       "CUM_SUM(SKEW(Results.DrawNo))                            -0.001741\n",
       "SUM(Results.TIME_SINCE(DrawDate))                        -0.001492\n",
       "MEAN(Results.CUM_MEAN(LuckyNo))                          -0.001477\n",
       "AVG_TIME_BETWEEN(Results.DrawDate)                       -0.001429\n",
       "PERCENTILE(SKEW(Results.DrawNo))                         -0.001354\n",
       "SKEW(Results.CUM_MEAN(LuckyNo))                          -0.001339\n",
       "SKEW(Results.CUM_SUM(DrawNo))                            -0.001294\n",
       "SKEW(Results.DrawNo)                                     -0.001030\n",
       "MAX(Results.PERCENTILE(DrawNo))                          -0.001006\n",
       "LAST(Results.DAY(DrawDate))                              -0.001000\n",
       "TREND(Results.CUM_SUM(DrawNo), DrawDate)                 -0.000958\n",
       "PERCENTILE(AVG_TIME_BETWEEN(Results.DrawDate))           -0.000921\n",
       "NUM_UNIQUE(Results.DAY(DrawDate))                        -0.000833\n",
       "MODE(Results.MONTH(DrawDate))                            -0.000827\n",
       "DAY(first_Results_time)                                  -0.000677\n",
       "TREND(Results.DrawNo, DrawDate)                          -0.000630\n",
       "SUM(Results.DrawNo)                                      -0.000541\n",
       "COUNT(Results)                                           -0.000535\n",
       "CUM_MEAN(SKEW(Results.DrawNo))                           -0.000398\n",
       "LAST(Results.MONTH(DrawDate))                            -0.000351\n",
       "NUM_UNIQUE(Results.MONTH(DrawDate))                      -0.000248\n",
       "SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))              -0.000226\n",
       "MEAN(Results.DrawNo)                                     -0.000160\n",
       "TREND(Results.PERCENTILE(TotalStrike), DrawDate)         -0.000156\n",
       "PERCENTILE(COUNT(Results))                               -0.000139\n",
       "LAST(Results.TIME_SINCE_PREVIOUS(DrawDate))              -0.000131\n",
       "PERCENTILE(LAST(Results.DrawNo))                         -0.000094\n",
       "TREND(Results.TIME_SINCE_PREVIOUS(DrawDate), DrawDate)    0.000169\n",
       "STD(Results.TIME_SINCE_PREVIOUS(DrawDate))                0.000213\n",
       "MEAN(Results.TIME_SINCE_PREVIOUS(DrawDate))               0.000345\n",
       "SUM(Results.TIME_SINCE_PREVIOUS(DrawDate))                0.000442\n",
       "MODE(Results.DAY(DrawDate))                               0.000471\n",
       "PERCENTILE(SUM(Results.DrawNo))                           0.000610\n",
       "TREND(Results.PERCENTILE(LuckyNo), DrawDate)              0.000687\n",
       "MONTH(first_Results_time)                                 0.000858\n",
       "PERCENTILE(TREND(Results.DrawNo, DrawDate))               0.000912\n",
       "MIN(Results.TIME_SINCE_PREVIOUS(DrawDate))                0.000984\n",
       "TIME_SINCE_PREVIOUS(first_Results_time)                   0.000987\n",
       "LAST(Results.CUM_MEAN(LuckyNo))                           0.000988\n",
       "MAX(Results.CUM_MEAN(LuckyNo))                            0.001007\n",
       "MEAN(Results.PERCENTILE(DrawNo))                          0.001149\n",
       "TREND(Results.CUM_MEAN(LuckyNo), DrawDate)                0.001493\n",
       "TREND(Results.PERCENTILE(DrawNo), DrawDate)               0.001528\n",
       "PERCENTILE(MAX(Results.TotalStrike))                      0.001564\n",
       "MIN(Results.DrawNo)                                       0.001718\n",
       "CUM_SUM(MIN(Results.DrawNo))                              0.001852\n",
       "MAX(Results.PERCENTILE(TotalStrike))                      0.002320\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs['Label'].head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "waeD1ED_kqDB"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9yrJyIVLh5So"
   },
   "outputs": [],
   "source": [
    "def recall_optim(y_true, y_pred):\n",
    "    \"\"\"Make a scoring function that improves specificity while identifying all strikes\n",
    "    \"\"\"\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Recall will be worth a greater value than specificity\n",
    "    rec = recall_score(y_true, y_pred) * 0.8 \n",
    "    spe = conf_matrix[0,0]/conf_matrix[0,:].sum() * 0.2 \n",
    "    \n",
    "    # Imperfect recalls will lose a penalty\n",
    "    # This means the best results will have perfect recalls and compete for specificity\n",
    "    if rec < 0.8:\n",
    "        rec -= 0.2\n",
    "    return rec + spe \n",
    "\n",
    "\n",
    "# Make a scoring callable from recall_score\n",
    "recall = make_scorer(recall_score)\n",
    "\n",
    "# Create a scoring callable based on the scoring function\n",
    "optimize = make_scorer(recall_optim)\n",
    "\n",
    "# Geometric mean scorer\n",
    "geo_mean_scorer = make_scorer(geometric_mean_score)\n",
    "\n",
    "# DataFrame to store classifier performance\n",
    "performance = pd.DataFrame(columns=['Train_Recall','Test_Recall','Test_Specificity', 'Optimize'])\n",
    "\n",
    "def to_labels(pos_probs, threshold):\n",
    "    \"\"\"Apply threshold to positive probabilities to create labels.\n",
    "    \"\"\"\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    " \n",
    "\n",
    "def score_optimization(dt, feature_matrix, clf, params, X_train, y_train, X_test, y_test, skip_grid_search_cv=False, optimized_scorer=False):\n",
    "    \"\"\"Find the optimized classifier.\n",
    "    \"\"\"\n",
    "    if not skip_grid_search_cv:\n",
    "      print(\"\\nFinding the optimized classifier...\")\n",
    "\n",
    "      # Load GridSearchCV\n",
    "      # search = GridSearchCV(\n",
    "      search = RandomizedSearchCV(\n",
    "            estimator=clf,\n",
    "            #param_grid=params,\n",
    "            param_distributions=params,\n",
    "            n_jobs=4,\n",
    "            scoring=optimize  # Use custom scorer\n",
    "      )\n",
    "\n",
    "      # Train search object\n",
    "      search.fit(X_train, y_train)\n",
    "\n",
    "      # Heading\n",
    "      print('\\n','-'*40,'\\n',clf.__class__.__name__,'\\n','-'*40)\n",
    "\n",
    "      # Extract best estimator\n",
    "      best = search.best_estimator_\n",
    "      print('Best parameters: \\n\\n',search.best_params_,'\\n')\n",
    "    \n",
    "    else:\n",
    "      print(\"\\nUse the passed in classifier...\\n\")\n",
    "      best = clf\n",
    "\n",
    "    # Cross-validate on the train data\n",
    "    if not skip_grid_search_cv: \n",
    "      print(\"TRAIN GROUP\")\n",
    "      #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "      cv = 3\n",
    "      if not optimized_scorer:\n",
    "        print('\\nUse default scorer')\n",
    "        train_cv = cross_val_score(\n",
    "                                  n_jobs=4,\n",
    "                                  X=X_train, \n",
    "                                  y=y_train, \n",
    "                                  estimator=best, \n",
    "                                  scoring=recall,\n",
    "                                  cv=cv)\n",
    "      else:\n",
    "        print('\\nUse optimized scorer')\n",
    "        train_cv = cross_val_score(\n",
    "                                  n_jobs=4,\n",
    "                                  X=X_train, \n",
    "                                  y=y_train, \n",
    "                                  estimator=best, \n",
    "                                  #scoring=optimize,\n",
    "                                  scoring='roc_auc',\n",
    "                                  #scoring=geo_mean_scorer,\n",
    "                                  cv=cv)\n",
    "\n",
    "      print(\"\\nCross-validation recall scores:\",train_cv)\n",
    "      print(\"Mean recall score:\",train_cv.mean())\n",
    "      print('Mean G-Mean: %.3f (%.3f)' % (np.mean(train_cv), np.std(train_cv)))\n",
    "    else:\n",
    "      train_cv = np.zeros(3)\n",
    "\n",
    "    # Now predict on the test group\n",
    "    print(\"\\nTEST GROUP\")\n",
    "    y_pred = best.fit(X_train, y_train).predict(X_test)\n",
    "    # y_pred = best.fit(X_train, y_train,\n",
    "    #                   eval_set=[(X_test, y_test)],\n",
    "    #                   eval_metric='auc',\n",
    "    #                   early_stopping_rounds=10,\n",
    "    #                   verbose=True\n",
    "    #                   ).predict(X_test)\n",
    "\n",
    "    # keep probabilities for the positive outcome only\n",
    "    probas = best.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # define thresholds\n",
    "    thresholds = np.arange(0, 1, 0.001)\n",
    "\n",
    "    # evaluate each threshold\n",
    "    scores = [f1_score(y_test, to_labels(probas, t)) for t in thresholds]\n",
    "\n",
    "    # get best threshold\n",
    "    ix = np.argmax(scores)\n",
    "    print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))\n",
    "\n",
    "    # print recall\n",
    "    print(\"\\nRecall:\",recall_score(y_test,y_pred))\n",
    "\n",
    "    # Get imbalanced classification report\n",
    "    print(classification_report_imbalanced(y_test, y_pred))\n",
    "\n",
    "    # Print confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "    plt.show()\n",
    "\n",
    "    # Store results\n",
    "    performance.loc[clf.__class__.__name__+'_optimize',:] = [\n",
    "        train_cv.mean(),\n",
    "        recall_score(y_test,y_pred),\n",
    "        conf_matrix[0,0]/conf_matrix[0,:].sum(),\n",
    "        recall_optim(y_test,y_pred)\n",
    "    ]\n",
    "    # Look at the parameters for the top best scores\n",
    "    if not skip_grid_search_cv:\n",
    "      display(pd.DataFrame(search.cv_results_).iloc[:,4:].sort_values(by='rank_test_score').head())\n",
    "    display(performance)\n",
    "\n",
    "    # Additionl info\n",
    "    print('\\n\\nAdditional Info')\n",
    "    print('='*40)\n",
    "    positive = np.where((y_pred==1))\n",
    "    print(f'Total predicted to be positive: {len(positive[0])} \\n')\n",
    "\n",
    "    # Total predicted matches\n",
    "    print('First 23 matches')\n",
    "    pred = np.where((y_pred==1))\n",
    "    print(23, pred[0][0:23])\n",
    "    print(f'\\n{probas[0:23]}\\n') \n",
    "\n",
    "    print(\"\\nTop 23 Probable Matches\")\n",
    "    #print('probas', probas)\n",
    "    topN = np.argpartition(probas, -23)[-23:]\n",
    "    print(f'\\n{topN}\\n')          # Top N most high probability numbers\n",
    "    print(f'\\n{probas[topN]}\\n')  # Top N probability\n",
    "  \n",
    "    # 25% - 75% percentile\n",
    "\n",
    "    \n",
    "    \n",
    "    # All predicted matches\n",
    "    all_preds = pred[0]\n",
    "    print(len(all_preds), all_preds)\n",
    "    \n",
    "    #print('Debug')\n",
    "    #print(pred)\n",
    "    \n",
    "    if len(positive[0]) > 0:\n",
    "    \n",
    "      # Matching draws\n",
    "      print('Matched draws')\n",
    "      md = np.where((y_pred==1) & (y_test==1))\n",
    "      print(f\"Count: {len(md[0])}, Index: {md}\")\n",
    "      month_data = feature_matrix.loc[feature_matrix['time'] == dt]\n",
    "      numbers = month_data.iloc[md[0]][['MAX(Results.LuckyNo)']]\n",
    "\n",
    "      print('\\n\\nTop 23 Possibility')\n",
    "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
    "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
    "                          (origin_data['LuckyNo'].isin(topN))].head(23))  \n",
    "      \n",
    "      print('\\n\\nFirst 23 Numbers')\n",
    "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
    "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
    "                          (origin_data['LuckyNo'].isin(pred[0][0:23]))].head(23))    \n",
    "             \n",
    "\n",
    "      print('\\n\\nAll matched')\n",
    "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
    "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
    "                          (origin_data['LuckyNo'].isin(numbers['MAX(Results.LuckyNo)']))].head(100))    \n",
    "                                                  \n",
    "    else:\n",
    "      print('No luck this month')  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrL8gYwjc-hd"
   },
   "outputs": [],
   "source": [
    "def remove_outliers(balanced, threshold=0.001, remove=True):\n",
    "    \"\"\"Removing Outliers from high-correlation features.\n",
    "    \"\"\"\n",
    "\n",
    "    if not remove:\n",
    "      return balanced\n",
    "\n",
    "    bal_corr = balanced.corr()\n",
    "    no_outliers=pd.DataFrame(balanced.copy())\n",
    "\n",
    "    cols = bal_corr.Label.index[:-1]\n",
    "\n",
    "    # For each feature correlated with Class...\n",
    "    for col in cols:\n",
    "        # If absolute correlation value is more than X percent...\n",
    "        correlation = bal_corr.loc['Label',col]\n",
    "\n",
    "        if np.absolute(correlation) > threshold:\n",
    "          # Separate the classes of the high-correlation column\n",
    "          nonstrikes = no_outliers.loc[no_outliers.Label==0,col]\n",
    "          strikes = no_outliers.loc[no_outliers.Label==1,col]\n",
    "\n",
    "          # Identify the 25th and 75th quartiles\n",
    "          all_values = no_outliers.loc[:,col]\n",
    "          q25, q75 = np.percentile(all_values, 25), np.percentile(all_values, 75)\n",
    "          # Get the inter quartile range\n",
    "          iqr = q75 - q25\n",
    "          # Smaller cutoffs will remove more outliers\n",
    "          cutoff = iqr * 7\n",
    "          # Set the bounds of the desired portion to keep\n",
    "          lower, upper = q25 - cutoff, q75 + cutoff\n",
    "          \n",
    "          # If positively correlated...\n",
    "          # Drop nonstrikes above upper bound, and strikes below lower bound\n",
    "          if correlation > 0: \n",
    "              no_outliers.drop(index=nonstrikes[nonstrikes>upper].index,inplace=True)\n",
    "              no_outliers.drop(index=strikes[strikes<lower].index,inplace=True)\n",
    "          \n",
    "          # If negatively correlated...\n",
    "          # Drop non strikes below lower bound, and strikes above upper bound\n",
    "          elif correlation < 0: \n",
    "              no_outliers.drop(index=nonstrikes[nonstrikes<lower].index,inplace=True)\n",
    "              no_outliers.drop(index=strikes[strikes>upper].index,inplace=True)\n",
    "        \n",
    "    print('\\nData shape before removing outliers:', balanced.shape)\n",
    "    print('\\nCounts of strikes VS non-strikes in previous data:')\n",
    "    print(balanced.Label.value_counts())\n",
    "    print('-'*40)\n",
    "    print('-'*40)\n",
    "    print('\\nData shape after removing outliers:', no_outliers.shape)\n",
    "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
    "    print(no_outliers.Label.value_counts())\n",
    "\n",
    "    # no_outliers.iloc[:,:-1].boxplot(rot=90,figsize=(16,4))\n",
    "    # plt.title('Distributions with Less Outliers', fontsize=17)\n",
    "    # plt.show()\n",
    "    \n",
    "    no_outliers.reset_index(drop=True, inplace=True)\n",
    "    return no_outliers\n",
    "\n",
    "\n",
    "def filter_features(no_outliers, threshold=0.001):\n",
    "    \"\"\"Feature selection.\n",
    "    \"\"\"\n",
    "    feat_sel = pd.DataFrame(no_outliers.copy())\n",
    "\n",
    "    # Make a dataframe with the label-correlations before removing outliers\n",
    "    # corr_change = pd.DataFrame()\n",
    "    # corr_change['correlation']= bal_corr.Label\n",
    "    # corr_change['origin']= 'w/outliers'\n",
    "\n",
    "    # Make a dataframe with label-correlations after removing outliers \n",
    "    # corr_other = pd.DataFrame()\n",
    "    # corr_other['correlation']= feat_sel.corr().Label\n",
    "    # corr_other['origin']= 'no_outliers'\n",
    "\n",
    "    # Join them\n",
    "    # corr_change = corr_change.append(corr_other)\n",
    "\n",
    "    # plt.figure(figsize=(14,6))\n",
    "    # plt.xticks(rotation=90)\n",
    "\n",
    "    # Plot them\n",
    "    # sns.set_style('darkgrid')\n",
    "    # plt.title('Label correlation per feature. With vs without outliers', fontsize=17)\n",
    "    # sns.barplot(data=corr_change,x=corr_change.index,y='correlation',hue='origin')\n",
    "    # plt.show()\n",
    "\n",
    "    # Feature Selection based on correlation with label\n",
    "\n",
    "    print('\\nData shape before feature selection:', feat_sel.shape)\n",
    "    print('\\nCounts of strikes vs non-strikes before feature selection:')\n",
    "    print(feat_sel.Label.value_counts())\n",
    "    print('-'*40)\n",
    "\n",
    "    # Correlation matrix after removing outliers\n",
    "    new_corr = feat_sel.corr()\n",
    "\n",
    "    for col in new_corr.Label.index[:-1]:\n",
    "        # Pick desired cutoff for dropping features. In absolute-value terms.\n",
    "        if np.absolute(new_corr.loc['Label',col]) < threshold:\n",
    "            # Drop the feature if correlation is below cutoff\n",
    "            feat_sel.drop(columns=col,inplace=True)\n",
    "\n",
    "    print('-'*40)\n",
    "    print('\\nData shape after feature selection:', feat_sel.shape)\n",
    "    print('\\nCounts of strikes vs non-strikes in new data:')\n",
    "    print(feat_sel.Label.value_counts())\n",
    "\n",
    "    return feat_sel\n",
    "\n",
    "    # feat_sel.iloc[:,:-1].boxplot(rot=90,figsize=(16,4))\n",
    "    # plt.title('Distribution of Features Selected', fontsize=17)\n",
    "    # plt.show()\n",
    "\n",
    "def under_sampler(data, sample_size=20000, sampling=False):\n",
    "    # Undersample model for efficiency and balance classes.\n",
    "\n",
    "    X_train = data.drop('Label',1)\n",
    "    y_train = data.Label\n",
    "\n",
    "    if not sampling:\n",
    "      return X_train, y_train\n",
    "\n",
    "    # After feature-selection, X_test needs to include only the same features as X_train\n",
    "    # cols = X_train.columns\n",
    "    # X_test = X_test[cols]\n",
    "\n",
    "    # Undersample and balance classes\n",
    "    X_train, y_train = RandomUnderSampler(sampling_strategy={1:sample_size,0:sample_size}).fit_resample(X_train,y_train)\n",
    "\n",
    "    print('\\nX_train shape after reduction:', X_train.shape)\n",
    "    print('\\nCounts of strikes VS non-strikes in y_train:')\n",
    "    print(np.unique(y_train, return_counts=True))\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pl5ZoepSNPf4"
   },
   "outputs": [],
   "source": [
    "def gen_train_test_set(dt, feature_matrix, file_prefix='data'): \n",
    "    \n",
    "    # Subset labels\n",
    "    test_labels = feature_matrix.loc[feature_matrix['time'] == dt, 'Label']\n",
    "    train_labels = feature_matrix.loc[feature_matrix['time'] < dt, 'Label']\n",
    "\n",
    "    # Features\n",
    "    X_train = feature_matrix[feature_matrix['time'] < dt].drop(columns = ['NumberId', 'time', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
    "    X_test = feature_matrix[feature_matrix['time'] == dt].drop(columns = ['NumberId', 'time', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
    "    feature_names = list(X_train.columns)\n",
    "    \n",
    "    # Labels\n",
    "    y_train = np.array(train_labels).reshape((-1, ))\n",
    "    y_test = np.array(test_labels).reshape((-1, ))\n",
    "    \n",
    "    print('Training on {} observations.'.format(len(X_train)))\n",
    "    print('Testing on {} observations.\\n'.format(len(X_test)))\n",
    "\n",
    "    # Join the train data\n",
    "    train = X_train.join(train_labels)\n",
    "\n",
    "    print('Data shape before balancing:', train.shape)\n",
    "    print('\\nCounts of strikes vs non-strikes in previous data:')\n",
    "    print(train.Label.value_counts())\n",
    "    print('-'*40)\n",
    "\n",
    "    # sklearn pipeline\n",
    "    pipeline = make_pipeline(\n",
    "        SimpleImputer(strategy = 'constant', fill_value=0),\n",
    "        StandardScaler())\n",
    "    \n",
    "    X_train = pipeline.fit_transform(X_train)\n",
    "    X_test = pipeline.transform(X_test)\n",
    "\n",
    "    # imblearn pipeline\n",
    "    imb_pipeline = make_pipeline_imb(\n",
    "          # NearMiss(version=3, n_neighbors_ver3=3, n_jobs=4)\n",
    "          # SMOTE(sampling_strategy='minority',random_state=42, n_jobs=4)\n",
    "          # ADASYN(sampling_strategy='minority',random_state=42, n_jobs=4)\n",
    "          # OneSidedSelection(n_neighbors=1, n_seeds_S=200, random_state=42, n_jobs=4)\n",
    "          SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='majority'))\n",
    "    )\n",
    "     \n",
    "    # Balance the data\n",
    "    to_balanced = True\n",
    "    if to_balanced:\n",
    "      print('\\nBalancing data')\n",
    "      X_bal, y_bal = imb_pipeline.fit_resample(X_train, y_train)\n",
    "      X_bal = pd.DataFrame(X_bal,columns=feature_names)\n",
    "      y_bal = pd.DataFrame(y_bal,columns=['Label'])\n",
    "    else:\n",
    "      print('\\nNO balancing')\n",
    "      X_bal = pd.DataFrame(X_train,columns=feature_names)\n",
    "      y_bal = pd.DataFrame(y_train,columns=['Label'])\n",
    "\n",
    "    balanced = X_bal.join(y_bal)\n",
    "\n",
    "    # print('-'*40)\n",
    "    print('Data shape after balancing:',balanced.shape)\n",
    "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
    "    print(balanced.Label.value_counts())\n",
    "\n",
    "    # Remove high correlation outliers\n",
    "    no_outliers = remove_outliers(balanced, remove=False)\n",
    "   \n",
    "    # Remove features with low correlation\n",
    "    remove_features = True\n",
    "    if remove_features:\n",
    "      print('\\nFiltering features')\n",
    "      features_selected = filter_features(no_outliers)\n",
    "    else:\n",
    "      print('\\nNO filtering')\n",
    "      features_selected = no_outliers \n",
    "\n",
    "    columns_selected = features_selected.drop('Label',1).columns\n",
    "\n",
    "    # Under sampling\n",
    "    X_train, y_train = under_sampler(features_selected, sampling=False) \n",
    "    X_train = pd.DataFrame(X_train,columns=columns_selected)\n",
    "    y_train = pd.DataFrame(y_train,columns=['Label'])\n",
    "\n",
    "    # For X_test, now only use the selected features\n",
    "    X_test = pd.DataFrame(X_test,columns=feature_names)\n",
    "    X_test = X_test[columns_selected]\n",
    "    y_test = pd.DataFrame(y_test,columns=['Label'])\n",
    "\n",
    "    #print(X_train.describe())\n",
    "    #return\n",
    "\n",
    "    # Save data\n",
    "    # print(X_train.head(10))\n",
    "    # print(y_train.head(10)) \n",
    "\n",
    "    # print(X_test.head(10))\n",
    "    # print(y_test.head(10)) \n",
    "    X_train.to_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
    "    y_train.to_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
    "   \n",
    "    X_test.to_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
    "    y_test.to_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
    "\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcKlL67TP9UM"
   },
   "outputs": [],
   "source": [
    "def model(dt, feature_matrix, file_prefix='data', csv=False):\n",
    "    \"\"\"Predict for a particular month.\n",
    "\n",
    "    - https://www.kaggle.com/miguelniblock/optimizing-imbalanced-classification-100-recall\n",
    "    - https://www.kaggle.com/saxinou/imbalanced-data-xgboost-tunning\n",
    "    - https://www.kaggle.com/andreanuzzo/balance-the-imbalanced-rf-and-xgboost-with-smote\n",
    "    - https://github.com/mengwangk/FraudDetection/blob/master/05_Sampling_techniques_for_extremely_imbalanced_data.ipynb\n",
    "    - https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
    "    - https://github.com/coding-maniacs/over-under-sampling/blob/master/src/main.py\n",
    "    - https://github.com/scikit-learn-contrib/imbalanced-learn/issues/552#issuecomment-466348310\n",
    "    - https://stackoverflow.com/questions/52499788/smotetomek-how-to-set-ratio-as-dictionary-for-fixed-balance\n",
    "    - https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.OneSidedSelection.html#imblearn.under_sampling.OneSidedSelection\n",
    "    - https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\n",
    "    - https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n",
    "    - https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "    - https://stats.stackexchange.com/questions/243207/what-is-the-proper-usage-of-scale-pos-weight-in-xgboost-for-imbalanced-datasets\n",
    "    - https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py\n",
    "    - https://machinelearningmastery.com/cost-sensitive-logistic-regression/\n",
    "    \n",
    "    - https://datascience.stackexchange.com/questions/28285/what-is-the-best-way-to-deal-with-imbalanced-data-for-xgboost/28292\n",
    "    - https://machinelearningmastery.com/xgboost-for-imbalanced-classification/\n",
    "    - https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Read data\n",
    "    if not csv:\n",
    "      X_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
    "      y_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
    "    \n",
    "      X_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
    "      y_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
    "    else:\n",
    "      X_train = pd.read_csv(DATASET_PATH/f\"{file_prefix}_X_train.csv\", header=0, sep=',', quotechar='\"')\n",
    "      y_train = pd.read_csv(DATASET_PATH/f\"{file_prefix}_y_train.csv\", header=0, sep=',', quotechar='\"')\n",
    "    \n",
    "      X_test = pd.read_csv(DATASET_PATH/f\"{file_prefix}_X_test.csv\", header=0, sep=',', quotechar='\"')\n",
    "      y_test = pd.read_csv(DATASET_PATH/f\"{file_prefix}_y_test.csv\", header=0, sep=',', quotechar='\"')\n",
    "\n",
    "    # Reshape\n",
    "    y_train = np.array(y_train).reshape((-1, ))\n",
    "    y_test = np.array(y_test).reshape((-1, ))\n",
    "    \n",
    "    print('Data shape')\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "    # print(X_train.describe())\n",
    "    # return\n",
    "\n",
    "    # Calculate hit ratio for xgboost classifier\n",
    "    print(\"\\nCalculating scale pos weight\")\n",
    "    counter = Counter(y_train)\n",
    "    print(Counter(y_train))\n",
    "    scale_pos_weight = float(counter[0] / counter[1])\n",
    "    print(f\"\\nscale_pos_weight - {scale_pos_weight}\\n\")\n",
    "    \n",
    "     # Modeling\n",
    "#     clf = xgb.XGBClassifier(\n",
    "#               n_jobs=4, \n",
    "#               random_state=42,\n",
    "#               #learning_rate=0.1,\n",
    "#               #n_estimators=500,\n",
    "#               #max_depth=6, \n",
    "#               #min_child_weight=3, \n",
    "#               #gamma=0,\n",
    "#               #subsample=0.8,\n",
    "#               #colsample_bytree=0.8,\n",
    "#               objective='binary:logistic', \n",
    "#               scale_pos_weight=scale_pos_weight,\n",
    "#               ##eval_metric=\"auc\",\n",
    "#               ##max_delta_step=1,\n",
    "#               seed=27)\n",
    "#     clf = xgb.XGBClassifier(n_jobs=4, \n",
    "#                             random_state=42,\n",
    "#                             objective='binary:logistic', \n",
    "#                             #scale_pos_weight=28)\n",
    "#                             scale_pos_weight=scale_pos_weight)\n",
    "    \n",
    "    clf = xgb.XGBClassifier(\n",
    "                    n_jobs=4, \n",
    "                    random_state=42,\n",
    "                    objective='binary:logistic',\n",
    "                    subsample=0.55, \n",
    "                    n_estimators=300,\n",
    "                    #n_estimators=400,\n",
    "                    min_child_weight=1,\n",
    "                    max_depth=3, \n",
    "                    learning_rate=0.007,\n",
    "                    gamma=0.1, \n",
    "                    colsample_bytree=0.95,\n",
    "                    tree_method='hist',\n",
    "                    booster='dart',\n",
    "                    scale_pos_weight=scale_pos_weight\n",
    "                    )\n",
    "\n",
    "    clf_params = clf.get_params()\n",
    "    print(clf_params)\n",
    "\n",
    "    # Set parameters\n",
    "    #clf_params['max_depth'] = 10\n",
    "    #clf.set_params(clf_params)\n",
    "\n",
    "    # Parameters to compare\n",
    "    weights = [i for i in range(1,36,1)]\n",
    "    weights.append(scale_pos_weight)\n",
    "    learn_params = {\n",
    "        'n_estimators': [100, 300, 500, 800, 1000], \n",
    "        'max_depth': range(3,10,2),\n",
    "        'min_child_weight': range(1,6,2),\n",
    "        #'gamma':[i/10.0 for i in range(0,5)],\n",
    "        'subsample':[i/100.0 for i in range(55,70,5)],\n",
    "        'colsample_bytree':[i/100.0 for i in range(85,100,5)],\n",
    "        #'learning_rate':[i/1000.0 for i in range(5,20,2)],\n",
    "        'scale_pos_weight': weights\n",
    "    }\n",
    "    print(f'Parameter distribution: {learn_params}')\n",
    "    \n",
    "    # Test and validate\n",
    "    score_optimization(dt,\n",
    "                       feature_matrix,\n",
    "                       clf, \n",
    "                       learn_params,  \n",
    "                       X_train, \n",
    "                       y_train, \n",
    "                       X_test, \n",
    "                       y_test, \n",
    "                       skip_grid_search_cv=True,\n",
    "                       optimized_scorer=True)\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    # clf.fit(X_train, y_train)\n",
    "    # y_pred = clf.predict(X_test)\n",
    "\n",
    "    # # ROC score\n",
    "    # auc = roc_auc_score(y_test, y_pred)\n",
    "    # print(\"ROC score: \", auc)\n",
    "\n",
    "    # # Print confusion matrix\n",
    "    # conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # sns.heatmap(conf_matrix, annot=True,fmt='d', cmap=plt.cm.copper)\n",
    "    # plt.show()\n",
    "\n",
    "    # Parameters to compare\n",
    "    # params = {\n",
    "    #     'criterion':['entropy','gini'],\n",
    "    #     'class_weight':[{1:1,0:0.3},{1:1,0:0.4},{1:1,0:0.5},{1:1,0:0.6},{1:1,0:7}]\n",
    "    # }\n",
    "\n",
    "    # Implement the classifier\n",
    "    # clf = RandomForestClassifier(\n",
    "    #     n_estimators=100,\n",
    "    #     max_features=None,\n",
    "    #     n_jobs=4,\n",
    "    # )\n",
    "\n",
    "    # # Test and validate\n",
    "    # score_optimization(clf, params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m9UobqUWMI9b",
    "outputId": "969520a3-6616-4331-b424-321d238a6b75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape\n",
      "(889893, 61) (889893,) (10000, 61) (10000,)\n",
      "\n",
      "Calculating scale pos weight\n",
      "Counter({0: 860060, 1: 29833})\n",
      "\n",
      "scale_pos_weight - 28.829148929038315\n",
      "\n",
      "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.829148929038315, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
      "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.829148929038315]}\n",
      "\n",
      "Use the passed in classifier...\n",
      "\n",
      "\n",
      "TEST GROUP\n",
      "Threshold=0.473, F-Score=0.06709\n",
      "\n",
      "Recall: 0.026785714285714284\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.97      0.98      0.03      0.97      0.16      0.03      9664\n",
      "          1       0.05      0.03      0.98      0.03      0.16      0.02       336\n",
      "\n",
      "avg / total       0.94      0.95      0.06      0.94      0.16      0.03     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAZBElEQVR4nO3de3hU9Z3H8U9mgHDZTsMgCUkQIagQFhe2pMULLkiEsDUEYm2DEYy1lro8AdxduVRrgqCV21ZdI+Kl1VgQda3cIhJca62m3iKCYKJgBAEzSTAXBwGDzMz+wT7TsiFZZk5+Gebk/fI5z8Oc3zkz38E8+fA9v3OJCQQCAQEAECZHpAsAAEQ3ggQAYAlBAgCwhCABAFhCkAAALCFIAACWdOnQT3t7UYd+HDqHbmOWRLoE2NCJk772e7NQf/ddGuL2EdaxQQIAnZHNL9fj0BYAwBI6EgAwzeYdCUECAKbZO0cIEgAwzuYdCXMkAABL6EgAwDSbdyQECQCYZu8cIUgAwDg6EgCAJfbOEYIEAIyjIwEAWEKQAAAssXeOECQAYJzNOxIuSAQAWEJHAgCm2bwjIUgAwDR75whBAgDG2bwjYY4EAGAJHQkAmGbzjoQgAQDT/AQJAMAKe+cIQQIA5tk7SQgSADDN3jlCkACAcUy2AwAssXeOECQAYJ69k4QgAQDT7J0jBAkAGMccCQDAEnvnCEECAMbRkQAALLF5kHD3XwAwLRDiEoLXXntNU6dO1ZQpU5SVlaVt27ZJkvbt26ecnBxlZGQoJydH+/fvD+4T7lhrCBIAMC0QCG0567cNaP78+Vq+fLk2btyo5cuXa8GCBfL7/SosLFRubq5KS0uVm5urgoKC4H7hjrWGIAGAc4zX69WhQ4daLF6vt8W2DodDR44ckSQdOXJE8fHxamxsVEVFhTIzMyVJmZmZqqioUENDg+rr68MaawtzJABgWohzJMXFxSoqKmqxPj8/X7Nnzw6+jomJ0QMPPKBZs2apZ8+eOnr0qB577DF5PB4lJCTI6XRKkpxOp+Lj4+XxeBQIBMIac7vdrdZLkACAaSHOe+Tl5Sk7O7vFepfLddrrkydP6tFHH9WqVas0atQovf/++7rtttu0fPlyK9WGjCABANNC7EhcLleL0DiTyspK1dXVadSoUZKkUaNGqUePHoqNjVVtba18Pp+cTqd8Pp/q6uqUmJioQCAQ1lhbmCMBANMMnbXVr18/1dTU6LPPPpMkVVVVqb6+XhdccIFSU1NVUlIiSSopKVFqaqrcbrf69OkT1lhbYgKBDjzB+e1FHfZR6Dy6jVkS6RJgQydO+trvzdbNCm3761ed9aabNm3S448/rpiYGEnSnDlzdPXVV6uqqkoLFy6U1+uVy+XSsmXLlJKSIklhj7WGIEHUI0hgQrsGyTMhBknu2QfJuYA5EgAwzW/vK9sJEgAwjVukAADQOjoSADAs1KnoGEN1mEKQAIBhoR7ZIkgAAKfpyJNjI4EgAQDD7B0jBAkAGEdHAgCwxOaXkRAkAGCazRsSggQATPPbPEm4INGwquqvdOPSVzXq1hc0Yd5mvVJ+sMU2RRt2a0jeOv3lo5rgumt++ZL+ceZ/BZdhP31Wt97/enD8rYoaZRds1fd+8V9Kv32Tnnvt0w75Pjg3/cusWXrr7Xd05OgxPfHb3502dt11P9aHu3arvrFJOz/cpaysKaeNDxo0SOs3blJ9Y5Oqa2p139KlHVl6p+APBEJaog0diUEnfX7NeuANTRt/oZ6cf5Xe/bhO/3L/n7W+/3c1qN+pZw0cqD2i0vcOqG9cj9P2fem+a4J/DgQCSr99syZ9f4Ak6duTfuX/55ualzNSOeMGa9e+BuUt/aNGDO6joQN6d9wXxDnDU+3Rfb/+tSZMnKgePf76s5SUlKSnnn5aP7o2W6Vbt+qff/hDrXv2OV00OEWHDx9W165dtWVrqVY/sko3XD9NPp9PF198cQS/iT1FYTaEhI7EoM88XtU1HddNGUPkdDh02bB++t5FfbWxbH9wm7t/X67bfzJS3bq0/r/ivU8Oq/HrZk38/vmSpK+ONuvr499qyuUDFRMTo39I6aOUJJc+/eIr018J56gNG9Zr06aNamioP219cv/+ampqUunWrZKkl7ds0dGjR5UyeLAk6ca8m+TxVOvBBx7QsWPH1NzcrF27dnV4/XYXCARCWqLNWQVJY2OjKisrVVlZqcbGRtM12VpAAe09dOoX/svvHlC3Lk6NHZHU5j7r3/xMGWnnq2fsqQbyvO/2UOalF+jFNz6Tz+/XB59+qeovj2rUxX2N14/o8n55uT7+uFKZmZPlcDiUlTXlVFh8+KEkafTo0fp8/+faVPKSqmtq9cqrr2r48OERrtp+DD3X6pzR5qGtAwcO6K677lJFRYXi4+MlSXV1dRo2bJjuvvtuDRw48Iz7eb1eeb3eFuv7W683qgzq55LbFasntlTqpoyheqeyVu99fFijU+P19fFvdf8LO/W7eVe1+R7Hm0+q9L2DeuS2fzpt/TWXXqBf/e4d3bt2uyRpUV6aEvv0MvZdEJ38fr/W/H6Nnl6zRt27d9eJEyd0/bQcHTt2TNKpjmXcuHG6Nnuq/vjqq5o9Z45eeHG9Lvn7Yfr2228jXL19ROO8RyjaDJL58+crNzdXTz75pByOU82L3+/X5s2btWDBAj333HNn3K+4uFhFRUUt1n9SfH07lBw9unZx6OE5V+qeNe/riZcqNXyQW5N+cL66dXWqaMMuZV0+SP37/l2b77Gt/KDi/i5WPxgaH1xXVe3Vv60q00NzrtQVf99P+2uP6Nb7X1d8XA+NG5ls+mshioxPT9d9S5fq6vTx+mD7dn1v1Ci9uH6DsjKv0c6dO/XN8eMqK3szeOjrN//xH/rlHXcqNTVVH/5v1wLrbJ4jbQdJU1OTsrKyTlvncDg0ZcoUPfLII63ul5eXp+zs7JYDh54Ir8ooNnRAb6254+rg62lLXtHUMYO07o97VdNwTOv+uFeS1OBt1m0Pl+mWa1I185phwe03lO3TlCsGBh+jKUl7v2jSwH7f0ZWXJEqSUhJdGjsiSX/+0EOQ4DQjRozQm2+8oe3vvy/p1KGu9959V+PT07Vz507t2vWhLrv88ghXaX/ROO8RijbnSOLi4lRSUnLaX0IgENCmTZvkcrla3c/lcql///4tls7o4wONaj7h0/Hmk/rtlkrVNR3XtWMG6akF41Vy7w+1YfEkbVg8SfG9e+jum76vG9IvCu5b03BM71TWKfuKQae957ABvfV57dd6q6JGgUBAB2qP6E87qjXk/LiO/no4RzidTsXGxsrpdJ725/Lycl0xZoxGjBghSRo5cqSuGDMmOKH+zNq1Gj36Uo1PT5fD4dCcuXP15ZdfqrKyMpJfx3YCgdCWaNNmR7J06VIVFhZq8eLFSkhIkCTV1tZq6NChWsq55mdl41/264XXq3TSF9Coi/vqyflXqVtXp7p1dZ62ndMRo+/26qZe3bv+dd+yfRp54XkakPCd07YdkPAd3fuz0bp3zXZ9UX9U3+nRVZMvG6gfjx3cId8J55477rxTdxUUBl/fMH26liy+W0sWL9aSxXdr3XPPKyEhQYcPH9aypffpv195RZK0Z88e3XTjjSp6eJXi4+P1wQfb9aPsqcyPtDN/VE6hn72YwFn0XA0NDfJ4PJKkxMREud3u8D7t7UXh7Qe0oduYJZEuATZ04qSv3d6r5qEbQ9q+3+yn2+2zO8JZXZDodrvDDw8A6OSi8XBVKLiyHQAMC9j80BZBAgCGcRt5AIAldj/9lyABAMNsniMECQCYRkcCALDEH+kCDCNIAMAwOhIAgCU2zxGCBABMoyMBAFjiI0gAAFbYPEcIEgAwjUNbAABLuEUKAMASbtoIALDE5ke2CBIAMI05EgCAJTbPEYIEAEzz2zxJHJEuAADsLhDiEorm5mYVFhZq4sSJmjx5su666y5J0r59+5STk6OMjAzl5ORo//79wX3CHWsNQQIAhvn9gZCWUKxYsUKxsbEqLS3V5s2bNXfuXElSYWGhcnNzVVpaqtzcXBUUFAT3CXesNQQJABjmDwRCWs7W0aNHtWHDBs2dO1cxMTGSpPPOO0/19fWqqKhQZmamJCkzM1MVFRVqaGgIe6wtzJEAgGGhHq7yer3yer0t1rtcLrlcruDrgwcPKi4uTkVFRXrnnXfUq1cvzZ07V927d1dCQoKcTqckyel0Kj4+Xh6PR4FAIKwxt9vdar0ECQAYFurpv8XFxSoqKmqxPj8/X7Nnzw6+9vl8OnjwoIYNG6YFCxZo586duvXWW/Xggw9arjkUBAkAGBbqSVt5eXnKzs5usf5vuxFJSkxMVJcuXYKHokaMGKHevXure/fuqq2tlc/nk9PplM/nU11dnRITExUIBMIaawtzJABgWKhzJC6XS/3792+x/N8gcbvdGj16tMrKyiSdOuOqvr5eAwcOVGpqqkpKSiRJJSUlSk1NldvtVp8+fcIaa0tMoCMvuXx7UYd9FDqPbmOWRLoE2NCJk752e683fzU1pO3H3LPhrLc9ePCg7rjjDjU1NalLly667bbbNHbsWFVVVWnhwoXyer1yuVxatmyZUlJSJCnssdYQJIh6BAlMaM8geeNXU0La/sp7NrbbZ3cE5kgAwDCbX9hOkACAaXa/RQpBAgCGESQAAEtsniMECQCYxvNIAACW8Mx2AIAldCQAAEvsHSMECQAYR0cCALCEORIAgCV0JAAAS2yeIwQJAJjms3mSECQAYBiHtgAAltg8RwgSADAtYPMrSQgSADCM038BAJYwRwIAsMTmOUKQAIBpdCQAAEvsHSMECQAYx6N2AQCW2DxHCBIAMI2OBABgCUHSjnqNvbcjPw6dxLc+f6RLANpk8xyhIwEA0zj9FwBgic1zhCABANP8Nr+ShCABAMPoSAAAljBHAgCwxOY5QpAAgGnMkQAALPHb/MlWBAkAGMahLQCAJUy2AwAssftNfAgSADCMjgQAYInNc4QgAQDT7N6ROCJdAADYnT8Q2hKOoqIiDRkyRHv27JEk7dixQ1lZWcrIyNDNN9+s+vr64LbhjrWGIAEAwwIh/heqjz76SDt27FBycrIkye/3a968eSooKFBpaanS0tK0cuVKS2NtIUgAwLBAILQlFCdOnNDixYu1aNGi4Lrdu3crNjZWaWlpkqRp06Zp69atlsbawhwJABjmC/F4ldfrldfrbbHe5XLJ5XKdtu7BBx9UVlaW+vfvH1zn8XiUlJQUfO12u+X3+9XU1BT2WFxcXKv1EiQAYFioh6uKi4tVVFTUYn1+fr5mz54dfP3BBx9o9+7duv322y3XaAVBAgCGhXq4Ki8vT9nZ2S3W/99u5L333lNVVZXS09MlSTU1NfrZz36mGTNmqLq6OrhdQ0ODHA6H4uLilJiYGNZYWwgSADAs1NN/z3QI60xmzpypmTNnBl+PHz9eq1ev1oUXXqjnn39e5eXlSktL07PPPqtJkyZJkoYPH65vvvkm5LG2ECQAYFhH3/zX4XBo+fLlKiwsVHNzs5KTk7VixQpLY22JCXTglTK9Yrt21EehEzl24mSkS4ANteevxkXZaaFtv7683T67I9CRAIBh9r6unSABAOPsfosUggQADLN5jhAkAGCa3+ZJQpAAgGEECQDAEpvnCEECAKbRkQAALLF5jhAkAGBaOM8YiSYECQAYRkcCALCEORIAgCU2zxGCBABMY44EAGAJHQkAwBLmSAAAlvg7+slWHYwgAQDD7B0jBAkAGMfzSAAAltj8yBZBAgCm0ZEAACyxeY4QJABgGhckAgAsYY4EAGAJcyQAAEtsniMECQCY5rN5khAkAGAYh7YAAJbYPEcIEgAwjY4EAGCJP9IFGOaIdAGdzW+fLFbV/gPyHK7Xjt0fKe+nN0uSvv+D0dq85WUd9NRq/6Fq/f6ZderXr19wv/WbNqu2vjG4NB45qnff/yBSXwNRZujQoXr11VfV1NSkvXv3aurUqZEuqVMJBAIhLdGGIOlgK5cvU+rFFyqxbx/95EfXqnDR3Rr5j99T795x+t0TT2jYxRcq9aLB+vrI11r9+BPB/bKzJiuhT+/g8vZbb+nFP7wQwW+CaOF0OrVx40aVlJTI7XZr5syZWrNmjS666KJIl9ZpBAKhLdGGIOlglZUVOnHihKS//islJSVF20pLtf7FP+jIkSM6fvy4Hn1klS697PIzvseACy7QFWPG6Jm1azqydESpoUOHKikpSffff7/8fr9ee+01lZWVacaMGZEurdOgI0G7u/8/H9Lhxq+0Y9dHqqmpUenWl1tsc8WVV6qyouKM++feMF1lb76pA59/brpU2FRMTIyGDx8e6TI6jUCIS7QJO0gmT57c6pjX69WhQ4daLDjlX+fMVkKf3rr6qnHauGG9mpubTxsfPvwSLbzjTt35ywVn3D93+nSt/f3THVEqbOCTTz5RXV2d5s2bpy5dumjChAkaO3asevbsGenSOg1/IBDSEm3aPGvr008/bXWssbGx1bHi4mIVFRWFX1Un4Pf79dZfyjQtN1c//8WteuThU39fKYMHa/2mzZr/7/+mv5SVtdjvssuvUEJCP61/8Q8dXTKi1MmTJzV16lQ99NBDWrBggcrLy/X888+3+AcMzOnUz2zPzMxUcnLyGY/ZNTU1tbpfXl6esrOzW6wfMnhQGCXaWxdnF6WkpEiSzh8wQCVbtmrpfb/WumfWnnH7G6bP0KYNG3T06NGOLBNRbteuXRo3blzwdVlZmYqLiyNXUCcThU1GSNoMkuTkZD3zzDNKSEhoMTZ27NhW93O5XHK5XNars5m+fftq7Lir9PKWl3T8+HGNT0/Xj3NydNON05WYlKQtpdv06OpV+u3jj51x/+7du+va667T9T+5roMrR7S75JJLtGfPHjkcDs2aNUuJiYl66qmnIl1Wp+GPypmPs9fmHMnEiRP1xRdfnHFswoQJRgqys0AgoFtm/kJ7PtuvL2oP69dLl2v+7f+uLSUluumnNyslZbDu+FXBadeL/K3JWVP0VVOTXv/TnyLzBRC1ZsyYIY/Ho7q6OqWnp2vChAnBswdhnt1P/40JdOC5Zr1iu3bUR6ETOXbiZKRLgA2156/GH44YENL2W3YeaLfP7gic/gsAhpnqSBobG/Xzn/9cGRkZmjx5svLz89XQ0CBJ2rFjh7KyspSRkaGbb75Z9fX1wf3CHWsNQQIAhvkVCGk5WzExMbrllltUWlqqzZs36/zzz9fKlSvl9/s1b948FRQUqLS0VGlpaVq5cuWpWsIcawtBAgCGmepI4uLiNHr06ODrkSNHqrq6Wrt371ZsbKzS0tIkSdOmTdPWrVslKeyxtnD3XwAwLNT5Fq/XK6/X22J9W2fE+v1+rVu3TuPHj5fH41FSUlJwzO12y+/3q6mpKeyxuLi4VuslSADAsFDn7Vu7qDs/P1+zZ88+4z5LlixRz549NX36dL3yyivhlBk2ggQADAv1tietXdTdWjeybNkyff7551q9erUcDocSExNVXV0dHG9oaJDD4VBcXFzYY20hSADAsFCDJJSLun/zm99o9+7deuyxx9StWzdJ0vDhw/XNN9+ovLxcaWlpevbZZzVp0iRLY23hOhJEPa4jgQnt+atx7NCk/3+jv/H6x9X//0aS9u7dq8zMTA0cOFDdu3eXJPXv318PP/ywtm/frsLCQjU3Nys5OVkrVqzQeeedJ0lhj7WGIEHUI0hgQnv+avynIYkhbf/nTzzt9tkdgUNbAGCYzW/+S5AAgGkBm9+0kSABAMOi8UaMoSBIAMCwaHwOeygIEgAwjDkSAIAlzJEAACyx+ZEtggQATPPZ/NgWQQIAhjHZDgCwxN4xQpAAgHF0JAAAS2w+RUKQAIBpdCQAAEvsHSMECQAYR0cCALDE5jlCkACAaaE+ajfaECQAYBhBAgCwxOY5QpAAgGl0JAAAS2yeIwQJAJjG80gAAJbQkQAALGGOBABgic1zhCABANO4RQoAwBJ7xwhBAgDG8cx2AIAlHNoCAFhi8xwhSADANC5IBABYYvMpEoIEAExjjgQAYInNc4QgAQDTmCMBAFjCHAkAwBLmSAAAltg8RwgSADDNZ/MkIUgAwDAObQEALLF5jhAkAGAaHQkAwBJ/pAswjCABAMPs3pHEBOz+DaOQ1+tVcXGx8vLy5HK5Il0ObIKfK5jiiHQBaMnr9aqoqEherzfSpcBG+LmCKQQJAMASggQAYAlBAgCwhCABAFhCkJyDXC6X8vPzObMG7YqfK5jC6b8AAEvoSAAAlhAkAABLCJJzzL59+5STk6OMjAzl5ORo//79kS4JNrBs2TKNHz9eQ4YM0Z49eyJdDmyGIDnHFBYWKjc3V6WlpcrNzVVBQUGkS4INpKena+3atUpOTo50KbAhguQcUl9fr4qKCmVmZkqSMjMzVVFRoYaGhghXhmiXlpamxMTESJcBmyJIziEej0cJCQlyOp2SJKfTqfj4eHk8nghXBgCtI0gAAJYQJOeQxMRE1dbWyufzSZJ8Pp/q6uo4JAHgnEaQnEP69Omj1NRUlZSUSJJKSkqUmpoqt9sd4coAoHVc2X6Oqaqq0sKFC+X1euVyubRs2TKlpKREuixEuXvuuUfbtm3Tl19+qd69eysuLk4vvfRSpMuCTRAkAABLOLQFALCEIAEAWEKQAAAsIUgAAJYQJAAASwgSAIAlBAkAwBKCBABgyf8AWUdenavrl8MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_Specificity</th>\n",
       "      <th>Optimize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier_optimize</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0267857</td>\n",
       "      <td>0.980753</td>\n",
       "      <td>0.0175792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Train_Recall Test_Recall Test_Specificity   Optimize\n",
       "XGBClassifier_optimize            0   0.0267857         0.980753  0.0175792"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Additional Info\n",
      "========================================\n",
      "Total predicted to be positive: 195 \n",
      "\n",
      "First 23 matches\n",
      "23 [  6  44  52  72 197 217 219 230 279 283 298 356 392 422 463 468 479 487\n",
      " 507 510 520 537 540]\n",
      "\n",
      "[0.4928678  0.49459755 0.4899699  0.48436505 0.47853076 0.49486348\n",
      " 0.5002664  0.48083615 0.48689976 0.49071145 0.48737586 0.47657302\n",
      " 0.4902268  0.49136972 0.46568576 0.4926672  0.4944449  0.49229163\n",
      " 0.48827845 0.47447297 0.48531222 0.48448154 0.48962215]\n",
      "\n",
      "\n",
      "Top 23 Probable Matches\n",
      "\n",
      "[4036  298  974 1553 1686 5311 7983 1047  903 4851 1671  595 4060  510\n",
      "  823 1009  803 4267  706  479  487  230  661]\n",
      "\n",
      "\n",
      "[0.5041618  0.5042279  0.5042699  0.5046981  0.50483483 0.50492716\n",
      " 0.5060979  0.50847775 0.5059647  0.50575113 0.50512415 0.50650465\n",
      " 0.50725734 0.5054924  0.50691855 0.50641996 0.50555366 0.5059609\n",
      " 0.505105   0.5055111  0.50520676 0.5052597  0.50692064]\n",
      "\n",
      "195 [   6   44   52   72  197  217  219  230  279  283  298  356  392  422\n",
      "  463  468  479  487  507  510  520  537  540  550  557  559  560  567\n",
      "  586  594  595  604  623  628  637  661  706  720  732  802  803  823\n",
      "  895  903  928  950  974  994 1009 1018 1047 1086 1093 1115 1217 1230\n",
      " 1271 1378 1446 1478 1504 1508 1535 1553 1597 1671 1686 1697 1702 1723\n",
      " 1807 1862 1914 1962 1989 2037 2105 2260 2276 2320 2326 2461 2466 2492\n",
      " 2502 2532 2550 2581 2633 2672 2792 2794 2958 2983 2989 3029 3034 3086\n",
      " 3105 3113 3138 3277 3340 3350 3356 3468 3470 3497 3526 3545 3624 3675\n",
      " 3781 3846 3948 3968 3987 4012 4015 4016 4036 4060 4112 4267 4321 4373\n",
      " 4479 4514 4528 4578 4663 4675 4725 4748 4836 4840 4851 4876 4974 5140\n",
      " 5185 5237 5240 5308 5311 5355 5426 5442 5501 5506 5523 5533 5618 5673\n",
      " 5720 5725 5820 5842 5921 5949 6019 6045 6156 6257 6447 6772 7106 7166\n",
      " 7181 7196 7222 7231 7249 7455 7466 7503 7513 7557 7583 7669 7686 7722\n",
      " 7931 7983 8051 8078 8186 8323 8701 8988 9028 9074 9234 9308 9465]\n",
      "Matched draws\n",
      "Count: 9, Index: (array([   6,   44,  217,  628,  994, 4663, 5501, 6257, 8988]),)\n",
      "\n",
      "\n",
      "Top 23 Possibility\n",
      "Empty DataFrame\n",
      "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
      "Index: []\n",
      "\n",
      "\n",
      "First 23 Numbers\n",
      "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
      "104635  495719 2019-06-08  ConsolationNo5        6\n",
      "104789  496419 2019-06-22      2ndPrizeNo       44\n",
      "104844  496619 2019-06-26  ConsolationNo7      217\n",
      "104856  496619 2019-06-26      SpecialNo9        6\n",
      "\n",
      "\n",
      "All matched\n",
      "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
      "104635  495719 2019-06-08  ConsolationNo5        6\n",
      "104789  496419 2019-06-22      2ndPrizeNo       44\n",
      "104798  496419 2019-06-22  ConsolationNo7     8988\n",
      "104803  496419 2019-06-22      SpecialNo2     6257\n",
      "104807  496419 2019-06-22      SpecialNo6     4663\n",
      "104844  496619 2019-06-26  ConsolationNo7      217\n",
      "104847  496619 2019-06-26      SpecialNo1      994\n",
      "104856  496619 2019-06-26      SpecialNo9        6\n",
      "104899  496819 2019-06-30      SpecialNo6     5501\n",
      "104900  496819 2019-06-30      SpecialNo7      628\n",
      "CPU times: user 35min 39s, sys: 2.56 s, total: 35min 42s\n",
      "Wall time: 9min 6s\n"
     ]
    }
   ],
   "source": [
    "# Predict for a particular month\n",
    "\n",
    "# %time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection)\n",
    "\n",
    "#%time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='test')\n",
    "%time model(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='orig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "Ns3Puh7Gnxl5",
    "outputId": "72b6ab88-2071-4889-dd49-19c5db975aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 889893 observations.\n",
      "Testing on 10000 observations.\n",
      "\n",
      "Data shape before balancing: (889893, 62)\n",
      "\n",
      "Counts of strikes vs non-strikes in previous data:\n",
      "0    860060\n",
      "1     29833\n",
      "Name: Label, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Balancing data\n",
      "Data shape after balancing: (1659806, 62)\n",
      "\n",
      "Counts of strikes VS non-strikes in new data:\n",
      "1    860060\n",
      "0    799746\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Filtering features\n",
      "\n",
      "Data shape before feature selection: (1659806, 62)\n",
      "\n",
      "Counts of strikes vs non-strikes before feature selection:\n",
      "1    860060\n",
      "0    799746\n",
      "Name: Label, dtype: int64\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Data shape after feature selection: (1659806, 50)\n",
      "\n",
      "Counts of strikes vs non-strikes in new data:\n",
      "1    860060\n",
      "0    799746\n",
      "Name: Label, dtype: int64\n",
      "CPU times: user 22h 49min 14s, sys: 54.5 s, total: 22h 50min 8s\n",
      "Wall time: 22h 49min 10s\n",
      "Data shape\n",
      "(1659806, 49) (1659806,) (10000, 49) (10000,)\n",
      "\n",
      "Calculating scale pos weight\n",
      "Counter({1: 860060, 0: 799746})\n",
      "\n",
      "scale_pos_weight - 0.9298723344882915\n",
      "\n",
      "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 0.9298723344882915, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
      "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 0.9298723344882915]}\n",
      "\n",
      "Use the passed in classifier...\n",
      "\n",
      "\n",
      "TEST GROUP\n",
      "Threshold=0.515, F-Score=0.06702\n",
      "\n",
      "Recall: 0.32142857142857145\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.97      0.71      0.32      0.82      0.48      0.24      9664\n",
      "          1       0.04      0.32      0.71      0.07      0.48      0.22       336\n",
      "\n",
      "avg / total       0.94      0.70      0.33      0.79      0.48      0.24     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_Specificity</th>\n",
       "      <th>Optimize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier_optimize</th>\n",
       "      <td>0</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.709748</td>\n",
       "      <td>0.199092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Train_Recall Test_Recall Test_Specificity  Optimize\n",
       "XGBClassifier_optimize            0    0.321429         0.709748  0.199092"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Additional Info\n",
      "========================================\n",
      "Total predicted to be positive: 2913 \n",
      "\n",
      "First 23 matches\n",
      "23 [ 6  7 10 16 22 23 25 28 30 32 37 40 41 42 43 46 49 55 56 57 58 59 62]\n",
      "\n",
      "[0.29724804 0.3970374  0.39437664 0.28878602 0.4132002  0.4828532\n",
      " 0.508274   0.52017266 0.40018952 0.3323856  0.52017266 0.26191115\n",
      " 0.44016305 0.42256764 0.3071298  0.40018952 0.52017266 0.35192677\n",
      " 0.4018113  0.3992262  0.47182348 0.36028227 0.52017266]\n",
      "\n",
      "\n",
      "Top 23 Probable Matches\n",
      "\n",
      "[3736 7541 3747 7535 3738 7545 3730 3757 3761 7526 3734 3772 7562 3729\n",
      " 7548 7550 3724 7552 3721 7557  671 7561  939]\n",
      "\n",
      "\n",
      "[0.52017266 0.52017266 0.52017266 0.52017266 0.52017266 0.52017266\n",
      " 0.52017266 0.52017266 0.52017266 0.52017266 0.52017266 0.52017266\n",
      " 0.52017266 0.52017266 0.52017266 0.52017266 0.52017266 0.52017266\n",
      " 0.52017266 0.52017266 0.52017266 0.52017266 0.52017266]\n",
      "\n",
      "2913 [   6    7   10   16   22   23   25   28   30   32   37   40   41   42\n",
      "   43   46   49   55   56   57   58   59   62   68   69   77   80   81\n",
      "   82   84   88   92   93  106  111  112  113  117  121  123  129  131\n",
      "  132  133  143  145  146  150  158  159  160  167  170  175  176  177\n",
      "  182  184  185  186  194  196  204  206  213  214  216  218  236  239\n",
      "  244  245  246  250  255  258  263  266  267  272  286  287  288  290\n",
      "  291  292  295  297  307  311  320  322  323  327  329  331  335  343\n",
      "  346  357  359  362  363  364  367  373  378  379  385  386  390  395\n",
      "  399  400  402  404  406  407  410  414  416  421  422  427  430  434\n",
      "  435  443  446  456  460  462  464  467  469  475  477  478  482  484\n",
      "  485  487  491  503  512  515  516  520  523  524  527  532  537  546\n",
      "  555  557  563  564  573  574  576  586  587  588  590  592  595  597\n",
      "  598  600  601  606  610  611  617  621  626  629  633  638  639  645\n",
      "  655  657  661  663  667  671  677  678  684  685  693  695  701  704\n",
      "  705  706  707  708  717  720  721  726  731  734  735  736  738  739\n",
      "  742  745  748  754  755  756  761  765  766  770  775  776  778  779\n",
      "  781  791  793  800  802  808  809  811  812  813  817  818  822  832\n",
      "  850  851  852  858  859  862  863  864  866  867  868  873  877  881\n",
      "  885  887  893  895  897  900  901  902  905  907  908  912  915  918\n",
      "  921  924  927  939  947  950  953  955  956  958  959  964  974  975\n",
      "  976  977  982  984  989 1001 1009 1016 1020 1023 1024 1027 1031 1032\n",
      " 1036 1039 1048 1049 1051 1054 1055 1056 1058 1066 1067 1070 1071 1074\n",
      " 1077 1081 1090 1092 1095 1097 1098 1102 1104 1113 1114 1115 1116 1117\n",
      " 1119 1120 1121 1129 1133 1134 1136 1139 1140 1141 1143 1144 1152 1153\n",
      " 1162 1168 1170 1177 1181 1184 1190 1195 1197 1198 1199 1200 1203 1205\n",
      " 1206 1207 1210 1214 1215 1224 1233 1234 1241 1247 1251 1252 1256 1260\n",
      " 1263 1264 1266 1267 1268 1270 1273 1274 1277 1281 1283 1285 1286 1288\n",
      " 1289 1291 1298 1301 1304 1308 1312 1313 1315 1320 1321 1322 1336 1337\n",
      " 1348 1350 1359 1364 1366 1368 1369 1372 1381 1383 1387 1388 1389 1393\n",
      " 1397 1403 1404 1411 1418 1421 1424 1428 1433 1434 1436 1440 1442 1447\n",
      " 1448 1452 1453 1454 1455 1461 1465 1466 1467 1469 1474 1482 1484 1493\n",
      " 1495 1498 1504 1507 1509 1511 1512 1513 1515 1518 1521 1522 1524 1525\n",
      " 1526 1528 1529 1534 1537 1538 1539 1545 1546 1547 1549 1550 1552 1558\n",
      " 1560 1570 1571 1572 1575 1579 1580 1581 1584 1591 1592 1606 1607 1608\n",
      " 1611 1613 1621 1626 1628 1629 1630 1635 1646 1654 1656 1661 1664 1666\n",
      " 1668 1669 1671 1672 1673 1674 1676 1679 1681 1683 1684 1685 1688 1690\n",
      " 1691 1694 1700 1710 1712 1714 1718 1719 1720 1722 1723 1724 1727 1731\n",
      " 1733 1734 1737 1740 1745 1751 1752 1758 1759 1761 1764 1770 1771 1776\n",
      " 1780 1782 1785 1787 1788 1796 1798 1808 1815 1817 1818 1822 1824 1831\n",
      " 1835 1839 1841 1843 1849 1851 1855 1860 1873 1876 1877 1883 1885 1888\n",
      " 1889 1893 1900 1903 1904 1907 1914 1919 1920 1921 1924 1925 1938 1941\n",
      " 1945 1951 1954 1957 1961 1962 1964 1965 1967 1968 1969 1974 1980 1981\n",
      " 1982 1989 1994 1997 1999 2000 2002 2008 2012 2014 2016 2020 2023 2036\n",
      " 2038 2039 2042 2043 2046 2047 2050 2055 2059 2061 2075 2084 2089 2097\n",
      " 2098 2100 2102 2106 2109 2113 2114 2116 2118 2120 2125 2127 2129 2133\n",
      " 2136 2143 2146 2147 2149 2153 2156 2157 2161 2162 2163 2165 2167 2170\n",
      " 2174 2176 2178 2180 2182 2183 2186 2187 2188 2189 2190 2191 2196 2200\n",
      " 2204 2211 2212 2217 2218 2219 2225 2228 2229 2231 2238 2239 2240 2242\n",
      " 2247 2248 2249 2252 2254 2260 2263 2268 2275 2276 2278 2284 2287 2288\n",
      " 2296 2297 2298 2301 2304 2309 2311 2316 2318 2321 2327 2330 2335 2337\n",
      " 2342 2344 2349 2350 2351 2353 2356 2359 2360 2364 2365 2374 2376 2377\n",
      " 2379 2382 2385 2389 2393 2395 2401 2403 2405 2407 2409 2418 2420 2422\n",
      " 2426 2428 2431 2433 2450 2451 2456 2463 2464 2466 2477 2479 2484 2485\n",
      " 2491 2492 2501 2502 2506 2508 2513 2516 2517 2521 2526 2530 2534 2537\n",
      " 2541 2545 2554 2556 2562 2563 2567 2569 2575 2577 2578 2580 2585 2592\n",
      " 2593 2598 2599 2600 2604 2605 2607 2608 2614 2616 2620 2626 2627 2634\n",
      " 2635 2641 2650 2652 2660 2661 2663 2664 2672 2677 2683 2686 2688 2693\n",
      " 2694 2696 2700 2702 2704 2711 2712 2717 2718 2721 2722 2723 2726 2727\n",
      " 2728 2729 2730 2732 2733 2736 2737 2738 2741 2747 2755 2758 2760 2761\n",
      " 2771 2772 2773 2774 2777 2778 2781 2782 2785 2787 2788 2793 2803 2806\n",
      " 2808 2810 2811 2814 2817 2824 2830 2834 2837 2838 2839 2840 2841 2842\n",
      " 2848 2852 2858 2866 2868 2869 2870 2873 2874 2876 2877 2878 2883 2890\n",
      " 2893 2895 2897 2898 2899 2900 2902 2903 2904 2905 2907 2909 2910 2912\n",
      " 2914 2915 2922 2928 2939 2942 2945 2946 2947 2949 2950 2957 2959 2960\n",
      " 2962 2965 2968 2970 2972 2973 2976 2981 2988 2992 2993 2994 3007 3008\n",
      " 3012 3013 3015 3017 3020 3021 3023 3035 3039 3042 3049 3051 3053 3054\n",
      " 3061 3062 3065 3066 3067 3070 3078 3081 3082 3084 3085 3092 3093 3097\n",
      " 3098 3099 3100 3104 3106 3110 3127 3128 3134 3146 3148 3149 3150 3153\n",
      " 3157 3160 3162 3169 3172 3178 3187 3188 3190 3192 3193 3196 3198 3199\n",
      " 3204 3212 3213 3219 3220 3221 3222 3229 3236 3237 3238 3240 3241 3243\n",
      " 3244 3251 3252 3254 3255 3259 3264 3268 3272 3276 3278 3279 3286 3287\n",
      " 3288 3290 3293 3300 3301 3305 3310 3315 3319 3321 3322 3323 3326 3327\n",
      " 3338 3340 3343 3344 3352 3354 3364 3367 3369 3372 3377 3379 3380 3381\n",
      " 3382 3384 3391 3393 3394 3403 3404 3407 3412 3413 3414 3417 3418 3419\n",
      " 3425 3428 3429 3430 3431 3451 3452 3459 3460 3464 3466 3468 3474 3476\n",
      " 3481 3486 3489 3492 3494 3495 3498 3503 3504 3511 3515 3516 3518 3521\n",
      " 3525 3528 3532 3534 3538 3541 3542 3543 3545 3549 3552 3557 3566 3571\n",
      " 3573 3575 3577 3582 3583 3585 3586 3591 3594 3598 3599 3603 3607 3610\n",
      " 3613 3617 3623 3624 3627 3629 3638 3642 3647 3649 3652 3654 3656 3664\n",
      " 3667 3669 3674 3678 3679 3681 3682 3687 3693 3696 3698 3702 3704 3706\n",
      " 3710 3711 3714 3715 3716 3721 3724 3729 3730 3734 3736 3738 3747 3757\n",
      " 3759 3761 3772 3774 3778 3786 3791 3792 3793 3799 3801 3809 3812 3817\n",
      " 3818 3827 3835 3839 3842 3851 3858 3861 3865 3868 3874 3877 3881 3887\n",
      " 3889 3890 3893 3896 3897 3899 3904 3908 3909 3910 3913 3916 3917 3926\n",
      " 3934 3935 3941 3942 3943 3945 3946 3947 3950 3965 3973 3979 3993 3994\n",
      " 4010 4017 4019 4022 4024 4028 4029 4031 4033 4034 4037 4038 4042 4045\n",
      " 4049 4050 4061 4067 4072 4073 4075 4076 4079 4080 4087 4091 4093 4098\n",
      " 4100 4101 4105 4106 4108 4110 4112 4118 4126 4129 4131 4140 4141 4148\n",
      " 4151 4156 4157 4162 4165 4166 4167 4170 4175 4178 4180 4183 4191 4194\n",
      " 4195 4202 4203 4204 4205 4206 4209 4213 4215 4221 4224 4232 4238 4240\n",
      " 4243 4253 4254 4255 4273 4281 4284 4286 4287 4288 4290 4294 4296 4300\n",
      " 4301 4304 4310 4313 4321 4322 4335 4340 4341 4342 4345 4348 4350 4351\n",
      " 4352 4358 4361 4362 4372 4376 4377 4378 4379 4380 4382 4384 4385 4386\n",
      " 4388 4389 4390 4396 4397 4400 4402 4405 4407 4408 4413 4415 4416 4423\n",
      " 4426 4427 4428 4432 4434 4437 4438 4440 4441 4445 4448 4451 4454 4456\n",
      " 4463 4467 4470 4479 4481 4482 4486 4487 4488 4490 4495 4496 4498 4499\n",
      " 4503 4504 4508 4516 4518 4520 4521 4524 4527 4528 4534 4543 4550 4551\n",
      " 4553 4561 4562 4566 4567 4569 4571 4574 4579 4583 4585 4594 4602 4606\n",
      " 4611 4612 4615 4618 4620 4621 4623 4625 4627 4630 4631 4635 4638 4641\n",
      " 4643 4644 4650 4652 4656 4661 4668 4674 4680 4685 4687 4691 4692 4695\n",
      " 4696 4697 4700 4702 4707 4710 4712 4713 4719 4720 4723 4726 4731 4733\n",
      " 4734 4737 4738 4741 4743 4744 4757 4760 4767 4772 4774 4775 4778 4779\n",
      " 4780 4786 4787 4788 4790 4791 4796 4801 4803 4804 4805 4809 4810 4811\n",
      " 4814 4834 4837 4844 4845 4850 4852 4853 4854 4857 4860 4861 4866 4867\n",
      " 4869 4873 4874 4876 4878 4881 4883 4897 4899 4904 4914 4918 4928 4931\n",
      " 4934 4935 4940 4943 4950 4952 4956 4961 4962 4963 4964 4965 4970 4975\n",
      " 4977 4991 5000 5001 5006 5008 5023 5024 5027 5028 5030 5032 5041 5043\n",
      " 5047 5052 5057 5062 5063 5065 5066 5067 5068 5071 5072 5076 5077 5081\n",
      " 5093 5096 5098 5099 5100 5107 5111 5117 5118 5120 5123 5129 5133 5139\n",
      " 5143 5144 5146 5148 5149 5151 5167 5168 5176 5178 5185 5187 5188 5190\n",
      " 5194 5195 5203 5208 5214 5215 5216 5220 5223 5227 5229 5234 5236 5246\n",
      " 5249 5251 5255 5256 5257 5259 5265 5279 5280 5283 5285 5290 5296 5298\n",
      " 5300 5307 5308 5311 5316 5320 5321 5322 5329 5331 5336 5339 5342 5348\n",
      " 5355 5356 5357 5358 5359 5360 5361 5362 5363 5366 5369 5371 5376 5378\n",
      " 5381 5382 5384 5387 5388 5390 5394 5399 5400 5401 5403 5405 5406 5414\n",
      " 5416 5417 5420 5421 5423 5425 5427 5428 5431 5434 5435 5436 5437 5439\n",
      " 5440 5441 5443 5444 5445 5450 5451 5455 5457 5460 5462 5471 5477 5479\n",
      " 5488 5491 5497 5500 5514 5515 5518 5521 5522 5523 5528 5529 5538 5552\n",
      " 5553 5555 5559 5566 5569 5570 5571 5577 5580 5583 5585 5586 5588 5590\n",
      " 5600 5603 5604 5605 5607 5610 5612 5616 5622 5631 5632 5638 5639 5640\n",
      " 5644 5648 5649 5662 5669 5676 5678 5679 5681 5684 5687 5688 5690 5692\n",
      " 5693 5697 5699 5702 5703 5708 5710 5715 5717 5722 5724 5727 5728 5732\n",
      " 5733 5740 5749 5750 5756 5757 5766 5774 5776 5782 5784 5785 5786 5797\n",
      " 5799 5801 5802 5803 5804 5805 5807 5808 5812 5814 5816 5820 5822 5823\n",
      " 5828 5830 5832 5838 5845 5853 5855 5858 5871 5872 5874 5876 5878 5880\n",
      " 5883 5884 5889 5890 5891 5893 5903 5907 5910 5915 5921 5923 5924 5928\n",
      " 5930 5936 5943 5946 5954 5955 5956 5962 5963 5967 5980 5983 5984 5987\n",
      " 5996 5997 6000 6001 6002 6011 6020 6025 6044 6045 6050 6054 6057 6058\n",
      " 6061 6064 6068 6070 6078 6090 6092 6094 6096 6103 6110 6112 6116 6118\n",
      " 6122 6124 6127 6128 6129 6136 6139 6145 6146 6148 6155 6157 6161 6163\n",
      " 6165 6168 6169 6178 6181 6183 6184 6187 6196 6201 6204 6205 6209 6212\n",
      " 6216 6217 6218 6226 6233 6243 6244 6245 6246 6248 6250 6254 6256 6258\n",
      " 6260 6264 6272 6273 6274 6280 6281 6283 6285 6290 6294 6295 6296 6298\n",
      " 6301 6304 6306 6307 6309 6315 6316 6319 6324 6327 6328 6330 6332 6337\n",
      " 6340 6342 6351 6353 6356 6365 6379 6381 6383 6385 6386 6389 6392 6400\n",
      " 6406 6408 6409 6410 6411 6414 6420 6423 6426 6428 6440 6447 6448 6449\n",
      " 6450 6451 6457 6460 6461 6463 6469 6470 6482 6483 6484 6486 6487 6489\n",
      " 6490 6491 6493 6496 6499 6505 6506 6508 6511 6522 6525 6526 6529 6530\n",
      " 6532 6544 6554 6556 6563 6568 6571 6587 6590 6606 6607 6611 6621 6622\n",
      " 6623 6630 6632 6633 6634 6635 6636 6637 6639 6647 6650 6652 6653 6654\n",
      " 6655 6657 6661 6662 6665 6667 6673 6680 6681 6683 6687 6689 6690 6692\n",
      " 6693 6696 6701 6708 6711 6712 6713 6715 6716 6721 6722 6736 6737 6742\n",
      " 6750 6752 6758 6760 6761 6763 6765 6768 6769 6775 6779 6780 6786 6792\n",
      " 6795 6796 6797 6804 6810 6811 6813 6814 6815 6816 6817 6824 6826 6831\n",
      " 6836 6839 6842 6846 6848 6853 6854 6859 6863 6870 6871 6873 6875 6879\n",
      " 6885 6892 6900 6901 6902 6903 6907 6914 6915 6917 6925 6926 6933 6939\n",
      " 6940 6942 6943 6945 6947 6953 6954 6956 6958 6962 6963 6964 6967 6970\n",
      " 6971 6972 6975 6978 6984 6988 6993 6996 6997 6998 7002 7004 7006 7008\n",
      " 7009 7013 7014 7016 7020 7021 7022 7026 7030 7032 7033 7035 7037 7040\n",
      " 7047 7049 7052 7053 7061 7064 7071 7074 7075 7076 7077 7085 7089 7090\n",
      " 7095 7096 7098 7099 7103 7113 7119 7120 7123 7145 7152 7156 7164 7167\n",
      " 7174 7179 7184 7185 7189 7195 7203 7210 7211 7215 7217 7224 7229 7231\n",
      " 7236 7237 7238 7241 7247 7248 7251 7254 7259 7261 7269 7274 7279 7285\n",
      " 7288 7296 7312 7315 7316 7320 7324 7325 7330 7331 7333 7334 7339 7340\n",
      " 7344 7347 7351 7352 7356 7357 7358 7361 7362 7366 7369 7370 7371 7378\n",
      " 7385 7388 7389 7391 7394 7397 7400 7403 7404 7407 7411 7423 7428 7429\n",
      " 7432 7433 7439 7446 7451 7455 7456 7460 7461 7463 7465 7470 7471 7472\n",
      " 7477 7479 7480 7485 7495 7496 7498 7501 7502 7504 7505 7512 7520 7521\n",
      " 7526 7535 7541 7545 7548 7550 7552 7557 7561 7562 7563 7564 7573 7574\n",
      " 7576 7578 7579 7587 7588 7595 7596 7599 7602 7603 7611 7612 7627 7631\n",
      " 7632 7633 7635 7636 7637 7641 7642 7644 7645 7647 7655 7660 7665 7666\n",
      " 7669 7671 7672 7673 7676 7684 7689 7691 7697 7701 7704 7705 7709 7711\n",
      " 7712 7713 7716 7720 7723 7729 7745 7751 7753 7757 7758 7761 7763 7769\n",
      " 7773 7778 7783 7789 7792 7795 7796 7798 7799 7803 7806 7811 7815 7820\n",
      " 7822 7823 7824 7826 7833 7836 7841 7848 7849 7853 7855 7858 7863 7864\n",
      " 7866 7867 7874 7876 7883 7885 7887 7894 7897 7898 7904 7911 7912 7913\n",
      " 7914 7916 7917 7925 7928 7929 7932 7937 7942 7943 7945 7946 7948 7958\n",
      " 7963 7971 7972 7983 7984 7985 7986 7991 7995 8006 8007 8012 8014 8017\n",
      " 8018 8019 8023 8027 8033 8036 8037 8043 8045 8046 8051 8057 8062 8065\n",
      " 8075 8081 8087 8090 8098 8105 8109 8111 8115 8117 8124 8125 8128 8129\n",
      " 8132 8142 8147 8149 8150 8151 8155 8156 8157 8158 8160 8170 8172 8176\n",
      " 8178 8179 8181 8183 8184 8185 8188 8192 8195 8199 8202 8203 8218 8223\n",
      " 8225 8226 8229 8233 8235 8236 8240 8247 8248 8255 8258 8259 8262 8265\n",
      " 8266 8268 8271 8273 8279 8280 8282 8283 8288 8293 8301 8303 8306 8307\n",
      " 8308 8313 8314 8324 8326 8328 8334 8340 8341 8344 8345 8347 8354 8362\n",
      " 8363 8369 8373 8374 8381 8386 8387 8388 8389 8394 8397 8402 8403 8404\n",
      " 8410 8415 8417 8420 8425 8426 8427 8429 8430 8431 8438 8447 8455 8457\n",
      " 8459 8461 8464 8468 8471 8474 8475 8476 8480 8484 8486 8487 8492 8498\n",
      " 8499 8512 8517 8519 8520 8521 8522 8524 8525 8529 8530 8534 8544 8545\n",
      " 8548 8550 8551 8554 8564 8566 8569 8572 8577 8587 8594 8595 8605 8609\n",
      " 8613 8614 8615 8618 8619 8623 8625 8638 8645 8652 8654 8656 8661 8662\n",
      " 8667 8670 8683 8687 8696 8711 8712 8714 8717 8720 8723 8725 8726 8728\n",
      " 8732 8735 8739 8741 8743 8745 8749 8754 8756 8757 8768 8772 8778 8783\n",
      " 8784 8788 8792 8799 8800 8804 8805 8806 8812 8817 8820 8821 8825 8833\n",
      " 8834 8836 8840 8841 8843 8850 8853 8856 8858 8862 8864 8866 8867 8870\n",
      " 8878 8881 8882 8883 8885 8895 8896 8897 8898 8905 8906 8907 8908 8909\n",
      " 8914 8916 8918 8919 8924 8925 8926 8928 8929 8932 8933 8934 8940 8943\n",
      " 8944 8951 8952 8957 8964 8965 8972 8974 8976 8978 8981 8984 8992 8994\n",
      " 8995 9000 9003 9011 9013 9014 9023 9025 9039 9050 9055 9056 9062 9064\n",
      " 9065 9066 9068 9076 9077 9079 9088 9092 9093 9099 9104 9108 9112 9116\n",
      " 9119 9124 9125 9127 9128 9136 9141 9143 9147 9149 9153 9155 9160 9168\n",
      " 9174 9175 9181 9187 9188 9204 9210 9213 9216 9218 9224 9225 9233 9234\n",
      " 9236 9237 9243 9244 9248 9250 9251 9255 9258 9261 9262 9263 9264 9270\n",
      " 9277 9288 9290 9294 9295 9296 9297 9303 9312 9319 9322 9326 9328 9334\n",
      " 9335 9336 9339 9340 9350 9353 9359 9363 9366 9369 9370 9376 9381 9385\n",
      " 9388 9390 9394 9397 9398 9401 9413 9414 9417 9422 9425 9428 9429 9430\n",
      " 9431 9438 9440 9443 9444 9445 9454 9455 9465 9468 9476 9477 9478 9485\n",
      " 9486 9487 9488 9493 9494 9499 9501 9503 9514 9515 9517 9518 9523 9525\n",
      " 9527 9530 9546 9548 9552 9553 9555 9560 9565 9569 9573 9575 9577 9581\n",
      " 9584 9586 9594 9599 9603 9611 9613 9615 9621 9623 9626 9628 9631 9640\n",
      " 9643 9648 9649 9651 9653 9655 9662 9667 9673 9676 9683 9687 9689 9690\n",
      " 9694 9695 9703 9706 9707 9708 9709 9711 9714 9716 9719 9720 9721 9729\n",
      " 9730 9735 9736 9737 9739 9740 9744 9746 9747 9749 9750 9752 9758 9759\n",
      " 9764 9766 9769 9774 9776 9778 9780 9782 9784 9788 9791 9794 9805 9807\n",
      " 9808 9821 9831 9832 9840 9843 9844 9850 9853 9860 9876 9878 9890 9892\n",
      " 9893 9895 9899 9902 9904 9905 9907 9908 9909 9912 9914 9916 9917 9919\n",
      " 9921 9924 9925 9926 9931 9936 9939 9940 9941 9942 9943 9946 9947 9950\n",
      " 9955 9960 9962 9963 9966 9968 9971 9975 9976 9979 9982 9984 9986 9991\n",
      " 9998]\n",
      "Matched draws\n",
      "Count: 108, Index: (array([   6,   22,  307,  311,  678,  761,  791,  812,  956,  977, 1081,\n",
      "       1144, 1199, 1252, 1359, 1381, 1387, 1495, 1552, 1661, 1808, 1815,\n",
      "       1889, 1904, 1961, 2089, 2133, 2189, 2537, 2663, 2677, 2785, 2837,\n",
      "       2962, 2965, 2976, 3153, 3222, 3252, 3301, 3498, 3542, 3566, 3610,\n",
      "       3649, 3669, 3799, 3909, 3947, 4031, 4076, 4183, 4206, 4255, 4486,\n",
      "       4618, 4668, 4738, 4811, 4867, 4878, 5099, 5414, 5553, 5612, 5622,\n",
      "       5684, 5687, 5983, 6090, 6124, 6163, 6272, 6590, 6737, 6775, 6780,\n",
      "       6804, 6964, 7022, 7037, 7052, 7330, 7340, 7351, 7389, 7394, 7403,\n",
      "       7428, 7579, 7637, 7758, 7761, 7778, 8075, 8178, 8179, 8280, 8389,\n",
      "       8550, 8661, 8792, 9297, 9390, 9503, 9517, 9525, 9569]),)\n",
      "\n",
      "\n",
      "Top 23 Possibility\n",
      "Empty DataFrame\n",
      "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
      "Index: []\n",
      "\n",
      "\n",
      "First 23 Numbers\n",
      "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
      "104635  495719 2019-06-08  ConsolationNo5        6\n",
      "104802  496419 2019-06-22     SpecialNo10       22\n",
      "104856  496619 2019-06-26      SpecialNo9        6\n",
      "\n",
      "\n",
      "All matched\n",
      "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
      "104559  495419 2019-06-01      2ndPrizeNo     8550\n",
      "104560  495419 2019-06-01      3rdPrizeNo     7022\n",
      "104565  495419 2019-06-01  ConsolationNo4     2089\n",
      "104566  495419 2019-06-01  ConsolationNo5     3649\n",
      "104567  495419 2019-06-01  ConsolationNo6     2537\n",
      "...        ...        ...             ...      ...\n",
      "104863  496719 2019-06-29  ConsolationNo3     3799\n",
      "104865  496719 2019-06-29  ConsolationNo5     8792\n",
      "104867  496719 2019-06-29  ConsolationNo7     5684\n",
      "104871  496719 2019-06-29     SpecialNo10     7394\n",
      "104872  496719 2019-06-29      SpecialNo2     2965\n",
      "\n",
      "[100 rows x 4 columns]\n",
      "CPU times: user 1h 1min 54s, sys: 5.49 s, total: 1h 1min 59s\n",
      "Wall time: 15min 57s\n"
     ]
    }
   ],
   "source": [
    "%time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='test')\n",
    "%time model(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qktZbi7OGqP3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")\n",
    "# NO Feature_selection\n",
    "# n_estimators = 300\n",
    "# NO remove outliers\n",
    "# filter features\n",
    "#start_mt = pd.datetime(2019,6,1)\n",
    "#how_many_mt = 7 \n",
    "#for i in range(how_many_mt):\n",
    "#  month_to_predict = start_mt + relativedelta(months=i)\n",
    "#  print(f\"\\n{month_to_predict}\\n-------------------\\n\")\n",
    "#  %time gen_train_test_set(month_to_predict, feature_matrix_selection, file_prefix='test')\n",
    "#  %time model(month_to_predict, feature_matrix_selection, file_prefix='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPIj7aePrnyg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "04_02_automated_machine_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python-37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
