{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "04_02_automated_machine_learning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengwangk/dl-projects/blob/master/04_08_auto_ml_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4hyoPGdjpqa_"
      },
      "source": [
        "# Automated ML - Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLxr2k_ue8yq",
        "colab": {}
      },
      "source": [
        "COLAB = True\n",
        "\n",
        "DATASET_NAME = '4D.zip'\n",
        "\n",
        "FEATURE_DATASET_PREFIX = 'feature_matrix_d2_v2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wwYshXtLt7b7",
        "colab": {}
      },
      "source": [
        "# !pip install -U imblearn\n",
        "# !pip install -U xgboost\n",
        "# !pip install -U featuretools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oy5ww2zRfFGG",
        "outputId": "c4e57301-cf08-4407-950e-b752dc79bd69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "if COLAB:\n",
        "  !rm -rf dl-projects\n",
        "  !git clone https://github.com/mengwangk/dl-projects"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dl-projects'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 1721 (delta 57), reused 25 (delta 9), pack-reused 1625\u001b[K\n",
            "Receiving objects: 100% (1721/1721), 76.62 MiB | 37.43 MiB/s, done.\n",
            "Resolving deltas: 100% (1052/1052), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G2xin10SfozR",
        "colab": {}
      },
      "source": [
        "if COLAB:\n",
        "  !cp dl-projects/utils* .\n",
        "  !cp dl-projects/preprocess* .\n",
        "  !cp dl-projects/plot* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fC2-l3JBpqbE",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "# %reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TP7V_IzepqbK",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "import matplotlib\n",
        "import sys\n",
        "import gc\n",
        "\n",
        "from scipy import stats\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import featuretools as ft\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, make_scorer, recall_score, roc_curve, mean_squared_error, accuracy_score, average_precision_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedShuffleSplit, RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from imblearn.under_sampling import (RandomUnderSampler, \n",
        "                                     ClusterCentroids,\n",
        "                                     TomekLinks,\n",
        "                                     NeighbourhoodCleaningRule,\n",
        "                                     AllKNN,\n",
        "                                     NearMiss,\n",
        "                                     OneSidedSelection)\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
        "from imblearn.metrics import classification_report_imbalanced \n",
        "from imblearn.over_sampling import SMOTE, SMOTENC, ADASYN\n",
        "import pylab as pl\n",
        "import xgboost as xgb\n",
        "from collections import Counter\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "\n",
        "# from skopt import BayesSearchCV\n",
        "# from skopt.space import Real, Categorical, Integer\n",
        "# from scikitplot.plotters import plot_precision_recall_curve\n",
        "\n",
        "from utils import feature_selection, plot_feature_importances\n",
        "from preprocess import *\n",
        "from plot import plot_correlation_matrix, plot_labeled_scatter\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "# The Answer to the Ultimate Question of Life, the Universe, and Everything.\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3bFT5CoxpqbP",
        "outputId": "04755b9a-302c-474b-9f6a-0da378bae34c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%aimport"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modules to reload:\n",
            "all-except-skipped\n",
            "\n",
            "Modules to skip:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3E16jPVPpqbV"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U421BuhtfYS7",
        "outputId": "f5ee2722-c86c-4abb-a332-b7548b1bd2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  GDRIVE_DATASET_FOLDER = Path('gdrive/My Drive/datasets/')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9IgnETKkpqbX",
        "outputId": "8e9be614-6dcf-46eb-c662-98a7fe915bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "if COLAB:\n",
        "  DATASET_PATH = GDRIVE_DATASET_FOLDER\n",
        "  ORIGIN_DATASET_PATH = Path('dl-projects/datasets')\n",
        "else:\n",
        "  DATASET_PATH = Path(\"../datasets\")\n",
        "  ORIGIN_DATASET_PATH = Path('datasets')\n",
        "\n",
        "DATASET = DATASET_PATH/f\"{FEATURE_DATASET_PREFIX}.ft\"\n",
        "ORIGIN_DATASET = ORIGIN_DATASET_PATH/DATASET_NAME\n",
        "\n",
        "if COLAB:\n",
        "  !ls -l gdrive/\"My Drive\"/datasets/ --block-size=M\n",
        "  !ls -l dl-projects/datasets --block-size=M"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 7081M\n",
            "-rw------- 1 root root 1548M Jan  7 00:07 feature_matrix_d2_v1.pkl\n",
            "-rw------- 1 root root 2454M Jan 12 01:24 feature_matrix_d2_v2.ft\n",
            "-rw------- 1 root root 1585M Jan 12 23:39 feature_matrix_d2_v3.ft\n",
            "-rw------- 1 root root    5M Jan 30 04:33 orig_X_test.ft\n",
            "-rw------- 1 root root  415M Jan 30 04:33 orig_X_train.ft\n",
            "-rw------- 1 root root    1M Jan 30 04:33 orig_y_test.ft\n",
            "-rw------- 1 root root    7M Jan 30 04:33 orig_y_train.ft\n",
            "-rw------- 1 root root   12M Feb  9 12:54 test_X_test.ft\n",
            "-rw------- 1 root root 1051M Feb  9 12:55 test_X_train.ft\n",
            "-rw------- 1 root root    1M Feb  9 12:54 test_y_test.ft\n",
            "-rw------- 1 root root    8M Feb  9 12:54 test_y_train.ft\n",
            "total 25M\n",
            "-rw-r--r-- 1 root root  1M Feb 16 13:09 4D.zip\n",
            "-rw-r--r-- 1 root root 25M Feb 16 13:09 labels.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urQTD6DQNutw",
        "colab": {}
      },
      "source": [
        "# Read the data\n",
        "data = pd.read_feather(DATASET)\n",
        "origin_data = format_tabular(ORIGIN_DATASET)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vOYlp-8Br61r"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kHiN1VVlG9Kh"
      },
      "source": [
        "### View data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JnQXyVqng5Cm",
        "colab": {}
      },
      "source": [
        "# Feature matrix\n",
        "feature_matrix = data.drop(columns=['NumberId', 'month', 'year'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apMYVNz9HK9e",
        "outputId": "2a584493-7271-4c5d-8c53-cdf5beec3a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Sort data\n",
        "feature_matrix.sort_values(by=['time', 'MAX(Results.LuckyNo)'], inplace=True)\n",
        "feature_matrix.info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 959893 entries, 7020 to 956511\n",
            "Columns: 332 entries, time to MODE(Results.PrizeType)_Prize\n",
            "dtypes: datetime64[ns](1), float64(214), int64(115), uint8(2)\n",
            "memory usage: 2.4 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CZKTbWRFJNUq",
        "outputId": "f42fdfd1-5f98-4b70-a7f8-e6cc6ac043bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print('Distribution')\n",
        "print(feature_matrix['Label'].value_counts())\n",
        "print()\n",
        "print('Positive: ' + str(feature_matrix['Label'].value_counts()[0]) + ' which is ', round(feature_matrix['Label'].value_counts()[0]/len(feature_matrix) * 100,2), '% of the dataset')\n",
        "print('Negative: ' + str(feature_matrix['Label'].value_counts()[1]) + ' which is ', round(feature_matrix['Label'].value_counts()[1]/len(feature_matrix) * 100,2), '% of the dataset')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution\n",
            "0    927839\n",
            "1     32054\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Positive: 927839 which is  96.66 % of the dataset\n",
            "Negative: 32054 which is  3.34 % of the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plplpAQ6JrKb",
        "outputId": "2b4fa923-17a1-4922-a687-9cb4eac4bf1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "feature_matrix.isna().sum().sort_values(ascending=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CUM_MEAN(TREND(Results.LuckyNo, DrawDate))      7636\n",
              "SKEW(Results.CUM_MAX(LuckyNo))                  7636\n",
              "SKEW(Results.PERCENTILE(DrawNo))                7636\n",
              "SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))     7636\n",
              "CUM_SUM(SKEW(Results.DrawNo))                   7636\n",
              "                                                ... \n",
              "CUM_SUM(MIN(Results.DrawNo))                       0\n",
              "SUM(Results.PERCENTILE(TotalStrike))               0\n",
              "CUM_MEAN(TIME_SINCE_FIRST(Results.DrawDate))       0\n",
              "CUM_SUM(MAX(Results.TotalStrike))                  0\n",
              "time                                               0\n",
              "Length: 332, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF_zCRksL1Ls"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1aLGsXSOa9K",
        "colab": {}
      },
      "source": [
        "# Fill all NaN with 0\n",
        "feature_matrix = feature_matrix.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5A8LZ805MqjP",
        "outputId": "60a27e37-a973-4954-ec85-8a59d04b83b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feature_matrix.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(959893, 332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rPFOkiGjhuKj",
        "colab": {}
      },
      "source": [
        "# feature_matrix_selection = feature_selection(feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label']))\n",
        "feature_matrix_selection = feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vT2K0WeJhugH",
        "outputId": "2bd2193c-2f23-4634-9c66-9689ca8fbf26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "feature_matrix_selection.shape, feature_matrix_selection.columns"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((959893, 329),\n",
              " Index(['NUM_UNIQUE(Results.PrizeType)', 'TIME_SINCE_FIRST(Results.DrawDate)',\n",
              "        'MIN(Results.TotalStrike)', 'SKEW(Results.LuckyNo)',\n",
              "        'LAST(Results.results_index)', 'SKEW(Results.TotalStrike)',\n",
              "        'AVG_TIME_BETWEEN(Results.DrawDate)', 'LAST(Results.DrawNo)',\n",
              "        'MIN(Results.LuckyNo)', 'LAST(Results.TotalStrike)',\n",
              "        ...\n",
              "        'MAX(Results.CUM_MAX(LuckyNo))', 'MAX(Results.CUM_MIN(DrawNo))',\n",
              "        'SKEW(Results.CUM_MEAN(TotalStrike))',\n",
              "        'MAX(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'CUM_MIN(TIME_SINCE(first_Results_time))',\n",
              "        'SUM(Results.CUM_MEAN(TotalStrike))',\n",
              "        'MAX(Results.CUM_SUM(TotalStrike))', 'CUM_MAX(SKEW(Results.DrawNo))',\n",
              "        'LAST(Results.PrizeType)_Prize', 'MODE(Results.PrizeType)_Prize'],\n",
              "       dtype='object', length=329))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZUhYrWFiRod",
        "colab": {}
      },
      "source": [
        "feature_matrix_selection['time'] = feature_matrix['time']\n",
        "feature_matrix_selection['TotalStrike'] = feature_matrix['TotalStrike']\n",
        "feature_matrix_selection['Label'] = feature_matrix['Label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hugygOqSiR6K"
      },
      "source": [
        "### Feature Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loagcqTEKOkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c95adffa-f44d-4d7d-d1e8-866e6be45f91"
      },
      "source": [
        "feature_matrix.isnull().sum().sort_values(ascending=False)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MODE(Results.PrizeType)_Prize           0\n",
              "STD(Results.CUM_MAX(TotalStrike))       0\n",
              "MIN(Results.PERCENTILE(TotalStrike))    0\n",
              "MIN(Results.CUM_MAX(DrawNo))            0\n",
              "LAST(Results.CUM_MAX(DrawNo))           0\n",
              "                                       ..\n",
              "CUM_SUM(SKEW(Results.DrawNo))           0\n",
              "MAX(Results.PERCENTILE(DrawNo))         0\n",
              "LAST(Results.CUM_MIN(LuckyNo))          0\n",
              "MIN(Results.CUM_MEAN(LuckyNo))          0\n",
              "time                                    0\n",
              "Length: 332, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u7Ha8Zlkhuoe",
        "colab": {}
      },
      "source": [
        "# Check with feature selection\n",
        "corrs = feature_matrix_selection.corr().sort_values('Label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EWRODfAdPk6j",
        "outputId": "9c5f608b-945a-41cb-b4d1-b69d0763c47f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "corrs['Label'].head(60)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CUM_MEAN(SUM(Results.LuckyNo))                 -0.003288\n",
              "CUM_MEAN(STD(Results.DrawNo))                  -0.003241\n",
              "CUM_MAX(SUM(Results.LuckyNo))                  -0.002972\n",
              "TIME_SINCE_FIRST(Results.DrawDate)             -0.002944\n",
              "CUM_MIN(TIME_SINCE_FIRST(Results.DrawDate))    -0.002944\n",
              "CUM_MIN(TIME_SINCE(first_Results_time))        -0.002944\n",
              "MAX(Results.TIME_SINCE(DrawDate))              -0.002944\n",
              "TIME_SINCE(first_Results_time)                 -0.002944\n",
              "CUM_MEAN(TIME_SINCE_FIRST(Results.DrawDate))   -0.002924\n",
              "STD(Results.CUM_SUM(LuckyNo))                  -0.002879\n",
              "STD(Results.CUM_MEAN(DrawNo))                  -0.002878\n",
              "STD(Results.CUM_SUM(TotalStrike))              -0.002878\n",
              "STD(Results.DrawNo)                            -0.002877\n",
              "STD(Results.CUM_MAX(DrawNo))                   -0.002877\n",
              "STD(Results.TIME_SINCE(DrawDate))              -0.002860\n",
              "STD(Results.CUM_SUM(DrawNo))                   -0.002778\n",
              "CUM_MAX(MEAN(Results.DrawNo))                  -0.002772\n",
              "MEAN(Results.PERCENTILE(LuckyNo))              -0.002685\n",
              "MAX(Results.PERCENTILE(LuckyNo))               -0.002685\n",
              "MIN(Results.PERCENTILE(LuckyNo))               -0.002685\n",
              "LAST(Results.PERCENTILE(LuckyNo))              -0.002685\n",
              "LAST(Results.LuckyNo)                          -0.002680\n",
              "MAX(Results.LuckyNo)                           -0.002680\n",
              "MEAN(Results.LuckyNo)                          -0.002680\n",
              "MIN(Results.LuckyNo)                           -0.002680\n",
              "PERCENTILE(MIN(Results.LuckyNo))               -0.002680\n",
              "PERCENTILE(MAX(Results.LuckyNo))               -0.002680\n",
              "PERCENTILE(MEAN(Results.LuckyNo))              -0.002680\n",
              "PERCENTILE(LAST(Results.LuckyNo))              -0.002680\n",
              "CUM_MEAN(COUNT(Results))                       -0.002548\n",
              "CUM_MEAN(SUM(Results.TotalStrike))             -0.002548\n",
              "CUM_MAX(MAX(Results.DrawNo))                   -0.002513\n",
              "CUM_MAX(LAST(Results.DrawNo))                  -0.002513\n",
              "CUM_MAX(MIN(Results.LuckyNo))                  -0.002510\n",
              "MIN(Results.CUM_MAX(LuckyNo))                  -0.002510\n",
              "CUM_MAX(MEAN(Results.LuckyNo))                 -0.002510\n",
              "CUM_MAX(MAX(Results.LuckyNo))                  -0.002510\n",
              "CUM_MAX(LAST(Results.LuckyNo))                 -0.002510\n",
              "LAST(Results.CUM_SUM(DrawNo))                  -0.002500\n",
              "MAX(Results.CUM_SUM(DrawNo))                   -0.002500\n",
              "CUM_MAX(TIME_SINCE(first_Results_time))        -0.002500\n",
              "CUM_MAX(TIME_SINCE_FIRST(Results.DrawDate))    -0.002500\n",
              "CUM_MAX(SUM(Results.TotalStrike))              -0.002478\n",
              "CUM_MAX(COUNT(Results))                        -0.002478\n",
              "CUM_MEAN(LAST(Results.DrawNo))                 -0.002448\n",
              "CUM_MEAN(MAX(Results.DrawNo))                  -0.002448\n",
              "CUM_MEAN(SUM(Results.DrawNo))                  -0.002437\n",
              "MAX(Results.CUM_MAX(LuckyNo))                  -0.002430\n",
              "LAST(Results.CUM_MAX(LuckyNo))                 -0.002430\n",
              "SUM(Results.PERCENTILE(LuckyNo))               -0.002429\n",
              "SUM(Results.LuckyNo)                           -0.002426\n",
              "PERCENTILE(SUM(Results.LuckyNo))               -0.002410\n",
              "LAST(Results.CUM_SUM(LuckyNo))                 -0.002378\n",
              "MAX(Results.CUM_SUM(LuckyNo))                  -0.002378\n",
              "LAST(Results.CUM_SUM(TotalStrike))             -0.002377\n",
              "MAX(Results.CUM_SUM(TotalStrike))              -0.002377\n",
              "LAST(Results.results_index)                    -0.002377\n",
              "MAX(Results.CUM_MEAN(DrawNo))                  -0.002377\n",
              "LAST(Results.CUM_MEAN(DrawNo))                 -0.002377\n",
              "LAST(Results.CUM_MAX(DrawNo))                  -0.002377\n",
              "Name: Label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "waeD1ED_kqDB"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9yrJyIVLh5So",
        "colab": {}
      },
      "source": [
        "def recall_optim(y_true, y_pred):\n",
        "    \"\"\"Make a scoring function that improves specificity while identifying all strikes\n",
        "    \"\"\"\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    # Recall will be worth a greater value than specificity\n",
        "    rec = recall_score(y_true, y_pred) * 0.8 \n",
        "    spe = conf_matrix[0,0]/conf_matrix[0,:].sum() * 0.2 \n",
        "    \n",
        "    # Imperfect recalls will lose a penalty\n",
        "    # This means the best results will have perfect recalls and compete for specificity\n",
        "    if rec < 0.8:\n",
        "        rec -= 0.2\n",
        "    return rec + spe \n",
        "\n",
        "\n",
        "# Make a scoring callable from recall_score\n",
        "recall = make_scorer(recall_score)\n",
        "\n",
        "# Create a scoring callable based on the scoring function\n",
        "optimize = make_scorer(recall_optim)\n",
        "\n",
        "# DataFrame to store classifier performance\n",
        "performance = pd.DataFrame(columns=['Train_Recall','Test_Recall','Test_Specificity', 'Optimize'])\n",
        "\n",
        "\n",
        "def score_optimization(dt, feature_matrix, clf, params, X_train, y_train, X_test, y_test, skip_grid_search_cv=False, optimized_scorer=False):\n",
        "    \"\"\"Find the optimized classifier.\n",
        "    \"\"\"\n",
        "    if not skip_grid_search_cv:\n",
        "      print(\"\\nFinding the optimized classifier...\")\n",
        "\n",
        "      # Load GridSearchCV\n",
        "      # search = GridSearchCV(\n",
        "      search = RandomizedSearchCV(\n",
        "            estimator=clf,\n",
        "            #param_grid=params,\n",
        "            param_distributions=params,\n",
        "            n_jobs=4,\n",
        "            scoring=optimize  # Use custom scorer\n",
        "      )\n",
        "\n",
        "      # Train search object\n",
        "      search.fit(X_train, y_train)\n",
        "\n",
        "      # Heading\n",
        "      print('\\n','-'*40,'\\n',clf.__class__.__name__,'\\n','-'*40)\n",
        "\n",
        "      # Extract best estimator\n",
        "      best = search.best_estimator_\n",
        "      print('Best parameters: \\n\\n',search.best_params_,'\\n')\n",
        "    \n",
        "    else:\n",
        "      print(\"\\nUse the passed in classifier...\\n\")\n",
        "      best = clf\n",
        "\n",
        "    # Cross-validate on the train data\n",
        "    print(\"TRAIN GROUP\")\n",
        "    #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
        "    cv = 3\n",
        "    if not optimized_scorer:\n",
        "      print('\\nUse default scorer')\n",
        "      train_cv = cross_val_score(\n",
        "                                n_jobs=4,\n",
        "                                X=X_train, \n",
        "                                y=y_train, \n",
        "                                estimator=best, \n",
        "                                scoring=recall,\n",
        "                                cv=cv)\n",
        "    else:\n",
        "      print('\\nUse optimized scorer')\n",
        "      train_cv = cross_val_score(\n",
        "                                n_jobs=4,\n",
        "                                X=X_train, \n",
        "                                y=y_train, \n",
        "                                estimator=best, \n",
        "                                #scoring=optimize,\n",
        "                                scoring='roc_auc',\n",
        "                                cv=cv)\n",
        "\n",
        "    print(\"\\nCross-validation recall scores:\",train_cv)\n",
        "    print(\"Mean recall score:\",train_cv.mean())\n",
        "\n",
        "    # Now predict on the test group\n",
        "    print(\"\\nTEST GROUP\")\n",
        "    y_pred = best.fit(X_train, y_train).predict(X_test)\n",
        "    probas = best.predict_proba(X_test)[:, 1]\n",
        "    print(\"\\nRecall:\",recall_score(y_test,y_pred))\n",
        "\n",
        "    # Get imbalanced classification report\n",
        "    print(classification_report_imbalanced(y_test, y_pred))\n",
        "\n",
        "    # Print confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test,y_pred)\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
        "    plt.show()\n",
        "\n",
        "    # Store results\n",
        "    performance.loc[clf.__class__.__name__+'_optimize',:] = [\n",
        "        train_cv.mean(),\n",
        "        recall_score(y_test,y_pred),\n",
        "        conf_matrix[0,0]/conf_matrix[0,:].sum(),\n",
        "        recall_optim(y_test,y_pred)\n",
        "    ]\n",
        "    # Look at the parameters for the top best scores\n",
        "    if not skip_grid_search_cv:\n",
        "      display(pd.DataFrame(search.cv_results_).iloc[:,4:].sort_values(by='rank_test_score').head())\n",
        "    display(performance)\n",
        "\n",
        "    # Additionl info\n",
        "    print('\\n\\nAdditional Info')\n",
        "    print('='*40)\n",
        "    positive = np.where((y_pred==1))\n",
        "    print(f'Total predicted to be positive: {len(positive[0])} \\n')\n",
        "\n",
        "    # Total predicted matches\n",
        "    print('Predicted matches')\n",
        "    pred = np.where((y_pred==1))\n",
        "    print(len(pred[0]), pred[0][0:23])\n",
        "    topN = np.argpartition(probas, -23)[-23:]\n",
        "    print(f'\\n{topN}\\n')  # Top N most high probability numbers\n",
        "  \n",
        "    if len(positive[0]) > 0:\n",
        "    \n",
        "      # Matching draws\n",
        "      print('Matched draws')\n",
        "      md = np.where((y_pred==1) & (y_test==1))\n",
        "      print(f\"Count: {len(md[0])}, Index: {md}\")\n",
        "      month_data = feature_matrix.loc[feature_matrix['time'] == dt]\n",
        "      numbers = month_data.iloc[md[0]][['MAX(Results.LuckyNo)']]\n",
        "\n",
        "      print('\\n\\nTop 23 Possibility')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(topN))].head(23))  \n",
        "      \n",
        "      print('\\n\\nFirst 23 Numbers')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(pred[0][0:23]))].head(23))    \n",
        "             \n",
        "\n",
        "      print('\\n\\nAll matched')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(numbers['MAX(Results.LuckyNo)']))].head(100))    \n",
        "                                                  \n",
        "    else:\n",
        "      print('No luck this month')  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VrL8gYwjc-hd",
        "colab": {}
      },
      "source": [
        "def remove_outliers(balanced, threshold=0.001, remove=True):\n",
        "    \"\"\"Removing Outliers from high-correlation features.\n",
        "    \"\"\"\n",
        "\n",
        "    if not remove:\n",
        "      return balanced\n",
        "\n",
        "    bal_corr = balanced.corr()\n",
        "    no_outliers=pd.DataFrame(balanced.copy())\n",
        "\n",
        "    cols = bal_corr.Label.index[:-1]\n",
        "\n",
        "    # For each feature correlated with Class...\n",
        "    for col in cols:\n",
        "        # If absolute correlation value is more than X percent...\n",
        "        correlation = bal_corr.loc['Label',col]\n",
        "\n",
        "        if np.absolute(correlation) > threshold:\n",
        "          # Separate the classes of the high-correlation column\n",
        "          nonstrikes = no_outliers.loc[no_outliers.Label==0,col]\n",
        "          strikes = no_outliers.loc[no_outliers.Label==1,col]\n",
        "\n",
        "          # Identify the 25th and 75th quartiles\n",
        "          all_values = no_outliers.loc[:,col]\n",
        "          q25, q75 = np.percentile(all_values, 25), np.percentile(all_values, 75)\n",
        "          # Get the inter quartile range\n",
        "          iqr = q75 - q25\n",
        "          # Smaller cutoffs will remove more outliers\n",
        "          cutoff = iqr * 7\n",
        "          # Set the bounds of the desired portion to keep\n",
        "          lower, upper = q25 - cutoff, q75 + cutoff\n",
        "          \n",
        "          # If positively correlated...\n",
        "          # Drop nonstrikes above upper bound, and strikes below lower bound\n",
        "          if correlation > 0: \n",
        "              no_outliers.drop(index=nonstrikes[nonstrikes>upper].index,inplace=True)\n",
        "              no_outliers.drop(index=strikes[strikes<lower].index,inplace=True)\n",
        "          \n",
        "          # If negatively correlated...\n",
        "          # Drop non strikes below lower bound, and strikes above upper bound\n",
        "          elif correlation < 0: \n",
        "              no_outliers.drop(index=nonstrikes[nonstrikes<lower].index,inplace=True)\n",
        "              no_outliers.drop(index=strikes[strikes>upper].index,inplace=True)\n",
        "        \n",
        "    print('\\nData shape before removing outliers:', balanced.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in previous data:')\n",
        "    print(balanced.Label.value_counts())\n",
        "    print('-'*40)\n",
        "    print('-'*40)\n",
        "    print('\\nData shape after removing outliers:', no_outliers.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
        "    print(no_outliers.Label.value_counts())\n",
        "\n",
        "    # no_outliers.iloc[:,:-1].boxplot(rot=90,figsize=(16,4))\n",
        "    # plt.title('Distributions with Less Outliers', fontsize=17)\n",
        "    # plt.show()\n",
        "    \n",
        "    no_outliers.reset_index(drop=True, inplace=True)\n",
        "    return no_outliers\n",
        "\n",
        "\n",
        "def filter_features(no_outliers, threshold=0.001):\n",
        "    \"\"\"Feature selection.\n",
        "    \"\"\"\n",
        "    feat_sel = pd.DataFrame(no_outliers.copy())\n",
        "\n",
        "    # Make a dataframe with the label-correlations before removing outliers\n",
        "    # corr_change = pd.DataFrame()\n",
        "    # corr_change['correlation']= bal_corr.Label\n",
        "    # corr_change['origin']= 'w/outliers'\n",
        "\n",
        "    # Make a dataframe with label-correlations after removing outliers \n",
        "    # corr_other = pd.DataFrame()\n",
        "    # corr_other['correlation']= feat_sel.corr().Label\n",
        "    # corr_other['origin']= 'no_outliers'\n",
        "\n",
        "    # Join them\n",
        "    # corr_change = corr_change.append(corr_other)\n",
        "\n",
        "    # plt.figure(figsize=(14,6))\n",
        "    # plt.xticks(rotation=90)\n",
        "\n",
        "    # Plot them\n",
        "    # sns.set_style('darkgrid')\n",
        "    # plt.title('Label correlation per feature. With vs without outliers', fontsize=17)\n",
        "    # sns.barplot(data=corr_change,x=corr_change.index,y='correlation',hue='origin')\n",
        "    # plt.show()\n",
        "\n",
        "    # Feature Selection based on correlation with label\n",
        "\n",
        "    print('\\nData shape before feature selection:', feat_sel.shape)\n",
        "    print('\\nCounts of strikes vs non-strikes before feature selection:')\n",
        "    print(feat_sel.Label.value_counts())\n",
        "    print('-'*40)\n",
        "\n",
        "    # Correlation matrix after removing outliers\n",
        "    new_corr = feat_sel.corr()\n",
        "\n",
        "    for col in new_corr.Label.index[:-1]:\n",
        "        # Pick desired cutoff for dropping features. In absolute-value terms.\n",
        "        if np.absolute(new_corr.loc['Label',col]) < threshold:\n",
        "            # Drop the feature if correlation is below cutoff\n",
        "            feat_sel.drop(columns=col,inplace=True)\n",
        "\n",
        "    print('-'*40)\n",
        "    print('\\nData shape after feature selection:', feat_sel.shape)\n",
        "    print('\\nCounts of strikes vs non-strikes in new data:')\n",
        "    print(feat_sel.Label.value_counts())\n",
        "\n",
        "    return feat_sel\n",
        "\n",
        "    # feat_sel.iloc[:,:-1].boxplot(rot=90,figsize=(16,4))\n",
        "    # plt.title('Distribution of Features Selected', fontsize=17)\n",
        "    # plt.show()\n",
        "\n",
        "def under_sampler(data, sample_size=20000, sampling=False):\n",
        "    # Undersample model for efficiency and balance classes.\n",
        "\n",
        "    X_train = data.drop('Label',1)\n",
        "    y_train = data.Label\n",
        "\n",
        "    if not sampling:\n",
        "      return X_train, y_train\n",
        "\n",
        "    # After feature-selection, X_test needs to include only the same features as X_train\n",
        "    # cols = X_train.columns\n",
        "    # X_test = X_test[cols]\n",
        "\n",
        "    # Undersample and balance classes\n",
        "    X_train, y_train = RandomUnderSampler(sampling_strategy={1:sample_size,0:sample_size}).fit_resample(X_train,y_train)\n",
        "\n",
        "    print('\\nX_train shape after reduction:', X_train.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in y_train:')\n",
        "    print(np.unique(y_train, return_counts=True))\n",
        "\n",
        "    return X_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pl5ZoepSNPf4",
        "colab": {}
      },
      "source": [
        "def gen_train_test_set(dt, feature_matrix, file_prefix='data'): \n",
        "    \n",
        "    # Subset labels\n",
        "    test_labels = feature_matrix.loc[feature_matrix['time'] == dt, 'Label']\n",
        "    train_labels = feature_matrix.loc[feature_matrix['time'] < dt, 'Label']\n",
        "\n",
        "    # Features\n",
        "    X_train = feature_matrix[feature_matrix['time'] < dt].drop(columns = ['NumberId', 'time', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    X_test = feature_matrix[feature_matrix['time'] == dt].drop(columns = ['NumberId', 'time', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
        "    feature_names = list(X_train.columns)\n",
        "    \n",
        "    # Labels\n",
        "    y_train = np.array(train_labels).reshape((-1, ))\n",
        "    y_test = np.array(test_labels).reshape((-1, ))\n",
        "    \n",
        "    print('Training on {} observations.'.format(len(X_train)))\n",
        "    print('Testing on {} observations.\\n'.format(len(X_test)))\n",
        "\n",
        "    # Join the train data\n",
        "    train = X_train.join(train_labels)\n",
        "\n",
        "    print('Data shape before balancing:', train.shape)\n",
        "    print('\\nCounts of strikes vs non-strikes in previous data:')\n",
        "    print(train.Label.value_counts())\n",
        "    print('-'*40)\n",
        "\n",
        "    # sklearn pipeline\n",
        "    pipeline = make_pipeline(\n",
        "        SimpleImputer(strategy = 'constant', fill_value=0),\n",
        "        StandardScaler())\n",
        "    \n",
        "    X_train = pipeline.fit_transform(X_train)\n",
        "    X_test = pipeline.transform(X_test)\n",
        "\n",
        "    # imblearn pipeline\n",
        "    imb_pipeline = make_pipeline_imb(\n",
        "          # NearMiss(version=3, n_neighbors_ver3=3, n_jobs=4)\n",
        "          # SMOTE(sampling_strategy='minority',random_state=42, n_jobs=4)\n",
        "          ADASYN(sampling_strategy='minority',random_state=42, n_jobs=4)\n",
        "          # OneSidedSelection(n_neighbors=1, n_seeds_S=200, random_state=42, n_jobs=4)\n",
        "    )\n",
        "     \n",
        "    # Balance the data\n",
        "    to_balanced = False\n",
        "    if to_balanced:\n",
        "      print('\\nBalancing data')\n",
        "      X_bal, y_bal = imb_pipeline.fit_resample(X_train, y_train)\n",
        "      X_bal = pd.DataFrame(X_bal,columns=feature_names)\n",
        "      y_bal = pd.DataFrame(y_bal,columns=['Label'])\n",
        "    else:\n",
        "      print('\\nNO balancing')\n",
        "      X_bal = pd.DataFrame(X_train,columns=feature_names)\n",
        "      y_bal = pd.DataFrame(y_train,columns=['Label'])\n",
        "\n",
        "    balanced = X_bal.join(y_bal)\n",
        "\n",
        "    # print('-'*40)\n",
        "    print('Data shape after balancing:',balanced.shape)\n",
        "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
        "    print(balanced.Label.value_counts())\n",
        "\n",
        "    # Remove high correlation outliers\n",
        "    no_outliers = remove_outliers(balanced, remove=False)\n",
        "   \n",
        "    # Remove features with low correlation\n",
        "    remove_features = True\n",
        "    if remove_features:\n",
        "      print('\\nFiltering features')\n",
        "      features_selected = filter_features(no_outliers)\n",
        "    else:\n",
        "      print('\\nNO filtering')\n",
        "      features_selected = no_outliers \n",
        "\n",
        "    columns_selected = features_selected.drop('Label',1).columns\n",
        "\n",
        "    # Under sampling\n",
        "    X_train, y_train = under_sampler(features_selected, sampling=False) \n",
        "    X_train = pd.DataFrame(X_train,columns=columns_selected)\n",
        "    y_train = pd.DataFrame(y_train,columns=['Label'])\n",
        "\n",
        "    # For X_test, now only use the selected features\n",
        "    X_test = pd.DataFrame(X_test,columns=feature_names)\n",
        "    X_test = X_test[columns_selected]\n",
        "    y_test = pd.DataFrame(y_test,columns=['Label'])\n",
        "\n",
        "    #print(X_train.describe())\n",
        "    #return\n",
        "\n",
        "    # Save data\n",
        "    # print(X_train.head(10))\n",
        "    # print(y_train.head(10)) \n",
        "\n",
        "    # print(X_test.head(10))\n",
        "    # print(y_test.head(10)) \n",
        "    X_train.to_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
        "    y_train.to_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
        "   \n",
        "    X_test.to_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
        "    y_test.to_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
        "\n",
        "    gc.collect()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PcKlL67TP9UM",
        "colab": {}
      },
      "source": [
        "def model(dt, feature_matrix, file_prefix='data', csv=False):\n",
        "    \"\"\"Predict for a particular month.\n",
        "\n",
        "    - https://www.kaggle.com/miguelniblock/optimizing-imbalanced-classification-100-recall\n",
        "    - https://www.kaggle.com/saxinou/imbalanced-data-xgboost-tunning\n",
        "    - https://www.kaggle.com/andreanuzzo/balance-the-imbalanced-rf-and-xgboost-with-smote\n",
        "    - https://github.com/mengwangk/FraudDetection/blob/master/05_Sampling_techniques_for_extremely_imbalanced_data.ipynb\n",
        "    - https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
        "    - https://github.com/coding-maniacs/over-under-sampling/blob/master/src/main.py\n",
        "    - https://github.com/scikit-learn-contrib/imbalanced-learn/issues/552#issuecomment-466348310\n",
        "    - https://stackoverflow.com/questions/52499788/smotetomek-how-to-set-ratio-as-dictionary-for-fixed-balance\n",
        "    - https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.OneSidedSelection.html#imblearn.under_sampling.OneSidedSelection\n",
        "    - https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\n",
        "    - https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n",
        "    - https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
        "    - https://stats.stackexchange.com/questions/243207/what-is-the-proper-usage-of-scale-pos-weight-in-xgboost-for-imbalanced-datasets\n",
        "    - https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py\n",
        "    - https://machinelearningmastery.com/cost-sensitive-logistic-regression/\n",
        "    \n",
        "    - https://datascience.stackexchange.com/questions/28285/what-is-the-best-way-to-deal-with-imbalanced-data-for-xgboost/28292\n",
        "    - https://machinelearningmastery.com/xgboost-for-imbalanced-classification/\n",
        "    - https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # Read data\n",
        "    if not csv:\n",
        "      X_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
        "      y_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
        "    \n",
        "      X_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
        "      y_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
        "    else:\n",
        "      X_train = pd.read_csv(DATASET_PATH/f\"{file_prefix}_X_train.csv\", header=0, sep=',', quotechar='\"')\n",
        "      y_train = pd.read_csv(DATASET_PATH/f\"{file_prefix}_y_train.csv\", header=0, sep=',', quotechar='\"')\n",
        "    \n",
        "      X_test = pd.read_csv(DATASET_PATH/f\"{file_prefix}_X_test.csv\", header=0, sep=',', quotechar='\"')\n",
        "      y_test = pd.read_csv(DATASET_PATH/f\"{file_prefix}_y_test.csv\", header=0, sep=',', quotechar='\"')\n",
        "\n",
        "    # Reshape\n",
        "    y_train = np.array(y_train).reshape((-1, ))\n",
        "    y_test = np.array(y_test).reshape((-1, ))\n",
        "    \n",
        "    print('Data shape')\n",
        "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "    # print(X_train.describe())\n",
        "    # return\n",
        "\n",
        "    # Calculate hit ratio for xgboost classifier\n",
        "    print(\"\\nCalculating scale pos weight\")\n",
        "    counter = Counter(y_train)\n",
        "    print(Counter(y_train))\n",
        "    scale_pos_weight = float(counter[0] / counter[1])\n",
        "    print(f\"\\nscale_pos_weight - {scale_pos_weight}\\n\")\n",
        "    \n",
        "     # Modeling\n",
        "#     clf = xgb.XGBClassifier(\n",
        "#               n_jobs=4, \n",
        "#               random_state=42,\n",
        "#               #learning_rate=0.1,\n",
        "#               #n_estimators=500,\n",
        "#               #max_depth=6, \n",
        "#               #min_child_weight=3, \n",
        "#               #gamma=0,\n",
        "#               #subsample=0.8,\n",
        "#               #colsample_bytree=0.8,\n",
        "#               objective='binary:logistic', \n",
        "#               scale_pos_weight=scale_pos_weight,\n",
        "#               ##eval_metric=\"auc\",\n",
        "#               ##max_delta_step=1,\n",
        "#               seed=27)\n",
        "#     clf = xgb.XGBClassifier(n_jobs=4, \n",
        "#                             random_state=42,\n",
        "#                             objective='binary:logistic', \n",
        "#                             #scale_pos_weight=28)\n",
        "#                             scale_pos_weight=scale_pos_weight)\n",
        "    \n",
        "    clf = xgb.XGBClassifier(\n",
        "                    n_jobs=4, \n",
        "                    random_state=42,\n",
        "                    objective='binary:logistic',\n",
        "                    subsample=0.55, \n",
        "                    n_estimators=300,\n",
        "                    #n_estimators=400,\n",
        "                    min_child_weight=1,\n",
        "                    max_depth=3, \n",
        "                    learning_rate=0.007,\n",
        "                    gamma=0.1, \n",
        "                    colsample_bytree=0.95,\n",
        "                    tree_method='hist',\n",
        "                    # booster='dart',\n",
        "                    scale_pos_weight=scale_pos_weight\n",
        "                    )\n",
        "\n",
        "    clf_params = clf.get_params()\n",
        "    print(clf_params)\n",
        "\n",
        "    # Set parameters\n",
        "    #clf_params['max_depth'] = 10\n",
        "    #clf.set_params(clf_params)\n",
        "\n",
        "    # Parameters to compare\n",
        "    weights = [i for i in range(1,36,1)]\n",
        "    weights.append(scale_pos_weight)\n",
        "    learn_params = {\n",
        "        'n_estimators': [100, 300, 500, 800, 1000], \n",
        "        'max_depth': range(3,10,2),\n",
        "        'min_child_weight': range(1,6,2),\n",
        "        #'gamma':[i/10.0 for i in range(0,5)],\n",
        "        'subsample':[i/100.0 for i in range(55,70,5)],\n",
        "        'colsample_bytree':[i/100.0 for i in range(85,100,5)],\n",
        "        #'learning_rate':[i/1000.0 for i in range(5,20,2)],\n",
        "        'scale_pos_weight': weights\n",
        "    }\n",
        "    print(f'Parameter distribution: {learn_params}')\n",
        "    \n",
        "    # Test and validate\n",
        "    score_optimization(dt,\n",
        "                       feature_matrix,\n",
        "                       clf, \n",
        "                       learn_params,  \n",
        "                       X_train, \n",
        "                       y_train, \n",
        "                       X_test, \n",
        "                       y_test, \n",
        "                       skip_grid_search_cv=True,\n",
        "                       optimized_scorer=True)\n",
        "\n",
        "    gc.collect()\n",
        "    \n",
        "    # clf.fit(X_train, y_train)\n",
        "    # y_pred = clf.predict(X_test)\n",
        "\n",
        "    # # ROC score\n",
        "    # auc = roc_auc_score(y_test, y_pred)\n",
        "    # print(\"ROC score: \", auc)\n",
        "\n",
        "    # # Print confusion matrix\n",
        "    # conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    # sns.heatmap(conf_matrix, annot=True,fmt='d', cmap=plt.cm.copper)\n",
        "    # plt.show()\n",
        "\n",
        "    # Parameters to compare\n",
        "    # params = {\n",
        "    #     'criterion':['entropy','gini'],\n",
        "    #     'class_weight':[{1:1,0:0.3},{1:1,0:0.4},{1:1,0:0.5},{1:1,0:0.6},{1:1,0:7}]\n",
        "    # }\n",
        "\n",
        "    # Implement the classifier\n",
        "    # clf = RandomForestClassifier(\n",
        "    #     n_estimators=100,\n",
        "    #     max_features=None,\n",
        "    #     n_jobs=4,\n",
        "    # )\n",
        "\n",
        "    # # Test and validate\n",
        "    # score_optimization(clf, params, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m9UobqUWMI9b",
        "jupyter": {
          "source_hidden": true
        },
        "colab": {}
      },
      "source": [
        "# Predict for a particular month\n",
        "# %time predict(pd.datetime(2019,6,1), feature_matrix_selection)\n",
        "\n",
        "# %time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection)\n",
        "\n",
        "# %time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='test')\n",
        "\n",
        "# %time model(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='orig')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qktZbi7OGqP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30f49aaa-cc85-4438-8f59-ee2a6cedc82a"
      },
      "source": [
        "# NO Feature_selection\n",
        "# n_estimators = 300\n",
        "# NO remove outliers\n",
        "# filter features\n",
        "start_mt = pd.datetime(2019,6,1)\n",
        "how_many_mt = 7 \n",
        "for i in range(how_many_mt):\n",
        "  month_to_predict = start_mt + relativedelta(months=i)\n",
        "  print(f\"\\n{month_to_predict}\\n-------------------\\n\")\n",
        "  %time gen_train_test_set(month_to_predict, feature_matrix_selection, file_prefix='test')\n",
        "  %time model(month_to_predict, feature_matrix_selection, file_prefix='test')\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2019-06-01 00:00:00\n",
            "-------------------\n",
            "\n",
            "Training on 889893 observations.\n",
            "Testing on 10000 observations.\n",
            "\n",
            "Data shape before balancing: (889893, 330)\n",
            "\n",
            "Counts of strikes vs non-strikes in previous data:\n",
            "0    860060\n",
            "1     29833\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "\n",
            "NO balancing\n",
            "Data shape after balancing: (889893, 330)\n",
            "\n",
            "Counts of strikes VS non-strikes in new data:\n",
            "0    860060\n",
            "1     29833\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Filtering features\n",
            "\n",
            "Data shape before feature selection: (889893, 330)\n",
            "\n",
            "Counts of strikes vs non-strikes before feature selection:\n",
            "0    860060\n",
            "1     29833\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "\n",
            "Data shape after feature selection: (889893, 237)\n",
            "\n",
            "Counts of strikes vs non-strikes in new data:\n",
            "0    860060\n",
            "1     29833\n",
            "Name: Label, dtype: int64\n",
            "CPU times: user 3min 46s, sys: 7.71 s, total: 3min 54s\n",
            "Wall time: 4min 36s\n",
            "Data shape\n",
            "(889893, 236) (889893,) (10000, 236) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 860060, 1: 29833})\n",
            "\n",
            "scale_pos_weight - 28.829148929038315\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.829148929038315, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.829148929038315]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "TRAIN GROUP\n",
            "\n",
            "Use optimized scorer\n",
            "\n",
            "Cross-validation recall scores: [0.49698789 0.49913208 0.49953632]\n",
            "Mean recall score: 0.49855209768833747\n",
            "\n",
            "TEST GROUP\n",
            "\n",
            "Recall: 0.002976190476190476\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      1.00      0.00      0.98      0.05      0.00      9664\n",
            "          1       0.09      0.00      1.00      0.01      0.05      0.00       336\n",
            "\n",
            "avg / total       0.94      0.97      0.04      0.95      0.05      0.00     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXiklEQVR4nO3dfXRU9Z3H8U9mgoGgQwiYGBIVAm0I\nuotbosieViuosUuIQteGpmJaRXwgiLtVQAtJUNoSoFZrUHyonNTnR8QEJVi1rdpKQQ0KCaLh2YQE\nJwmjYMIyc/cPz06LIVlmbn4Z5ub98txznPu7N/MdT04+fu9v7v3FWJZlCQCAMLkiXQAAILoRJAAA\nWwgSAIAtBAkAwBaCBABgC0ECALAltkff7d2SHn079A4x4xZGugQ4ULfeGRHq377zQzw+wno2SACg\nN3L47Xpc2gIA2EJHAgCmObwjIUgAwDRn5whBAgDGObwjYY4EAGALHQkAmObwjoQgAQDTnJ0jBAkA\nGEdHAgCwxdk5QpAAgHF0JAAAWwgSAIAtzs4RggQAjHN4R8INiQAAW+hIAMA0h3ckBAkAmObsHCFI\nAMA4h3ckzJEAAGyhIwEA0xzekRAkAGBagCABANjh7BwhSADAPGcnCUECAKY5O0cIEgAwjsl2AIAt\nzs4RggQAzHN2khAkAGCas3OEIAEA45gjAQDY4uwcIUgAwDg6EgCALQQJAMAWZ+cIQQIAxjm8I2E9\nEgCALQQJAJhmWaFtIXjzzTd1xRVX6PLLL1dubq7WrVsnSdqxY4fy8vKUnZ2tvLw87dy5M3hOuGOd\nIUgAwDQrxO14f6xlac6cOVqyZIlWr16tJUuWaO7cuQoEAiouLlZ+fr6qqqqUn5+voqKi4HnhjnWG\nIAEA0wx2JC6XS1988YUk6YsvvlBSUpJaWlpUU1OjnJwcSVJOTo5qamrU3Nwsr9cb1lhXmGwHANNC\nnGv3+Xzy+Xwd9ns8Hnk8nuDrmJgY3XPPPbrpppsUHx+vgwcP6qGHHlJDQ4OSk5PldrslSW63W0lJ\nSWpoaJBlWWGNJSYmdlovQQIAxoWWJOXl5SorK+uwv7CwULNmzQq+PnLkiB588EHdf//9GjNmjN57\n7z3dcsstWrJkie2KQ0GQAIBpIXYkBQUFmjx5cof9/9yNSFJtba2ampo0ZswYSdKYMWPUr18/xcXF\nqbGxUX6/X263W36/X01NTUpJSZFlWWGNdYU5EgAwLWCFtHk8HqWlpXXYvhkkp512mvbt26ft27dL\nkurq6uT1enXmmWcqMzNTlZWVkqTKykplZmYqMTFRgwYNCmusKzGW1YN3yrxb0mNvhd4jZtzCSJcA\nB+rWP42P3RDa8dNWHPehL7/8sh5++GHFxMRIkm6++WZdfPHFqqur07x58+Tz+eTxeFRaWqr09HRJ\nCnusMwQJoh5BAhOiJUhOBMyRAIBhoYZSjKE6TCFIAMCwUJsbggQAcJSenEGIBIIEAAxzdowQJABg\nHB0JAMCWgLNzhCABANMc3pAQJABgWsDhScIjUgyrqz+gqxe/rjE3PK9LbqvQaxv3BMe+aj+ikvIN\nGjvzBY254Xn95Jd/DI7dt+ojnXXN0/q3Gc8Ftz1NX3b4+S+9vUMZBU/puT/V9cjnQXSYOXOmNmzY\noLa2Nq1cufKosfHjx6u2tlYHDx7UG2+8oTPOOCNCVfYeAcsKaYs2dCQGHfEHdNM9b2nq+BFaOeci\n/X1rk2787V+0Km2Ahp3m0YKVf5c/YOnVX0/UgJNPUu2u1qPO/8F5Z2jZDf/e6c8/cPCwVlRu0bdS\nB5j+KIgy9fX1WrRokbKzs9WvX7/g/kGDBunFF1/U9OnTVVFRobvuukvPPPOMxo0bF8FqnS8KsyEk\ndCQGbW/wqan1K/00O0Nul0vjRp2m73zrVK1+Z6fq6n1644PPdNfPzlOip6/cLpfOHtb1g9G+6TfP\nbdK0SzI08JQ4Q58A0WrVqlVavXq1vF7vUfunTJmiLVu26Pnnn1d7e7tKSko0evRoZWRkRKjS3sGy\nrJC2aHNcQdLS0qLa2lrV1taqpaXFdE2OZsnSJ3sP6KPtXqUO7q/fvfiRxs58QZN+8YqqNuw56tg3\nq+t13k0vaOLta/Tk658cNfZhnVebdzTrxxeN6MnyEeXOOussbdq0Kfj60KFDqqur01lnnRXBqpzP\n0Eq7J4wuL23t3r1bCxYsUE1NjZKSkiRJTU1NGjVqlBYuXKihQ4ce87zOVvdKs19vVBl2mkeJnjg9\n8kqtfpo9UutrG7Vh636NzUzSvpZD2rb3gC7NOl1v3XuFqj/16vq7/6wRqR4NHzJAPzjvDP3o+8M1\neEBfbarz6ub73pYnvo9yxg2VPxBQyR82qmjaGLlc0fYwBUTSySefrP379x+178CBAzrllFMiVFHv\nEI3zHqHoMkjmzJmj/Px8rVy5Ui7X181LIBBQRUWF5s6dq2eeeeaY53W2utfH5T/uhpKjR59Yl5bf\n/D0tevw9PbKmVmcPS9Rl552uk/q41bePW33cLt2Ye5Zi3S6dNzJJYzOT9PbmfRo+ZIBG/NO8x3e+\ndaquvjRDVRv3KGfcUD35+qfKOH2AzhkxOIKfDtHoyy+/7LCmhcfjCa75DTMcniNdB0lra6tyc3OP\n2udyuXT55ZfrgQce6PS8zlb30t5Hwqsyio08Y6Aev+Pi4Oupd72mK747TGcmnXyMo7voLmL+8cv4\nt5p92rC1SX/5cJUk6cCXh1Wzq0W1u1tUdHVWN1YPp9myZYsKCgqCr+Pj4zV8+HBt2bIlglU5XzTO\ne4SiyyBJSEhQZWWlJk6cGFw0xbIsVVRUdPi/mn/2zQXqg/baKzYabd3domGneRSwLD35+idqav1K\nU747TDExMUoZFK8HK2t0fc4obarzav3WRt2Wd44k6Y/v79W5GUnyxPfRR9ub9di6bfrvK/9VkrR4\n+vlq/x9/8D1m3fe2ss89Xf95QdeLz6D3cLvdio2NldvtltvtVlxcnI4cOaJVq1Zp6dKlmjJlitas\nWaOioiJ9+OGH+vjjjyNdsqM5PEe6DpLFixeruLhYd955p5KTkyVJjY2NGjlypBYvXtwjBUa71X/d\nqef/XKcjfktjvn2qVs65SCf1cUuS7p99geY/ul4PV9ZoyOD+WnLd+Ro+5OsAfuXdXfrFI+t1+EhA\nyYn9dN3ETE3+7tdB4el/0lHv0SfWpZP79tEp8UfvR+81f/58lZSUBF9PmzZNJSUlWrhwoX74wx+q\nrKxMjz/+uNavX6+pU6dGrtBeIhCVU+jH77hWSGxublZDQ4MkKSUl5f9dv7dTrJAIA1ghESZ05+Wo\nffddHdLxp836Q7e9d084rhsSExMTww8PAOjlevWlLQCAfZbDL20RJABgGI+RBwDY0qu//gsAsM/h\nOUKQAIBpdCQAAFsCkS7AMIIEAAyjIwEA2OLwHCFIAMA0OhIAgC1+ggQAYIfDc4QgAQDTuLQFALCF\nR6QAAGzhoY0AAFscfmWLIAEA05gjAQDY4vAcIUgAwLSAw5OEIAEAw5wdIwQJABgXcPj3fwkSADDM\n6Ze2XJEuAACczgpxC0V7e7uKi4t16aWXatKkSVqwYIEkaceOHcrLy1N2drby8vK0c+fO4DnhjnWG\nIAEAwyzLCmkLxdKlSxUXF6eqqipVVFRo9uzZkqTi4mLl5+erqqpK+fn5KioqCp4T7lhnCBIAMMyy\nQtt8Pp/27t3bYfP5fEf93IMHD+qll17S7NmzFRMTI0kaPHiwvF6vampqlJOTI0nKyclRTU2Nmpub\nwx7rCnMkAGBYqHMk5eXlKisr67C/sLBQs2bNCr7es2ePEhISVFZWpvXr16t///6aPXu2+vbtq+Tk\nZLndbkmS2+1WUlKSGhoaZFlWWGOJiYmd1kuQAIBhoc61FxQUaPLkyR32ezyeo177/X7t2bNHo0aN\n0ty5c7Vp0ybdcMMNuvfee+2UGzKCBAAMC/WhjR6Pp0NoHEtKSopiY2ODl6JGjx6tgQMHqm/fvmps\nbJTf75fb7Zbf71dTU5NSUlJkWVZYY11hjgQADAt1juR4JSYmauzYsXrnnXckff2NK6/Xq6FDhyoz\nM1OVlZWSpMrKSmVmZioxMVGDBg0Ka6wrMVZPPk3s3ZIeeyv0HjHjFka6BDhQd/5p/NMduSEd//1f\nvXzcx+7Zs0d33HGHWltbFRsbq1tuuUUXXnih6urqNG/ePPl8Pnk8HpWWlio9PV2Swh7rDEGCqEeQ\nwITu/NP4xu2TQjp+/K8ruu29ewJzJABgmMNvbCdIAMA01iMBANji8Gc2EiQAYBodCQDAFmfHCEEC\nAMbRkQAAbGGOBABgCx0JAMAWh+cIQQIApvkdniQECQAYxqUtAIAtDs8RggQATAt1PZJoQ5AAgGF8\n/RcAYAtzJAAAWxyeIwQJAJhGRwIAsMXZMUKQAIBxAToSAIAdDs8RggQATKMjAQDYQpB0o/4X/rIn\n3w4ATggOzxE6EgAwja//AgBscXiOECQAYFrA4XeSECQAYBgdCQDAFuZIAAC2ODxHCBIAMI05EgCA\nLQGHr2xFkACAYVzaAgDYwmQ7AMCWQKQLMIwgAQDD6EgAALY4PEcIEgAwjY4EAGCLw7/9S5AAgGmW\nw29IdEW6AABwOssKbQtHWVmZMjIytG3bNklSdXW1cnNzlZ2drWuuuUZerzd4bLhjnSFIAMAwf8AK\naQvVli1bVF1drdTUVElSIBDQbbfdpqKiIlVVVSkrK0vLli2zNdYVggQADLNC/CcUhw8f1p133qmS\nkpLgvs2bNysuLk5ZWVmSpKlTp2rt2rW2xrrCHAkAGBbq5Sqfzyefz9dhv8fjkcfjOWrfvffeq9zc\nXKWlpQX3NTQ0aMiQIcHXiYmJCgQCam1tDXssISGh03oJEgAwLNSv/5aXl6usrKzD/sLCQs2aNSv4\n+oMPPtDmzZt166232q7RDoIEAAwLddqjoKBAkydP7rD/m93Ihg0bVFdXpwkTJkiS9u3bp2uvvVbT\npk1TfX198Ljm5ma5XC4lJCQoJSUlrLGuECQAYFioHcmxLmEdy4wZMzRjxozg6/Hjx2vFihUaMWKE\nnn32WW3cuFFZWVl6+umnddlll0mSzj77bLW1tYU81hWCBAAM6+m7SFwul5YsWaLi4mK1t7crNTVV\nS5cutTXWlRirB+/d7x/Xp6feCr3IocNHIl0CHKg7/zQWXTEmpOPvfOm9bnvvnkBHAgCGOfxRWwQJ\nAJgWcHiSECQAYBhBAgCwxeE5QpAAgGl0JAAAWxyeIwQJAJjm9PVICBIAMIyOBABgC3MkAABbHJ4j\nBAkAmMYcCQDAFjoSAIAtzJEAAGwJhLqyVZQhSADAMGfHCEECAMb14LJPEUGQAIBhDr+yRZAAgGl0\nJAAAWxyeIwQJAJjGDYkAAFuYIwEA2MIcCQDAFofnCEECAKb5HZ4kBAkAGMalLQCALQ7PEYIEAEyj\nIwEA2BKIdAGGuSJdQG/z+5Xlqtu5Ww37varevEUFP7tGkjRyZKbe+uu72ruvSXv3Nany1bUaOTIz\neN4d8xeo9ctDavS2BLehw4ZF6mMgysycOVMbNmxQW1ubVq5cGelyeh3LskLaog0dSQ9btqRUN15/\nnQ4fPqxvZ2Ro7bo/alN1tXZsr9NPfpyn3bt2yeVy6fobb1L5409obNZ3gue+8NxzuvZnBRGsHtGq\nvr5eixYtUnZ2tvr16xfpcnqdKMyGkBAkPay2tib47//3fx/p6emq/uB9HThwQJIUExMjv9+v9OHD\nI1UmHGbVqlWSpKysLKWlpUW4mt4nGruMUHBpKwJ++7v7tL/lgKo/2qJ9+/apau2rwbHPGver2fel\nfvPbe7S0dPFR5/1g4kTtaWjUhg+qNX3G9T1dNoAwWSFu0SbsjmTSpEmqqKg45pjP55PP5wu7KKf7\nr5tn6ee3zNbY88fpexdcoPb29uBYavKpio+P10+mXa3du3cF97/4/PN69PePqKmxUeeeN1ZPPv2M\nDrS26rlnn4nERwAQgl69Zvunn37a6VhLS0unY+Xl5SorKwu/ql4gEAjob399R1Pz83Xd9TfogeX/\n+O916NAhPfLQg9r1WYPGjP4X7d+/X1u31gbH17/7N91fdp+umDKFIAGiQK9esz0nJ0epqanHvL7X\n2tra6XkFBQWaPHlyh/0Zw/mW0TfFumOVnp7eYb/L5VJ8fLyGDEnV/v37O4xblqWYmJieKBGATQ5v\nSLoOktTUVD355JNKTk7uMHbhhRd2ep7H45HH47FfncOceuqpuvD7F+nVV9boq6++0vgJE3RlXp5+\nevVVGj9hgryfe/XRRx+qf//+Klp4p1pbWoKdyMRJk/TOW2+ptbVVY7LO1Y0zC1VStCDCnwjRwu12\nKzY2Vm63W263W3FxcTpy5Ij8fn+kS+sVAlE583H8upxsv/TSS/XZZ58dc+ySSy4xUpCTWZal6TOu\n17btO/VZ4379avESzbn153qlslIDBiRo5WOPqWG/Vx/Vfqz09HRdMSknOH9y5ZU/0oc1W9XobdHD\njz6qu3+zTE88/liEPxGixfz589XW1qbbb79d06ZNU1tbm+bPnx/psnoNywptizYxVg9+L61/XJ+e\neiv0IocOH4l0CXCg7vzT+B+jzwjp+Fc27e629+4J3EcCAIZFY5cRCu4jAQDDArJC2o5XS0uLrrvu\nOmVnZ2vSpEkqLCxUc3OzJKm6ulq5ubnKzs7WNddcI6/XGzwv3LHOECQAYJipOZKYmBhNnz5dVVVV\nqqio0Omnn65ly5YpEAjotttuU1FRkaqqqpSVlaVly5ZJUthjXSFIAMAwUw9tTEhI0NixY4Ovzznn\nHNXX12vz5s2Ki4tTVlaWJGnq1Klau3atJIU91hXmSADAsFDnSDp7OkhXt1YEAgE99dRTGj9+vBoa\nGjRkyJDgWGJiogKBgFpbW8MeS0hI6LReggQADAv1ESmdPR2ksLBQs2bNOuY5d911l+Lj43XVVVfp\ntddeC6vOcBEkAGBYqEHS2dNBOutGSktLtWvXLq1YsUIul0spKSmqr68Pjjc3N8vlcikhISHssa4w\nRwIAhoU62e7xeJSWltZhO1aQ3H333dq8ebOWL1+uk046SZJ09tlnq62tTRs3bpQkPf3007rsssts\njXWFGxIR9bghESZ055/GCzJSQjr+Lx83HNdxn3zyiXJycjR06FD17dtXkpSWlqbly5fr/fffV3Fx\nsdrb25WamqqlS5dq8ODBkhT2WGcIEkQ9ggQmdOefxu9+O7QgeXvb8QXJiYI5EgAwzHL4QxsJEgAw\nzOmPSCFIAMAwp6/ZTpAAgGEOXyCRIAEA05gjAQDY4vArWwQJAJjmd/i1LYIEAAxjsh0AYIuzY4Qg\nAQDj6EgAALY4fIqEIAEA0+hIAAC2ODtGCBIAMI6OBABgi8NzhCABANNCXWo32hAkAGAYQQIAsMXh\nOUKQAIBpdCQAAFscniMECQCYxnokAABb6EgAALYwRwIAsMXhOUKQAIBpPCIFAGCLs2OEIAEA41iz\nHQBgC5e2AAC2ODxHCBIAMI0bEgEAtjh8ioQgAQDTmCMBANji8BwhSADANOZIAAC2MEcCALCFORIA\ngC0OzxGCBABM8zs8SQgSADCMS1sAAFscniMECQCYRkcCALAlEOkCDCNIAMAwp3ckMZbTP2EU8vl8\nKi8vV0FBgTweT6TLgUPwewVTXJEuAB35fD6VlZXJ5/NFuhQ4CL9XMIUgAQDYQpAAAGwhSAAAthAk\nAABbCJITkMfjUWFhId+sQbfi9wqm8PVfAIAtdCQAAFsIEgCALQTJCWbHjh3Ky8tTdna28vLytHPn\nzkiXBAcoLS3V+PHjlZGRoW3btkW6HDgMQXKCKS4uVn5+vqqqqpSfn6+ioqJIlwQHmDBhgp544gml\npqZGuhQ4EEFyAvF6vaqpqVFOTo4kKScnRzU1NWpubo5wZYh2WVlZSklJiXQZcCiC5ATS0NCg5ORk\nud1uSZLb7VZSUpIaGhoiXBkAdI4gAQDYQpCcQFJSUtTY2Ci/3y9J8vv9ampq4pIEgBMaQXICGTRo\nkDIzM1VZWSlJqqysVGZmphITEyNcGQB0jjvbTzB1dXWaN2+efD6fPB6PSktLlZ6eHumyEOUWLVqk\ndevW6fPPP9fAgQOVkJCgNWvWRLosOARBAgCwhUtbAABbCBIAgC0ECQDAFoIEAGALQQIAsIUgAQDY\nQpAAAGwhSAAAtvwvdICXAIOK4dMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0.498552</td>\n",
              "      <td>0.00297619</td>\n",
              "      <td>0.998965</td>\n",
              "      <td>0.002174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity  Optimize\n",
              "XGBClassifier_optimize     0.498552  0.00297619         0.998965  0.002174"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 11 \n",
            "\n",
            "Predicted matches\n",
            "11 [1702 1933 1949 2185 2260 2633 2958 3319 4586 4613 4640]\n",
            "\n",
            "[6742 2479 5921 5311 2107 2210  923 4166 3090 2936 7166 1933 6772 3319\n",
            " 2958 2633 4640 4613 2260 4586 2185 1702 1949]\n",
            "\n",
            "Matched draws\n",
            "Count: 1, Index: (array([4613]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "104898  496819 2019-06-30  SpecialNo5     4613\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "104898  496819 2019-06-30  SpecialNo5     4613\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "104898  496819 2019-06-30  SpecialNo5     4613\n",
            "CPU times: user 9min 20s, sys: 5.25 s, total: 9min 25s\n",
            "Wall time: 13min 47s\n",
            "\n",
            "2019-07-01 00:00:00\n",
            "-------------------\n",
            "\n",
            "Training on 899893 observations.\n",
            "Testing on 10000 observations.\n",
            "\n",
            "Data shape before balancing: (899893, 330)\n",
            "\n",
            "Counts of strikes vs non-strikes in previous data:\n",
            "0    869724\n",
            "1     30169\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "\n",
            "NO balancing\n",
            "Data shape after balancing: (899893, 330)\n",
            "\n",
            "Counts of strikes VS non-strikes in new data:\n",
            "0    869724\n",
            "1     30169\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Filtering features\n",
            "\n",
            "Data shape before feature selection: (899893, 330)\n",
            "\n",
            "Counts of strikes vs non-strikes before feature selection:\n",
            "0    869724\n",
            "1     30169\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "\n",
            "Data shape after feature selection: (899893, 243)\n",
            "\n",
            "Counts of strikes vs non-strikes in new data:\n",
            "0    869724\n",
            "1     30169\n",
            "Name: Label, dtype: int64\n",
            "CPU times: user 4min 1s, sys: 9.52 s, total: 4min 11s\n",
            "Wall time: 4min 25s\n",
            "Data shape\n",
            "(899893, 242) (899893,) (10000, 242) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 869724, 1: 30169})\n",
            "\n",
            "scale_pos_weight - 28.828400013258644\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.828400013258644, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.828400013258644]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "TRAIN GROUP\n",
            "\n",
            "Use optimized scorer\n",
            "\n",
            "Cross-validation recall scores: [0.49275842 0.49796525 0.50015439]\n",
            "Mean recall score: 0.496959351277195\n",
            "\n",
            "TEST GROUP\n",
            "\n",
            "Recall: 0.012738853503184714\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.97      0.98      0.01      0.97      0.11      0.01      9686\n",
            "          1       0.02      0.01      0.98      0.02      0.11      0.01       314\n",
            "\n",
            "avg / total       0.94      0.95      0.04      0.94      0.11      0.01     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train_Recall</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_Specificity</th>\n",
              "      <th>Optimize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier_optimize</th>\n",
              "      <td>0.496959</td>\n",
              "      <td>0.0127389</td>\n",
              "      <td>0.978319</td>\n",
              "      <td>0.00585493</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Train_Recall Test_Recall Test_Specificity    Optimize\n",
              "XGBClassifier_optimize     0.496959   0.0127389         0.978319  0.00585493"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 214 \n",
            "\n",
            "Predicted matches\n",
            "214 [  0  19  28  29  52  72  92 121 151 163 193 197 201 219 230 243 253 259\n",
            " 271 272 279 283 291]\n",
            "\n",
            "[ 706 3996  219 1009  630  553  392  283 1504  507  322  567  592 1508\n",
            "  895  897  661  903  641  923 1949  193  974]\n",
            "\n",
            "Matched draws\n",
            "Count: 4, Index: (array([ 28, 463, 502, 559]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "Empty DataFrame\n",
            "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
            "Index: []\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "104996  497319 2019-07-13  2ndPrizeNo       28\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate       PrizeType  LuckyNo\n",
            "104996  497319 2019-07-13      2ndPrizeNo       28\n",
            "105002  497319 2019-07-13  ConsolationNo4      502\n",
            "105124  497819 2019-07-24     SpecialNo10      559\n",
            "105208  498219 2019-07-31  ConsolationNo3      463\n",
            "CPU times: user 9min 33s, sys: 5.32 s, total: 9min 38s\n",
            "Wall time: 13min 11s\n",
            "\n",
            "2019-08-01 00:00:00\n",
            "-------------------\n",
            "\n",
            "Training on 909893 observations.\n",
            "Testing on 10000 observations.\n",
            "\n",
            "Data shape before balancing: (909893, 330)\n",
            "\n",
            "Counts of strikes vs non-strikes in previous data:\n",
            "0    879410\n",
            "1     30483\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "\n",
            "NO balancing\n",
            "Data shape after balancing: (909893, 330)\n",
            "\n",
            "Counts of strikes VS non-strikes in new data:\n",
            "0    879410\n",
            "1     30483\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Filtering features\n",
            "\n",
            "Data shape before feature selection: (909893, 330)\n",
            "\n",
            "Counts of strikes vs non-strikes before feature selection:\n",
            "0    879410\n",
            "1     30483\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "\n",
            "Data shape after feature selection: (909893, 241)\n",
            "\n",
            "Counts of strikes vs non-strikes in new data:\n",
            "0    879410\n",
            "1     30483\n",
            "Name: Label, dtype: int64\n",
            "CPU times: user 4min 8s, sys: 11.8 s, total: 4min 19s\n",
            "Wall time: 4min 35s\n",
            "Data shape\n",
            "(909893, 240) (909893,) (10000, 240) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 879410, 1: 30483})\n",
            "\n",
            "scale_pos_weight - 28.849194633074173\n",
            "\n",
            "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.849194633074173, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
            "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.849194633074173]}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "TRAIN GROUP\n",
            "\n",
            "Use optimized scorer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TerminatedWorkerError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-514c801f611c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n{month_to_predict}\\n-------------------\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time gen_train_test_set(month_to_predict, feature_matrix_selection, file_prefix='test')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time model(month_to_predict, feature_matrix_selection, file_prefix='test')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-f122b947905a>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(dt, feature_matrix, file_prefix, csv)\u001b[0m\n\u001b[1;32m    126\u001b[0m                        \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                        \u001b[0mskip_grid_search_cv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                        optimized_scorer=True)\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-7792f48c185a>\u001b[0m in \u001b[0;36mscore_optimization\u001b[0;34m(dt, feature_matrix, clf, params, X_train, y_train, X_test, y_test, skip_grid_search_cv, optimized_scorer)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                 \u001b[0;31m#scoring=optimize,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                                 cv=cv)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCross-validation recall scores:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DPIj7aePrnyg",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}