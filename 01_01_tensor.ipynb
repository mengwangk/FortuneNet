{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATASET = Path(\"datasets/lotto/data_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into data frame\n",
    "dataset = pd.read_csv(DATASET, header=0, sep=',', quotechar='\"', parse_dates=['DrawDate'], dtype={'PrizeType': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import operator\n",
    "import torch\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = tensor(np.arange(1,10,1))\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.view(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [9]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [9]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "unsqueeze(input, dim) -> Tensor\n",
       "\n",
       "Returns a new tensor with a dimension of size one inserted at the\n",
       "specified position.\n",
       "\n",
       "The returned tensor shares the same underlying data with this tensor.\n",
       "\n",
       "A :attr:`dim` value within the range ``[-input.dim() - 1, input.dim() + 1)``\n",
       "can be used. Negative :attr:`dim` will correspond to :meth:`unsqueeze`\n",
       "applied at :attr:`dim` = ``dim + input.dim() + 1``.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor.\n",
       "    dim (int): the index at which to insert the singleton dimension\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> x = torch.tensor([1, 2, 3, 4])\n",
       "    >>> torch.unsqueeze(x, 0)\n",
       "    tensor([[ 1,  2,  3,  4]])\n",
       "    >>> torch.unsqueeze(x, 1)\n",
       "    tensor([[ 1],\n",
       "            [ 2],\n",
       "            [ 3],\n",
       "            [ 4]])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?torch.unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4]) tensor([1, 2, 3, 4])\n",
      "torch.Size([1, 4]) tensor([[1, 2, 3, 4]])\n",
      "torch.Size([4, 1]) tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4])\n",
    "print(x.shape, x)\n",
    "y = torch.unsqueeze(x,0)\n",
    "print(y.shape, y)\n",
    "y = torch.unsqueeze(x,1)\n",
    "print(y.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "empty(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
       "\n",
       "Returns a tensor filled with uninitialized data. The shape of the tensor is\n",
       "defined by the variable argument :attr:`size`.\n",
       "\n",
       "Args:\n",
       "    size (int...): a sequence of integers defining the shape of the output tensor.\n",
       "        Can be a variable number of arguments or a collection like a list or tuple.\n",
       "    out (Tensor, optional): the output tensor.\n",
       "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
       "        Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
       "    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
       "        Default: ``torch.strided``.\n",
       "    device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
       "        Default: if ``None``, uses the current device for the default tensor type\n",
       "        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
       "        for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
       "    requires_grad (bool, optional): If autograd should record operations on the\n",
       "        returned tensor. Default: ``False``.\n",
       "    pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
       "        the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
       "    memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
       "        returned Tensor. Default: ``torch.contiguous_format``.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.empty(2, 3)\n",
       "    tensor(1.00000e-08 *\n",
       "           [[ 6.3984,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?torch.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5,3)\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 3]),\n",
       " tensor([[[1.1210e-44, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00]]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(1,5,3) \n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3241, 0.0215, 0.4287],\n",
       "        [0.1927, 0.7167, 0.5681],\n",
       "        [0.3061, 0.8101, 0.0186],\n",
       "        [0.1976, 0.2463, 0.3205],\n",
       "        [0.0907, 0.5189, 0.6617]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(5,3, dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 3.0000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.5,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.new_ones(5,3, dtype=torch.double)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6646, -1.3416, -0.7051],\n",
       "        [-0.2318,  1.3066,  1.6423],\n",
       "        [-1.8371,  0.9593,  1.5381],\n",
       "        [-0.5668,  0.2819,  1.1210],\n",
       "        [ 1.3762, -0.2620,  1.0973]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9491, -1.3252, -0.5420],\n",
       "        [ 0.1703,  1.4707,  1.7180],\n",
       "        [-1.1559,  1.6384,  2.1097],\n",
       "        [ 0.2242,  0.6419,  2.0776],\n",
       "        [ 2.1598, -0.0729,  1.3510]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9491, -1.3252, -0.5420],\n",
       "        [ 0.1703,  1.4707,  1.7180],\n",
       "        [-1.1559,  1.6384,  2.1097],\n",
       "        [ 0.2242,  0.6419,  2.0776],\n",
       "        [ 2.1598, -0.0729,  1.3510]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9491, -1.3252, -0.5420],\n",
      "        [ 0.1703,  1.4707,  1.7180],\n",
      "        [-1.1559,  1.6384,  2.1097],\n",
      "        [ 0.2242,  0.6419,  2.0776],\n",
      "        [ 2.1598, -0.0729,  1.3510]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9491, -1.3252, -0.5420],\n",
       "        [ 0.1703,  1.4707,  1.7180],\n",
       "        [-1.1559,  1.6384,  2.1097],\n",
       "        [ 0.2242,  0.6419,  2.0776],\n",
       "        [ 2.1598, -0.0729,  1.3510]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "torch.add(x,y, out=result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9491, -1.3252, -0.5420],\n",
       "        [ 0.1703,  1.4707,  1.7180],\n",
       "        [-1.1559,  1.6384,  2.1097],\n",
       "        [ 0.2242,  0.6419,  2.0776],\n",
       "        [ 2.1598, -0.0729,  1.3510]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9491, -1.3252, -0.5420],\n",
       "        [ 0.1703,  1.4707,  1.7180],\n",
       "        [-1.1559,  1.6384,  2.1097],\n",
       "        [ 0.2242,  0.6419,  2.0776],\n",
       "        [ 2.1598, -0.0729,  1.3510]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.empty(5,3)\n",
    "z.copy_(y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9491, -1.3252, -0.5420],\n",
       "        [ 0.1703,  1.4707,  1.7180],\n",
       "        [-1.1559,  1.6384,  2.1097],\n",
       "        [ 0.2242,  0.6419,  2.0776],\n",
       "        [ 2.1598, -0.0729,  1.3510]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.t_()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6646, -1.3416, -0.7051],\n",
      "        [-0.2318,  1.3066,  1.6423],\n",
      "        [-1.8371,  0.9593,  1.5381],\n",
      "        [-0.5668,  0.2819,  1.1210],\n",
      "        [ 1.3762, -0.2620,  1.0973]])\n",
      "tensor([-1.3416,  1.3066,  0.9593,  0.2819, -0.2620])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "tensor([[0.6800, 0.5682, 0.8101, 0.6739],\n",
      "        [0.0190, 0.6950, 0.2429, 0.1885],\n",
      "        [0.8962, 0.5534, 0.5090, 0.5022],\n",
      "        [0.7804, 0.1696, 0.0247, 0.0464]]) tensor([0.6800, 0.5682, 0.8101, 0.6739, 0.0190, 0.6950, 0.2429, 0.1885, 0.8962,\n",
      "        0.5534, 0.5090, 0.5022, 0.7804, 0.1696, 0.0247, 0.0464]) tensor([[0.6800, 0.5682, 0.8101, 0.6739, 0.0190, 0.6950, 0.2429, 0.1885],\n",
      "        [0.8962, 0.5534, 0.5090, 0.5022, 0.7804, 0.1696, 0.0247, 0.0464]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(),y.size(), z.size())\n",
    "print(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0095])\n",
      "0.00954516977071762\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(a, 1, out=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2.0\n",
       " 2.0\n",
       " 2.0\n",
       " 2.0\n",
       " 2.0\n",
       "[torch.DoubleStorage of size 5]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4721, dtype=torch.float64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b*b).sum().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape\n",
    "    br,bc = b.shape\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            # Any trailing \",:\" can be removed\n",
    "            c[i,j] = (a[i,:] * b[:,j]).sum()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = tensor([[1., 2, 3], [4,5,6], [7,8,9]], dtype=torch.float); m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = tensor([[1., 2, 3], [4,5,6], [7,8,9]], dtype=torch.float); m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.21 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "443 µs ± 246 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _ = matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
    "def test_near(a,b): test(a,b,near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False) -> bool\n",
       "\n",
       "This function checks if all :attr:`input` and :attr:`other` satisfy the condition:\n",
       "\n",
       ".. math::\n",
       "    \\lvert \\text{input} - \\text{other} \\rvert \\leq \\texttt{atol} + \\texttt{rtol} \\times \\lvert \\text{other} \\rvert\n",
       "\n",
       "elementwise, for all elements of :attr:`input` and :attr:`other`. The behaviour of this function is analogous to\n",
       "`numpy.allclose <https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html>`_\n",
       "\n",
       "Args:\n",
       "    input (Tensor): first tensor to compare\n",
       "    other (Tensor): second tensor to compare\n",
       "    atol (float, optional): absolute tolerance. Default: 1e-08\n",
       "    rtol (float, optional): relative tolerance. Default: 1e-05\n",
       "    equal_nan (bool, optional): if ``True``, then two ``NaN`` s will be considered equal. Default: ``False``\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09]))\n",
       "    True\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]))\n",
       "    False\n",
       "    >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True)\n",
       "    True\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.allclose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tensor([1,2,3])\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = c.expand_as(m1)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 4, 6],\n",
       "        [3, 6, 9]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:] * c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:] @ c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:] > c[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape\n",
    "    br,bc = b.shape\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        # c[i,j] = (a[i,:]          * b[:,j]).sum() # previous\n",
    "        c[i] = (a[i  ].unsqueeze(-1) * b).sum(dim=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 6.11 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "149 µs ± 129 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einstein summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c[i,j] += a[i,k] * b[k,j]\n",
    "# c[i,j] = (a[i,:] * b[:,j]).sum()\n",
    "def matmul(a,b): return torch.einsum('ik,kj->ij', a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 35.72 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "280 µs ± 565 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 406.52 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "224 µs ± 538 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 m1.matmul(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 23.26 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "31.8 µs ± 49 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 t2= m1@m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_near(t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python notebook2script.py 01_basic.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chain rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1]) torch.Size([10, 1])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]])\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "#preds = torch.rand(10,1)\n",
    "preds = torch.randint(0,2, (10,1))\n",
    "targs = torch.randint(0,2, (10,1))\n",
    "print(preds.shape, targs.shape)\n",
    "print(preds)\n",
    "print(targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9416, 0.7571, 0.7640, 0.5057, 0.5663, 0.5435])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nonzero(preds > 0.5)\n",
    "# preds[torch.nonzero(preds > 0.5)]\n",
    "preds[preds > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, make_scorer, recall_score, roc_curve, mean_squared_error, accuracy_score, average_precision_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAASs0lEQVR4nO3df7DddX3n8eeLkKJbFURciklsaEl3oUwbu7tB6u6AOq7gOqQzUjY4bdVSb+uUqc7SFu1MEfijUzsd3XFkpHclCtYRLLpOypilbIFFxxKJMaSQUMhKNbmmhRINzYBskvveP+6pPb3ee8655OR7vnzzfGQ+wznf7+d+vp8MmVc+eX9/paqQJDXjhElPQJKOJ4auJDXI0JWkBhm6ktQgQ1eSGmToSlKDDF1JGiDJsiTfSHLHAvtOSnJbkt1JtiRZPWw8Q1eSBnsvsGuRfVcA362qs4CPAB8aNpihK0mLSLIS+C/AJxbpsh64uff5duCNSTJozBPHN72FffLdr/eWN/2Qd11xwaSnoDZ67bUDA2sk9187cubk/Ot+HZjq2zRdVdN93/878LvASxcZYgWwB6CqDic5ALwC+IfFjnnMQ1eS2qoXsNML7UvyVuCJqvp6kgvHdUzLC5K6pWr0NtjrgEuS/C1wK/CGJH86r88MsAogyYnAycBTgwY1dCV1y5hCt6o+UFUrq2o1sAG4u6p+aV63TcA7ep8v7fUZOLDlBUndcozPIiW5HthaVZuAm4BPJ9kN7GcunAcydCV1yzF4XG1V3Qvc2/t8Td/27wO/uJSxLC9IUoNc6Urqlpa/mMHQldQt7c5cQ1dSx8y2O3UNXUkdY+hKUnPanbmGrqSO8USaJDWo3Zlr6ErqGFe6ktQgQ1eSGtTuzDV0JXVMy1e6PntBkhrkSldSt7R8pWvoSuoWbwOWpAa1O3MNXUld0+7UNXQldUu7M9erFyR1zJheTJnkRUm+luTBJA8nuW6BPu9M8mSS7b32a8Om50pXUreM7+qF54A3VNXBJMuBryTZXFX3z+t3W1VdOeqghq6kbhlT5vZepX6w93V5rx316JYXJHXLmMoLAEmWJdkOPAHcVVVbFuj2tiQ7ktyeZNWwMQ1dSd1So7ckU0m29rWpfzFU1ZGqWgusBNYlOXfe0f4cWF1VPwPcBdw8bHqWFyR1yxJqulU1DUyP0O97Se4BLgIe6tv+VF+3TwB/NGwsV7qStIAkr0xySu/zi4E3AY/M63NG39dLgF3DxnWlK6lbxncb8BnAzUmWMbdA/VxV3ZHkemBrVW0CfivJJcBhYD/wzmGDGrqSumVMl4xV1Q7gNQtsv6bv8weADyxlXMsLktQgV7qSusVHO0pSg9qduYaupI5xpStJDTJ0JalB7c5cQ1dSx7jSlaQGtTtzDV1JHeNKV5KaU0sI3RzDeSzG0JXUKUtZ6Bq6knSUlrLSnQRDV1KntDtyDV1JHeNKV5IaNL7H6R4bhq6kTplteeoaupI6pd2Ra+hK6phZa7r60Ze/kv/0qx/gxS97OQU8et8d7PzLz096WmqBI7OzvO2Dd3L6y/8Vf/LfLpj0dDqh5Zlr6DZhdvYID/zZx3nq249x4kkv5pLf/xNmdm7lwL5vTXpqmrBb/uJRfvJVJ3Pw2UOTnkpnjOvqhSQvAu4DTmIuK2+vqg/O63MScAvw74CngP9aVX87aNyh70hL8m+TXJ3ko712dZKzn+fv47j07IH9PPXtxwA4/NyzHNj3bX70lNMmPCtN2t/tf4Z7H/wOl17wE5OeSqfUEtoQzwFvqKqfBdYCFyV57bw+VwDfraqzgI8AHxo26MDQTXI1cCtzd8t9rdcCfDbJ+4fPWfO95BWnc+qqs3jy8V2Tnoom7A8+s43fuWwtJ2QSN6N215HZGrkNUnMO9r4u77X5P7QeuLn3+Xbgjcng/6HDVrpXAP+hqv6wqv601/4QWNfbt6AkU0m2Jtl67yPfGXKI48eJJ72I17/ner522w0c+v4zk56OJuie7TOc+rKTOPfMUyc9lc6pqpFbf1b12lT/WEmWJdkOPAHcVVVb5h1uBbCnd9zDwAHgFYPmN6ymOwu8CphffDyjt2+x3/Q0MA3wyXe/vuVl7WZk2TLe8J7r+eaW/823vvHlSU9HE7bt0Se5+xsz3LdjH88dOsLBZw/x2zd+lT/+jZ+f9NRe8JZS0u3PqkX2HwHWJjkF+J9Jzq2qh45mfsNC933AXyZ5jF6aA68GzgKuPJoDH2/+4zt+l+/t+xYP3/Vnk56KWuCqy9Zy1WVrAdiy6+/ZuPkRA3dMZo/BlbpV9b0k9wAXAf2hOwOsAvYmORE4mbkTaosaGLpV9b+S/BRz5YQVfQd5oPc3gEbwr886l7PO/8/s3/t/ueSa/wHAti98gr0Pzf+XiqSjNa5LxpK8EjjUC9wXA2/ih0+UbQLeAfwVcClwdw25fGLoJWNVNQvc/7xmLQCe2P0Qn3z36yc9DbXUeWefznlnnz7paXTGGG8DPgO4Ocky5s5/fa6q7khyPbC1qjYBNwGfTrIb2A9sGDao1+lK6pQaU3mhqnYAr1lg+zV9n78P/OJSxjV0JXVKy593Y+hK6hafpytJDWp55hq6krrFla4kNeiIoStJzWl55hq6krrF8oIkNchLxiSpQeO6OeJYMXQldUrLqwuGrqRuGfZw8kkzdCV1iuUFSWqQ5QVJapCXjElSg1qeuYaupG7xNmBJapDlBUlqUMszlxMmPQFJGqfZqpHbIElWJbknyc4kDyd57wJ9LkxyIMn2XrtmobH6udKV1CljXOgeBq6qqm1JXgp8PcldVbVzXr8vV9VbRx3U0JXUKeOq6VbVPmBf7/M/JtkFrADmh+6SWF6Q1ClHZmvklmQqyda+NrXQmElWM/dm4C0L7D4/yYNJNif56WHzc6UrqVOWstCtqmlgelCfJC8BPg+8r6qenrd7G/DjVXUwyVuALwJrBo3nSldSp9QSfg2TZDlzgfuZqvrCDx2r6umqOtj7/CVgeZLTBo1p6ErqlKrR2yBJAtwE7KqqDy/S58d6/UiyjrlMfWrQuJYXJHXKsEvBluB1wC8Df51ke2/b7wGvBqiqG4FLgfckOQw8C2yoIWfyDF1JnTKu0K2qrwAZ0udjwMeWMq6hK6lT2n5HmqErqVN89oIkNajlb+sxdCV1iytdSWpQuyPX0JXUMb4NWJIaZHlBkhrU8sw1dCV1yyjPVJgkQ1dSp7S8pGvoSuoWa7qS1KAxPvDmmDB0JXWK5QVJapDlBUlqUMsz19CV1C2udCWpQUcMXUlqTssz1xdTSuqWqhq5DZJkVZJ7kuxM8nCS9y7QJ0k+mmR3kh1Jfm7Y/FzpSuqUMS50DwNXVdW2JC8Fvp7krqra2dfnYmBNr50HfLz330W50pXUKbNVI7dBqmpfVW3rff5HYBewYl639cAtNed+4JQkZwwa95ivdN91xQXH+hB6Acr51016CmqhqmvHMMbofZNMAVN9m6aranqBfquB1wBb5u1aAezp+763t23fYse0vCCpU2aXcEtaL2B/KGT7JXkJ8HngfVX19NHNztCV1DGzY6zqJlnOXOB+pqq+sECXGWBV3/eVvW2LsqYrqVOqRm+DJAlwE7Crqj68SLdNwK/0rmJ4LXCgqhYtLYArXUkdM8Y70l4H/DLw10m297b9HvDq3nFuBL4EvAXYDTwDvGvYoIaupE4ZV+ZW1VeADOlTwG8uZVxDV1KnjLOmeywYupI6ZSlXL0yCoSupU9r+7AVDV1Kn+GhHSWrQ7KQnMIShK6lTXOlKUoM8kSZJDWp55hq6krqlvE5XkprT8pKuoSupWzyRJkkNsqYrSQ0a9hqeSTN0JXWK5QVJapDlBUlqkCtdSWpQuyPX0JXUMW1f6fpiSkmdcmS2Rm7DJNmY5IkkDy2y/8IkB5Js77Vrho3pSldSp4x5nfsp4GPALQP6fLmq3jrqgIaupE4ZZ3mhqu5LsnpsA2J5QVLHVI3ekkwl2drXpp7HIc9P8mCSzUl+elhnV7qSOmUpd6RV1TQwfRSH2wb8eFUdTPIW4IvAmkE/4EpXUqfMVo3cjlZVPV1VB3ufvwQsT3LaoJ8xdCV1ylLKC0cryY8lSe/zOuYy9alBP2N5QVKnjPOBN0k+C1wInJZkL/BBYDlAVd0IXAq8J8lh4FlgQw05k2foSuqUcd4bUVWXD9n/MeYuKRuZoSupU3xdjyQ1qOV3ARu6krpllNt7J8nQldQpbX/gjaErqVPaHbmGrqSOcaUrSQ1qeUnX0JXULbMtT11DV1KneJ2uJDWo5QtdQ1dSt3giTZIa1PLMNXQldYs1XUlqkLcBS1KDLC9IUoM8kSZJDZqd9ASG8B1pDTkyO8sv/P5mfv3D/2fSU1GLvPnNb+aRRx7hscce4+qrr570dDqhqkZuk2DoNuSWv3iUn3zVyZOehlrkhBNO4IYbbuDiiy/mnHPO4fLLL+fss8+e9LRe8Mb5YsokG5M8keShRfYnyUeT7E6yI8nPDRvT0G3A3+1/hnsf/A6XXvATk56KWmTdunXs3r2bxx9/nEOHDnHrrbeyfv36SU/rBW/Mr2D/FHDRgP0XA2t6bQr4+LABDd0G/MFntvE7l63lhLk3NUsArFixgj179vzg+969e1mxYsUEZ9QN4wzdqroP2D+gy3rglppzP3BKkjMGjfm8QzfJuwbsm0qyNcnW6S9+/fkeohPu2T7DqS87iXPPPHXSU5GOC0spL/RnVa9NLfFwK4A9fd/39rYt6miuXrgO+ORCO6pqGpgG4P5r2339xjG27dEnufsbM9y3Yx/PHTrCwWcP8ds3fpU//o2fn/TUNGEzMzOsWrXqB99XrlzJzMzMBGfUDUs5QfYvsqohA0M3yY7FdgGnj3863XPVZWu56rK1AGzZ9fds3PyIgSsAHnjgAdasWcPq1auZmZlhw4YNvP3tb5/0tF7wGr4oYQZY1fd9ZW/booatdE8H3gx8d972AF9d6uwk/bMjR45w5ZVXcuedd7Js2TI2btzIzp07Jz2tF7wjzabuJuDKJLcC5wEHqmrfoB8YFrp3AC+pqu3zdyS593lO8rh13tmnc97Z/gNB/2zz5s1s3rx50tPolHFef5vks8CFwGlJ9gIfBJb3jnMj8CXgLcBu4Blg0XNd/2Rg6FbVFQP2+e8gSa0zzoVuVV0+ZH8Bv7mUMb0NWFKnzPpoR0lqTsufd2PoSuoWnzImSQ3yIeaS1KB2R66hK6ljLC9IUoNanrmGrqRucaUrSQ1q+Xk0Q1dSt4z4cPKJMXQldYrlBUlqkOUFSWpQtfxKXUNXUqe0vLpg6ErqFm8DlqQGeSJNkhrU7sg1dCV1TNtXuidMegKSNE6zNXobJslFSf4mye4k719g/zuTPJlke6/92rAxXelK6pRxrXSTLANuAN4E7AUeSLKpqua/svm2qrpy1HENXUmdMsbbgNcBu6vqmwC916yvB+aH7pJYXpDUKVWjtyFWAHv6vu/tbZvvbUl2JLk9yaphgxq6kjpltmrklmQqyda+NrXEw/05sLqqfga4C7h52A9YXpDUKUupLlTVNDC9yO4ZoH/lurK3rf/nn+r7+gngj4Yd05WupE6pJfwa4gFgTZIzk/wIsAHY1N8hyRl9Xy8Bdg0b1JWupE4Z13m0qjqc5ErgTmAZsLGqHk5yPbC1qjYBv5XkEuAwsB9457Bxc8wvJL7/2nZfqayJyPnXTXoKaqGqytGOceYrXzZy5jz+5NNHfbylcqUrqVN8tKMkNajldwEbupK6xXekSVKDWp65hq6kbnGlK0kNMnQlqUEtz1xDV1K3tP0h5oaupE5peeYaupK6xZsjJKlBvoJdkhpkeUGSGmR5QZIa1PLqgqErqVu8ZEySGtTyzDV0JXXLkZanrqErqVMsL0hSg1qeub4NWFK3VNXIbZgkFyX5myS7k7x/gf0nJbmtt39LktXDxjR0JXXK7BLaIEmWATcAFwPnAJcnOWdetyuA71bVWcBHgA8Nm5+hK6lTZmdr5DbEOmB3VX2zqv4fcCuwfl6f9cDNvc+3A29MMvANw8e+pvvaaxt/xXFbJZmqqulJz6MNqq6d9BRawz8X47WU17gnmQKm+jZN9/2/WAHs6du3Fzhv3hA/6FNVh5McAF4B/MNix3Sl26yp4V10HPLPxYRU1XRV/fu+dsz/8jN0JWlhM8Cqvu8re9sW7JPkROBk4KlBgxq6krSwB4A1Sc5M8iPABmDTvD6bgHf0Pl8K3F1DLovwOt1mWbfTQvxz0UK9Gu2VwJ3AMmBjVT2c5Hpga1VtAm4CPp1kN7CfuWAeKG2/e0OSusTygiQ1yNCVpAYZug0Zdjuhjj9JNiZ5IslDk56LmmPoNmDE2wl1/PkUcNGkJ6FmGbrNGOV2Qh1nquo+5s546zhi6DZjodsJV0xoLpImyNCVpAYZus0Y5XZCSccBQ7cZo9xOKOk4YOg2oKoOA/90O+Eu4HNV9fBkZ6VJS/JZ4K+Af5Nkb5IrJj0nHXveBixJDXKlK0kNMnQlqUGGriQ1yNCVpAYZupLUIENXkhpk6EpSg/4/tkkrPpjv3T0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(targs, preds)\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1936, 0.6673],\n",
       "        [0.8174, 0.7016],\n",
       "        [0.4848, 0.9997],\n",
       "        [0.0095, 0.9354],\n",
       "        [0.1782, 0.3274]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = torch.rand(5,2)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
