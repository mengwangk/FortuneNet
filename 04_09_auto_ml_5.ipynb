{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mengwangk/dl-projects/blob/master/04_09_auto_ml_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hyoPGdjpqa_"
   },
   "source": [
    "# Automated ML - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLxr2k_ue8yq"
   },
   "outputs": [],
   "source": [
    "COLAB = True\n",
    "\n",
    "DATASET_NAME = '4D.zip'\n",
    "\n",
    "FEATURE_DATASET_PREFIX = 'feature_matrix_d2_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwYshXtLt7b7"
   },
   "outputs": [],
   "source": [
    "#!pip install -U imblearn\n",
    "#!pip install -U xgboost\n",
    "# !pip install -U featuretools\n",
    "\n",
    "# https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28\n",
    "# https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "# https://machinelearningmastery.com/imbalanced-classification-model-to-detect-oil-spills/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "oy5ww2zRfFGG",
    "outputId": "ff0a27b0-d5b6-4111-919c-9c4907f99c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dl-projects'...\n",
      "remote: Enumerating objects: 166, done.\u001b[K\n",
      "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
      "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
      "remote: Total 1968 (delta 103), reused 17 (delta 7), pack-reused 1802\u001b[K\n",
      "Receiving objects: 100% (1968/1968), 78.43 MiB | 32.07 MiB/s, done.\n",
      "Resolving deltas: 100% (1214/1214), done.\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "  !rm -rf dl-projects\n",
    "  !git clone https://github.com/mengwangk/dl-projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G2xin10SfozR"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  !cp dl-projects/utils* .\n",
    "  !cp dl-projects/preprocess* .\n",
    "  !cp dl-projects/plot* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "fC2-l3JBpqbE",
    "outputId": "86c98025-6ec8-4ca8-a16e-12b81fe81e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TP7V_IzepqbK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import matplotlib\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import featuretools as ft\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, make_scorer, recall_score, roc_curve, mean_squared_error, accuracy_score, average_precision_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedShuffleSplit, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.under_sampling import (RandomUnderSampler, \n",
    "                                     ClusterCentroids,\n",
    "                                     TomekLinks,\n",
    "                                     NeighbourhoodCleaningRule,\n",
    "                                     AllKNN,\n",
    "                                     NearMiss,\n",
    "                                     OneSidedSelection,\n",
    "                                     EditedNearestNeighbours)\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC, ADASYN \n",
    "import pylab as pl\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "# from skopt import BayesSearchCV\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "# from scikitplot.plotters import plot_precision_recall_curve\n",
    "\n",
    "from utils import feature_selection, plot_feature_importances\n",
    "from preprocess import *\n",
    "from plot import plot_correlation_matrix, plot_labeled_scatter\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# The Answer to the Ultimate Question of Life, the Universe, and Everything.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "3bFT5CoxpqbP",
    "outputId": "3bf780be-5d5b-48ed-f387-dd046a1c8e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%aimport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3E16jPVPpqbV"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U421BuhtfYS7",
    "outputId": "5c3d72e7-840f-4d4b-bc2a-0e288be5ee2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  GDRIVE_DATASET_FOLDER = Path('gdrive/My Drive/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "9IgnETKkpqbX",
    "outputId": "783d5742-73c3-47cf-a3a3-bec2273b9c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4795M\n",
      "-rw------- 1 root root   17M Mar  1 05:47 feature_matrix_2020_feb.ft\n",
      "-rw------- 1 root root   17M Mar  1 05:39 feature_matrix_2020_jan.ft\n",
      "-rw------- 1 root root   17M Mar  1 05:56 feature_matrix_2020_mar.ft\n",
      "-rw------- 1 root root 2454M Jan 12 01:24 feature_matrix_d2_v2.ft\n",
      "-rw------- 1 root root 1585M Jan 12 23:39 feature_matrix_d2_v3.ft\n",
      "-rw------- 1 root root   17M Feb 21 13:07 feature_matrix_snapshot.ft\n",
      "-rw------- 1 root root    5M Jan 30 04:33 orig_X_test.ft\n",
      "-rw------- 1 root root  415M Jan 30 04:33 orig_X_train.ft\n",
      "-rw------- 1 root root    1M Jan 30 04:33 orig_y_test.ft\n",
      "-rw------- 1 root root    7M Jan 30 04:33 orig_y_train.ft\n",
      "-rw------- 1 root root    3M Mar  4 13:46 test_X_test.ft\n",
      "-rw------- 1 root root  255M Mar  4 13:46 test_X_train.ft\n",
      "-rw------- 1 root root    1M Mar  4 13:46 test_y_test.ft\n",
      "-rw------- 1 root root    8M Mar  4 13:46 test_y_train.ft\n",
      "total 25M\n",
      "-rw-r--r-- 1 root root  1M Mar  4 13:47 4D.zip\n",
      "-rw-r--r-- 1 root root 25M Mar  4 13:47 labels.csv\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "  DATASET_PATH = GDRIVE_DATASET_FOLDER\n",
    "  ORIGIN_DATASET_PATH = Path('dl-projects/datasets')\n",
    "else:\n",
    "  DATASET_PATH = Path(\"../datasets\")\n",
    "  ORIGIN_DATASET_PATH = Path('datasets')\n",
    "\n",
    "DATASET = DATASET_PATH/f\"{FEATURE_DATASET_PREFIX}.ft\"\n",
    "ORIGIN_DATASET = ORIGIN_DATASET_PATH/DATASET_NAME\n",
    "\n",
    "if COLAB:\n",
    "  !ls -l gdrive/\"My Drive\"/datasets/ --block-size=M\n",
    "  !ls -l dl-projects/datasets --block-size=M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urQTD6DQNutw"
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_feather(DATASET)\n",
    "origin_data = format_tabular(ORIGIN_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zov05QHZxxiS"
   },
   "source": [
    "## Add new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "foPB8T1vx2tp",
    "outputId": "131edf7e-f476-4dee-8315-1e875e035e49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959893, 217)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "43sc1Eaux25j"
   },
   "outputs": [],
   "source": [
    "jan_2020 = pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_jan.ft\")\n",
    "feb_2020= pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_feb.ft\")\n",
    "mar_2020= pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_mar.ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2vISxEbsyQG1",
    "outputId": "c0bc1a95-7da6-4db2-b21e-55ca12735ac2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989893, 217)"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = data.append(jan_2020[data.columns],ignore_index=True)\n",
    "new_data = new_data.append(feb_2020[data.columns],ignore_index=True)\n",
    "new_data = new_data.append(mar_2020[data.columns],ignore_index=True)\n",
    "new_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FVVMXCj-zyaW",
    "outputId": "94189562-7b55-4450-8fca-2576e6c47d18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989893, 217)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = new_data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vOYlp-8Br61r"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHiN1VVlG9Kh"
   },
   "source": [
    "### View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnQXyVqng5Cm"
   },
   "outputs": [],
   "source": [
    "# Feature matrix\n",
    "feature_matrix = data.drop(columns=['NumberId', 'month', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "apMYVNz9HK9e",
    "outputId": "bb828358-9a48-4fd8-b5e0-60c478eaee9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 989893 entries, 7020 to 986394\n",
      "Columns: 214 entries, time to LAST(Results.PrizeType)_Prize\n",
      "dtypes: datetime64[ns](1), float64(155), int64(56), uint8(2)\n",
      "memory usage: 1.6 GB\n"
     ]
    }
   ],
   "source": [
    "# Sort data\n",
    "feature_matrix.sort_values(by=['time', 'MAX(Results.LuckyNo)'], inplace=True)\n",
    "feature_matrix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "CZKTbWRFJNUq",
    "outputId": "85b6c1f7-fffc-46fa-893b-ef0d1ad97ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution\n",
      "0    957191\n",
      "1     32702\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Positive: 957191 which is  96.7 % of the dataset\n",
      "Negative: 32702 which is  3.3 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "print('Distribution')\n",
    "print(feature_matrix['Label'].value_counts())\n",
    "print()\n",
    "print('Positive: ' + str(feature_matrix['Label'].value_counts()[0]) + ' which is ', round(feature_matrix['Label'].value_counts()[0]/len(feature_matrix) * 100,2), '% of the dataset')\n",
    "print('Negative: ' + str(feature_matrix['Label'].value_counts()[1]) + ' which is ', round(feature_matrix['Label'].value_counts()[1]/len(feature_matrix) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "plplpAQ6JrKb",
    "outputId": "037e9ebe-aff7-453a-df92-5f79e5e2a129"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))               7657\n",
       "CUM_MEAN(TREND(Results.LuckyNo, DrawDate))                7657\n",
       "TREND(Results.TIME_SINCE_PREVIOUS(DrawDate), DrawDate)    7657\n",
       "TREND(Results.CUM_MEAN(TotalStrike), DrawDate)            7657\n",
       "TREND(Results.CUM_SUM(LuckyNo), DrawDate)                 7657\n",
       "                                                          ... \n",
       "CUM_SUM(MIN(Results.DrawNo))                                 0\n",
       "NUM_UNIQUE(Results.DAY(DrawDate))                            0\n",
       "NUM_UNIQUE(Results.MONTH(DrawDate))                          0\n",
       "SUM(Results.PERCENTILE(LuckyNo))                             0\n",
       "time                                                         0\n",
       "Length: 214, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zF_zCRksL1Ls"
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1aLGsXSOa9K"
   },
   "outputs": [],
   "source": [
    "# Fill all NaN with 0\n",
    "feature_matrix = feature_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "5A8LZ805MqjP",
    "outputId": "5bcab015-7beb-4557-b703-2e7be40b0f4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989893, 214)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "rPFOkiGjhuKj",
    "outputId": "da19a96f-d6d1-4f4d-8363-00ba646bf981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:  (989893, 211)\n",
      "0 missing columns with threshold: 90.\n",
      "41 zero variance columns.\n",
      "108 collinear columns removed with threshold: 0.95.\n",
      "Total columns removed:  149\n",
      "Shape after feature selection: (989893, 62).\n"
     ]
    }
   ],
   "source": [
    "feature_matrix_selection = feature_selection(feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label']))\n",
    "# feature_matrix_selection = feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "vT2K0WeJhugH",
    "outputId": "2d70c59f-128f-4394-9f74-b3f0c78f3ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((989893, 62),\n",
       " Index(['STD(Results.DrawNo)', 'MAX(Results.DrawNo)', 'MAX(Results.LuckyNo)',\n",
       "        'MIN(Results.DrawNo)', 'MEAN(Results.DrawNo)', 'SKEW(Results.DrawNo)',\n",
       "        'AVG_TIME_BETWEEN(Results.DrawDate)', 'COUNT(Results)',\n",
       "        'SUM(Results.DrawNo)', 'SUM(Results.LuckyNo)',\n",
       "        'TREND(Results.DrawNo, DrawDate)', 'MONTH(first_Results_time)',\n",
       "        'DAY(first_Results_time)', 'TIME_SINCE(first_Results_time)',\n",
       "        'TIME_SINCE_PREVIOUS(first_Results_time)',\n",
       "        'STD(Results.PERCENTILE(DrawNo))',\n",
       "        'STD(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'STD(Results.CUM_SUM(DrawNo))', 'STD(Results.CUM_MEAN(LuckyNo))',\n",
       "        'MAX(Results.PERCENTILE(DrawNo))',\n",
       "        'MAX(Results.PERCENTILE(TotalStrike))',\n",
       "        'MAX(Results.CUM_MEAN(LuckyNo))',\n",
       "        'MIN(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'MIN(Results.CUM_SUM(DrawNo))', 'MIN(Results.CUM_MEAN(LuckyNo))',\n",
       "        'MODE(Results.MONTH(DrawDate))', 'MODE(Results.DAY(DrawDate))',\n",
       "        'MEAN(Results.TIME_SINCE(DrawDate))',\n",
       "        'MEAN(Results.PERCENTILE(DrawNo))',\n",
       "        'MEAN(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'MEAN(Results.CUM_MEAN(LuckyNo))',\n",
       "        'SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'SKEW(Results.CUM_SUM(DrawNo))', 'SKEW(Results.CUM_MEAN(LuckyNo))',\n",
       "        'LAST(Results.DAY(DrawDate))',\n",
       "        'LAST(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'LAST(Results.MONTH(DrawDate))', 'LAST(Results.CUM_MEAN(LuckyNo))',\n",
       "        'SUM(Results.TIME_SINCE(DrawDate))',\n",
       "        'SUM(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
       "        'TREND(Results.CUM_MEAN(LuckyNo), DrawDate)',\n",
       "        'TREND(Results.PERCENTILE(LuckyNo), DrawDate)',\n",
       "        'TREND(Results.PERCENTILE(DrawNo), DrawDate)',\n",
       "        'TREND(Results.PERCENTILE(TotalStrike), DrawDate)',\n",
       "        'TREND(Results.TIME_SINCE_PREVIOUS(DrawDate), DrawDate)',\n",
       "        'TREND(Results.CUM_SUM(DrawNo), DrawDate)',\n",
       "        'NUM_UNIQUE(Results.MONTH(DrawDate))',\n",
       "        'NUM_UNIQUE(Results.DAY(DrawDate))', 'CUM_SUM(MIN(Results.DrawNo))',\n",
       "        'CUM_SUM(SKEW(Results.DrawNo))',\n",
       "        'CUM_MEAN(AVG_TIME_BETWEEN(Results.DrawDate))',\n",
       "        'CUM_MEAN(SUM(Results.LuckyNo))', 'CUM_MEAN(SKEW(Results.DrawNo))',\n",
       "        'PERCENTILE(STD(Results.LuckyNo))', 'PERCENTILE(LAST(Results.DrawNo))',\n",
       "        'PERCENTILE(MAX(Results.TotalStrike))',\n",
       "        'PERCENTILE(AVG_TIME_BETWEEN(Results.DrawDate))',\n",
       "        'PERCENTILE(COUNT(Results))', 'PERCENTILE(STD(Results.DrawNo))',\n",
       "        'PERCENTILE(SKEW(Results.DrawNo))', 'PERCENTILE(SUM(Results.DrawNo))',\n",
       "        'PERCENTILE(TREND(Results.DrawNo, DrawDate))'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_selection.shape, feature_matrix_selection.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZUhYrWFiRod"
   },
   "outputs": [],
   "source": [
    "feature_matrix_selection['time'] = feature_matrix['time']\n",
    "feature_matrix_selection['TotalStrike'] = feature_matrix['TotalStrike']\n",
    "feature_matrix_selection['Label'] = feature_matrix['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hugygOqSiR6K"
   },
   "source": [
    "### Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "loagcqTEKOkO"
   },
   "outputs": [],
   "source": [
    "#feature_matrix.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7Ha8Zlkhuoe"
   },
   "outputs": [],
   "source": [
    "# Check with feature selection\n",
    "#corrs = feature_matrix_selection.corr().sort_values('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWRODfAdPk6j"
   },
   "outputs": [],
   "source": [
    "#corrs['Label'].head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "waeD1ED_kqDB"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9yrJyIVLh5So"
   },
   "outputs": [],
   "source": [
    "def recall_optim(y_true, y_pred):\n",
    "    \"\"\"Make a scoring function that improves specificity while identifying all strikes\n",
    "    \"\"\"\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Recall will be worth a greater value than specificity\n",
    "    rec = recall_score(y_true, y_pred) * 0.8 \n",
    "    spe = conf_matrix[0,0]/conf_matrix[0,:].sum() * 0.2 \n",
    "    \n",
    "    # Imperfect recalls will lose a penalty\n",
    "    # This means the best results will have perfect recalls and compete for specificity\n",
    "    if rec < 0.8:\n",
    "        rec -= 0.2\n",
    "    return rec + spe \n",
    "\n",
    "\n",
    "# Make a scoring callable from recall_score\n",
    "recall = make_scorer(recall_score)\n",
    "\n",
    "# Create a scoring callable based on the scoring function\n",
    "optimize = make_scorer(recall_optim)\n",
    "\n",
    "# Geometric mean scorer\n",
    "geo_mean_scorer = make_scorer(geometric_mean_score)\n",
    "\n",
    "# DataFrame to store classifier performance\n",
    "performance = pd.DataFrame(columns=['Train_Recall','Test_Recall','Test_Specificity', 'Optimize'])\n",
    "\n",
    "def to_labels(pos_probs, threshold):\n",
    "    \"\"\"Apply threshold to positive probabilities to create labels.\n",
    "    \"\"\"\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    " \n",
    "\n",
    "def score_optimization(dt, feature_matrix, clf, params, X_train, y_train, X_test, y_test, skip_grid_search_cv=False, optimized_scorer=False):\n",
    "    \"\"\"Find the optimized classifier.\n",
    "    \"\"\"\n",
    "    if not skip_grid_search_cv:\n",
    "      print(\"\\nFinding the optimized classifier...\")\n",
    "\n",
    "      # Load GridSearchCV\n",
    "      # search = GridSearchCV(\n",
    "      search = RandomizedSearchCV(\n",
    "            estimator=clf,\n",
    "            #param_grid=params,\n",
    "            param_distributions=params,\n",
    "            n_jobs=4,\n",
    "            scoring=optimize  # Use custom scorer\n",
    "      )\n",
    "\n",
    "      # Train search object\n",
    "      search.fit(X_train, y_train)\n",
    "\n",
    "      # Heading\n",
    "      print('\\n','-'*40,'\\n',clf.__class__.__name__,'\\n','-'*40)\n",
    "\n",
    "      # Extract best estimator\n",
    "      best = search.best_estimator_\n",
    "      print('Best parameters: \\n\\n',search.best_params_,'\\n')\n",
    "    \n",
    "    else:\n",
    "      print(\"\\nUse the passed in classifier...\\n\")\n",
    "      best = clf\n",
    "\n",
    "    # Cross-validate on the train data\n",
    "    if not skip_grid_search_cv: \n",
    "      print(\"TRAIN GROUP\")\n",
    "      #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "      cv = 3\n",
    "      if not optimized_scorer:\n",
    "        print('\\nUse default scorer')\n",
    "        train_cv = cross_val_score(\n",
    "                                  n_jobs=4,\n",
    "                                  X=X_train, \n",
    "                                  y=y_train, \n",
    "                                  estimator=best, \n",
    "                                  scoring=recall,\n",
    "                                  cv=cv)\n",
    "      else:\n",
    "        print('\\nUse optimized scorer')\n",
    "        train_cv = cross_val_score(\n",
    "                                  n_jobs=4,\n",
    "                                  X=X_train, \n",
    "                                  y=y_train, \n",
    "                                  estimator=best, \n",
    "                                  #scoring=optimize,\n",
    "                                  scoring='roc_auc',\n",
    "                                  #scoring=geo_mean_scorer,\n",
    "                                  cv=cv)\n",
    "\n",
    "      print(\"\\nCross-validation recall scores:\",train_cv)\n",
    "      print(\"Mean recall score:\",train_cv.mean())\n",
    "      print('Mean G-Mean: %.3f (%.3f)' % (np.mean(train_cv), np.std(train_cv)))\n",
    "    else:\n",
    "      train_cv = np.zeros(3)\n",
    "\n",
    "    # Now predict on the test group\n",
    "    print(\"\\nTEST GROUP\")\n",
    "    y_pred = best.fit(X_train, y_train).predict(X_test)\n",
    "    # y_pred = best.fit(X_train, y_train,\n",
    "    #                   eval_set=[(X_test, y_test)],\n",
    "    #                   eval_metric='auc',\n",
    "    #                   early_stopping_rounds=10,\n",
    "    #                   verbose=True\n",
    "    #                   ).predict(X_test)\n",
    "\n",
    "    # keep probabilities for the positive outcome only\n",
    "    probas = best.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # define thresholds\n",
    "    thresholds = np.arange(0, 1, 0.001)\n",
    "\n",
    "    # evaluate each threshold\n",
    "    scores = [f1_score(y_test, to_labels(probas, t)) for t in thresholds]\n",
    "\n",
    "    # get best threshold\n",
    "    ix = np.argmax(scores)\n",
    "    print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))\n",
    "\n",
    "    # print recall\n",
    "    print(\"\\nRecall:\",recall_score(y_test,y_pred))\n",
    "\n",
    "    # Get imbalanced classification report\n",
    "    print(classification_report_imbalanced(y_test, y_pred))\n",
    "\n",
    "    # Print confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "    plt.show()\n",
    "\n",
    "    # Store results\n",
    "    performance.loc[clf.__class__.__name__+'_optimize',:] = [\n",
    "        train_cv.mean(),\n",
    "        recall_score(y_test,y_pred),\n",
    "        conf_matrix[0,0]/conf_matrix[0,:].sum(),\n",
    "        recall_optim(y_test,y_pred)\n",
    "    ]\n",
    "    # Look at the parameters for the top best scores\n",
    "    if not skip_grid_search_cv:\n",
    "      display(pd.DataFrame(search.cv_results_).iloc[:,4:].sort_values(by='rank_test_score').head())\n",
    "    display(performance)\n",
    "\n",
    "    # Additionl info\n",
    "    print('\\n\\nAdditional Info')\n",
    "    print('='*40)\n",
    "    positive = np.where((y_pred==1))\n",
    "    print(f'Total predicted to be positive: {len(positive[0])} \\n')\n",
    "\n",
    "    pred = np.where((y_pred==1))\n",
    "    all_preds = pred[0]\n",
    "\n",
    "    # Total predicted matches\n",
    "    print('First 23 matches')\n",
    "    print(23, all_preds[0:23])\n",
    "    print(f'\\n{probas[all_preds[0:23]]}\\n') \n",
    "\n",
    "    print(\"\\nTop 23 Probable Matches\")\n",
    "    #print('probas', probas)\n",
    "    topN = np.argpartition(probas, -23)[-23:]\n",
    "    print(f'\\n{topN}\\n')          # Top N most high probability numbers\n",
    "    print(f'\\n{probas[topN]}\\n')  # Top N probability\n",
    "\n",
    "    # Check for 2 to 3 digits range \n",
    "    print('\\n2 To 3 Digits\\n')\n",
    "    idx_range = np.where((all_preds < 1000) & (all_preds >= 10))\n",
    "    #print(idx_range)\n",
    "    range_numbers = all_preds[idx_range]\n",
    "    print(len(range_numbers), range_numbers)\n",
    "    print(f'\\n{probas[range_numbers]}\\n') \n",
    "\n",
    "\n",
    "    # 2 to 3 Digits > Average Probas\n",
    "    print('\\n2 To 3 Digits Average Proba\\n')\n",
    "    avg_proba = np.average(probas[range_numbers])\n",
    "    print(f'Average proba {avg_proba}\\n')\n",
    "    idx_avg_proba = np.where(probas > avg_proba) \n",
    "    print(len(idx_avg_proba[0]), idx_avg_proba[0])\n",
    "\n",
    "    # 2 to 3 Digits > All Average Probas\n",
    "    print('\\n\\nAll Average Proba\\n')\n",
    "    all_avg_proba = np.average(probas[all_preds])\n",
    "    print(f'All average probas {all_avg_proba}\\n')\n",
    "    idx_all_avg_proba = np.where(probas > all_avg_proba) \n",
    "    print(len(idx_all_avg_proba[0]), idx_all_avg_proba[0])\n",
    "\n",
    "\n",
    "    # All predicted matches\n",
    "    print('\\n\\nAll Predictions\\n')\n",
    "    print(len(all_preds), all_preds)\n",
    "    print()\n",
    "    print(len(probas[all_preds]), probas[all_preds])\n",
    "    \n",
    "    #print('Debug')\n",
    "    #print(pred)\n",
    "    \n",
    "    if len(positive[0]) > 0:\n",
    "    \n",
    "      # Matching draws\n",
    "      print('\\nMatched draws')\n",
    "      md = np.where((y_pred==1) & (y_test==1))\n",
    "      print(f\"Count: {len(md[0])}, Index: {md}\")\n",
    "      month_data = feature_matrix.loc[feature_matrix['time'] == dt]\n",
    "      numbers = month_data.iloc[md[0]][['MAX(Results.LuckyNo)']]\n",
    "\n",
    "      print('\\n\\nTop 23 Possibility')\n",
    "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
    "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
    "                          (origin_data['LuckyNo'].isin(topN))].head(23))  \n",
    "      \n",
    "      print('\\n\\nFirst 23 Numbers')\n",
    "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
    "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
    "                          (origin_data['LuckyNo'].isin(pred[0][0:23]))].head(23))    \n",
    "             \n",
    "\n",
    "      print('\\n\\n2 To 3 Digits Numbers')\n",
    "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
    "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
    "                          (origin_data['LuckyNo'].isin(range_numbers))].head(23))    \n",
    "     \n",
    "\n",
    "      print('\\n\\nAll matched')\n",
    "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
    "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
    "                          (origin_data['LuckyNo'].isin(numbers['MAX(Results.LuckyNo)']))].head(100))    \n",
    "                                                  \n",
    "    else:\n",
    "      print('No luck this month')  \n",
    "\n",
    "    if len(range_numbers) >= 50:\n",
    "      return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrL8gYwjc-hd"
   },
   "outputs": [],
   "source": [
    "def remove_outliers(balanced, threshold=0.001, remove=True):\n",
    "    \"\"\"Removing Outliers from high-correlation features.\n",
    "    \"\"\"\n",
    "\n",
    "    if not remove:\n",
    "      return balanced\n",
    "\n",
    "    bal_corr = balanced.corr()\n",
    "    no_outliers=pd.DataFrame(balanced.copy())\n",
    "\n",
    "    cols = bal_corr.Label.index[:-1]\n",
    "\n",
    "    # For each feature correlated with Class...\n",
    "    for col in cols:\n",
    "        # If absolute correlation value is more than X percent...\n",
    "        correlation = bal_corr.loc['Label',col]\n",
    "\n",
    "        if np.absolute(correlation) > threshold:\n",
    "          # Separate the classes of the high-correlation column\n",
    "          nonstrikes = no_outliers.loc[no_outliers.Label==0,col]\n",
    "          strikes = no_outliers.loc[no_outliers.Label==1,col]\n",
    "\n",
    "          # Identify the 25th and 75th quartiles\n",
    "          all_values = no_outliers.loc[:,col]\n",
    "          q25, q75 = np.percentile(all_values, 25), np.percentile(all_values, 75)\n",
    "          # Get the inter quartile range\n",
    "          iqr = q75 - q25\n",
    "          # Smaller cutoffs will remove more outliers\n",
    "          cutoff = iqr * 7\n",
    "          # Set the bounds of the desired portion to keep\n",
    "          lower, upper = q25 - cutoff, q75 + cutoff\n",
    "          \n",
    "          # If positively correlated...\n",
    "          # Drop nonstrikes above upper bound, and strikes below lower bound\n",
    "          if correlation > 0: \n",
    "              no_outliers.drop(index=nonstrikes[nonstrikes>upper].index,inplace=True)\n",
    "              no_outliers.drop(index=strikes[strikes<lower].index,inplace=True)\n",
    "          \n",
    "          # If negatively correlated...\n",
    "          # Drop non strikes below lower bound, and strikes above upper bound\n",
    "          elif correlation < 0: \n",
    "              no_outliers.drop(index=nonstrikes[nonstrikes<lower].index,inplace=True)\n",
    "              no_outliers.drop(index=strikes[strikes>upper].index,inplace=True)\n",
    "        \n",
    "    print('\\nData shape before removing outliers:', balanced.shape)\n",
    "    print('\\nCounts of strikes VS non-strikes in previous data:')\n",
    "    print(balanced.Label.value_counts())\n",
    "    print('-'*40)\n",
    "    print('-'*40)\n",
    "    print('\\nData shape after removing outliers:', no_outliers.shape)\n",
    "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
    "    print(no_outliers.Label.value_counts())\n",
    "\n",
    "    # no_outliers.iloc[:,:-1].boxplot(rot=90,figsize=(16,4))\n",
    "    # plt.title('Distributions with Less Outliers', fontsize=17)\n",
    "    # plt.show()\n",
    "    \n",
    "    no_outliers.reset_index(drop=True, inplace=True)\n",
    "    return no_outliers\n",
    "\n",
    "\n",
    "def filter_features(no_outliers, threshold=0.001):\n",
    "    \"\"\"Feature selection.\n",
    "    \"\"\"\n",
    "    feat_sel = pd.DataFrame(no_outliers.copy())\n",
    "\n",
    "    # Make a dataframe with the label-correlations before removing outliers\n",
    "    # corr_change = pd.DataFrame()\n",
    "    # corr_change['correlation']= bal_corr.Label\n",
    "    # corr_change['origin']= 'w/outliers'\n",
    "\n",
    "    # Make a dataframe with label-correlations after removing outliers \n",
    "    # corr_other = pd.DataFrame()\n",
    "    # corr_other['correlation']= feat_sel.corr().Label\n",
    "    # corr_other['origin']= 'no_outliers'\n",
    "\n",
    "    # Join them\n",
    "    # corr_change = corr_change.append(corr_other)\n",
    "\n",
    "    # plt.figure(figsize=(14,6))\n",
    "    # plt.xticks(rotation=90)\n",
    "\n",
    "    # Plot them\n",
    "    # sns.set_style('darkgrid')\n",
    "    # plt.title('Label correlation per feature. With vs without outliers', fontsize=17)\n",
    "    # sns.barplot(data=corr_change,x=corr_change.index,y='correlation',hue='origin')\n",
    "    # plt.show()\n",
    "\n",
    "    # Feature Selection based on correlation with label\n",
    "\n",
    "    print('\\nData shape before feature selection:', feat_sel.shape)\n",
    "    print('\\nCounts of strikes vs non-strikes before feature selection:')\n",
    "    print(feat_sel.Label.value_counts())\n",
    "    print('-'*40)\n",
    "\n",
    "    # Correlation matrix after removing outliers\n",
    "    new_corr = feat_sel.corr()\n",
    "\n",
    "    for col in new_corr.Label.index[:-1]:\n",
    "        # Pick desired cutoff for dropping features. In absolute-value terms.\n",
    "        if np.absolute(new_corr.loc['Label',col]) < threshold:\n",
    "            # Drop the feature if correlation is below cutoff\n",
    "            feat_sel.drop(columns=col,inplace=True)\n",
    "\n",
    "    print('-'*40)\n",
    "    print('\\nData shape after feature selection:', feat_sel.shape)\n",
    "    print('\\nCounts of strikes vs non-strikes in new data:')\n",
    "    print(feat_sel.Label.value_counts())\n",
    "\n",
    "    return feat_sel\n",
    "\n",
    "    # feat_sel.iloc[:,:-1].boxplot(rot=90,figsize=(16,4))\n",
    "    # plt.title('Distribution of Features Selected', fontsize=17)\n",
    "    # plt.show()\n",
    "\n",
    "def under_sampler(data, sample_size=20000, sampling=False):\n",
    "    # Undersample model for efficiency and balance classes.\n",
    "\n",
    "    X_train = data.drop('Label',1)\n",
    "    y_train = data.Label\n",
    "\n",
    "    if not sampling:\n",
    "      return X_train, y_train\n",
    "\n",
    "    # After feature-selection, X_test needs to include only the same features as X_train\n",
    "    # cols = X_train.columns\n",
    "    # X_test = X_test[cols]\n",
    "\n",
    "    # Undersample and balance classes\n",
    "    X_train, y_train = RandomUnderSampler(sampling_strategy={1:sample_size,0:sample_size}).fit_resample(X_train,y_train)\n",
    "\n",
    "    print('\\nX_train shape after reduction:', X_train.shape)\n",
    "    print('\\nCounts of strikes VS non-strikes in y_train:')\n",
    "    print(np.unique(y_train, return_counts=True))\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pl5ZoepSNPf4"
   },
   "outputs": [],
   "source": [
    "def gen_train_test_set(dt, feature_matrix, file_prefix='data'): \n",
    "    \n",
    "    # Subset labels\n",
    "    test_labels = feature_matrix.loc[feature_matrix['time'] == dt, 'Label']\n",
    "    train_labels = feature_matrix.loc[feature_matrix['time'] < dt, 'Label']\n",
    "\n",
    "    # Features\n",
    "    X_train = feature_matrix[feature_matrix['time'] < dt].drop(columns = ['NumberId', 'time', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
    "    X_test = feature_matrix[feature_matrix['time'] == dt].drop(columns = ['NumberId', 'time', 'Label', 'TotalStrike', 'month', 'year', 'index'], errors='ignore')\n",
    "    feature_names = list(X_train.columns)\n",
    "    \n",
    "    # Labels\n",
    "    y_train = np.array(train_labels).reshape((-1, ))\n",
    "    y_test = np.array(test_labels).reshape((-1, ))\n",
    "    \n",
    "    print('Training on {} observations.'.format(len(X_train)))\n",
    "    print('Testing on {} observations.\\n'.format(len(X_test)))\n",
    "\n",
    "    # Join the train data\n",
    "    train = X_train.join(train_labels)\n",
    "\n",
    "    print('Data shape before balancing:', train.shape)\n",
    "    print('\\nCounts of strikes vs non-strikes in previous data:')\n",
    "    print(train.Label.value_counts())\n",
    "    print('-'*40)\n",
    "\n",
    "    # sklearn pipeline\n",
    "    pipeline = make_pipeline(\n",
    "        SimpleImputer(strategy = 'constant', fill_value=0),\n",
    "        StandardScaler())\n",
    "    \n",
    "    X_train = pipeline.fit_transform(X_train)\n",
    "    X_test = pipeline.transform(X_test)\n",
    "\n",
    "    # imblearn pipeline\n",
    "    imb_pipeline = make_pipeline_imb(\n",
    "          # NearMiss(version=3, n_neighbors_ver3=3, n_jobs=4)\n",
    "          # SMOTE(sampling_strategy='minority',random_state=42, n_jobs=4)\n",
    "          # ADASYN(sampling_strategy='minority',random_state=42, n_jobs=4)\n",
    "          # OneSidedSelection(n_neighbors=1, n_seeds_S=200, random_state=42, n_jobs=4)\n",
    "          SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='majority'))\n",
    "    )\n",
    "     \n",
    "    # Balance the data\n",
    "    to_balanced = False\n",
    "    if to_balanced:\n",
    "      print('\\nBalancing data')\n",
    "      X_bal, y_bal = imb_pipeline.fit_resample(X_train, y_train)\n",
    "      X_bal = pd.DataFrame(X_bal,columns=feature_names)\n",
    "      y_bal = pd.DataFrame(y_bal,columns=['Label'])\n",
    "    else:\n",
    "      print('\\nNO balancing')\n",
    "      X_bal = pd.DataFrame(X_train,columns=feature_names)\n",
    "      y_bal = pd.DataFrame(y_train,columns=['Label'])\n",
    "\n",
    "    balanced = X_bal.join(y_bal)\n",
    "\n",
    "    # print('-'*40)\n",
    "    print('Data shape after balancing:',balanced.shape)\n",
    "    print('\\nCounts of strikes VS non-strikes in new data:')\n",
    "    print(balanced.Label.value_counts())\n",
    "\n",
    "    # Remove high correlation outliers\n",
    "    no_outliers = remove_outliers(balanced, remove=False)\n",
    "   \n",
    "    # Remove features with low correlation\n",
    "    remove_features = True\n",
    "    if remove_features:\n",
    "      print('\\nFiltering features')\n",
    "      features_selected = filter_features(no_outliers)\n",
    "    else:\n",
    "      print('\\nNO filtering')\n",
    "      features_selected = no_outliers \n",
    "\n",
    "    columns_selected = features_selected.drop('Label',1).columns\n",
    "\n",
    "    # Under sampling\n",
    "    X_train, y_train = under_sampler(features_selected, sampling=False) \n",
    "    X_train = pd.DataFrame(X_train,columns=columns_selected)\n",
    "    y_train = pd.DataFrame(y_train,columns=['Label'])\n",
    "\n",
    "    # For X_test, now only use the selected features\n",
    "    X_test = pd.DataFrame(X_test,columns=feature_names)\n",
    "    X_test = X_test[columns_selected]\n",
    "    y_test = pd.DataFrame(y_test,columns=['Label'])\n",
    "\n",
    "    #print(X_train.describe())\n",
    "    #return\n",
    "\n",
    "    # Save data\n",
    "    # print(X_train.head(10))\n",
    "    # print(y_train.head(10)) \n",
    "\n",
    "    # print(X_test.head(10))\n",
    "    # print(y_test.head(10)) \n",
    "    X_train.to_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
    "    y_train.to_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
    "   \n",
    "    X_test.to_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
    "    y_test.to_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
    "\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcKlL67TP9UM"
   },
   "outputs": [],
   "source": [
    "def model(dt, feature_matrix, file_prefix='data', csv=False, class_weight=1.0, estimators=300, depth=3):\n",
    "    \"\"\"Predict for a particular month.\n",
    "\n",
    "    - https://www.kaggle.com/miguelniblock/optimizing-imbalanced-classification-100-recall\n",
    "    - https://www.kaggle.com/saxinou/imbalanced-data-xgboost-tunning\n",
    "    - https://www.kaggle.com/andreanuzzo/balance-the-imbalanced-rf-and-xgboost-with-smote\n",
    "    - https://github.com/mengwangk/FraudDetection/blob/master/05_Sampling_techniques_for_extremely_imbalanced_data.ipynb\n",
    "    - https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
    "    - https://github.com/coding-maniacs/over-under-sampling/blob/master/src/main.py\n",
    "    - https://github.com/scikit-learn-contrib/imbalanced-learn/issues/552#issuecomment-466348310\n",
    "    - https://stackoverflow.com/questions/52499788/smotetomek-how-to-set-ratio-as-dictionary-for-fixed-balance\n",
    "    - https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.OneSidedSelection.html#imblearn.under_sampling.OneSidedSelection\n",
    "    - https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\n",
    "    - https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n",
    "    - https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "    - https://stats.stackexchange.com/questions/243207/what-is-the-proper-usage-of-scale-pos-weight-in-xgboost-for-imbalanced-datasets\n",
    "    - https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py\n",
    "    - https://machinelearningmastery.com/cost-sensitive-logistic-regression/\n",
    "    \n",
    "    - https://datascience.stackexchange.com/questions/28285/what-is-the-best-way-to-deal-with-imbalanced-data-for-xgboost/28292\n",
    "    - https://machinelearningmastery.com/xgboost-for-imbalanced-classification/\n",
    "    - https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Read data\n",
    "    if not csv:\n",
    "      X_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
    "      y_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
    "    \n",
    "      X_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
    "      y_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
    "    else:\n",
    "      X_train = pd.read_csv(DATASET_PATH/f\"{file_prefix}_X_train.csv\", header=0, sep=',', quotechar='\"')\n",
    "      y_train = pd.read_csv(DATASET_PATH/f\"{file_prefix}_y_train.csv\", header=0, sep=',', quotechar='\"')\n",
    "    \n",
    "      X_test = pd.read_csv(DATASET_PATH/f\"{file_prefix}_X_test.csv\", header=0, sep=',', quotechar='\"')\n",
    "      y_test = pd.read_csv(DATASET_PATH/f\"{file_prefix}_y_test.csv\", header=0, sep=',', quotechar='\"')\n",
    "\n",
    "\n",
    "    print(f'\\n-----------{dt}-----------------\\n')\n",
    "\n",
    "    # Reshape\n",
    "    y_train = np.array(y_train).reshape((-1, ))\n",
    "    y_test = np.array(y_test).reshape((-1, ))\n",
    "    \n",
    "    print('Data shape')\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "    # print(X_train.describe())\n",
    "    # return\n",
    "\n",
    "    # Calculate hit ratio for xgboost classifier\n",
    "    print(\"\\nCalculating scale pos weight\")\n",
    "    counter = Counter(y_train)\n",
    "    print(Counter(y_train))\n",
    "    #scale_pos_weight = float(counter[0] / counter[1])\n",
    "    scale_pos_weight = (float(counter[0] / counter[1])) * class_weight\n",
    "    print(f\"\\nscale_pos_weight - {scale_pos_weight}\\n\")\n",
    "    \n",
    "     # Modeling\n",
    "#     clf = xgb.XGBClassifier(\n",
    "#               n_jobs=4, \n",
    "#               random_state=42,\n",
    "#               #learning_rate=0.1,\n",
    "#               #n_estimators=500,\n",
    "#               #max_depth=6, \n",
    "#               #min_child_weight=3, \n",
    "#               #gamma=0,\n",
    "#               #subsample=0.8,\n",
    "#               #colsample_bytree=0.8,\n",
    "#               objective='binary:logistic', \n",
    "#               scale_pos_weight=scale_pos_weight,\n",
    "#               ##eval_metric=\"auc\",\n",
    "#               ##max_delta_step=1,\n",
    "#               seed=27)\n",
    "#     clf = xgb.XGBClassifier(n_jobs=4, \n",
    "#                             random_state=42,\n",
    "#                             objective='binary:logistic', \n",
    "#                             #scale_pos_weight=28)\n",
    "#                             scale_pos_weight=scale_pos_weight)\n",
    "    \n",
    "    clf = xgb.XGBClassifier(\n",
    "                    n_jobs=4, \n",
    "                    random_state=42,\n",
    "                    objective='binary:logistic',\n",
    "                    subsample=0.55, \n",
    "                    #n_estimators=300,\n",
    "                    n_estimators=estimators,\n",
    "                    #n_estimators=550,\n",
    "                    min_child_weight=1,\n",
    "                    #max_depth=3, \n",
    "                    max_depth=depth, \n",
    "                    learning_rate=0.007,\n",
    "                    gamma=0.1, \n",
    "                    colsample_bytree=0.95,\n",
    "                    tree_method='hist',\n",
    "                    booster='dart',\n",
    "                    scale_pos_weight=scale_pos_weight\n",
    "                    )\n",
    "\n",
    "    clf_params = clf.get_params()\n",
    "    print(clf_params)\n",
    "\n",
    "    # Set parameters\n",
    "    #clf_params['max_depth'] = 10\n",
    "    #clf.set_params(clf_params)\n",
    "\n",
    "    # Parameters to compare\n",
    "    weights = [i for i in range(1,36,1)]\n",
    "    weights.append(scale_pos_weight)\n",
    "    learn_params = {\n",
    "        'n_estimators': [100, 300, 500, 800, 1000], \n",
    "        'max_depth': range(3,10,2),\n",
    "        'min_child_weight': range(1,6,2),\n",
    "        #'gamma':[i/10.0 for i in range(0,5)],\n",
    "        'subsample':[i/100.0 for i in range(55,70,5)],\n",
    "        'colsample_bytree':[i/100.0 for i in range(85,100,5)],\n",
    "        #'learning_rate':[i/1000.0 for i in range(5,20,2)],\n",
    "        'scale_pos_weight': weights\n",
    "    }\n",
    "    print(f'Parameter distribution: {learn_params}')\n",
    "    \n",
    "    # Test and validate\n",
    "    ret_val = score_optimization(dt,\n",
    "                       feature_matrix,\n",
    "                       clf, \n",
    "                       learn_params,  \n",
    "                       X_train, \n",
    "                       y_train, \n",
    "                       X_test, \n",
    "                       y_test, \n",
    "                       skip_grid_search_cv=True,\n",
    "                       optimized_scorer=True)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return ret_val\n",
    "    \n",
    "    # clf.fit(X_train, y_train)\n",
    "    # y_pred = clf.predict(X_test)\n",
    "\n",
    "    # # ROC score\n",
    "    # auc = roc_auc_score(y_test, y_pred)\n",
    "    # print(\"ROC score: \", auc)\n",
    "\n",
    "    # # Print confusion matrix\n",
    "    # conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # sns.heatmap(conf_matrix, annot=True,fmt='d', cmap=plt.cm.copper)\n",
    "    # plt.show()\n",
    "\n",
    "    # Parameters to compare\n",
    "    # params = {\n",
    "    #     'criterion':['entropy','gini'],\n",
    "    #     'class_weight':[{1:1,0:0.3},{1:1,0:0.4},{1:1,0:0.5},{1:1,0:0.6},{1:1,0:7}]\n",
    "    # }\n",
    "\n",
    "    # Implement the classifier\n",
    "    # clf = RandomForestClassifier(\n",
    "    #     n_estimators=100,\n",
    "    #     max_features=None,\n",
    "    #     n_jobs=4,\n",
    "    # )\n",
    "\n",
    "    # # Test and validate\n",
    "    # score_optimization(clf, params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9UobqUWMI9b",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Predict for a particular month\n",
    "\n",
    "# %time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection)\n",
    "\n",
    "#%time gen_train_test_set(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='test')\n",
    "#%time model(pd.datetime(2019,6,1), feature_matrix_selection, file_prefix='orig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ns3Puh7Gnxl5",
    "outputId": "b0500623-4454-46e1-ab9b-a79425309815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 979893 observations.\n",
      "Testing on 10000 observations.\n",
      "\n",
      "Data shape before balancing: (979893, 63)\n",
      "\n",
      "Counts of strikes vs non-strikes in previous data:\n",
      "0    947191\n",
      "1     32702\n",
      "Name: Label, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "NO balancing\n",
      "Data shape after balancing: (979893, 63)\n",
      "\n",
      "Counts of strikes VS non-strikes in new data:\n",
      "0    947191\n",
      "1     32702\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "Filtering features\n",
      "\n",
      "Data shape before feature selection: (979893, 63)\n",
      "\n",
      "Counts of strikes vs non-strikes before feature selection:\n",
      "0    947191\n",
      "1     32702\n",
      "Name: Label, dtype: int64\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "Data shape after feature selection: (979893, 35)\n",
      "\n",
      "Counts of strikes vs non-strikes in new data:\n",
      "0    947191\n",
      "1     32702\n",
      "Name: Label, dtype: int64\n",
      "CPU times: user 13.8 s, sys: 197 ms, total: 14 s\n",
      "Wall time: 14.4 s\n",
      "\n",
      "-----------2020-03-01 00:00:00-----------------\n",
      "\n",
      "Data shape\n",
      "(979893, 34) (979893,) (10000, 34) (10000,)\n",
      "\n",
      "Calculating scale pos weight\n",
      "Counter({0: 947191, 1: 32702})\n",
      "\n",
      "scale_pos_weight - 28.964314109228795\n",
      "\n",
      "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 300, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.964314109228795, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
      "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.964314109228795]}\n",
      "\n",
      "Use the passed in classifier...\n",
      "\n",
      "\n",
      "TEST GROUP\n",
      "Threshold=0.000, F-Score=0.00000\n",
      "\n",
      "Recall: 0.0\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
      "          1       0.00      0.00      0.95      0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.95      0.00      0.97      0.00      0.00     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCBIAgCMECQDAkf8DggskRHfu+VcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_Specificity</th>\n",
       "      <th>Optimize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBClassifier_optimize</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9469</td>\n",
       "      <td>-0.01062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Train_Recall Test_Recall Test_Specificity Optimize\n",
       "XGBClassifier_optimize            0           0           0.9469 -0.01062"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Additional Info\n",
      "========================================\n",
      "Total predicted to be positive: 531 \n",
      "\n",
      "First 23 matches\n",
      "23 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
      " 314 315 325 344 363]\n",
      "\n",
      "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
      " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
      " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
      " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055 ]\n",
      "\n",
      "\n",
      "Top 23 Probable Matches\n",
      "\n",
      "[9254 2255 9258 1933 2479  905 4562 4609 9595 1949  824 3111 1047 5378\n",
      " 8938 5311 1271  950 7455   19  823  592 5301]\n",
      "\n",
      "\n",
      "[0.5162541  0.516391   0.51641345 0.5169088  0.51692504 0.5199717\n",
      " 0.517191   0.52135193 0.5219561  0.5214425  0.51795864 0.51976407\n",
      " 0.5233011  0.5244196  0.53384894 0.5305647  0.5237737  0.5277239\n",
      " 0.53266937 0.52574754 0.52792144 0.53220713 0.53645223]\n",
      "\n",
      "\n",
      "2 To 3 Digits\n",
      "\n",
      "107 [ 19  35  42 114 131 147 160 193 197 210 216 219 270 272 279 283 298 305\n",
      " 314 315 325 344 363 372 391 392 422 430 437 446 473 479 486 495 496 498\n",
      " 504 507 509 519 520 535 537 546 553 557 567 568 572 575 581 591 592 594\n",
      " 604 607 622 623 625 626 628 630 641 661 691 706 708 716 720 728 736 743\n",
      " 744 746 757 758 764 767 799 802 803 806 810 816 818 823 824 854 859 874\n",
      " 895 900 903 905 916 921 922 923 925 928 932 945 950 952 954 974 993]\n",
      "\n",
      "[0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
      " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
      " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
      " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
      " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
      " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
      " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
      " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
      " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
      " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
      " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
      " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
      " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
      " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
      " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
      " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
      " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
      " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003]\n",
      "\n",
      "\n",
      "2 To 3 Digits Average Proba\n",
      "\n",
      "Average proba 0.505134642124176\n",
      "\n",
      "130 [  19   35  147  210  216  283  422  495  504  507  509  546  567  572\n",
      "  592  594  622  641  661  708  743  758  799  802  806  810  823  824\n",
      "  854  895  900  903  905  923  925  950 1047 1083 1216 1230 1271 1457\n",
      " 1467 1508 1553 1597 1686 1702 1754 1807 1811 1933 1949 1979 1989 2017\n",
      " 2107 2144 2185 2209 2243 2255 2266 2377 2479 2532 2536 2609 2908 3111\n",
      " 3114 3224 3411 3545 3576 3591 3981 4016 4339 4465 4562 4603 4609 4859\n",
      " 4879 5018 5045 5154 5199 5261 5301 5311 5378 5401 5825 6114 6152 6326\n",
      " 6770 6772 6874 6945 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635\n",
      " 7730 7770 7781 7904 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258\n",
      " 9282 9364 9595 9963]\n",
      "\n",
      "\n",
      "All Average Proba\n",
      "\n",
      "All average probas 0.5041610598564148\n",
      "\n",
      "173 [  19   35  147  210  216  283  315  422  473  495  498  504  507  509\n",
      "  535  546  553  557  567  572  575  592  594  604  622  625  641  661\n",
      "  708  743  758  799  802  806  810  823  824  854  895  900  903  905\n",
      "  923  925  950 1047 1083 1126 1216 1230 1271 1378 1409 1457 1467 1508\n",
      " 1531 1553 1597 1671 1686 1702 1747 1754 1807 1811 1905 1933 1949 1979\n",
      " 1989 2017 2107 2144 2185 2209 2243 2255 2260 2266 2269 2377 2479 2532\n",
      " 2536 2609 2641 2865 2871 2908 2958 3010 3090 3111 3114 3209 3224 3242\n",
      " 3411 3436 3453 3545 3576 3591 3854 3981 4016 4060 4267 4339 4369 4465\n",
      " 4562 4603 4609 4780 4859 4879 4912 5018 5045 5154 5199 5261 5301 5311\n",
      " 5378 5401 5825 6114 6152 6326 6451 6749 6770 6772 6874 6930 6945 7081\n",
      " 7136 7166 7222 7227 7231 7317 7402 7405 7410 7455 7635 7730 7770 7781\n",
      " 7809 7904 8078 8307 8499 8690 8701 8938 8981 9028 9223 9254 9258 9282\n",
      " 9364 9465 9595 9755 9963]\n",
      "\n",
      "\n",
      "All Predictions\n",
      "\n",
      "531 [  19   35   42  114  131  147  160  193  197  210  216  219  270  272\n",
      "  279  283  298  305  314  315  325  344  363  372  391  392  422  430\n",
      "  437  446  473  479  486  495  496  498  504  507  509  519  520  535\n",
      "  537  546  553  557  567  568  572  575  581  591  592  594  604  607\n",
      "  622  623  625  626  628  630  641  661  691  706  708  716  720  728\n",
      "  736  743  744  746  757  758  764  767  799  802  803  806  810  816\n",
      "  818  823  824  854  859  874  895  900  903  905  916  921  922  923\n",
      "  925  928  932  945  950  952  954  974  993 1025 1047 1055 1062 1064\n",
      " 1083 1085 1088 1112 1115 1124 1126 1138 1148 1152 1156 1198 1207 1216\n",
      " 1221 1230 1249 1255 1256 1270 1271 1287 1289 1296 1302 1320 1353 1378\n",
      " 1403 1408 1409 1432 1445 1457 1467 1472 1475 1489 1508 1516 1531 1549\n",
      " 1550 1553 1563 1571 1597 1601 1606 1650 1651 1655 1671 1684 1686 1689\n",
      " 1700 1702 1710 1713 1718 1747 1754 1761 1766 1773 1775 1807 1811 1879\n",
      " 1892 1905 1914 1933 1942 1949 1950 1979 1980 1989 1992 2017 2020 2036\n",
      " 2037 2048 2056 2071 2074 2075 2087 2097 2107 2128 2144 2158 2162 2172\n",
      " 2185 2188 2209 2213 2243 2255 2256 2260 2266 2269 2276 2311 2320 2326\n",
      " 2335 2350 2369 2376 2377 2398 2414 2451 2466 2479 2485 2497 2515 2525\n",
      " 2532 2533 2536 2550 2603 2609 2633 2641 2645 2670 2674 2679 2692 2704\n",
      " 2723 2750 2759 2785 2804 2842 2865 2869 2871 2892 2895 2899 2908 2936\n",
      " 2958 2989 3000 3009 3010 3029 3034 3043 3057 3066 3090 3091 3111 3113\n",
      " 3114 3138 3156 3171 3209 3210 3224 3242 3251 3266 3289 3319 3334 3350\n",
      " 3356 3411 3416 3431 3436 3453 3492 3494 3526 3545 3567 3569 3576 3591\n",
      " 3616 3621 3673 3675 3733 3751 3772 3830 3845 3854 3859 3928 3968 3981\n",
      " 3988 4012 4016 4036 4060 4100 4116 4166 4180 4253 4267 4282 4315 4321\n",
      " 4336 4339 4369 4373 4465 4473 4479 4554 4562 4578 4603 4609 4662 4669\n",
      " 4725 4730 4780 4789 4813 4836 4848 4851 4859 4879 4912 5018 5045 5067\n",
      " 5084 5154 5191 5199 5237 5240 5261 5297 5301 5309 5311 5378 5401 5440\n",
      " 5442 5506 5508 5523 5587 5709 5725 5773 5796 5803 5820 5825 5875 5913\n",
      " 5915 5937 5991 5994 6033 6045 6077 6103 6114 6117 6152 6156 6210 6222\n",
      " 6237 6241 6275 6326 6391 6401 6451 6481 6510 6520 6559 6603 6620 6642\n",
      " 6660 6698 6742 6749 6770 6772 6874 6881 6911 6919 6926 6930 6945 6960\n",
      " 6962 6982 6992 6997 7041 7055 7081 7097 7100 7126 7136 7165 7166 7196\n",
      " 7202 7222 7227 7231 7249 7317 7320 7339 7397 7402 7405 7410 7433 7438\n",
      " 7454 7455 7457 7532 7539 7567 7586 7635 7682 7709 7722 7730 7770 7772\n",
      " 7780 7781 7809 7836 7904 7917 7931 7956 8009 8031 8037 8051 8078 8260\n",
      " 8265 8287 8307 8353 8413 8446 8490 8499 8524 8690 8701 8747 8872 8938\n",
      " 8950 8981 8983 9028 9064 9110 9223 9254 9258 9282 9308 9315 9317 9364\n",
      " 9372 9465 9482 9571 9595 9598 9671 9692 9755 9761 9909 9947 9963]\n",
      "\n",
      "531 [0.52574754 0.50703806 0.5029288  0.50080454 0.50020105 0.5056296\n",
      " 0.5029369  0.5029233  0.50346977 0.51508045 0.5139096  0.5020226\n",
      " 0.50185966 0.503349   0.50191027 0.5079054  0.50414807 0.5031669\n",
      " 0.502498   0.5046048  0.50072634 0.5002362  0.5018055  0.5011687\n",
      " 0.5022754  0.5036865  0.50580305 0.5011069  0.50243205 0.5004\n",
      " 0.50454175 0.5006605  0.5007128  0.5104836  0.50255924 0.5047185\n",
      " 0.5055888  0.50778717 0.5054272  0.500547   0.5001082  0.5045893\n",
      " 0.5030562  0.5071827  0.5051092  0.50423956 0.5073805  0.503193\n",
      " 0.506904   0.505024   0.50346786 0.5001618  0.53220713 0.50573945\n",
      " 0.50464535 0.50021446 0.51548916 0.50054574 0.5050284  0.5005583\n",
      " 0.5013865  0.50159127 0.5081088  0.5076124  0.50205755 0.5015398\n",
      " 0.5146197  0.5027434  0.500064   0.503612   0.50171477 0.5077632\n",
      " 0.50038606 0.50090724 0.5028683  0.5057479  0.5021052  0.50103295\n",
      " 0.5059615  0.50546676 0.50285035 0.507507   0.5121238  0.5004937\n",
      " 0.500084   0.52792144 0.51795864 0.50684196 0.5031301  0.50005776\n",
      " 0.5101467  0.5073833  0.51334184 0.5199717  0.5021009  0.5004827\n",
      " 0.5018454  0.5063731  0.50578374 0.5016932  0.5013524  0.50011975\n",
      " 0.5277239  0.50176555 0.50047666 0.5013797  0.50156003 0.50193864\n",
      " 0.5233011  0.5019427  0.5018813  0.50333184 0.5077932  0.50032276\n",
      " 0.50399214 0.5019776  0.5021962  0.5033606  0.5050345  0.5007271\n",
      " 0.5004271  0.5017781  0.5036346  0.50294876 0.50129485 0.5051949\n",
      " 0.5017786  0.5161055  0.50030917 0.5002334  0.50054634 0.502441\n",
      " 0.5237737  0.5001335  0.5006088  0.50079876 0.5014565  0.50006247\n",
      " 0.50135255 0.50461596 0.5019814  0.5039658  0.5043177  0.5013857\n",
      " 0.502333   0.5085428  0.5096458  0.50051713 0.50184417 0.50187564\n",
      " 0.5099776  0.5015396  0.5042541  0.5000276  0.5010012  0.50823355\n",
      " 0.50321233 0.5006847  0.50657576 0.5020534  0.5022483  0.5023252\n",
      " 0.5014854  0.5001313  0.5045973  0.50070107 0.507189   0.5002941\n",
      " 0.5032144  0.5077739  0.50406307 0.5028727  0.50317496 0.50501096\n",
      " 0.50741047 0.5005272  0.5007295  0.5030393  0.50157464 0.5061432\n",
      " 0.5058737  0.50209904 0.500265   0.5042856  0.5025591  0.5169088\n",
      " 0.500369   0.5214425  0.5026731  0.5059941  0.5012068  0.505363\n",
      " 0.5002419  0.50673103 0.5031148  0.5022421  0.50023556 0.5003679\n",
      " 0.50088286 0.5002486  0.5011168  0.500298   0.50125176 0.50034547\n",
      " 0.5058143  0.5004563  0.5068892  0.5018134  0.5005777  0.5015998\n",
      " 0.50586724 0.5013415  0.5067641  0.5007844  0.50625074 0.516391\n",
      " 0.5032432  0.50455743 0.5083711  0.50418454 0.5023767  0.50140953\n",
      " 0.5024658  0.5008551  0.5035298  0.50405866 0.5040264  0.5013136\n",
      " 0.5051417  0.50176305 0.5002963  0.50232077 0.5040539  0.51692504\n",
      " 0.5022951  0.50303423 0.5035956  0.5005876  0.5138081  0.50151676\n",
      " 0.50688004 0.5035969  0.50227123 0.5066609  0.5006303  0.50437456\n",
      " 0.5034663  0.501092   0.50317615 0.5015915  0.5000509  0.50150824\n",
      " 0.5033506  0.501502   0.5015722  0.50149184 0.5027045  0.5010111\n",
      " 0.5048253  0.50238866 0.50417536 0.50079346 0.50387055 0.5008435\n",
      " 0.50570333 0.50241864 0.5049395  0.50353813 0.50055224 0.5001007\n",
      " 0.50495845 0.5020584  0.5029562  0.50052553 0.50013536 0.50102925\n",
      " 0.5042794  0.50152725 0.51976407 0.50223374 0.5095835  0.50119936\n",
      " 0.50206643 0.50154394 0.50441885 0.50040376 0.5090414  0.50425774\n",
      " 0.50005317 0.50170726 0.50056136 0.5039086  0.50194675 0.5036079\n",
      " 0.500602   0.51120573 0.5003541  0.5008197  0.5046707  0.5047756\n",
      " 0.5013298  0.5008607  0.5029928  0.5081413  0.50048333 0.5002262\n",
      " 0.5062425  0.51041156 0.5010636  0.50207835 0.5004797  0.5024966\n",
      " 0.5009555  0.50120705 0.50257754 0.5039481  0.5017446  0.5046624\n",
      " 0.50180703 0.50295836 0.50405467 0.5089567  0.50125986 0.50239694\n",
      " 0.5055027  0.5020613  0.50466657 0.5017311  0.50364494 0.5028926\n",
      " 0.502351   0.5008175  0.5048126  0.50009435 0.5000998  0.50252193\n",
      " 0.5009848  0.5095472  0.50449383 0.5014222  0.50868195 0.5000881\n",
      " 0.5028848  0.5000194  0.517191   0.5017843  0.51050824 0.52135193\n",
      " 0.50004286 0.500251   0.5026527  0.5033862  0.50450546 0.5012733\n",
      " 0.50316685 0.5001279  0.50104624 0.50388986 0.5065444  0.5117828\n",
      " 0.5046769  0.5077476  0.5073464  0.5024187  0.502269   0.5068733\n",
      " 0.5025758  0.50690585 0.50012517 0.50204784 0.51100546 0.5031314\n",
      " 0.53645223 0.50260043 0.5305647  0.5244196  0.5123694  0.50030005\n",
      " 0.50179744 0.50070655 0.50187504 0.50241065 0.50097615 0.5004209\n",
      " 0.50410026 0.50412995 0.50075006 0.50034535 0.5006251  0.50871956\n",
      " 0.50043744 0.50387764 0.50013226 0.5001125  0.5010285  0.50263464\n",
      " 0.5017195  0.50063664 0.50241137 0.5002141  0.51622677 0.5017507\n",
      " 0.5054098  0.5012449  0.5019777  0.50268674 0.501439   0.5006176\n",
      " 0.50002676 0.51473963 0.5032707  0.50065583 0.5042906  0.50046515\n",
      " 0.5008358  0.50289613 0.50163007 0.50055    0.5006611  0.50001824\n",
      " 0.500902   0.5025525  0.50301874 0.50429374 0.5061972  0.50630987\n",
      " 0.5104396  0.5004639  0.5016632  0.5005977  0.50134534 0.5041905\n",
      " 0.5057943  0.5005898  0.5011946  0.5020207  0.50016475 0.50245583\n",
      " 0.5004136  0.5007595  0.5042677  0.5003235  0.5001593  0.50168556\n",
      " 0.5041696  0.50180286 0.50803363 0.50103134 0.50168335 0.507005\n",
      " 0.5105519  0.5059834  0.5016305  0.50811034 0.5013556  0.5019086\n",
      " 0.50172263 0.5073309  0.5156956  0.50974417 0.5032969  0.5011608\n",
      " 0.50009733 0.53266937 0.5035469  0.5028987  0.50063163 0.500409\n",
      " 0.50032055 0.5122719  0.5012948  0.5000725  0.50118923 0.5057144\n",
      " 0.506186   0.501088   0.5000707  0.5078673  0.5045751  0.50388914\n",
      " 0.51368195 0.5019669  0.50036156 0.50219053 0.5032656  0.5004837\n",
      " 0.5024662  0.5008789  0.50419086 0.50123715 0.50037897 0.5009113\n",
      " 0.50567675 0.5000989  0.5010555  0.5028809  0.50204444 0.51495695\n",
      " 0.5028022  0.5118773  0.50547427 0.50415117 0.500101   0.53384894\n",
      " 0.5004925  0.5157178  0.5012213  0.5075401  0.50168836 0.5015672\n",
      " 0.50564915 0.5162541  0.51641345 0.5074288  0.5005564  0.5019221\n",
      " 0.50063413 0.5065996  0.5004202  0.5044905  0.50132984 0.5010047\n",
      " 0.5219561  0.5008338  0.5003478  0.50031644 0.5042497  0.5006778\n",
      " 0.50030535 0.5016988  0.506133  ]\n",
      "\n",
      "Matched draws\n",
      "Count: 0, Index: (array([], dtype=int64),)\n",
      "\n",
      "\n",
      "Top 23 Possibility\n",
      "Empty DataFrame\n",
      "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
      "Index: []\n",
      "\n",
      "\n",
      "First 23 Numbers\n",
      "Empty DataFrame\n",
      "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
      "Index: []\n",
      "\n",
      "\n",
      "2 To 3 Digits Numbers\n",
      "Empty DataFrame\n",
      "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
      "Index: []\n",
      "\n",
      "\n",
      "All matched\n",
      "Empty DataFrame\n",
      "Columns: [DrawNo, DrawDate, PrizeType, LuckyNo]\n",
      "Index: []\n",
      "CPU times: user 34min 58s, sys: 1.15 s, total: 34min 59s\n",
      "Wall time: 9min\n",
      "\n",
      "-----------2020-03-01 00:00:00-----------------\n",
      "\n",
      "Data shape\n",
      "(979893, 34) (979893,) (10000, 34) (10000,)\n",
      "\n",
      "Calculating scale pos weight\n",
      "Counter({0: 947191, 1: 32702})\n",
      "\n",
      "scale_pos_weight - 28.964314109228795\n",
      "\n",
      "{'base_score': 0.5, 'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 0.95, 'gamma': 0.1, 'learning_rate': 0.007, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 1, 'missing': None, 'n_estimators': 500, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 28.964314109228795, 'seed': None, 'silent': None, 'subsample': 0.55, 'verbosity': 1, 'tree_method': 'hist'}\n",
      "Parameter distribution: {'n_estimators': [100, 300, 500, 800, 1000], 'max_depth': range(3, 10, 2), 'min_child_weight': range(1, 6, 2), 'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.85, 0.9, 0.95], 'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 28.964314109228795]}\n",
      "\n",
      "Use the passed in classifier...\n",
      "\n",
      "\n",
      "TEST GROUP\n"
     ]
    }
   ],
   "source": [
    "target_mt = pd.datetime(2020,3,1)\n",
    "%time gen_train_test_set(target_mt, feature_matrix_selection, file_prefix='test')\n",
    "\n",
    "for (estimators, depth) in ((300,3), (500,6), (550,6), (600,6)):\n",
    "#for (estimators, depth) in ((300,3),):\n",
    "  %time model(target_mt, feature_matrix_selection, file_prefix='test', estimators=estimators, depth=depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRtzlp_pcBGd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VE6Xbz-IyvLj"
   },
   "outputs": [],
   "source": [
    "# weight=1.0\n",
    "# decrement = 0.000\n",
    "# to_stop=False\n",
    "\n",
    "# dt = pd.datetime(2020,1,1)\n",
    "# %time gen_train_test_set(dt, feature_matrix_selection, file_prefix='test')\n",
    "# while not to_stop:\n",
    "#   to_stop = model(dt, feature_matrix_selection, file_prefix='test', class_weight=(weight-decrement))\n",
    "#   decrement = decrement + 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qktZbi7OGqP3"
   },
   "outputs": [],
   "source": [
    "# start_mt = pd.datetime(2019,7,1)\n",
    "# how_many_mt = 6 \n",
    "# for i in range(how_many_mt):\n",
    "#   month_to_predict = start_mt + relativedelta(months=i)\n",
    "#   print(f\"\\n{month_to_predict}\\n-------------------\\n\")\n",
    "\n",
    "#   weight=1.0\n",
    "#   decrement = 0.000\n",
    "#   to_stop=False\n",
    "\n",
    "#   gen_train_test_set(month_to_predict, feature_matrix_selection, file_prefix='test')\n",
    "#   while not to_stop:\n",
    "#     to_stop = model(month_to_predict, feature_matrix_selection, file_prefix='test', class_weight=(weight-decrement))\n",
    "#     decrement = decrement + 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8tcqn4yIl21"
   },
   "outputs": [],
   "source": [
    "# weight=1.0\n",
    "# decrement = 0.000\n",
    "# to_stop=False\n",
    "\n",
    "# dt = pd.datetime(2020,2,1)\n",
    "# %time gen_train_test_set(dt, feature_matrix_selection, file_prefix='test')\n",
    "# while not to_stop:\n",
    "#   to_stop = model(dt, feature_matrix_selection, file_prefix='test', class_weight=(weight-decrement))\n",
    "#   decrement = decrement + 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1SC8YG8P_ljs"
   },
   "outputs": [],
   "source": [
    "# weight=1.0\n",
    "# decrement = 0.000\n",
    "# to_stop=False\n",
    "\n",
    "# dt = pd.datetime(2020,3,1)\n",
    "# %time gen_train_test_set(dt, feature_matrix_selection, file_prefix='test')\n",
    "# while not to_stop:\n",
    "#   to_stop = model(dt, feature_matrix_selection, file_prefix='test', class_weight=(weight-decrement))\n",
    "#   decrement = decrement + 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yASd8nZFR7Qb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "153K-Fpie_vd"
   },
   "outputs": [],
   "source": [
    "# target_mt = pd.datetime(2020,3,1)\n",
    "# %time gen_train_test_set(target_mt, feature_matrix_selection, file_prefix='test')\n",
    "\n",
    "# for (estimators, depth) in ((300,3), (500,6), (550,6), (600,6)):\n",
    "#   %time model(target_mt, feature_matrix_selection, file_prefix='test', estimators=estimators, depth=depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4FzHxatfCd7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "04_02_automated_machine_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
