{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_02_automated_machine_learning.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengwangk/dl-projects/blob/master/04_09_auto_ml_6_temp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4hyoPGdjpqa_"
      },
      "source": [
        "# Machine Learning - Finance 20200726"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLxr2k_ue8yq",
        "colab": {}
      },
      "source": [
        "COLAB = True\n",
        "\n",
        "DATASET_NAME = '4D.zip'\n",
        "\n",
        "FEATURE_DATASET_PREFIX = 'feature_matrix_d2_v3'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wwYshXtLt7b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "a4b65264-b84c-4a5e-be61-0ffdcac14d64"
      },
      "source": [
        "if COLAB:\n",
        "  !pip install -U xgboost\n",
        "\n",
        "  !rm -rf dl-projects\n",
        "  !git clone https://github.com/mengwangk/dl-projects\n",
        "  \n",
        "  !cp dl-projects/utils* .\n",
        "  !cp dl-projects/preprocess* .\n",
        "  !cp dl-projects/plot* ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: imblearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied, skipping upgrade: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (from imblearn) (0.4.3)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (0.16.0)\n",
            "Collecting xgboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/32/a11befbb003e0e6b7e062a77f010dfcec0ec3589be537b02d2eb2ff93b9a/xgboost-1.1.1-py3-none-manylinux2010_x86_64.whl (127.6MB)\n",
            "\u001b[K     |████████████████████████████████| 127.6MB 31kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Installing collected packages: xgboost\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.1.1\n",
            "Cloning into 'dl-projects'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (116/116), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 2093 (delta 68), reused 25 (delta 10), pack-reused 1977\u001b[K\n",
            "Receiving objects: 100% (2093/2093), 79.17 MiB | 18.94 MiB/s, done.\n",
            "Resolving deltas: 100% (1293/1293), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fC2-l3JBpqbE",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TP7V_IzepqbK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5c5ee43a-9637-4b05-addb-98ab6ee1d201"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "import matplotlib\n",
        "import sys\n",
        "import gc\n",
        "import xgboost as xgb\n",
        "\n",
        "from scipy import stats\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, precision_recall_curve, make_scorer, recall_score, roc_curve, mean_squared_error, accuracy_score, average_precision_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedShuffleSplit, RepeatedStratifiedKFold\n",
        "from collections import Counter\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "from utils import feature_selection, plot_feature_importances\n",
        "from plot import plot_correlation_matrix, plot_labeled_scatter\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "from preprocess import *\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "# The Answer to the Ultimate Question of Life, the Universe, and Everything.\n",
        "np.random.seed(42)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3bFT5CoxpqbP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3b608abc-fdab-46d3-bd63-e4601cf67003"
      },
      "source": [
        "%aimport"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modules to reload:\n",
            "all-except-skipped\n",
            "\n",
            "Modules to skip:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3E16jPVPpqbV"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U421BuhtfYS7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "37a00464-0a81-475d-803e-c15716f8ee47"
      },
      "source": [
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  GDRIVE_DATASET_FOLDER = Path('gdrive/My Drive/datasets/')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9IgnETKkpqbX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "f4ae7aa5-5416-4d02-d2e2-1d05302d6a1c"
      },
      "source": [
        "if COLAB:\n",
        "  DATASET_PATH = GDRIVE_DATASET_FOLDER\n",
        "  ORIGIN_DATASET_PATH = Path('dl-projects/datasets')\n",
        "else:\n",
        "  DATASET_PATH = Path(\"../datasets\")\n",
        "  ORIGIN_DATASET_PATH = Path('datasets')\n",
        "\n",
        "DATASET = DATASET_PATH/f\"{FEATURE_DATASET_PREFIX}.ft\"\n",
        "ORIGIN_DATASET = ORIGIN_DATASET_PATH/DATASET_NAME\n",
        "\n",
        "if COLAB:\n",
        "  !ls -l gdrive/\"My Drive\"/datasets/ --block-size=M\n",
        "  !ls -l dl-projects/datasets --block-size=M"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 5149M\n",
            "-rw------- 1 root root   17M Jul  6 14:06 feature_matrix_2020_apr.ft\n",
            "-rw------- 1 root root   17M Jul  6 14:06 feature_matrix_2020_apr_orig.pkl\n",
            "-rw------- 1 root root   17M Mar  1 05:47 feature_matrix_2020_feb.ft\n",
            "-rw------- 1 root root   17M Mar  1 05:39 feature_matrix_2020_jan.ft\n",
            "-rw------- 1 root root   17M Jul  7 13:52 feature_matrix_2020_jul.ft\n",
            "-rw------- 1 root root   17M Jul  7 13:52 feature_matrix_2020_jul_orig.pkl\n",
            "-rw------- 1 root root   17M Jul  5 07:30 feature_matrix_2020_jun.ft\n",
            "-rw------- 1 root root   17M Jul  5 07:30 feature_matrix_2020_jun_orig.pkl\n",
            "-rw------- 1 root root   17M Jul  6 13:56 feature_matrix_2020_mar.ft\n",
            "-rw------- 1 root root   17M Jul  6 13:56 feature_matrix_2020_mar_orig.pkl\n",
            "-rw------- 1 root root   17M Jul  7 13:40 feature_matrix_2020_may.ft\n",
            "-rw------- 1 root root   17M Jul  7 13:40 feature_matrix_2020_may_orig.pkl\n",
            "-rw------- 1 root root 2454M Jan 12  2020 feature_matrix_d2_v2.ft\n",
            "-rw------- 1 root root 1585M Jan 12  2020 feature_matrix_d2_v3.ft\n",
            "-rw------- 1 root root   17M Feb 21 13:07 feature_matrix_snapshot.ft\n",
            "-rw------- 1 root root    1M Jul  7 13:43 labels.csv\n",
            "-rw------- 1 root root    5M Jan 30 04:33 orig_X_test.ft\n",
            "-rw------- 1 root root  415M Jan 30 04:33 orig_X_train.ft\n",
            "-rw------- 1 root root    1M Jan 30 04:33 orig_y_test.ft\n",
            "-rw------- 1 root root    7M Jan 30 04:33 orig_y_train.ft\n",
            "-rw------- 1 root root    5M Jul 26 03:15 test_X_test.ft\n",
            "-rw------- 1 root root  459M Jul 26 03:15 test_X_train.ft\n",
            "-rw------- 1 root root    1M Jul 26 03:15 test_y_test.ft\n",
            "-rw------- 1 root root    8M Jul 26 03:15 test_y_train.ft\n",
            "total 26M\n",
            "-rw-r--r-- 1 root root  1M Jul 26 07:13 4D.txt\n",
            "-rw-r--r-- 1 root root  1M Jul 26 07:13 4D.zip\n",
            "-rw-r--r-- 1 root root 25M Jul 26 07:13 labels.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urQTD6DQNutw",
        "colab": {}
      },
      "source": [
        "# Read the data\n",
        "data = pd.read_feather(DATASET)\n",
        "origin_data = format_tabular(ORIGIN_DATASET)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djbAQMP7VEsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display null rows\n",
        "# data[data.isna().any(axis=1)]\n",
        "#for col in data.columns:\n",
        "#  print(col)\n",
        "#\n",
        "#data.head(1).T"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zov05QHZxxiS"
      },
      "source": [
        "## Add new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "foPB8T1vx2tp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73c4b89e-6a48-4b52-e824-5661003681dc"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(959893, 217)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "43sc1Eaux25j",
        "colab": {}
      },
      "source": [
        "jan_2020 = pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_jan.ft\")\n",
        "feb_2020 = pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_feb.ft\")\n",
        "mar_2020 = pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_mar.ft\")\n",
        "apr_2020 = pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_apr.ft\")\n",
        "may_2020 = pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_may.ft\")\n",
        "jun_2020 = pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_jun.ft\")\n",
        "jul_2020 = pd.read_feather(DATASET_PATH/f\"feature_matrix_2020_jul.ft\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2vISxEbsyQG1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "da68ccce-fdca-4df4-c9f6-83439e3287c9"
      },
      "source": [
        "new_data = data.append(jan_2020[data.columns],ignore_index=True)\n",
        "new_data = new_data.append(feb_2020[data.columns],ignore_index=True)\n",
        "new_data = new_data.append(mar_2020[data.columns],ignore_index=True)\n",
        "new_data = new_data.append(apr_2020[data.columns],ignore_index=True)\n",
        "new_data = new_data.append(may_2020[data.columns],ignore_index=True)\n",
        "new_data = new_data.append(jun_2020[data.columns],ignore_index=True)\n",
        "new_data = new_data.append(jul_2020[data.columns],ignore_index=True)\n",
        "new_data.shape "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1029893, 217)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FVVMXCj-zyaW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "122eca90-e98f-4dbf-985a-079ee53dad38"
      },
      "source": [
        "data = new_data\n",
        "data.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1029893, 217)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9o3f2PXXSMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "4fcbf078-e400-4680-dc48-a78a0e03c4b2"
      },
      "source": [
        "data.isna().sum().sort_values(ascending=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CUM_SUM(SKEW(Results.TotalStrike))           7685\n",
              "CUM_MEAN(TREND(Results.DrawNo, DrawDate))    7685\n",
              "TREND(Results.CUM_SUM(DrawNo), DrawDate)     7685\n",
              "TREND(Results.CUM_SUM(LuckyNo), DrawDate)    7685\n",
              "CUM_SUM(SKEW(Results.LuckyNo))               7685\n",
              "                                             ... \n",
              "CUM_SUM(MIN(Results.DrawNo))                    0\n",
              "NUM_UNIQUE(Results.DAY(DrawDate))               0\n",
              "NUM_UNIQUE(Results.MONTH(DrawDate))             0\n",
              "SUM(Results.PERCENTILE(LuckyNo))                0\n",
              "NumberId                                        0\n",
              "Length: 217, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUHePaWKSZDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#display(data.head(10).T)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vOYlp-8Br61r"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kHiN1VVlG9Kh"
      },
      "source": [
        "### View data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JnQXyVqng5Cm",
        "colab": {}
      },
      "source": [
        "# Feature matrix\n",
        "#feature_matrix = data.drop(columns=['NumberId', 'month', 'year'])\n",
        "feature_matrix = data"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apMYVNz9HK9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8cf98ead-896b-4334-bf20-332d94e2c9e7"
      },
      "source": [
        "# Sort data\n",
        "feature_matrix.sort_values(by=['time', 'MAX(Results.LuckyNo)'], inplace=True)\n",
        "feature_matrix.info()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1029893 entries, 7020 to 1026411\n",
            "Columns: 217 entries, NumberId to year\n",
            "dtypes: datetime64[ns](1), float64(155), int64(59), uint8(2)\n",
            "memory usage: 1.7 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CZKTbWRFJNUq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "bbff1920-db2f-447e-a31d-9c84eb8d69a1"
      },
      "source": [
        "print('Distribution')\n",
        "print(feature_matrix['Label'].value_counts())\n",
        "print()\n",
        "print('Positive: ' + str(feature_matrix['Label'].value_counts()[0]) + ' which is ', round(feature_matrix['Label'].value_counts()[0]/len(feature_matrix) * 100,2), '% of the dataset')\n",
        "print('Negative: ' + str(feature_matrix['Label'].value_counts()[1]) + ' which is ', round(feature_matrix['Label'].value_counts()[1]/len(feature_matrix) * 100,2), '% of the dataset')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution\n",
            "0    996848\n",
            "1     33045\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Positive: 996848 which is  96.79 % of the dataset\n",
            "Negative: 33045 which is  3.21 % of the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plplpAQ6JrKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "ac6be0e0-aa3c-44d1-c1e5-01e49a795ae4"
      },
      "source": [
        "feature_matrix.isna().sum().sort_values(ascending=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CUM_SUM(SKEW(Results.TotalStrike))           7685\n",
              "CUM_MEAN(TREND(Results.DrawNo, DrawDate))    7685\n",
              "TREND(Results.CUM_SUM(DrawNo), DrawDate)     7685\n",
              "TREND(Results.CUM_SUM(LuckyNo), DrawDate)    7685\n",
              "CUM_SUM(SKEW(Results.LuckyNo))               7685\n",
              "                                             ... \n",
              "CUM_SUM(MIN(Results.DrawNo))                    0\n",
              "NUM_UNIQUE(Results.DAY(DrawDate))               0\n",
              "NUM_UNIQUE(Results.MONTH(DrawDate))             0\n",
              "SUM(Results.PERCENTILE(LuckyNo))                0\n",
              "NumberId                                        0\n",
              "Length: 217, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF_zCRksL1Ls"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1aLGsXSOa9K",
        "colab": {}
      },
      "source": [
        "# Fill all NaN with 0\n",
        "feature_matrix = feature_matrix.fillna(0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5A8LZ805MqjP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c6f943d-48ac-4ea0-ab3f-ba9bb5ffd827"
      },
      "source": [
        "feature_matrix.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1029893, 217)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rPFOkiGjhuKj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "271a89fc-1189-44d4-e940-e9c5e69ca8ce"
      },
      "source": [
        "# With feature selection\n",
        "feature_matrix_selection = feature_selection(feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label']))\n",
        "\n",
        "# Without feature selection\n",
        "# feature_matrix_selection = feature_matrix.drop(columns = ['time', 'TotalStrike', 'Label'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape:  (1029893, 214)\n",
            "0 missing columns with threshold: 90.\n",
            "41 zero variance columns.\n",
            "111 collinear columns removed with threshold: 0.95.\n",
            "Total columns removed:  152\n",
            "Shape after feature selection: (1029893, 62).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vT2K0WeJhugH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "outputId": "9d2a211b-3336-4d4f-bfc4-cf5a3ecf7b47"
      },
      "source": [
        "feature_matrix_selection.shape, feature_matrix_selection.columns"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1029893, 62),\n",
              " Index(['NumberId', 'STD(Results.DrawNo)', 'MAX(Results.DrawNo)',\n",
              "        'MIN(Results.DrawNo)', 'MEAN(Results.DrawNo)', 'SKEW(Results.DrawNo)',\n",
              "        'AVG_TIME_BETWEEN(Results.DrawDate)', 'COUNT(Results)',\n",
              "        'SUM(Results.DrawNo)', 'SUM(Results.LuckyNo)',\n",
              "        'TREND(Results.DrawNo, DrawDate)', 'MONTH(first_Results_time)',\n",
              "        'DAY(first_Results_time)', 'TIME_SINCE(first_Results_time)',\n",
              "        'TIME_SINCE_PREVIOUS(first_Results_time)',\n",
              "        'STD(Results.PERCENTILE(DrawNo))',\n",
              "        'STD(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'STD(Results.CUM_SUM(DrawNo))', 'STD(Results.CUM_MEAN(LuckyNo))',\n",
              "        'MAX(Results.PERCENTILE(DrawNo))',\n",
              "        'MAX(Results.PERCENTILE(TotalStrike))',\n",
              "        'MAX(Results.CUM_MEAN(LuckyNo))',\n",
              "        'MIN(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'MIN(Results.CUM_SUM(DrawNo))', 'MIN(Results.CUM_MEAN(LuckyNo))',\n",
              "        'MODE(Results.MONTH(DrawDate))', 'MODE(Results.DAY(DrawDate))',\n",
              "        'MEAN(Results.TIME_SINCE(DrawDate))',\n",
              "        'MEAN(Results.PERCENTILE(DrawNo))', 'MEAN(Results.CUM_MEAN(LuckyNo))',\n",
              "        'SKEW(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'SKEW(Results.CUM_SUM(DrawNo))', 'SKEW(Results.CUM_MEAN(LuckyNo))',\n",
              "        'LAST(Results.DAY(DrawDate))',\n",
              "        'LAST(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'LAST(Results.MONTH(DrawDate))', 'LAST(Results.CUM_MEAN(LuckyNo))',\n",
              "        'SUM(Results.TIME_SINCE(DrawDate))',\n",
              "        'SUM(Results.TIME_SINCE_PREVIOUS(DrawDate))',\n",
              "        'TREND(Results.CUM_MEAN(LuckyNo), DrawDate)',\n",
              "        'TREND(Results.PERCENTILE(LuckyNo), DrawDate)',\n",
              "        'TREND(Results.PERCENTILE(DrawNo), DrawDate)',\n",
              "        'TREND(Results.PERCENTILE(TotalStrike), DrawDate)',\n",
              "        'TREND(Results.TIME_SINCE_PREVIOUS(DrawDate), DrawDate)',\n",
              "        'TREND(Results.CUM_SUM(DrawNo), DrawDate)',\n",
              "        'NUM_UNIQUE(Results.MONTH(DrawDate))',\n",
              "        'NUM_UNIQUE(Results.DAY(DrawDate))', 'CUM_SUM(MIN(Results.DrawNo))',\n",
              "        'CUM_SUM(SKEW(Results.DrawNo))',\n",
              "        'CUM_MEAN(AVG_TIME_BETWEEN(Results.DrawDate))',\n",
              "        'CUM_MEAN(SUM(Results.LuckyNo))', 'CUM_MEAN(SKEW(Results.DrawNo))',\n",
              "        'PERCENTILE(STD(Results.LuckyNo))', 'PERCENTILE(LAST(Results.DrawNo))',\n",
              "        'PERCENTILE(MAX(Results.TotalStrike))',\n",
              "        'PERCENTILE(AVG_TIME_BETWEEN(Results.DrawDate))',\n",
              "        'PERCENTILE(COUNT(Results))', 'PERCENTILE(STD(Results.DrawNo))',\n",
              "        'PERCENTILE(SKEW(Results.DrawNo))', 'PERCENTILE(SUM(Results.DrawNo))',\n",
              "        'PERCENTILE(TREND(Results.DrawNo, DrawDate))', 'month'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZUhYrWFiRod",
        "colab": {}
      },
      "source": [
        "feature_matrix_selection['time'] = feature_matrix['time']\n",
        "feature_matrix_selection['TotalStrike'] = feature_matrix['TotalStrike']\n",
        "feature_matrix_selection['Label'] = feature_matrix['Label']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMuvyRxvxFIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f68da272-8410-486c-cd5e-fc84ac033e98"
      },
      "source": [
        "feature_matrix_selection.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1029893, 65)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "waeD1ED_kqDB"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9yrJyIVLh5So",
        "colab": {}
      },
      "source": [
        "def to_labels(pos_probs, threshold):\n",
        "    \"\"\"Apply threshold to positive probabilities to create labels.\n",
        "    \"\"\"\n",
        "    return (pos_probs >= threshold).astype('int')\n",
        " \n",
        "\n",
        "def score_optimization(dt, feature_matrix, clf, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    print(\"\\nUse the passed in classifier...\\n\")\n",
        "    # Now predict on the test group\n",
        "    print(\"\\nTEST GROUP\")\n",
        "    y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "    \n",
        "    # keep probabilities for the positive outcome only\n",
        "    probas = clf.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # define thresholds\n",
        "    thresholds = np.arange(0, 1, 0.001)\n",
        "\n",
        "    # evaluate each threshold\n",
        "    scores = [f1_score(y_test, to_labels(probas, t)) for t in thresholds]\n",
        "\n",
        "    # get best threshold\n",
        "    ix = np.argmax(scores)\n",
        "    print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))\n",
        "\n",
        "    # print recall\n",
        "    print(\"\\nRecall:\",recall_score(y_test,y_pred))\n",
        "\n",
        "    # Get imbalanced classification report\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Print confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test,y_pred)\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
        "    plt.show()\n",
        "\n",
        "    # Additionl info\n",
        "    print('\\n\\nAdditional Info')\n",
        "    print('='*40)\n",
        "    positive = np.where((y_pred==1))\n",
        "    print(f'Total predicted to be positive: {len(positive[0])} \\n')\n",
        "\n",
        "    pred = np.where((y_pred==1))\n",
        "    all_preds = pred[0]\n",
        "\n",
        "    # Total predicted matches\n",
        "    print('First 23 matches')\n",
        "    print(23, all_preds[0:23])\n",
        "    print(f'\\n{probas[all_preds[0:23]]}\\n') \n",
        "\n",
        "    print(\"\\nTop 23 Probable Matches\")\n",
        "    #print('probas', probas)\n",
        "    topN = np.argpartition(probas, -23)[-23:]\n",
        "    print(f'\\n{topN}\\n')          # Top N most high probability numbers\n",
        "    print(f'\\n{probas[topN]}\\n')  # Top N probability\n",
        "\n",
        "    # Check for 2 to 3 digits range \n",
        "    print('\\n2 To 3 Digits\\n')\n",
        "    idx_range = np.where((all_preds < 1000) & (all_preds >= 10))\n",
        "    #print(idx_range)\n",
        "    range_numbers = all_preds[idx_range]\n",
        "    print(len(range_numbers), range_numbers)\n",
        "    print(f'\\n{probas[range_numbers]}\\n') \n",
        "\n",
        "\n",
        "    # 2 to 3 Digits > Average Probas\n",
        "    print('\\n2 To 3 Digits Average Proba\\n')\n",
        "    avg_proba = np.average(probas[range_numbers])\n",
        "    print(f'Average proba {avg_proba}\\n')\n",
        "    idx_avg_proba = np.where(probas > avg_proba) \n",
        "    print(len(idx_avg_proba[0]), idx_avg_proba[0])\n",
        "\n",
        "    # 2 to 3 Digits > All Average Probas\n",
        "    print('\\n\\nAll Average Proba\\n')\n",
        "    all_avg_proba = np.average(probas[all_preds])\n",
        "    print(f'All average probas {all_avg_proba}\\n')\n",
        "    idx_all_avg_proba = np.where(probas > all_avg_proba) \n",
        "    print(len(idx_all_avg_proba[0]), idx_all_avg_proba[0])\n",
        "\n",
        "\n",
        "    # All predicted matches\n",
        "    print('\\n\\nAll Predictions\\n')\n",
        "    print(len(all_preds), all_preds)\n",
        "    print()\n",
        "    print(len(probas[all_preds]), probas[all_preds])\n",
        "    \n",
        "    #print('Debug')\n",
        "    #print(pred)\n",
        "    \n",
        "    if len(positive[0]) > 0:\n",
        "    \n",
        "      # Matching draws\n",
        "      print('\\nMatched draws')\n",
        "      md = np.where((y_pred==1) & (y_test==1))\n",
        "      print(f\"Count: {len(md[0])}, Index: {md}\")\n",
        "      month_data = feature_matrix.loc[feature_matrix['time'] == dt]\n",
        "      numbers = month_data.iloc[md[0]][['NumberId']]\n",
        "\n",
        "      print('\\n\\nTop 23 Possibility')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(topN))].head(23))  \n",
        "      \n",
        "      print('\\n\\nFirst 23 Numbers')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(pred[0][0:23]))].head(23))    \n",
        "             \n",
        "\n",
        "      print('\\n\\n2 To 3 Digits Numbers')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(range_numbers))].head(23))    \n",
        "     \n",
        "\n",
        "      print('\\n\\nAll matched')\n",
        "      print(origin_data[(origin_data['DrawDate'].dt.year == dt.year) & \n",
        "                          (origin_data['DrawDate'].dt.month == dt.month) &  \n",
        "                          (origin_data['LuckyNo'].isin(numbers['NumberId']))].head(100))    \n",
        "                                                  \n",
        "    else:\n",
        "      print('No luck this month')  \n",
        "\n",
        "    if len(range_numbers) >= 50:\n",
        "      return False\n",
        "\n",
        "    return True"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pl5ZoepSNPf4",
        "colab": {}
      },
      "source": [
        "def gen_train_test_set(dt, feature_matrix, file_prefix='data'): \n",
        "    \n",
        "    # Subset labels\n",
        "    train_labels = feature_matrix.loc[feature_matrix['time'] < dt, 'Label']\n",
        "    test_labels = feature_matrix.loc[feature_matrix['time'] == dt, 'Label']\n",
        "\n",
        "    # Features - add back 'NumberId', 'month'\n",
        "    X_train = feature_matrix[feature_matrix['time'] < dt].drop(columns = ['time', 'Label', 'TotalStrike', 'year', 'index'], errors='ignore')\n",
        "    X_test = feature_matrix[feature_matrix['time'] == dt].drop(columns = ['time', 'Label', 'TotalStrike', 'year', 'index'], errors='ignore')\n",
        "    feature_names = list(X_train.columns)\n",
        "    \n",
        "    # Labels\n",
        "    y_train = np.array(train_labels).reshape((-1, ))\n",
        "    y_test = np.array(test_labels).reshape((-1, ))\n",
        "    \n",
        "    print('Training on {} observations.'.format(len(X_train)))\n",
        "    print('Testing on {} observations.\\n'.format(len(X_test)))\n",
        "\n",
        "    # Join the train data\n",
        "    train = X_train.join(train_labels)\n",
        "    print('Train data shape: ', train.shape)\n",
        "    print('\\nCounts of strikes vs non-strikes in previous data:')\n",
        "    print(train.Label.value_counts())\n",
        "    print('-'*40)\n",
        "\n",
        "    # sklearn pipeline\n",
        "    pipeline = make_pipeline(\n",
        "        SimpleImputer(strategy = 'constant', fill_value=0),\n",
        "        StandardScaler())\n",
        "    \n",
        "    X_train = pipeline.fit_transform(X_train)\n",
        "    X_test = pipeline.transform(X_test)\n",
        "\n",
        "    # Saving the data\n",
        "    X_train = pd.DataFrame(X_train,columns=feature_names)\n",
        "    y_train = pd.DataFrame(y_train,columns=['Label'])\n",
        "\n",
        "    # For X_test, now only use the selected features\n",
        "    X_test = pd.DataFrame(X_test,columns=feature_names)\n",
        "    y_test = pd.DataFrame(y_test,columns=['Label'])\n",
        "\n",
        "    print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "    print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "    X_train.to_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
        "    y_train.to_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
        "   \n",
        "    X_test.to_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
        "    y_test.to_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
        "\n",
        "    gc.collect()\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PcKlL67TP9UM",
        "colab": {}
      },
      "source": [
        "def model(dt, feature_matrix, file_prefix='data', estimators=300, depth=3):\n",
        "    \"\"\"Predict for a particular month.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load train test\n",
        "    X_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_train.ft\")\n",
        "    y_train = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_train.ft\")\n",
        "    X_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_X_test.ft\")\n",
        "    y_test = pd.read_feather(DATASET_PATH/f\"{file_prefix}_y_test.ft\")\n",
        "\n",
        "    print(f'\\n-----------{dt}-----------------\\n')\n",
        "\n",
        "    # Reshape\n",
        "    y_train = np.array(y_train).reshape((-1, ))\n",
        "    y_test = np.array(y_test).reshape((-1, ))\n",
        "    \n",
        "    print('Data shape')\n",
        "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "    # Calculate hit ratio for xgboost classifier\n",
        "    print(\"\\nCalculating scale pos weight\")\n",
        "    counter = Counter(y_train)\n",
        "    print(Counter(y_train))\n",
        "    scale_pos_weight = float(counter[0] / counter[1])\n",
        "    print(f\"\\nScale pos weight - {scale_pos_weight}\\n\")\n",
        "    \n",
        "     # Modeling\n",
        "    eval_set=[(X_train, y_train), (X_test, y_test)]\n",
        "    clf = xgb.XGBClassifier(\n",
        "                    n_jobs=4, \n",
        "                    random_state=42,\n",
        "                    objective='binary:logistic',\n",
        "                    #subsample=0.55, \n",
        "                    n_estimators=estimators,\n",
        "                    #min_child_weight=1,\n",
        "                    max_depth=depth, \n",
        "                    learning_rate=0.007,\n",
        "                    #gamma=0.1, \n",
        "                    #colsample_bytree=0.95,\n",
        "                    #tree_method='hist',\n",
        "                    booster='dart',\n",
        "                    scale_pos_weight=scale_pos_weight,\n",
        "                    eval_metric='auc',\n",
        "                    #eval_set=eval_set,\n",
        "                    #early_stopping_rounds=10\n",
        "                    )\n",
        "\n",
        "    clf_params = clf.get_params()\n",
        "    print(clf_params)\n",
        "\n",
        "    # Test and validate\n",
        "    ret_val = score_optimization(dt,\n",
        "                       feature_matrix,\n",
        "                       clf, \n",
        "                       X_train, \n",
        "                       y_train, \n",
        "                       X_test, \n",
        "                       y_test)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    return ret_val"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ns3Puh7Gnxl5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "0ef33a85-1116-4a6c-d291-5f31acc0615e"
      },
      "source": [
        "target_mth = pd.datetime(2020,2,1)\n",
        "%time gen_train_test_set(target_mth, feature_matrix_selection, file_prefix='test')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on 969893 observations.\n",
            "Testing on 10000 observations.\n",
            "\n",
            "Train data shape:  (969893, 63)\n",
            "\n",
            "Counts of strikes vs non-strikes in previous data:\n",
            "0    937508\n",
            "1     32385\n",
            "Name: Label, dtype: int64\n",
            "----------------------------------------\n",
            "X_train: (969893, 62), y_train: (969893, 1)\n",
            "X_test: (10000, 62), y_test: (10000, 1)\n",
            "CPU times: user 2.5 s, sys: 433 ms, total: 2.93 s\n",
            "Wall time: 3.83 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaZLnkONsWtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7899c8a1-e75a-4ae6-a7cc-995cda4df1e6"
      },
      "source": [
        "#for (estimators, depth) in ((300,3), (500,6), (550,6), (600,6)):\n",
        "for (estimators, depth) in ((300,3),):\n",
        "  %time model(target_mth, feature_matrix_selection, file_prefix='test', estimators=estimators, depth=depth)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-----------2020-02-01 00:00:00-----------------\n",
            "\n",
            "Data shape\n",
            "(969893, 62) (969893,) (10000, 62) (10000,)\n",
            "\n",
            "Calculating scale pos weight\n",
            "Counter({0: 937508, 1: 32385})\n",
            "\n",
            "Scale pos weight - 28.94883433688436\n",
            "\n",
            "{'objective': 'binary:logistic', 'base_score': None, 'booster': 'dart', 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'gamma': None, 'gpu_id': None, 'importance_type': 'gain', 'interaction_constraints': None, 'learning_rate': 0.007, 'max_delta_step': None, 'max_depth': 3, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 300, 'n_jobs': 4, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'scale_pos_weight': 28.94883433688436, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'eval_metric': 'auc'}\n",
            "\n",
            "Use the passed in classifier...\n",
            "\n",
            "\n",
            "TEST GROUP\n",
            "Threshold=0.491, F-Score=0.06155\n",
            "\n",
            "Recall: 0.17034700315457413\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.81      0.88      9683\n",
            "           1       0.03      0.17      0.05       317\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.50      0.49      0.47     10000\n",
            "weighted avg       0.94      0.79      0.86     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Additional Info\n",
            "========================================\n",
            "Total predicted to be positive: 1896 \n",
            "\n",
            "First 23 matches\n",
            "23 [  0  17  19  20  28  33  35  42  52  54  61  70  72  76  79  80  81  86\n",
            "  96  97  98 102 107]\n",
            "\n",
            "[0.5013311  0.5321198  0.5643916  0.50540155 0.5025578  0.5007135\n",
            " 0.52291733 0.50229317 0.50119203 0.50352496 0.52869874 0.50094324\n",
            " 0.50231284 0.50470066 0.53259826 0.509858   0.56403095 0.5133421\n",
            " 0.5009181  0.56316847 0.50924486 0.50106734 0.5166235 ]\n",
            "\n",
            "\n",
            "Top 23 Probable Matches\n",
            "\n",
            "[5371  592 1096 2922 9584 7079 6901 2298 5923 9270 9514 4185 4133 7550\n",
            " 8115 2244  625 2866 6908 4542 4710 1668 2335]\n",
            "\n",
            "\n",
            "[0.56682503 0.5671298  0.56987476 0.56865776 0.56990695 0.5685524\n",
            " 0.57083154 0.56987965 0.5711289  0.57138413 0.5713432  0.5720327\n",
            " 0.5723979  0.5759232  0.57383686 0.5729982  0.58072776 0.5752186\n",
            " 0.5720327  0.57484883 0.5753069  0.5754032  0.574818  ]\n",
            "\n",
            "\n",
            "2 To 3 Digits\n",
            "\n",
            "269 [ 17  19  20  28  33  35  42  52  54  61  70  72  76  79  80  81  86  96\n",
            "  97  98 102 107 113 115 125 132 138 144 148 151 152 160 163 179 184 189\n",
            " 193 195 197 199 202 210 212 217 219 220 222 226 230 240 242 243 247 258\n",
            " 264 270 272 274 279 281 282 283 288 298 299 301 302 308 313 314 320 321\n",
            " 323 324 325 328 329 330 331 341 345 349 352 353 354 361 363 376 382 386\n",
            " 391 392 393 394 402 407 408 409 411 415 418 421 425 429 430 431 437 442\n",
            " 446 450 454 459 463 464 467 468 474 479 480 483 485 487 492 495 496 498\n",
            " 502 505 507 510 519 520 525 527 533 535 537 538 540 546 550 551 557 567\n",
            " 568 569 575 581 582 585 587 589 592 598 603 604 609 611 614 616 618 619\n",
            " 622 625 630 634 637 642 645 649 650 651 659 661 662 666 667 672 682 683\n",
            " 689 692 695 697 699 706 716 720 721 733 739 743 744 745 746 747 757 764\n",
            " 771 773 776 778 780 782 796 801 802 803 806 807 809 810 811 817 818 819\n",
            " 823 824 828 831 832 833 835 839 848 855 858 861 862 868 871 876 886 887\n",
            " 888 890 892 893 895 897 903 905 910 913 914 922 923 925 926 928 934 940\n",
            " 941 950 952 953 959 961 963 965 966 967 973 974 980 981 987 993 994]\n",
            "\n",
            "[0.5321198  0.5643916  0.50540155 0.5025578  0.5007135  0.52291733\n",
            " 0.50229317 0.50119203 0.50352496 0.52869874 0.50094324 0.50231284\n",
            " 0.50470066 0.53259826 0.509858   0.56403095 0.5133421  0.5009181\n",
            " 0.56316847 0.50924486 0.50106734 0.5166235  0.50074786 0.5012822\n",
            " 0.501986   0.5004746  0.56558573 0.5284014  0.50028265 0.50060827\n",
            " 0.50124097 0.558176   0.5013876  0.5056122  0.50052834 0.56369877\n",
            " 0.50022835 0.5322862  0.5051004  0.5027739  0.50688976 0.5033902\n",
            " 0.5294236  0.5005939  0.50091195 0.5029511  0.5013214  0.500574\n",
            " 0.511833   0.5034596  0.50862813 0.5034164  0.51846015 0.50211215\n",
            " 0.51240593 0.50066894 0.5061511  0.5064978  0.50242484 0.50024027\n",
            " 0.50124097 0.50124097 0.5051741  0.5073249  0.5294224  0.5132415\n",
            " 0.5372837  0.50141376 0.5015462  0.5008765  0.532419   0.5060627\n",
            " 0.5019193  0.50604427 0.5182449  0.5003652  0.5030048  0.502123\n",
            " 0.5022707  0.50170547 0.532262   0.56403095 0.5030293  0.5334074\n",
            " 0.51014394 0.5621744  0.5034278  0.5001179  0.501755   0.50300294\n",
            " 0.5035149  0.5002241  0.5087422  0.5058812  0.50669396 0.51930624\n",
            " 0.53670514 0.5500819  0.50133824 0.5011151  0.5010333  0.5007001\n",
            " 0.50599873 0.5015219  0.5069661  0.5039471  0.5028714  0.50059754\n",
            " 0.5025381  0.50092745 0.50137734 0.5152513  0.5067466  0.5338032\n",
            " 0.50222945 0.50246775 0.51242954 0.50043917 0.5015623  0.5036435\n",
            " 0.56569785 0.5025058  0.51798797 0.51785505 0.50697    0.5010311\n",
            " 0.51642996 0.50635636 0.5012353  0.53516597 0.5017076  0.5192768\n",
            " 0.50689197 0.5005774  0.5647545  0.5017076  0.50067943 0.50149727\n",
            " 0.5159107  0.5043216  0.50411296 0.5309612  0.50017625 0.50359875\n",
            " 0.5014417  0.50032747 0.50018597 0.5002602  0.50284475 0.50321746\n",
            " 0.50475395 0.5607975  0.5671298  0.5056169  0.5020453  0.50347275\n",
            " 0.5292822  0.50170135 0.50246817 0.501104   0.50798    0.50389034\n",
            " 0.5084046  0.58072776 0.5022982  0.50069547 0.5009143  0.52966285\n",
            " 0.5097844  0.5020306  0.50216216 0.5096418  0.5000343  0.51206887\n",
            " 0.5004841  0.5040186  0.50200415 0.50194836 0.5003078  0.50283337\n",
            " 0.55041414 0.5012657  0.5015415  0.50500005 0.5033086  0.5036775\n",
            " 0.50428474 0.50190014 0.52988076 0.56476694 0.56258905 0.50294966\n",
            " 0.50244653 0.5017703  0.54427826 0.50495577 0.5020556  0.5017635\n",
            " 0.5018059  0.5087097  0.5017808  0.50061023 0.5113542  0.5255153\n",
            " 0.5030103  0.50323284 0.5007795  0.50129616 0.5027955  0.50083625\n",
            " 0.50286466 0.5068699  0.500603   0.50201815 0.5022165  0.50430596\n",
            " 0.556622   0.5158973  0.5003564  0.50099915 0.50566113 0.5016164\n",
            " 0.5039857  0.5012091  0.5016459  0.50139725 0.50635636 0.527111\n",
            " 0.50203353 0.5070629  0.500386   0.50528383 0.5003231  0.5008908\n",
            " 0.5156976  0.51571846 0.5011334  0.51846594 0.5027566  0.50111365\n",
            " 0.50018656 0.5187291  0.51622134 0.508936   0.5090903  0.5025422\n",
            " 0.50208914 0.5044141  0.51617265 0.5046     0.52983665 0.50380933\n",
            " 0.5038038  0.5604905  0.5037358  0.535763   0.50873846 0.5015785\n",
            " 0.50244653 0.51247984 0.5382781  0.5025559  0.5016938  0.5039406\n",
            " 0.5031924  0.56410915 0.50229216 0.5047097  0.50340605]\n",
            "\n",
            "\n",
            "2 To 3 Digits Average Proba\n",
            "\n",
            "Average proba 0.511268675327301\n",
            "\n",
            "841 [  17   19   35   61   79   81   86   97  107  138  144  160  189  195\n",
            "  212  230  247  264  299  301  302  320  325  345  349  353  361  407\n",
            "  408  409  459  464  474  485  492  495  502  510  520  533  540  551\n",
            "  589  592  609  625  642  661  689  721  733  739  746  780  782  823\n",
            "  824  861  888  890  893  905  910  926  934  950  953  965  966  981\n",
            " 1021 1063 1070 1079 1096 1098 1121 1127 1141 1147 1155 1172 1177 1214\n",
            " 1215 1228 1230 1271 1274 1293 1305 1309 1315 1322 1323 1327 1333 1336\n",
            " 1360 1371 1386 1447 1448 1452 1463 1468 1482 1486 1494 1500 1502 1509\n",
            " 1520 1558 1567 1575 1577 1584 1589 1606 1608 1613 1624 1646 1649 1659\n",
            " 1668 1683 1691 1722 1742 1751 1762 1763 1770 1780 1789 1845 1862 1870\n",
            " 1893 1899 1905 1906 1922 1925 1933 1945 1949 1955 1973 2008 2017 2029\n",
            " 2030 2058 2090 2106 2135 2151 2168 2170 2173 2174 2232 2233 2243 2244\n",
            " 2254 2255 2263 2275 2277 2290 2291 2298 2307 2319 2328 2331 2335 2342\n",
            " 2360 2361 2364 2388 2411 2420 2439 2440 2448 2453 2455 2471 2479 2497\n",
            " 2532 2572 2596 2597 2609 2636 2641 2643 2663 2664 2665 2685 2716 2719\n",
            " 2725 2762 2763 2775 2784 2787 2806 2809 2816 2817 2836 2846 2863 2866\n",
            " 2871 2874 2888 2895 2914 2918 2922 2923 2928 2932 2942 2957 2992 3013\n",
            " 3016 3019 3035 3037 3038 3040 3041 3051 3058 3061 3087 3114 3156 3160\n",
            " 3162 3178 3184 3185 3195 3202 3219 3233 3236 3255 3267 3275 3279 3284\n",
            " 3295 3306 3323 3343 3345 3348 3360 3372 3377 3382 3384 3388 3392 3401\n",
            " 3406 3411 3440 3446 3471 3474 3489 3499 3508 3517 3518 3519 3522 3523\n",
            " 3525 3545 3558 3570 3578 3591 3634 3651 3665 3692 3695 3697 3701 3706\n",
            " 3722 3754 3773 3775 3794 3801 3810 3815 3846 3857 3871 3879 3880 3889\n",
            " 3890 3898 3919 3921 3930 3931 3935 3944 3963 3984 3985 4000 4026 4036\n",
            " 4042 4044 4051 4055 4071 4088 4100 4116 4133 4140 4148 4152 4155 4162\n",
            " 4164 4176 4185 4193 4195 4227 4228 4233 4236 4254 4261 4274 4277 4282\n",
            " 4290 4291 4302 4304 4339 4342 4352 4366 4369 4374 4378 4395 4406 4410\n",
            " 4414 4425 4427 4436 4465 4484 4487 4496 4505 4512 4516 4519 4528 4529\n",
            " 4542 4558 4559 4562 4563 4574 4585 4597 4609 4630 4638 4640 4642 4648\n",
            " 4659 4680 4682 4694 4702 4710 4738 4742 4754 4758 4761 4770 4791 4804\n",
            " 4809 4814 4823 4828 4838 4868 4905 4930 4931 4944 4952 4959 5009 5012\n",
            " 5017 5029 5070 5104 5115 5122 5170 5191 5219 5220 5268 5284 5286 5293\n",
            " 5298 5311 5321 5334 5338 5349 5371 5372 5378 5395 5409 5428 5431 5464\n",
            " 5465 5472 5474 5485 5490 5513 5516 5517 5555 5559 5587 5604 5619 5627\n",
            " 5639 5655 5661 5664 5683 5693 5707 5716 5728 5745 5794 5799 5850 5860\n",
            " 5866 5873 5886 5890 5894 5923 5932 5941 5949 5976 6015 6032 6043 6069\n",
            " 6070 6077 6106 6111 6114 6121 6122 6135 6144 6174 6181 6182 6186 6190\n",
            " 6195 6204 6206 6212 6218 6221 6226 6231 6235 6251 6253 6260 6298 6309\n",
            " 6321 6326 6330 6350 6356 6368 6373 6375 6385 6409 6431 6440 6482 6489\n",
            " 6493 6498 6500 6507 6531 6540 6551 6565 6582 6594 6606 6652 6665 6669\n",
            " 6671 6683 6684 6685 6702 6719 6742 6745 6754 6757 6761 6784 6785 6792\n",
            " 6795 6817 6820 6839 6847 6854 6880 6901 6908 6947 6987 7007 7030 7031\n",
            " 7079 7117 7121 7122 7139 7146 7156 7164 7173 7177 7188 7202 7203 7212\n",
            " 7225 7226 7227 7241 7260 7263 7266 7280 7327 7329 7358 7374 7384 7385\n",
            " 7388 7395 7405 7406 7410 7413 7433 7450 7455 7462 7476 7478 7488 7495\n",
            " 7497 7506 7518 7529 7548 7550 7573 7580 7582 7586 7591 7599 7607 7610\n",
            " 7612 7633 7635 7646 7663 7669 7690 7694 7696 7704 7710 7728 7740 7747\n",
            " 7757 7763 7790 7792 7799 7804 7818 7836 7868 7869 7873 7877 7891 7894\n",
            " 7904 7917 7926 7928 7944 7983 7986 7990 7995 8018 8036 8038 8046 8049\n",
            " 8060 8062 8088 8115 8120 8143 8200 8234 8240 8258 8261 8270 8285 8296\n",
            " 8315 8325 8327 8328 8341 8356 8364 8376 8382 8388 8390 8403 8419 8435\n",
            " 8449 8480 8516 8539 8569 8591 8592 8608 8619 8625 8653 8660 8675 8683\n",
            " 8685 8690 8696 8724 8726 8735 8738 8755 8765 8776 8797 8800 8816 8823\n",
            " 8825 8835 8863 8875 8900 8909 8928 8933 8938 8941 8970 8995 9000 9004\n",
            " 9009 9013 9019 9023 9031 9037 9044 9058 9082 9099 9106 9125 9126 9128\n",
            " 9129 9179 9180 9188 9220 9221 9227 9238 9258 9260 9270 9275 9285 9296\n",
            " 9309 9326 9344 9350 9358 9365 9387 9388 9405 9417 9451 9499 9500 9505\n",
            " 9509 9512 9514 9532 9584 9594 9598 9605 9606 9607 9623 9667 9680 9690\n",
            " 9695 9697 9709 9724 9730 9733 9762 9765 9766 9777 9788 9791 9803 9827\n",
            " 9841 9844 9850 9859 9867 9885 9891 9894 9901 9909 9924 9963 9976 9989\n",
            " 9999]\n",
            "\n",
            "\n",
            "All Average Proba\n",
            "\n",
            "All average probas 0.5167262554168701\n",
            "\n",
            "694 [  17   19   35   61   79   81   97  138  144  160  189  195  212  247\n",
            "  299  302  320  325  345  349  353  361  407  408  409  464  485  492\n",
            "  495  510  520  533  551  589  592  609  625  642  689  721  733  739\n",
            "  746  782  823  861  893  905  934  950  953  966  981 1021 1070 1079\n",
            " 1096 1098 1121 1127 1141 1147 1155 1172 1214 1215 1228 1230 1271 1274\n",
            " 1293 1305 1309 1315 1322 1333 1336 1360 1371 1386 1447 1448 1463 1482\n",
            " 1494 1500 1502 1509 1520 1558 1575 1584 1589 1608 1613 1646 1649 1659\n",
            " 1668 1683 1691 1722 1742 1751 1762 1763 1770 1780 1789 1845 1862 1870\n",
            " 1893 1899 1906 1922 1925 1933 1945 1973 2008 2029 2058 2090 2106 2135\n",
            " 2151 2168 2170 2174 2232 2233 2243 2244 2254 2255 2263 2277 2290 2291\n",
            " 2298 2307 2319 2328 2331 2335 2342 2360 2361 2364 2388 2411 2420 2439\n",
            " 2440 2448 2453 2455 2471 2479 2532 2596 2597 2636 2643 2664 2665 2685\n",
            " 2716 2719 2762 2763 2775 2784 2787 2806 2809 2816 2836 2846 2863 2866\n",
            " 2874 2895 2918 2922 2932 2942 2957 2992 3013 3016 3035 3037 3040 3041\n",
            " 3051 3058 3061 3087 3114 3160 3162 3178 3184 3185 3195 3202 3233 3255\n",
            " 3275 3279 3284 3295 3323 3343 3345 3348 3360 3377 3382 3384 3388 3392\n",
            " 3406 3440 3446 3471 3474 3489 3499 3508 3517 3519 3523 3525 3545 3558\n",
            " 3570 3578 3591 3695 3697 3701 3706 3722 3773 3794 3801 3810 3815 3846\n",
            " 3857 3871 3879 3880 3889 3890 3898 3921 3930 3931 3935 3944 3963 3984\n",
            " 3985 4000 4026 4036 4042 4044 4051 4055 4071 4088 4100 4116 4133 4140\n",
            " 4152 4155 4162 4164 4176 4185 4193 4195 4227 4228 4233 4254 4261 4274\n",
            " 4282 4290 4291 4302 4304 4342 4352 4366 4369 4378 4395 4410 4414 4425\n",
            " 4427 4436 4465 4484 4487 4496 4505 4512 4519 4528 4529 4542 4558 4559\n",
            " 4562 4574 4585 4597 4609 4630 4638 4640 4642 4648 4659 4682 4694 4702\n",
            " 4710 4738 4742 4754 4758 4761 4770 4791 4804 4809 4814 4828 4838 4868\n",
            " 4905 4930 4952 4959 5012 5017 5029 5070 5104 5122 5170 5219 5220 5268\n",
            " 5284 5286 5293 5311 5321 5334 5338 5349 5371 5372 5378 5395 5409 5428\n",
            " 5431 5464 5465 5472 5474 5485 5490 5513 5516 5517 5555 5559 5587 5604\n",
            " 5619 5639 5655 5661 5664 5683 5707 5716 5745 5794 5799 5850 5860 5866\n",
            " 5873 5886 5894 5923 5932 5941 5949 5976 6015 6032 6043 6069 6070 6106\n",
            " 6111 6114 6121 6122 6135 6144 6174 6181 6182 6186 6195 6206 6212 6218\n",
            " 6221 6231 6251 6253 6260 6298 6309 6321 6326 6350 6356 6368 6373 6375\n",
            " 6385 6409 6431 6440 6482 6489 6500 6531 6540 6551 6565 6582 6594 6606\n",
            " 6652 6665 6669 6671 6683 6684 6685 6702 6719 6745 6754 6757 6761 6784\n",
            " 6785 6792 6795 6817 6839 6847 6854 6901 6908 6947 6987 7007 7030 7079\n",
            " 7117 7121 7122 7139 7146 7156 7164 7177 7202 7203 7212 7225 7226 7227\n",
            " 7241 7260 7263 7266 7280 7327 7329 7358 7374 7385 7388 7395 7405 7406\n",
            " 7413 7433 7455 7462 7478 7488 7495 7497 7518 7529 7548 7550 7573 7580\n",
            " 7582 7591 7599 7607 7612 7633 7635 7646 7663 7669 7690 7694 7696 7710\n",
            " 7740 7747 7757 7763 7790 7799 7804 7818 7836 7868 7873 7877 7891 7894\n",
            " 7904 7917 7926 7928 7944 7986 7990 7995 8036 8038 8049 8060 8062 8088\n",
            " 8115 8143 8200 8234 8258 8261 8270 8285 8296 8315 8325 8327 8328 8341\n",
            " 8356 8376 8382 8388 8390 8403 8419 8435 8449 8539 8591 8608 8619 8625\n",
            " 8653 8660 8675 8683 8690 8696 8726 8735 8738 8755 8765 8776 8797 8800\n",
            " 8816 8835 8863 8900 8909 8928 8933 8938 9004 9009 9013 9019 9031 9037\n",
            " 9044 9058 9082 9099 9106 9125 9126 9129 9179 9180 9188 9220 9221 9227\n",
            " 9258 9270 9285 9296 9309 9326 9344 9350 9358 9365 9387 9451 9499 9500\n",
            " 9505 9514 9584 9594 9598 9605 9606 9607 9623 9667 9680 9690 9695 9697\n",
            " 9724 9730 9733 9762 9765 9766 9777 9788 9791 9803 9827 9841 9844 9850\n",
            " 9859 9867 9891 9909 9924 9963 9976 9989]\n",
            "\n",
            "\n",
            "All Predictions\n",
            "\n",
            "1896 [   0   17   19   20   28   33   35   42   52   54   61   70   72   76\n",
            "   79   80   81   86   96   97   98  102  107  113  115  125  132  138\n",
            "  144  148  151  152  160  163  179  184  189  193  195  197  199  202\n",
            "  210  212  217  219  220  222  226  230  240  242  243  247  258  264\n",
            "  270  272  274  279  281  282  283  288  298  299  301  302  308  313\n",
            "  314  320  321  323  324  325  328  329  330  331  341  345  349  352\n",
            "  353  354  361  363  376  382  386  391  392  393  394  402  407  408\n",
            "  409  411  415  418  421  425  429  430  431  437  442  446  450  454\n",
            "  459  463  464  467  468  474  479  480  483  485  487  492  495  496\n",
            "  498  502  505  507  510  519  520  525  527  533  535  537  538  540\n",
            "  546  550  551  557  567  568  569  575  581  582  585  587  589  592\n",
            "  598  603  604  609  611  614  616  618  619  622  625  630  634  637\n",
            "  642  645  649  650  651  659  661  662  666  667  672  682  683  689\n",
            "  692  695  697  699  706  716  720  721  733  739  743  744  745  746\n",
            "  747  757  764  771  773  776  778  780  782  796  801  802  803  806\n",
            "  807  809  810  811  817  818  819  823  824  828  831  832  833  835\n",
            "  839  848  855  858  861  862  868  871  876  886  887  888  890  892\n",
            "  893  895  897  903  905  910  913  914  922  923  925  926  928  934\n",
            "  940  941  950  952  953  959  961  963  965  966  967  973  974  980\n",
            "  981  987  993  994 1003 1005 1009 1011 1017 1018 1021 1026 1037 1039\n",
            " 1050 1053 1061 1063 1064 1069 1070 1073 1079 1090 1095 1096 1098 1112\n",
            " 1115 1121 1126 1127 1134 1141 1147 1155 1164 1172 1176 1177 1198 1206\n",
            " 1207 1208 1212 1214 1215 1216 1227 1228 1230 1231 1239 1241 1245 1249\n",
            " 1253 1255 1256 1257 1263 1269 1271 1274 1276 1284 1287 1288 1289 1292\n",
            " 1293 1294 1299 1300 1305 1309 1312 1315 1320 1322 1323 1327 1333 1336\n",
            " 1337 1351 1360 1362 1369 1371 1378 1379 1386 1390 1409 1413 1415 1422\n",
            " 1423 1431 1435 1445 1447 1448 1451 1452 1453 1455 1461 1463 1467 1468\n",
            " 1474 1476 1482 1486 1489 1491 1494 1500 1502 1505 1508 1509 1520 1526\n",
            " 1531 1535 1542 1551 1552 1555 1558 1567 1570 1575 1577 1584 1589 1591\n",
            " 1593 1597 1603 1606 1608 1612 1613 1615 1624 1626 1637 1643 1646 1648\n",
            " 1649 1651 1658 1659 1668 1671 1677 1683 1686 1691 1694 1696 1702 1708\n",
            " 1713 1715 1716 1722 1723 1738 1739 1742 1747 1751 1752 1755 1758 1760\n",
            " 1762 1763 1766 1770 1773 1780 1789 1798 1807 1832 1840 1843 1845 1853\n",
            " 1859 1862 1867 1870 1879 1882 1883 1884 1886 1893 1894 1899 1905 1906\n",
            " 1911 1913 1922 1925 1928 1933 1936 1938 1940 1945 1946 1949 1952 1955\n",
            " 1973 1980 1989 1991 1994 2008 2010 2011 2017 2020 2029 2030 2036 2037\n",
            " 2046 2050 2053 2055 2056 2058 2073 2087 2090 2092 2105 2106 2107 2110\n",
            " 2131 2133 2135 2144 2145 2149 2151 2156 2157 2162 2163 2168 2170 2172\n",
            " 2173 2174 2181 2185 2188 2190 2192 2198 2203 2207 2209 2211 2232 2233\n",
            " 2238 2243 2244 2248 2251 2254 2255 2256 2258 2260 2263 2269 2274 2275\n",
            " 2277 2278 2290 2291 2298 2302 2307 2310 2311 2314 2315 2317 2319 2325\n",
            " 2326 2327 2328 2331 2335 2341 2342 2343 2348 2351 2356 2360 2361 2364\n",
            " 2367 2370 2388 2390 2392 2393 2398 2403 2407 2411 2413 2416 2418 2419\n",
            " 2420 2421 2422 2425 2436 2439 2440 2441 2444 2445 2448 2451 2453 2455\n",
            " 2461 2466 2470 2471 2472 2479 2483 2489 2491 2497 2502 2512 2514 2517\n",
            " 2525 2532 2533 2539 2545 2550 2552 2556 2560 2562 2566 2572 2581 2596\n",
            " 2597 2603 2608 2609 2614 2626 2628 2636 2641 2643 2645 2660 2663 2664\n",
            " 2665 2669 2671 2674 2679 2685 2692 2696 2704 2716 2719 2723 2725 2729\n",
            " 2741 2746 2750 2759 2762 2763 2769 2770 2775 2779 2784 2787 2806 2809\n",
            " 2813 2816 2817 2821 2822 2836 2839 2842 2844 2846 2848 2860 2863 2865\n",
            " 2866 2869 2871 2872 2874 2887 2888 2895 2897 2906 2914 2915 2916 2918\n",
            " 2922 2923 2928 2932 2934 2936 2939 2942 2951 2952 2954 2956 2957 2964\n",
            " 2990 2992 2996 3005 3007 3009 3010 3013 3016 3019 3026 3029 3033 3034\n",
            " 3035 3037 3038 3039 3040 3041 3043 3045 3048 3051 3058 3061 3066 3074\n",
            " 3087 3090 3091 3099 3104 3113 3114 3125 3132 3138 3139 3145 3152 3154\n",
            " 3156 3160 3162 3163 3170 3171 3178 3184 3185 3195 3202 3216 3219 3222\n",
            " 3233 3236 3254 3255 3266 3267 3269 3275 3279 3284 3285 3290 3291 3295\n",
            " 3296 3302 3306 3313 3320 3323 3334 3343 3345 3348 3360 3361 3372 3377\n",
            " 3382 3384 3386 3388 3392 3397 3400 3401 3406 3411 3427 3431 3437 3440\n",
            " 3442 3444 3446 3453 3464 3465 3471 3474 3477 3479 3482 3485 3489 3494\n",
            " 3495 3499 3508 3516 3517 3518 3519 3522 3523 3525 3526 3544 3545 3547\n",
            " 3554 3558 3568 3570 3576 3578 3591 3595 3600 3611 3615 3620 3624 3634\n",
            " 3637 3644 3647 3651 3653 3665 3675 3682 3692 3693 3695 3697 3701 3704\n",
            " 3706 3710 3716 3722 3733 3737 3754 3755 3756 3760 3773 3775 3781 3794\n",
            " 3801 3804 3810 3811 3814 3815 3816 3818 3828 3830 3835 3846 3857 3866\n",
            " 3871 3879 3880 3889 3890 3894 3898 3899 3908 3919 3921 3930 3931 3935\n",
            " 3940 3944 3952 3960 3963 3968 3984 3985 4000 4016 4026 4036 4042 4044\n",
            " 4051 4053 4055 4071 4079 4088 4098 4100 4111 4112 4116 4123 4126 4133\n",
            " 4134 4140 4148 4150 4152 4155 4162 4164 4176 4178 4184 4185 4187 4193\n",
            " 4195 4223 4227 4228 4233 4236 4251 4254 4261 4269 4272 4274 4277 4282\n",
            " 4290 4291 4302 4304 4321 4323 4336 4339 4342 4352 4358 4366 4369 4373\n",
            " 4374 4378 4395 4398 4406 4410 4414 4425 4427 4436 4446 4457 4465 4466\n",
            " 4479 4484 4487 4488 4490 4496 4503 4505 4512 4516 4519 4526 4528 4529\n",
            " 4542 4553 4558 4559 4562 4563 4574 4576 4585 4597 4603 4604 4609 4630\n",
            " 4638 4639 4640 4642 4648 4659 4662 4672 4675 4680 4682 4693 4694 4695\n",
            " 4697 4698 4702 4710 4729 4738 4742 4753 4754 4758 4761 4763 4770 4778\n",
            " 4780 4781 4791 4792 4802 4804 4809 4814 4819 4823 4828 4832 4838 4846\n",
            " 4851 4852 4855 4859 4861 4868 4874 4889 4891 4895 4905 4921 4923 4924\n",
            " 4930 4931 4934 4944 4952 4959 4969 4974 4976 5000 5009 5012 5017 5018\n",
            " 5024 5029 5047 5062 5066 5070 5075 5080 5084 5087 5092 5099 5104 5106\n",
            " 5115 5122 5130 5133 5143 5150 5170 5183 5191 5193 5204 5213 5219 5220\n",
            " 5226 5234 5240 5249 5267 5268 5284 5286 5293 5298 5301 5311 5312 5321\n",
            " 5332 5334 5338 5349 5351 5365 5371 5372 5378 5395 5398 5409 5415 5418\n",
            " 5428 5431 5437 5444 5459 5464 5465 5469 5472 5474 5478 5485 5489 5490\n",
            " 5491 5499 5513 5516 5517 5521 5523 5538 5546 5553 5555 5559 5576 5587\n",
            " 5593 5602 5604 5619 5623 5627 5631 5639 5641 5655 5661 5664 5673 5683\n",
            " 5693 5707 5716 5717 5725 5726 5728 5739 5744 5745 5761 5778 5792 5794\n",
            " 5799 5814 5820 5824 5825 5827 5837 5845 5850 5860 5866 5867 5873 5886\n",
            " 5890 5894 5907 5908 5909 5923 5932 5941 5949 5967 5976 5989 6015 6019\n",
            " 6027 6029 6032 6043 6045 6055 6056 6060 6061 6064 6069 6070 6076 6077\n",
            " 6088 6090 6106 6111 6114 6117 6120 6121 6122 6135 6144 6174 6181 6182\n",
            " 6186 6189 6190 6195 6204 6206 6212 6214 6218 6219 6220 6221 6222 6226\n",
            " 6231 6235 6236 6239 6251 6253 6254 6260 6269 6273 6295 6298 6309 6321\n",
            " 6326 6330 6350 6352 6353 6356 6359 6368 6373 6375 6385 6409 6431 6432\n",
            " 6439 6440 6463 6468 6473 6477 6481 6482 6483 6489 6492 6493 6496 6498\n",
            " 6500 6507 6531 6537 6540 6543 6551 6557 6565 6567 6571 6582 6583 6592\n",
            " 6594 6601 6606 6609 6620 6635 6652 6665 6668 6669 6671 6682 6683 6684\n",
            " 6685 6702 6711 6719 6735 6742 6745 6749 6754 6757 6761 6770 6772 6781\n",
            " 6784 6785 6792 6795 6817 6820 6822 6839 6847 6854 6863 6866 6867 6874\n",
            " 6880 6896 6901 6906 6908 6913 6917 6923 6926 6935 6945 6947 6972 6976\n",
            " 6983 6987 6992 6995 7007 7030 7031 7061 7079 7082 7117 7121 7122 7131\n",
            " 7134 7139 7143 7146 7156 7160 7162 7164 7173 7177 7188 7198 7202 7203\n",
            " 7210 7211 7212 7225 7226 7227 7231 7236 7241 7251 7260 7263 7264 7266\n",
            " 7280 7294 7295 7302 7316 7317 7318 7327 7329 7358 7374 7384 7385 7388\n",
            " 7395 7396 7397 7400 7402 7405 7406 7410 7413 7433 7440 7450 7455 7457\n",
            " 7462 7476 7478 7484 7488 7495 7497 7498 7506 7513 7518 7528 7529 7535\n",
            " 7539 7548 7550 7555 7562 7566 7567 7569 7573 7577 7578 7580 7582 7584\n",
            " 7586 7587 7590 7591 7599 7607 7610 7612 7613 7622 7633 7635 7646 7649\n",
            " 7663 7665 7669 7686 7690 7694 7696 7704 7710 7722 7728 7730 7740 7747\n",
            " 7750 7757 7761 7763 7783 7790 7792 7798 7799 7804 7813 7818 7820 7836\n",
            " 7837 7849 7862 7868 7869 7873 7877 7890 7891 7894 7904 7908 7910 7916\n",
            " 7917 7922 7926 7928 7931 7944 7970 7981 7983 7986 7990 7995 8004 8009\n",
            " 8018 8031 8036 8038 8039 8042 8046 8049 8051 8053 8060 8062 8082 8088\n",
            " 8093 8095 8111 8115 8120 8130 8137 8143 8144 8152 8160 8175 8177 8183\n",
            " 8186 8200 8217 8234 8240 8244 8250 8258 8261 8265 8266 8270 8271 8283\n",
            " 8285 8286 8295 8296 8298 8315 8322 8324 8325 8327 8328 8330 8334 8341\n",
            " 8354 8356 8364 8376 8382 8388 8390 8395 8403 8411 8419 8421 8428 8429\n",
            " 8435 8437 8439 8444 8445 8449 8465 8474 8477 8480 8499 8516 8524 8533\n",
            " 8539 8558 8569 8590 8591 8592 8608 8619 8625 8635 8639 8650 8653 8660\n",
            " 8670 8675 8683 8685 8690 8696 8724 8726 8731 8735 8738 8746 8755 8765\n",
            " 8771 8772 8776 8782 8793 8797 8799 8800 8816 8823 8825 8835 8837 8862\n",
            " 8863 8875 8878 8884 8890 8897 8900 8908 8909 8911 8918 8928 8933 8938\n",
            " 8941 8954 8965 8968 8970 8981 8983 8987 8995 8997 9000 9001 9004 9009\n",
            " 9013 9018 9019 9023 9031 9037 9044 9053 9058 9082 9099 9104 9106 9110\n",
            " 9120 9125 9126 9128 9129 9163 9165 9171 9172 9175 9177 9178 9179 9180\n",
            " 9183 9188 9195 9196 9216 9218 9220 9221 9222 9223 9224 9227 9236 9238\n",
            " 9254 9258 9260 9270 9275 9276 9282 9285 9287 9296 9308 9309 9326 9331\n",
            " 9336 9340 9344 9350 9358 9364 9365 9367 9370 9372 9374 9375 9387 9388\n",
            " 9392 9398 9405 9406 9415 9417 9418 9422 9444 9451 9454 9462 9463 9465\n",
            " 9473 9477 9487 9497 9499 9500 9505 9509 9512 9514 9530 9532 9533 9535\n",
            " 9559 9562 9571 9577 9583 9584 9594 9596 9598 9605 9606 9607 9623 9631\n",
            " 9640 9644 9660 9661 9667 9671 9674 9680 9684 9688 9690 9692 9693 9695\n",
            " 9697 9703 9709 9713 9716 9724 9730 9731 9733 9742 9755 9762 9765 9766\n",
            " 9777 9779 9780 9788 9791 9803 9810 9827 9829 9841 9844 9850 9859 9861\n",
            " 9866 9867 9885 9891 9894 9901 9909 9922 9924 9925 9933 9934 9942 9952\n",
            " 9963 9976 9978 9979 9989 9999]\n",
            "\n",
            "1896 [0.5013311  0.5321198  0.5643916  0.50540155 0.5025578  0.5007135\n",
            " 0.52291733 0.50229317 0.50119203 0.50352496 0.52869874 0.50094324\n",
            " 0.50231284 0.50470066 0.53259826 0.509858   0.56403095 0.5133421\n",
            " 0.5009181  0.56316847 0.50924486 0.50106734 0.5166235  0.50074786\n",
            " 0.5012822  0.501986   0.5004746  0.56558573 0.5284014  0.50028265\n",
            " 0.50060827 0.50124097 0.558176   0.5013876  0.5056122  0.50052834\n",
            " 0.56369877 0.50022835 0.5322862  0.5051004  0.5027739  0.50688976\n",
            " 0.5033902  0.5294236  0.5005939  0.50091195 0.5029511  0.5013214\n",
            " 0.500574   0.511833   0.5034596  0.50862813 0.5034164  0.51846015\n",
            " 0.50211215 0.51240593 0.50066894 0.5061511  0.5064978  0.50242484\n",
            " 0.50024027 0.50124097 0.50124097 0.5051741  0.5073249  0.5294224\n",
            " 0.5132415  0.5372837  0.50141376 0.5015462  0.5008765  0.532419\n",
            " 0.5060627  0.5019193  0.50604427 0.5182449  0.5003652  0.5030048\n",
            " 0.502123   0.5022707  0.50170547 0.532262   0.56403095 0.5030293\n",
            " 0.5334074  0.51014394 0.5621744  0.5034278  0.5001179  0.501755\n",
            " 0.50300294 0.5035149  0.5002241  0.5087422  0.5058812  0.50669396\n",
            " 0.51930624 0.53670514 0.5500819  0.50133824 0.5011151  0.5010333\n",
            " 0.5007001  0.50599873 0.5015219  0.5069661  0.5039471  0.5028714\n",
            " 0.50059754 0.5025381  0.50092745 0.50137734 0.5152513  0.5067466\n",
            " 0.5338032  0.50222945 0.50246775 0.51242954 0.50043917 0.5015623\n",
            " 0.5036435  0.56569785 0.5025058  0.51798797 0.51785505 0.50697\n",
            " 0.5010311  0.51642996 0.50635636 0.5012353  0.53516597 0.5017076\n",
            " 0.5192768  0.50689197 0.5005774  0.5647545  0.5017076  0.50067943\n",
            " 0.50149727 0.5159107  0.5043216  0.50411296 0.5309612  0.50017625\n",
            " 0.50359875 0.5014417  0.50032747 0.50018597 0.5002602  0.50284475\n",
            " 0.50321746 0.50475395 0.5607975  0.5671298  0.5056169  0.5020453\n",
            " 0.50347275 0.5292822  0.50170135 0.50246817 0.501104   0.50798\n",
            " 0.50389034 0.5084046  0.58072776 0.5022982  0.50069547 0.5009143\n",
            " 0.52966285 0.5097844  0.5020306  0.50216216 0.5096418  0.5000343\n",
            " 0.51206887 0.5004841  0.5040186  0.50200415 0.50194836 0.5003078\n",
            " 0.50283337 0.55041414 0.5012657  0.5015415  0.50500005 0.5033086\n",
            " 0.5036775  0.50428474 0.50190014 0.52988076 0.56476694 0.56258905\n",
            " 0.50294966 0.50244653 0.5017703  0.54427826 0.50495577 0.5020556\n",
            " 0.5017635  0.5018059  0.5087097  0.5017808  0.50061023 0.5113542\n",
            " 0.5255153  0.5030103  0.50323284 0.5007795  0.50129616 0.5027955\n",
            " 0.50083625 0.50286466 0.5068699  0.500603   0.50201815 0.5022165\n",
            " 0.50430596 0.556622   0.5158973  0.5003564  0.50099915 0.50566113\n",
            " 0.5016164  0.5039857  0.5012091  0.5016459  0.50139725 0.50635636\n",
            " 0.527111   0.50203353 0.5070629  0.500386   0.50528383 0.5003231\n",
            " 0.5008908  0.5156976  0.51571846 0.5011334  0.51846594 0.5027566\n",
            " 0.50111365 0.50018656 0.5187291  0.51622134 0.508936   0.5090903\n",
            " 0.5025422  0.50208914 0.5044141  0.51617265 0.5046     0.52983665\n",
            " 0.50380933 0.5038038  0.5604905  0.5037358  0.535763   0.50873846\n",
            " 0.5015785  0.50244653 0.51247984 0.5382781  0.5025559  0.5016938\n",
            " 0.5039406  0.5031924  0.56410915 0.50229216 0.5047097  0.50340605\n",
            " 0.5038558  0.50958735 0.5039406  0.50228    0.50407344 0.5002241\n",
            " 0.5644871  0.505613   0.5105922  0.5000502  0.5010688  0.5099832\n",
            " 0.5019479  0.5139704  0.5028714  0.5013656  0.56530535 0.5054715\n",
            " 0.5213684  0.5028714  0.5034268  0.56987476 0.533325   0.5009022\n",
            " 0.5016261  0.5642384  0.5010101  0.5325215  0.50046414 0.53087234\n",
            " 0.5226731  0.563468   0.5015645  0.53223425 0.50078535 0.5152386\n",
            " 0.50147617 0.5016977  0.50238436 0.5081504  0.501072   0.5346923\n",
            " 0.5309611  0.5109421  0.5030971  0.5230128  0.5219127  0.50407344\n",
            " 0.501264   0.5042685  0.5034376  0.50219655 0.50205266 0.503602\n",
            " 0.50060093 0.50205266 0.5019045  0.50146604 0.55991775 0.53007394\n",
            " 0.50196505 0.5011284  0.50321645 0.50013757 0.5034278  0.500878\n",
            " 0.51726276 0.5014412  0.5035462  0.5025198  0.5629205  0.51835793\n",
            " 0.50888675 0.5331751  0.50240415 0.5181975  0.51272434 0.51582783\n",
            " 0.52318925 0.53246254 0.5021581  0.50135815 0.532888   0.50104845\n",
            " 0.50321645 0.52947545 0.50410223 0.50321645 0.5309666  0.50190324\n",
            " 0.51027495 0.5060126  0.50158197 0.5098718  0.50649154 0.5060019\n",
            " 0.50094604 0.5020322  0.5329657  0.5296236  0.5031022  0.51493496\n",
            " 0.5017509  0.50281805 0.500749   0.53247744 0.5004041  0.5155751\n",
            " 0.5024967  0.5022192  0.5328967  0.5129152  0.50014126 0.5030305\n",
            " 0.5214004  0.5649734  0.53238326 0.50190485 0.5020188  0.5341923\n",
            " 0.5455065  0.5077667  0.5045752  0.5010042  0.50701    0.50124776\n",
            " 0.5061484  0.50020725 0.5603832  0.5156933  0.5059516  0.52357316\n",
            " 0.5115273  0.5326746  0.5563835  0.50150776 0.5007266  0.50098526\n",
            " 0.5020831  0.51530397 0.5204674  0.5019727  0.52162653 0.5018904\n",
            " 0.5125318  0.5021038  0.50357825 0.51089674 0.5654962  0.5026581\n",
            " 0.5246842  0.510991   0.50014627 0.53400767 0.5754032  0.5029078\n",
            " 0.5023383  0.56540143 0.5011762  0.5201203  0.51085514 0.5016301\n",
            " 0.50266266 0.5015425  0.5042945  0.5000789  0.5017767  0.56613964\n",
            " 0.5015176  0.5002883  0.501146   0.56469494 0.50187606 0.5435138\n",
            " 0.5048813  0.5087858  0.50795454 0.5100099  0.5300368  0.52648646\n",
            " 0.500343   0.5604052  0.5017291  0.53180516 0.5275496  0.508939\n",
            " 0.5018309  0.5095863  0.5106475  0.5048473  0.53087246 0.5026163\n",
            " 0.5001431  0.5356661  0.5006486  0.519674   0.5015822  0.50054765\n",
            " 0.5051322  0.5046511  0.50042844 0.5317109  0.5016034  0.5194895\n",
            " 0.51188993 0.55271757 0.50028545 0.50400376 0.5178066  0.53668404\n",
            " 0.50266546 0.52278036 0.5006068  0.50228626 0.5035983  0.5317109\n",
            " 0.510867   0.5150132  0.50351554 0.51312643 0.52913916 0.5000741\n",
            " 0.50052655 0.50028515 0.50087327 0.5598569  0.50210446 0.5110808\n",
            " 0.5145814  0.50560427 0.52689683 0.51548254 0.50404346 0.50537604\n",
            " 0.50968057 0.5009202  0.5026581  0.50183046 0.50094134 0.53290015\n",
            " 0.5048179  0.50330734 0.5286972  0.5026216  0.5006322  0.5335203\n",
            " 0.50230014 0.50113803 0.5040831  0.50231034 0.5321025  0.50094134\n",
            " 0.5015528  0.50539494 0.5357315  0.5004265  0.50135714 0.5008276\n",
            " 0.5009013  0.5360915  0.5649254  0.50360966 0.5142057  0.53271043\n",
            " 0.5019476  0.5037103  0.5007692  0.50310856 0.50442535 0.50021917\n",
            " 0.5076998  0.5044273  0.50583243 0.5111981  0.52098656 0.562256\n",
            " 0.5009379  0.51859754 0.5729982  0.5000924  0.5087173  0.5463653\n",
            " 0.5244358  0.5098188  0.5066054  0.50586915 0.5281765  0.5005783\n",
            " 0.50008583 0.5131765  0.562256   0.5019279  0.51746255 0.562256\n",
            " 0.56987965 0.50328666 0.51722413 0.50040984 0.510542   0.5047425\n",
            " 0.50231457 0.5047868  0.53945154 0.5013098  0.500344   0.51055026\n",
            " 0.531755   0.53490925 0.574818   0.5024468  0.52573943 0.5019176\n",
            " 0.50139713 0.50278157 0.50828767 0.5230914  0.5360915  0.5168696\n",
            " 0.5040187  0.50649124 0.54434425 0.50724167 0.50673616 0.50246924\n",
            " 0.5059574  0.5009389  0.50036496 0.5300368  0.50795454 0.50557834\n",
            " 0.50395316 0.5013654  0.5644799  0.50539494 0.5024662  0.50490046\n",
            " 0.5035045  0.5363392  0.5354333  0.50321877 0.50124484 0.5111749\n",
            " 0.53396076 0.5054166  0.5657918  0.53160095 0.50118864 0.50378007\n",
            " 0.5048915  0.53456146 0.5093128  0.5609624  0.5031327  0.5016258\n",
            " 0.50607747 0.51393116 0.5089486  0.50029767 0.50075185 0.5111411\n",
            " 0.5027951  0.52653617 0.5018435  0.5013568  0.508256   0.5015482\n",
            " 0.5030737  0.5045512  0.50170994 0.50219065 0.50022805 0.5133352\n",
            " 0.50144845 0.5641478  0.5251159  0.50007135 0.50183046 0.5132984\n",
            " 0.50123596 0.5049334  0.5010004  0.56565386 0.5153082  0.5628037\n",
            " 0.5047064  0.5018904  0.5140767  0.53226507 0.5179221  0.50742185\n",
            " 0.500287   0.5007744  0.5035037  0.52362615 0.5000108  0.5029269\n",
            " 0.5020992  0.5172605  0.5641478  0.50517803 0.5149191  0.5004303\n",
            " 0.50530154 0.5035411  0.50139326 0.5017536  0.52785516 0.52005315\n",
            " 0.50111884 0.50053245 0.5410685  0.5012319  0.53417844 0.5237524\n",
            " 0.53301376 0.53417844 0.5054085  0.5243745  0.51253986 0.50792843\n",
            " 0.50077176 0.56363577 0.5047425  0.5051956  0.50288266 0.5592322\n",
            " 0.50230604 0.5066185  0.5580512  0.50036544 0.5752186  0.5021468\n",
            " 0.5150611  0.5000306  0.5325531  0.501283   0.51216936 0.5435138\n",
            " 0.501283   0.5054897  0.5154002  0.50540364 0.5024885  0.5296454\n",
            " 0.56865776 0.5136196  0.5132538  0.52909327 0.50113356 0.5001156\n",
            " 0.5034457  0.5187765  0.50265306 0.50048363 0.508256   0.508256\n",
            " 0.53117156 0.50221103 0.5083924  0.5628037  0.50322783 0.50257456\n",
            " 0.5043296  0.5026581  0.501877   0.53417844 0.5172427  0.51216936\n",
            " 0.50505877 0.5036063  0.5026581  0.50044876 0.554618   0.52017635\n",
            " 0.5162071  0.501319   0.562256   0.5194696  0.5021017  0.50724167\n",
            " 0.5035641  0.53647435 0.5599382  0.56279504 0.5020419  0.5013453\n",
            " 0.5649794  0.500343   0.500672   0.500343   0.50583243 0.5008564\n",
            " 0.521866   0.50185746 0.5096001  0.5006322  0.50084466 0.50183773\n",
            " 0.5030102  0.5042548  0.51658034 0.52417403 0.5209929  0.50758535\n",
            " 0.5005716  0.5005874  0.5281507  0.56356496 0.5360915  0.53193676\n",
            " 0.54169345 0.50015783 0.513115   0.501552   0.5334458  0.5151279\n",
            " 0.50214994 0.5189197  0.50062245 0.51255393 0.50175893 0.56389713\n",
            " 0.56167257 0.51744795 0.5104894  0.50499016 0.5034653  0.51849425\n",
            " 0.5005203  0.5004084  0.51403624 0.5048554  0.50493777 0.5329664\n",
            " 0.50334275 0.5175293  0.5432139  0.56167257 0.52748877 0.50661594\n",
            " 0.51439404 0.5585512  0.5636172  0.52133954 0.500403   0.56356496\n",
            " 0.56167257 0.500584   0.5008106  0.5143632  0.5450901  0.5121069\n",
            " 0.50332475 0.50146973 0.50849766 0.5282561  0.50146353 0.5001669\n",
            " 0.5450987  0.5099347  0.508939   0.50795895 0.5625052  0.5282561\n",
            " 0.5008194  0.5024355  0.50113654 0.5003505  0.53690225 0.51018184\n",
            " 0.5046741  0.517588   0.5591462  0.50007945 0.55982125 0.5159175\n",
            " 0.531719   0.5122783  0.55938506 0.5422459  0.5009603  0.50302136\n",
            " 0.51783156 0.5041265  0.5005758  0.5266576  0.5035095  0.5383329\n",
            " 0.50758547 0.5480466  0.5199338  0.50860626 0.50472933 0.5044599\n",
            " 0.5005048  0.5039756  0.50101537 0.514093   0.5036391  0.5028988\n",
            " 0.50125176 0.5142585  0.50290895 0.5159294  0.5014287  0.50080305\n",
            " 0.5113802  0.50378907 0.5275528  0.56520563 0.5178136  0.5031571\n",
            " 0.5180135  0.50053763 0.5006829  0.53590584 0.5002294  0.50716245\n",
            " 0.51664627 0.50788754 0.5054622  0.5038625  0.5244248  0.5141283\n",
            " 0.50114375 0.51798886 0.5275528  0.50043947 0.5313244  0.50146586\n",
            " 0.509469   0.5311918  0.50059474 0.50132596 0.50016135 0.5002294\n",
            " 0.504498   0.5312828  0.5275528  0.50042725 0.5170488  0.5453649\n",
            " 0.52762306 0.5205266  0.5388859  0.50346553 0.5411202  0.50299037\n",
            " 0.507073   0.5131669  0.533987   0.5279101  0.5307668  0.55084145\n",
            " 0.50088245 0.5275528  0.5014183  0.50453407 0.5186585  0.5006124\n",
            " 0.5442442  0.519304   0.5298635  0.50175506 0.5299225  0.5175584\n",
            " 0.55967706 0.53789175 0.52952015 0.50539356 0.53374505 0.5174029\n",
            " 0.5002737  0.5298635  0.5004715  0.5242726  0.5060667  0.50525725\n",
            " 0.5204311  0.501075   0.50029725 0.5723979  0.50077957 0.5271192\n",
            " 0.5113617  0.51039994 0.5627905  0.5275528  0.53615135 0.56110406\n",
            " 0.55866    0.50793374 0.5096201  0.5720327  0.50336754 0.5354489\n",
            " 0.5335355  0.50352335 0.53629017 0.5423527  0.5186081  0.51463354\n",
            " 0.5041048  0.5167346  0.52699804 0.50077957 0.5048825  0.56110406\n",
            " 0.5165319  0.53445685 0.5306657  0.5275086  0.56110406 0.52973646\n",
            " 0.5001613  0.50600886 0.50181586 0.51257354 0.5168317  0.55973303\n",
            " 0.50693506 0.51798886 0.5341416  0.5002087  0.51567453 0.5450323\n",
            " 0.5643087  0.5063947  0.51573724 0.5312376  0.5239295  0.5553002\n",
            " 0.53166133 0.5172831  0.5028194  0.5005085  0.5192418  0.5020101\n",
            " 0.5003232  0.53537786 0.51750183 0.5027087  0.50708663 0.5210099\n",
            " 0.5023674  0.5552353  0.5615844  0.5142739  0.5640242  0.50479245\n",
            " 0.52689254 0.52028215 0.57484883 0.5100821  0.55921394 0.5280389\n",
            " 0.5576548  0.5122671  0.5279949  0.5012728  0.5239295  0.5212147\n",
            " 0.50878495 0.50003576 0.54170847 0.5193041  0.54125845 0.50057626\n",
            " 0.5185466  0.5168317  0.5299076  0.5283957  0.50617754 0.5072307\n",
            " 0.5024305  0.51596326 0.5202563  0.50849026 0.5368999  0.501268\n",
            " 0.50402826 0.5016282  0.5256326  0.5753069  0.50872767 0.5615844\n",
            " 0.5168651  0.5058927  0.53098786 0.5283957  0.5208376  0.50102746\n",
            " 0.56110406 0.5002024  0.5002671  0.5028374  0.5640242  0.50444955\n",
            " 0.5037633  0.5265644  0.56354445 0.5603297  0.5015236  0.51646185\n",
            " 0.52699804 0.5005572  0.54270524 0.5000194  0.5023114  0.5060091\n",
            " 0.5018898  0.50146586 0.50078285 0.5351831  0.5077647  0.5005527\n",
            " 0.5014918  0.5013702  0.5212099  0.5034806  0.50705    0.5016563\n",
            " 0.53127253 0.51162815 0.50149983 0.5142738  0.5621323  0.53501743\n",
            " 0.50051373 0.50026286 0.50080305 0.50539356 0.5139203  0.53162986\n",
            " 0.5215042  0.50513566 0.50062567 0.53183544 0.50045264 0.5034806\n",
            " 0.50468117 0.5545833  0.5042096  0.5027193  0.5037849  0.5082229\n",
            " 0.50057626 0.506487   0.52786726 0.5041048  0.5129676  0.5202102\n",
            " 0.5028637  0.5077647  0.5053135  0.50049645 0.52748424 0.5059701\n",
            " 0.51289195 0.5059193  0.5052745  0.50133103 0.5356636  0.53665096\n",
            " 0.50818765 0.5002294  0.50074184 0.50501853 0.5065585  0.5176131\n",
            " 0.52968967 0.5340893  0.5513804  0.5130235  0.50359464 0.5566568\n",
            " 0.5107415  0.54457    0.5011623  0.55838    0.5402181  0.54364896\n",
            " 0.5071182  0.5002381  0.56682503 0.5311918  0.53700817 0.52419764\n",
            " 0.5058456  0.5512963  0.5086198  0.5097313  0.5310865  0.5311441\n",
            " 0.50113267 0.50138456 0.5015836  0.54019254 0.5170046  0.50089407\n",
            " 0.5366002  0.53374505 0.5017401  0.53093684 0.5075747  0.52660084\n",
            " 0.50427824 0.50062644 0.5197362  0.5397571  0.52211446 0.5000114\n",
            " 0.50953376 0.50088245 0.5039709  0.5033616  0.53143215 0.5615844\n",
            " 0.50491804 0.52762014 0.5021072  0.5026179  0.5353292  0.5309037\n",
            " 0.5023255  0.5139384  0.5031567  0.51760453 0.50403696 0.5271083\n",
            " 0.53379685 0.54547274 0.50091493 0.562881   0.5140663  0.5638043\n",
            " 0.52699804 0.50025415 0.50017345 0.5008708  0.5116219  0.50499517\n",
            " 0.50647926 0.5303952  0.50354844 0.5000304  0.5048446  0.5275528\n",
            " 0.5610626  0.5069971  0.50050664 0.50230235 0.5072667  0.5031601\n",
            " 0.5012673  0.50141484 0.52645993 0.5253275  0.52710897 0.5047845\n",
            " 0.5602755  0.56294596 0.512784   0.5515619  0.5012156  0.50020814\n",
            " 0.5028286  0.5711289  0.5338095  0.55838    0.5427958  0.50444686\n",
            " 0.52677226 0.5059294  0.5208271  0.50033915 0.50727266 0.5014673\n",
            " 0.53121996 0.5315858  0.5019783  0.50057626 0.5074461  0.5103687\n",
            " 0.50195336 0.50730145 0.5629647  0.52017754 0.5070653  0.5139873\n",
            " 0.5006059  0.50095356 0.56110406 0.56110406 0.53807545 0.50175506\n",
            " 0.50017345 0.5207675  0.51724195 0.5280389  0.5190856  0.5180135\n",
            " 0.53600246 0.5416727  0.5299225  0.5031718  0.51323915 0.560776\n",
            " 0.5114538  0.523043   0.5423527  0.50119954 0.5340893  0.5014183\n",
            " 0.50773126 0.5188334  0.50102514 0.5147889  0.5242403  0.5127462\n",
            " 0.50378907 0.50660396 0.5237147  0.5212102  0.50206774 0.56491315\n",
            " 0.5003144  0.50201946 0.5040812  0.53527    0.5513804  0.5615844\n",
            " 0.527098   0.51598245 0.55838    0.5014219  0.5033758  0.52003974\n",
            " 0.5012672  0.5206395  0.5621323  0.5323103  0.52504116 0.5208818\n",
            " 0.5269539  0.5000231  0.50293106 0.5214988  0.5029135  0.5082916\n",
            " 0.50427824 0.50910574 0.50118935 0.5621323  0.5041319  0.552948\n",
            " 0.5015359  0.51187533 0.50711817 0.5161946  0.5280389  0.5137137\n",
            " 0.52463114 0.50057656 0.5294919  0.5052375  0.52174026 0.50387156\n",
            " 0.5289416  0.5019783  0.50793374 0.55900574 0.5033758  0.5005085\n",
            " 0.55526453 0.50165874 0.52107847 0.5047659  0.50057626 0.50294936\n",
            " 0.558577   0.5485715  0.50777924 0.53162986 0.54341173 0.5011623\n",
            " 0.5355173  0.53537786 0.54196954 0.5174986  0.50931734 0.51710325\n",
            " 0.50901735 0.5162761  0.5629647  0.50320804 0.5634769  0.53162986\n",
            " 0.54301286 0.50076073 0.5004979  0.5004794  0.5239049  0.5266668\n",
            " 0.56343454 0.5241353  0.52238005 0.51451486 0.5080431  0.5275528\n",
            " 0.52744013 0.519617   0.50053763 0.5050551  0.50960094 0.5024055\n",
            " 0.51209146 0.50443906 0.57083154 0.5056661  0.5720327  0.50314283\n",
            " 0.5058557  0.5032349  0.5003232  0.5036187  0.5028591  0.5287417\n",
            " 0.50099975 0.50778747 0.5000691  0.54819655 0.5007858  0.5041048\n",
            " 0.52744013 0.5220838  0.5126109  0.5070577  0.5685524  0.5006303\n",
            " 0.53113407 0.55091125 0.52072334 0.501009   0.50513065 0.537729\n",
            " 0.50245357 0.5282354  0.5417746  0.5002792  0.5101732  0.5253717\n",
            " 0.5132001  0.5315858  0.51143396 0.5006637  0.5512033  0.5590834\n",
            " 0.5056689  0.50463694 0.52419764 0.5182204  0.5285056  0.55920833\n",
            " 0.5020558  0.50080305 0.53321344 0.5036171  0.52508533 0.5297581\n",
            " 0.5002792  0.55104625 0.534609   0.5019904  0.50396484 0.51044047\n",
            " 0.50020814 0.502232   0.5046489  0.5171348  0.55104625 0.5223667\n",
            " 0.5314877  0.5113593  0.5640242  0.52096575 0.52587503 0.5015458\n",
            " 0.50114834 0.5002381  0.50323087 0.5303751  0.5315011  0.5134563\n",
            " 0.5311918  0.51697415 0.50732136 0.5134727  0.54667646 0.50145715\n",
            " 0.5305898  0.5159121  0.55194646 0.5000255  0.53144926 0.53078246\n",
            " 0.54015887 0.5027804  0.5142738  0.5054631  0.5241043  0.5085144\n",
            " 0.5296578  0.5028245  0.5017034  0.5300454  0.5759232  0.5079885\n",
            " 0.5000189  0.5033907  0.5003782  0.5027563  0.52699804 0.5071943\n",
            " 0.5028093  0.5290782  0.5208289  0.5036607  0.51181895 0.5102265\n",
            " 0.5090341  0.54524946 0.56463444 0.5174471  0.5136131  0.53041786\n",
            " 0.5080431  0.50371677 0.5335657  0.5174495  0.56241703 0.50108844\n",
            " 0.5265644  0.505608   0.5368325  0.50204283 0.5280389  0.544793\n",
            " 0.52089477 0.5161946  0.5305898  0.5005274  0.51362354 0.5035576\n",
            " 0.52822185 0.53895134 0.5041653  0.5285496  0.5028107  0.53501743\n",
            " 0.50513065 0.55804694 0.5125917  0.50127685 0.5212859  0.5283957\n",
            " 0.5043236  0.56382906 0.50441796 0.562561   0.50044984 0.5006528\n",
            " 0.5088885  0.52699804 0.5116028  0.5344814  0.5208593  0.5055515\n",
            " 0.54098433 0.5624846  0.5180785  0.5005369  0.50083566 0.5033863\n",
            " 0.5183983  0.50394166 0.52607805 0.51743317 0.5013702  0.5618532\n",
            " 0.5008138  0.5014515  0.5166089  0.53376544 0.56354445 0.517168\n",
            " 0.50083566 0.5056149  0.5153219  0.5015081  0.5313776  0.55955005\n",
            " 0.5033758  0.50473416 0.516468   0.5171899  0.5005076  0.5074892\n",
            " 0.53050035 0.5416727  0.50076324 0.53190166 0.50391424 0.5002467\n",
            " 0.50024635 0.57383686 0.5139058  0.50138247 0.5014619  0.5624846\n",
            " 0.50388604 0.50192344 0.5031718  0.5075906  0.50516886 0.50671643\n",
            " 0.5015081  0.5273913  0.5018721  0.51785284 0.5148297  0.50019926\n",
            " 0.5014183  0.5621913  0.5275528  0.5104847  0.5007771  0.5640242\n",
            " 0.5034806  0.5002467  0.550652   0.50569564 0.5039622  0.56165206\n",
            " 0.50044477 0.5279949  0.50111806 0.5059765  0.53534466 0.52398914\n",
            " 0.56165206 0.50359994 0.50021255 0.55852646 0.5048207  0.5227104\n",
            " 0.5155718  0.55221695 0.5169461  0.52710897 0.5167983  0.5048825\n",
            " 0.52127457 0.5072275  0.5173068  0.5108487  0.5022039  0.5050259\n",
            " 0.5284044  0.50985026 0.5042096  0.5030961  0.5043698  0.5197026\n",
            " 0.5035084  0.5004559  0.50401914 0.5143815  0.5110774  0.5133752\n",
            " 0.5000245  0.5092978  0.5282669  0.5011623  0.5130205  0.50190914\n",
            " 0.5450099  0.51378185 0.51785284 0.56354445 0.5269718  0.5042096\n",
            " 0.5107738  0.500925   0.5374432  0.5275528  0.5006847  0.5198271\n",
            " 0.53493094 0.51384056 0.51708    0.542157   0.51664764 0.5467472\n",
            " 0.5034806  0.5513804  0.52047515 0.5075669  0.5634769  0.51954675\n",
            " 0.5059701  0.5041267  0.5288818  0.5009434  0.5005011  0.51798886\n",
            " 0.5044845  0.5590143  0.5167833  0.5144492  0.51601624 0.5340893\n",
            " 0.5041653  0.50881433 0.5278775  0.51212347 0.50326204 0.5059135\n",
            " 0.5051246  0.5070495  0.52398914 0.5022201  0.5280389  0.503607\n",
            " 0.50963163 0.55286574 0.5209053  0.5556933  0.51543564 0.50172114\n",
            " 0.50681543 0.50128245 0.51629305 0.5026213  0.5081842  0.50140727\n",
            " 0.51250327 0.50615036 0.5160074  0.5077647  0.52748424 0.526338\n",
            " 0.5216972  0.50032604 0.5171174  0.5152055  0.5313881  0.5173241\n",
            " 0.5275086  0.50049454 0.53098786 0.5619169  0.52843255 0.50126594\n",
            " 0.5450538  0.50175506 0.50045687 0.51995915 0.54185545 0.51637125\n",
            " 0.53053224 0.5019971  0.50312203 0.5107415  0.504394   0.50083554\n",
            " 0.5005315  0.5084524  0.5189065  0.5640242  0.5058014  0.52863455\n",
            " 0.50604266 0.50008535 0.5104686  0.5016657  0.5416045  0.53126025\n",
            " 0.5002068  0.5002043  0.50322163 0.54892135 0.5033758  0.5152142\n",
            " 0.5100676  0.5224728  0.51488024 0.57138413 0.51487774 0.50716245\n",
            " 0.50290924 0.5629647  0.5011692  0.5250006  0.50089556 0.5602755\n",
            " 0.5231416  0.50036836 0.50771666 0.509384   0.52450514 0.5621323\n",
            " 0.5621323  0.51047593 0.56382906 0.50225294 0.5084082  0.50082684\n",
            " 0.50620675 0.5005796  0.5199613  0.5150656  0.500401   0.5033836\n",
            " 0.5165071  0.5054167  0.5005061  0.5146747  0.50500244 0.50138324\n",
            " 0.5094953  0.5615844  0.5005843  0.5037633  0.5071943  0.50141275\n",
            " 0.5024245  0.5088885  0.50050324 0.50392795 0.558577   0.53343123\n",
            " 0.53125155 0.51230776 0.5146584  0.5713432  0.5003906  0.5167069\n",
            " 0.5012996  0.50111806 0.5053082  0.5015223  0.50169593 0.5012715\n",
            " 0.5035155  0.56990695 0.5640242  0.50139093 0.540246   0.5327224\n",
            " 0.5507239  0.5648558  0.5467663  0.500834   0.50034785 0.51098955\n",
            " 0.50032604 0.50211257 0.5205708  0.50175506 0.50537956 0.5208376\n",
            " 0.5030634  0.50206774 0.5640242  0.5003144  0.5040725  0.52260613\n",
            " 0.52699804 0.508156   0.5143815  0.50053763 0.50744903 0.51760453\n",
            " 0.52278733 0.50652647 0.5313235  0.50287384 0.5003144  0.5179693\n",
            " 0.5189833  0.5558439  0.5209065  0.5007903  0.50088245 0.55791974\n",
            " 0.51906973 0.5265644  0.51012915 0.56354445 0.50203705 0.51760453\n",
            " 0.52137077 0.53183323 0.5367059  0.50534934 0.5035437  0.54583997\n",
            " 0.5142739  0.5316527  0.512784   0.51268005 0.54648983 0.50250673\n",
            " 0.51683354 0.5092703  0.50354844 0.5014183  0.50050664 0.5036295\n",
            " 0.5465106  0.5225605  0.50580406 0.5017034  0.5369896  0.5117082 ]\n",
            "\n",
            "Matched draws\n",
            "Count: 54, Index: (array([  70,  392,  402,  699,  721,  801, 1070, 1228, 1284, 1467, 1551,\n",
            "       1789, 1884, 2030, 2145, 2274, 2311, 2315, 2445, 2517, 2674, 2809,\n",
            "       3145, 3348, 3400, 3595, 3615, 3692, 4116, 4152, 4185, 4398, 4457,\n",
            "       4823, 5012, 5744, 5794, 6077, 6439, 6652, 6684, 6880, 6896, 7134,\n",
            "       7528, 7586, 7635, 7747, 7916, 8036, 8382, 9398, 9688, 9859]),)\n",
            "\n",
            "\n",
            "Top 23 Possibility\n",
            "        DrawNo   DrawDate   PrizeType  LuckyNo\n",
            "107336  507420 2020-02-12  SpecialNo5     4185\n",
            "\n",
            "\n",
            "First 23 Numbers\n",
            "        DrawNo   DrawDate        PrizeType  LuckyNo\n",
            "107184  506820 2020-02-01  ConsolationNo10       70\n",
            "\n",
            "\n",
            "2 To 3 Digits Numbers\n",
            "        DrawNo   DrawDate        PrizeType  LuckyNo\n",
            "107184  506820 2020-02-01  ConsolationNo10       70\n",
            "107190  506820 2020-02-01   ConsolationNo7      699\n",
            "107191  506820 2020-02-01   ConsolationNo8      801\n",
            "107349  507520 2020-02-15   ConsolationNo5      402\n",
            "107356  507520 2020-02-15       SpecialNo2      392\n",
            "107358  507520 2020-02-15       SpecialNo4      721\n",
            "\n",
            "\n",
            "All matched\n",
            "        DrawNo   DrawDate        PrizeType  LuckyNo\n",
            "107183  506820 2020-02-01   ConsolationNo1     3145\n",
            "107184  506820 2020-02-01  ConsolationNo10       70\n",
            "107187  506820 2020-02-01   ConsolationNo4     1789\n",
            "107189  506820 2020-02-01   ConsolationNo6     9398\n",
            "107190  506820 2020-02-01   ConsolationNo7      699\n",
            "107191  506820 2020-02-01   ConsolationNo8      801\n",
            "107199  506820 2020-02-01       SpecialNo6     2030\n",
            "107207  506920 2020-02-02  ConsolationNo10     8382\n",
            "107211  506920 2020-02-02   ConsolationNo5     4398\n",
            "107216  506920 2020-02-02       SpecialNo1     1467\n",
            "107219  506920 2020-02-02       SpecialNo3     2311\n",
            "107223  506920 2020-02-02       SpecialNo7     1284\n",
            "107236  507020 2020-02-04   ConsolationNo7     7528\n",
            "107238  507020 2020-02-04   ConsolationNo9     6077\n",
            "107243  507020 2020-02-04       SpecialNo4     1884\n",
            "107251  507120 2020-02-05       3rdPrizeNo     7635\n",
            "107253  507120 2020-02-05  ConsolationNo10     2809\n",
            "107266  507120 2020-02-05       SpecialNo4     2315\n",
            "107269  507120 2020-02-05       SpecialNo7     3595\n",
            "107277  507220 2020-02-08   ConsolationNo2     7916\n",
            "107282  507220 2020-02-08   ConsolationNo7     4823\n",
            "107286  507220 2020-02-08      SpecialNo10     1551\n",
            "107289  507220 2020-02-08       SpecialNo4     4116\n",
            "107305  507320 2020-02-09   ConsolationNo7     9859\n",
            "107312  507320 2020-02-09       SpecialNo4     3692\n",
            "107321  507420 2020-02-12   ConsolationNo1     3348\n",
            "107336  507420 2020-02-12       SpecialNo5     4185\n",
            "107339  507420 2020-02-12       SpecialNo8     4152\n",
            "107349  507520 2020-02-15   ConsolationNo5      402\n",
            "107350  507520 2020-02-15   ConsolationNo6     5012\n",
            "107353  507520 2020-02-15   ConsolationNo9     3348\n",
            "107356  507520 2020-02-15       SpecialNo2      392\n",
            "107358  507520 2020-02-15       SpecialNo4      721\n",
            "107360  507520 2020-02-15       SpecialNo6     8036\n",
            "107365  507620 2020-02-16       2ndPrizeNo     1228\n",
            "107385  507620 2020-02-16       SpecialNo8     3400\n",
            "107387  507720 2020-02-19       1stPrizeNo     2274\n",
            "107396  507720 2020-02-19   ConsolationNo6     2517\n",
            "107397  507720 2020-02-19   ConsolationNo7     3615\n",
            "107399  507720 2020-02-19   ConsolationNo9     6684\n",
            "107400  507720 2020-02-19       SpecialNo1     2445\n",
            "107402  507720 2020-02-19       SpecialNo2     2145\n",
            "107409  507720 2020-02-19       SpecialNo9     7747\n",
            "107412  507820 2020-02-22       3rdPrizeNo     6880\n",
            "107418  507820 2020-02-22   ConsolationNo5     9688\n",
            "107420  507820 2020-02-22   ConsolationNo7     6652\n",
            "107423  507820 2020-02-22       SpecialNo1     6896\n",
            "107426  507820 2020-02-22       SpecialNo3     2674\n",
            "107442  507920 2020-02-23   ConsolationNo6     5744\n",
            "107443  507920 2020-02-23   ConsolationNo7     7586\n",
            "107447  507920 2020-02-23      SpecialNo10     4457\n",
            "107449  507920 2020-02-23       SpecialNo3     5794\n",
            "107475  508020 2020-02-26       SpecialNo6     6439\n",
            "107483  508120 2020-02-29  ConsolationNo10     1070\n",
            "107498  508120 2020-02-29       SpecialNo6     7134\n",
            "CPU times: user 40min 31s, sys: 1.82 s, total: 40min 33s\n",
            "Wall time: 10min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVy0yRaIIOIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classification metrics optimization?\n",
        "\n",
        "# Grid search for Xgboost?\n",
        "\n",
        "# Mean encoding?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y22VT9u7xR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}